2021-11-04 01:42:49 CARME Slurm ID: 31649
2021-11-04 01:42:49 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=0, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 01:42:49 CARME Slurm ID: 31649
2021-11-04 01:42:49 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=1, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 01:42:49 CARME Slurm ID: 31649
2021-11-04 01:42:49 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=2, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 01:42:56 => loading baseline model '_fgpm_pretrained_best.resnet50.2018-07-16-4310/small_model_all_conv_1e-06.pth.tar'
2021-11-04 01:42:56 => loading baseline model '_fgpm_pretrained_best.resnet50.2018-07-16-4310/small_model_all_conv_1e-06.pth.tar'
2021-11-04 01:42:56 => loading baseline model '_fgpm_pretrained_best.resnet50.2018-07-16-4310/small_model_all_conv_1e-06.pth.tar'
2021-11-04 01:42:56 => loaded baseline model '_fgpm_pretrained_best.resnet50.2018-07-16-4310/small_model_all_conv_1e-06.pth.tar'
2021-11-04 01:42:56 => loaded baseline model '_fgpm_pretrained_best.resnet50.2018-07-16-4310/small_model_all_conv_1e-06.pth.tar'
2021-11-04 01:42:56 => loaded baseline model '_fgpm_pretrained_best.resnet50.2018-07-16-4310/small_model_all_conv_1e-06.pth.tar'
2021-11-04 01:43:04 Computational complexity:       2.02 GMac
2021-11-04 01:43:04 Computational complexity:       2.02 GMac
2021-11-04 01:43:04 Computational complexity:       2.02 GMac
2021-11-04 01:43:04 Number of parameters:           13.35 M 
2021-11-04 01:43:04 Number of parameters:           13.35 M 
2021-11-04 01:43:04 Number of parameters:           13.35 M 
2021-11-04 01:43:21 valid 0000, loss 6.437e-01, top1 88.24, top5 95.29
2021-11-04 01:43:22 valid 0000, loss 6.437e-01, top1 88.24, top5 95.29
2021-11-04 01:43:22 valid 0000, loss 6.437e-01, top1 88.24, top5 95.29
2021-11-04 01:47:44 (JOBID 31649) epoch -1: valid_top1 69.59, valid_top5 89.52, inference time 275.75
2021-11-04 01:47:48 (JOBID 31649) epoch -1: valid_top1 69.59, valid_top5 89.52, inference time 279.07
2021-11-04 01:47:49 (JOBID 31649) epoch -1: valid_top1 69.59, valid_top5 89.52, inference time 279.73
2021-11-04 01:48:07 train 0000, loss 7.761e-01, top1 82.35, top5 94.12
2021-11-04 01:48:07 train 0000, loss 6.772e-01, top1 80.00, top5 92.94
2021-11-04 01:48:07 train 0000, loss 9.533e-01, top1 80.00, top5 90.59
2021-11-04 02:02:14 train 1000, loss 3.288e+00, top1 31.74, top5 56.50
2021-11-04 02:02:14 train 1000, loss 3.282e+00, top1 31.93, top5 56.65
2021-11-04 02:02:14 train 1000, loss 3.274e+00, top1 32.16, top5 56.89
2021-11-04 02:16:23 train 2000, loss 2.959e+00, top1 37.21, top5 62.30
2021-11-04 02:16:23 train 2000, loss 2.958e+00, top1 37.13, top5 62.35
2021-11-04 02:16:23 train 2000, loss 2.950e+00, top1 37.30, top5 62.54
2021-11-04 02:30:33 train 3000, loss 2.796e+00, top1 39.94, top5 65.03
2021-11-04 02:30:33 train 3000, loss 2.797e+00, top1 39.77, top5 65.13
2021-11-04 02:30:33 train 3000, loss 2.789e+00, top1 40.03, top5 65.31
2021-11-04 02:44:47 train 4000, loss 2.695e+00, top1 41.70, top5 66.75
2021-11-04 02:44:47 train 4000, loss 2.695e+00, top1 41.58, top5 66.84
2021-11-04 02:44:47 train 4000, loss 2.690e+00, top1 41.72, top5 66.95
2021-11-04 02:58:56 train 5000, loss 2.628e+00, top1 42.82, top5 67.89
2021-11-04 02:58:56 train 5000, loss 2.624e+00, top1 42.86, top5 68.00
2021-11-04 02:58:56 train 5000, loss 2.621e+00, top1 42.91, top5 68.11
2021-11-04 02:59:29 valid 0000, loss 1.216e+00, top1 76.47, top5 84.71
2021-11-04 02:59:29 valid 0000, loss 1.216e+00, top1 76.47, top5 84.71
2021-11-04 02:59:29 valid 0000, loss 1.216e+00, top1 76.47, top5 84.71
2021-11-04 03:04:11 (JOBID 31649) epoch 0: train time 4290.58, inference time 291.89s, valid_top1 50.65 (best_top1 50.65), valid_top5 76.99
2021-11-04 03:04:13 (JOBID 31649) epoch 0: train time 4291.25, inference time 293.55s, valid_top1 50.65 (best_top1 50.65), valid_top5 76.99
2021-11-04 03:04:15 (JOBID 31649) epoch 0: train time 4294.79, inference time 294.51s, valid_top1 50.65 (best_top1 50.65), valid_top5 76.99
2021-11-04 03:04:26 train 0000, loss 2.506e+00, top1 45.88, top5 69.41
2021-11-04 03:04:26 train 0000, loss 1.882e+00, top1 58.82, top5 84.71
2021-11-04 03:04:29 train 0000, loss 2.099e+00, top1 55.29, top5 70.59
2021-11-04 03:18:41 train 1000, loss 2.266e+00, top1 49.06, top5 73.82
2021-11-04 03:18:41 train 1000, loss 2.282e+00, top1 48.87, top5 73.65
2021-11-04 03:18:42 train 1000, loss 2.279e+00, top1 48.97, top5 73.74
2021-11-04 03:32:56 train 2000, loss 2.275e+00, top1 48.96, top5 73.70
2021-11-04 03:32:56 train 2000, loss 2.279e+00, top1 48.97, top5 73.74
2021-11-04 03:32:56 train 2000, loss 2.281e+00, top1 48.91, top5 73.72
2021-11-04 03:47:04 train 3000, loss 2.280e+00, top1 48.85, top5 73.69
2021-11-04 03:47:04 train 3000, loss 2.277e+00, top1 49.05, top5 73.70
2021-11-04 03:47:04 train 3000, loss 2.276e+00, top1 48.95, top5 73.80
2021-11-04 04:01:12 train 4000, loss 2.275e+00, top1 49.00, top5 73.78
2021-11-04 04:01:12 train 4000, loss 2.275e+00, top1 49.09, top5 73.71
2021-11-04 04:01:12 train 4000, loss 2.272e+00, top1 49.08, top5 73.89
2021-11-04 04:15:25 train 5000, loss 2.272e+00, top1 49.09, top5 73.80
2021-11-04 04:15:25 train 5000, loss 2.272e+00, top1 49.16, top5 73.76
2021-11-04 04:15:25 train 5000, loss 2.271e+00, top1 49.13, top5 73.91
2021-11-04 04:15:55 valid 0000, loss 1.425e+00, top1 75.29, top5 84.71
2021-11-04 04:15:55 valid 0000, loss 1.425e+00, top1 75.29, top5 84.71
2021-11-04 04:15:55 valid 0000, loss 1.425e+00, top1 75.29, top5 84.71
2021-11-04 04:20:18 (JOBID 31649) epoch 1: train time 4292.87, inference time 272.58s, valid_top1 51.11 (best_top1 51.11), valid_top5 77.06
2021-11-04 04:20:22 (JOBID 31649) epoch 1: train time 4294.17, inference time 276.61s, valid_top1 51.11 (best_top1 51.11), valid_top5 77.06
2021-11-04 04:20:30 (JOBID 31649) epoch 1: train time 4290.73, inference time 283.80s, valid_top1 51.11 (best_top1 51.11), valid_top5 77.06
2021-11-04 04:20:33 train 0000, loss 2.504e+00, top1 43.53, top5 70.59
2021-11-04 04:20:36 train 0000, loss 1.952e+00, top1 54.12, top5 78.82
2021-11-04 04:20:44 train 0000, loss 2.273e+00, top1 51.76, top5 71.76
2021-11-04 04:34:50 train 1000, loss 2.203e+00, top1 50.41, top5 74.89
2021-11-04 04:34:50 train 1000, loss 2.241e+00, top1 49.68, top5 74.31
2021-11-04 04:34:50 train 1000, loss 2.219e+00, top1 50.16, top5 74.52
2021-11-04 04:48:58 train 2000, loss 2.217e+00, top1 50.13, top5 74.73
2021-11-04 04:48:58 train 2000, loss 2.234e+00, top1 49.82, top5 74.39
2021-11-04 04:48:59 train 2000, loss 2.231e+00, top1 49.95, top5 74.36
2021-11-04 05:03:08 train 3000, loss 2.236e+00, top1 49.88, top5 74.39
2021-11-04 05:03:08 train 3000, loss 2.236e+00, top1 49.85, top5 74.34
2021-11-04 05:03:08 train 3000, loss 2.226e+00, top1 49.94, top5 74.59
2021-11-04 05:17:12 train 4000, loss 2.240e+00, top1 49.74, top5 74.27
2021-11-04 05:17:12 train 4000, loss 2.237e+00, top1 49.88, top5 74.35
2021-11-04 05:17:12 train 4000, loss 2.232e+00, top1 49.89, top5 74.46
2021-11-04 05:31:17 train 5000, loss 2.239e+00, top1 49.74, top5 74.28
2021-11-04 05:31:17 train 5000, loss 2.238e+00, top1 49.83, top5 74.35
2021-11-04 05:31:17 train 5000, loss 2.232e+00, top1 49.86, top5 74.46
2021-11-04 05:31:48 valid 0000, loss 1.537e+00, top1 69.41, top5 78.82
2021-11-04 05:31:48 valid 0000, loss 1.537e+00, top1 69.41, top5 78.82
2021-11-04 05:31:48 valid 0000, loss 1.537e+00, top1 69.41, top5 78.82
2021-11-04 05:36:09 (JOBID 31649) epoch 2: train time 4268.36, inference time 270.78s, valid_top1 51.87 (best_top1 51.87), valid_top5 77.66
2021-11-04 05:36:19 (JOBID 31649) epoch 2: train time 4280.23, inference time 280.40s, valid_top1 51.87 (best_top1 51.87), valid_top5 77.66
2021-11-04 05:36:19 (JOBID 31649) epoch 2: train time 4276.16, inference time 280.71s, valid_top1 51.87 (best_top1 51.87), valid_top5 77.66
2021-11-04 05:36:23 train 0000, loss 2.362e+00, top1 50.59, top5 74.12
2021-11-04 05:36:32 train 0000, loss 2.040e+00, top1 54.12, top5 78.82
2021-11-04 05:36:32 train 0000, loss 2.115e+00, top1 51.76, top5 72.94
2021-11-04 05:50:40 train 1000, loss 2.207e+00, top1 50.08, top5 74.82
2021-11-04 05:50:40 train 1000, loss 2.199e+00, top1 50.66, top5 74.89
2021-11-04 05:50:40 train 1000, loss 2.208e+00, top1 50.17, top5 74.94
2021-11-04 06:04:44 train 2000, loss 2.210e+00, top1 50.32, top5 74.72
2021-11-04 06:04:44 train 2000, loss 2.220e+00, top1 49.99, top5 74.58
2021-11-04 06:04:44 train 2000, loss 2.211e+00, top1 50.27, top5 74.83
2021-11-04 06:18:51 train 3000, loss 2.223e+00, top1 49.97, top5 74.56
2021-11-04 06:18:51 train 3000, loss 2.219e+00, top1 50.18, top5 74.56
2021-11-04 06:18:51 train 3000, loss 2.220e+00, top1 50.14, top5 74.67
2021-11-04 06:32:59 train 4000, loss 2.222e+00, top1 50.04, top5 74.56
2021-11-04 06:32:59 train 4000, loss 2.222e+00, top1 50.10, top5 74.51
2021-11-04 06:32:59 train 4000, loss 2.223e+00, top1 50.12, top5 74.64
2021-11-04 06:47:09 train 5000, loss 2.224e+00, top1 50.07, top5 74.51
2021-11-04 06:47:09 train 5000, loss 2.225e+00, top1 50.06, top5 74.51
2021-11-04 06:47:09 train 5000, loss 2.225e+00, top1 50.08, top5 74.58
2021-11-04 06:47:40 valid 0000, loss 7.968e-01, top1 80.00, top5 94.12
2021-11-04 06:47:40 valid 0000, loss 7.968e-01, top1 80.00, top5 94.12
2021-11-04 06:47:40 valid 0000, loss 7.968e-01, top1 80.00, top5 94.12
2021-11-04 06:52:23 (JOBID 31649) epoch 3: train time 4271.13, inference time 292.75s, valid_top1 52.22 (best_top1 52.22), valid_top5 78.43
2021-11-04 06:52:23 (JOBID 31649) epoch 3: train time 4280.36, inference time 293.07s, valid_top1 52.22 (best_top1 52.22), valid_top5 78.43
2021-11-04 06:52:23 (JOBID 31649) epoch 3: train time 4270.86, inference time 293.71s, valid_top1 52.22 (best_top1 52.22), valid_top5 78.43
2021-11-04 06:52:37 train 0000, loss 1.761e+00, top1 51.76, top5 83.53
2021-11-04 06:52:37 train 0000, loss 2.655e+00, top1 44.71, top5 67.06
2021-11-04 06:52:37 train 0000, loss 2.415e+00, top1 47.06, top5 77.65
2021-11-04 07:06:42 train 1000, loss 2.201e+00, top1 50.42, top5 74.93
2021-11-04 07:06:42 train 1000, loss 2.201e+00, top1 50.50, top5 74.85
2021-11-04 07:06:42 train 1000, loss 2.197e+00, top1 50.56, top5 75.07
2021-11-04 07:20:48 train 2000, loss 2.215e+00, top1 50.21, top5 74.72
2021-11-04 07:20:48 train 2000, loss 2.209e+00, top1 50.34, top5 74.69
2021-11-04 07:20:48 train 2000, loss 2.209e+00, top1 50.32, top5 74.74
2021-11-04 07:34:52 train 3000, loss 2.215e+00, top1 50.27, top5 74.67
2021-11-04 07:34:52 train 3000, loss 2.215e+00, top1 50.29, top5 74.62
2021-11-04 07:34:52 train 3000, loss 2.216e+00, top1 50.23, top5 74.70
2021-11-04 07:48:58 train 4000, loss 2.218e+00, top1 50.19, top5 74.65
2021-11-04 07:48:58 train 4000, loss 2.219e+00, top1 50.17, top5 74.57
2021-11-04 07:48:59 train 4000, loss 2.221e+00, top1 50.16, top5 74.62
2021-11-04 08:03:01 train 5000, loss 2.225e+00, top1 50.09, top5 74.56
2021-11-04 08:03:01 train 5000, loss 2.222e+00, top1 50.11, top5 74.55
2021-11-04 08:03:01 train 5000, loss 2.225e+00, top1 50.09, top5 74.57
2021-11-04 08:03:31 valid 0000, loss 1.042e+00, top1 81.18, top5 88.24
2021-11-04 08:03:31 valid 0000, loss 1.042e+00, top1 81.18, top5 88.24
2021-11-04 08:03:31 valid 0000, loss 1.042e+00, top1 81.18, top5 88.24
2021-11-04 08:08:25 (JOBID 31649) epoch 4: train time 4258.07, inference time 303.08s, valid_top1 52.54 (best_top1 52.54), valid_top5 78.04
2021-11-04 08:08:25 (JOBID 31649) epoch 4: train time 4258.71, inference time 304.08s, valid_top1 52.54 (best_top1 52.54), valid_top5 78.04
2021-11-04 08:08:28 (JOBID 31649) epoch 4: train time 4258.11, inference time 306.99s, valid_top1 52.54 (best_top1 52.54), valid_top5 78.04
2021-11-04 08:08:40 train 0000, loss 2.306e+00, top1 43.53, top5 65.88
2021-11-04 08:08:40 train 0000, loss 1.901e+00, top1 61.18, top5 81.18
2021-11-04 08:08:43 train 0000, loss 2.583e+00, top1 44.71, top5 69.41
2021-11-04 08:44:45 CARME Slurm ID: 31649
2021-11-04 08:44:45 CARME Slurm ID: 31649
2021-11-04 08:44:45 CARME Slurm ID: 31649
2021-11-04 08:44:45 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=0, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 08:44:45 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=2, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 08:44:45 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=1, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 08:44:58 Computational complexity:       2.02 GMac
2021-11-04 08:44:58 Number of parameters:           13.35 M 
2021-11-04 08:44:58 => loading checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243'
2021-11-04 08:44:58 Computational complexity:       2.02 GMac
2021-11-04 08:44:58 Number of parameters:           13.35 M 
2021-11-04 08:44:58 => loading checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243'
2021-11-04 08:44:58 Computational complexity:       2.02 GMac
2021-11-04 08:44:58 Number of parameters:           13.35 M 
2021-11-04 08:44:58 => loading checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243'
2021-11-04 08:44:58 => loaded checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243' (epoch 5)
2021-11-04 08:44:58 => loaded checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243' (epoch 5)
2021-11-04 08:44:58 => loaded checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243' (epoch 5)
2021-11-04 08:45:17 valid 0000, loss 1.042e+00, top1 81.18, top5 88.24
2021-11-04 08:45:17 valid 0000, loss 1.042e+00, top1 81.18, top5 88.24
2021-11-04 08:45:17 valid 0000, loss 1.042e+00, top1 81.18, top5 88.24
2021-11-04 08:49:20 (JOBID 31649) epoch -1: valid_top1 52.54, valid_top5 78.04, inference time 255.93
2021-11-04 08:50:00 (JOBID 31649) epoch -1: valid_top1 52.54, valid_top5 78.04, inference time 296.64
2021-11-04 08:50:03 (JOBID 31649) epoch -1: valid_top1 52.54, valid_top5 78.04, inference time 298.94
2021-11-04 08:50:21 train 0000, loss 1.948e+00, top1 57.65, top5 83.53
2021-11-04 08:50:21 train 0000, loss 2.473e+00, top1 47.06, top5 65.88
2021-11-04 08:50:21 train 0000, loss 2.111e+00, top1 45.88, top5 74.12
2021-11-04 09:04:51 train 1000, loss 2.191e+00, top1 50.56, top5 75.07
2021-11-04 09:04:51 train 1000, loss 2.196e+00, top1 50.56, top5 75.00
2021-11-04 09:04:51 train 1000, loss 2.184e+00, top1 50.85, top5 75.24
2021-11-04 09:19:19 train 2000, loss 2.206e+00, top1 50.35, top5 74.85
2021-11-04 09:19:19 train 2000, loss 2.207e+00, top1 50.39, top5 74.84
2021-11-04 09:19:19 train 2000, loss 2.195e+00, top1 50.65, top5 75.02
2021-11-04 09:33:36 train 3000, loss 2.212e+00, top1 50.28, top5 74.78
2021-11-04 09:33:36 train 3000, loss 2.212e+00, top1 50.33, top5 74.75
2021-11-04 09:33:36 train 3000, loss 2.206e+00, top1 50.43, top5 74.89
2021-11-04 09:48:00 train 4000, loss 2.223e+00, top1 50.13, top5 74.61
2021-11-04 09:48:00 train 4000, loss 2.219e+00, top1 50.16, top5 74.62
2021-11-04 09:48:01 train 4000, loss 2.213e+00, top1 50.30, top5 74.74
2021-11-04 10:02:21 train 5000, loss 2.222e+00, top1 50.09, top5 74.59
2021-11-04 10:02:21 train 5000, loss 2.223e+00, top1 50.12, top5 74.59
2021-11-04 10:02:21 train 5000, loss 2.218e+00, top1 50.18, top5 74.68
2021-11-04 10:02:54 valid 0000, loss 1.210e+00, top1 78.82, top5 83.53
2021-11-04 10:02:55 valid 0000, loss 1.210e+00, top1 78.82, top5 83.53
2021-11-04 10:02:55 valid 0000, loss 1.210e+00, top1 78.82, top5 83.53
2021-11-04 10:07:23 (JOBID 31649) epoch 5: train time 4404.76, inference time 278.73s, valid_top1 52.66 (best_top1 52.66), valid_top5 78.67
2021-11-04 10:07:30 (JOBID 31649) epoch 5: train time 4364.05, inference time 284.82s, valid_top1 52.66 (best_top1 52.66), valid_top5 78.67
2021-11-04 10:07:33 (JOBID 31649) epoch 5: train time 4361.76, inference time 289.03s, valid_top1 52.66 (best_top1 52.66), valid_top5 78.67
2021-11-04 10:07:44 train 0000, loss 1.946e+00, top1 51.76, top5 74.12
2021-11-04 10:07:38 train 0000, loss 2.907e+00, top1 36.47, top5 61.18
2021-11-04 10:07:47 train 0000, loss 2.474e+00, top1 49.41, top5 70.59
2021-11-04 10:22:02 train 1000, loss 2.209e+00, top1 50.35, top5 74.74
2021-11-04 10:22:02 train 1000, loss 2.189e+00, top1 50.90, top5 75.19
2021-11-04 10:22:02 train 1000, loss 2.206e+00, top1 50.51, top5 74.80
2021-11-04 10:36:16 train 2000, loss 2.207e+00, top1 50.53, top5 74.94
2021-11-04 10:36:16 train 2000, loss 2.218e+00, top1 50.13, top5 74.66
2021-11-04 10:36:16 train 2000, loss 2.205e+00, top1 50.31, top5 74.84
2021-11-04 10:50:34 train 3000, loss 2.219e+00, top1 50.15, top5 74.67
2021-11-04 10:50:34 train 3000, loss 2.213e+00, top1 50.35, top5 74.81
2021-11-04 10:50:34 train 3000, loss 2.210e+00, top1 50.24, top5 74.83
2021-11-04 11:35:28 CARME Slurm ID: 31649
2021-11-04 11:35:28 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=2, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 11:35:28 CARME Slurm ID: 31649
2021-11-04 11:35:28 CARME Slurm ID: 31649
2021-11-04 11:35:28 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=0, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 11:35:28 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=1, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 11:35:42 Computational complexity:       2.02 GMac
2021-11-04 11:35:42 Number of parameters:           13.35 M 
2021-11-04 11:35:42 Computational complexity:       2.02 GMac
2021-11-04 11:35:42 Number of parameters:           13.35 M 
2021-11-04 11:35:42 => loading checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243'
2021-11-04 11:35:42 => loading checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243'
2021-11-04 11:35:42 Computational complexity:       2.02 GMac
2021-11-04 11:35:42 Number of parameters:           13.35 M 
2021-11-04 11:35:42 => loading checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243'
2021-11-04 11:35:42 => loaded checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243' (epoch 6)
2021-11-04 11:35:42 => loaded checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243' (epoch 6)
2021-11-04 11:35:42 => loaded checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243' (epoch 6)
2021-11-04 11:36:09 train 0000, loss 2.935e+00, top1 36.47, top5 61.18
2021-11-04 11:36:09 train 0000, loss 1.935e+00, top1 52.94, top5 77.65
2021-11-04 11:36:10 train 0000, loss 2.339e+00, top1 52.94, top5 70.59
2021-11-04 11:50:07 train 1000, loss 2.205e+00, top1 50.47, top5 74.79
2021-11-04 11:50:07 train 1000, loss 2.197e+00, top1 50.68, top5 74.87
2021-11-04 11:50:07 train 1000, loss 2.212e+00, top1 50.55, top5 74.81
2021-11-04 12:04:03 train 2000, loss 2.214e+00, top1 50.22, top5 74.63
2021-11-04 12:04:03 train 2000, loss 2.215e+00, top1 50.24, top5 74.68
2021-11-04 12:04:03 train 2000, loss 2.202e+00, top1 50.52, top5 74.92
2021-11-04 12:18:06 train 3000, loss 2.216e+00, top1 50.24, top5 74.61
2021-11-04 12:18:06 train 3000, loss 2.220e+00, top1 50.17, top5 74.63
2021-11-04 12:18:06 train 3000, loss 2.211e+00, top1 50.31, top5 74.81
2021-11-04 12:32:12 train 4000, loss 2.220e+00, top1 50.21, top5 74.59
2021-11-04 12:32:12 train 4000, loss 2.223e+00, top1 50.13, top5 74.62
2021-11-04 12:32:13 train 4000, loss 2.214e+00, top1 50.28, top5 74.72
2021-11-04 12:46:14 train 5000, loss 2.223e+00, top1 50.14, top5 74.57
2021-11-04 12:46:14 train 5000, loss 2.227e+00, top1 50.06, top5 74.55
2021-11-04 12:46:14 train 5000, loss 2.220e+00, top1 50.20, top5 74.63
2021-11-04 12:46:47 valid 0000, loss 6.315e-01, top1 89.41, top5 96.47
2021-11-04 12:46:47 valid 0000, loss 6.315e-01, top1 89.41, top5 96.47
2021-11-04 12:46:47 valid 0000, loss 6.315e-01, top1 89.41, top5 96.47
2021-11-04 12:51:20 (JOBID 31649) epoch 6: train time 4249.36, inference time 283.87s, valid_top1 52.55 (best_top1 52.66), valid_top5 77.99
2021-11-04 12:51:20 (JOBID 31649) epoch 6: train time 4249.41, inference time 283.89s, valid_top1 52.55 (best_top1 52.66), valid_top5 77.99
2021-11-04 12:51:22 (JOBID 31649) epoch 6: train time 4249.23, inference time 285.02s, valid_top1 52.55 (best_top1 52.66), valid_top5 77.99
2021-11-04 12:51:35 train 0000, loss 2.885e+00, top1 34.12, top5 64.71
2021-11-04 12:51:35 train 0000, loss 2.354e+00, top1 51.76, top5 75.29
2021-11-04 12:51:38 train 0000, loss 1.900e+00, top1 57.65, top5 82.35
2021-11-04 13:05:42 train 1000, loss 2.205e+00, top1 50.43, top5 74.86
2021-11-04 13:05:42 train 1000, loss 2.206e+00, top1 50.36, top5 74.79
2021-11-04 13:05:42 train 1000, loss 2.205e+00, top1 50.61, top5 74.93
2021-11-04 13:19:48 train 2000, loss 2.211e+00, top1 50.32, top5 74.74
2021-11-04 13:19:48 train 2000, loss 2.209e+00, top1 50.37, top5 74.78
2021-11-04 13:19:49 train 2000, loss 2.207e+00, top1 50.50, top5 74.92
2021-11-04 13:33:49 train 3000, loss 2.218e+00, top1 50.23, top5 74.69
2021-11-04 13:33:49 train 3000, loss 2.215e+00, top1 50.26, top5 74.69
2021-11-04 13:33:49 train 3000, loss 2.213e+00, top1 50.38, top5 74.79
2021-11-04 13:47:43 train 4000, loss 2.220e+00, top1 50.23, top5 74.67
2021-11-04 13:47:43 train 4000, loss 2.218e+00, top1 50.14, top5 74.64
2021-11-04 13:47:43 train 4000, loss 2.216e+00, top1 50.31, top5 74.70
2021-11-04 14:01:46 train 5000, loss 2.223e+00, top1 50.16, top5 74.62
2021-11-04 14:01:46 train 5000, loss 2.221e+00, top1 50.05, top5 74.60
2021-11-04 14:01:46 train 5000, loss 2.222e+00, top1 50.18, top5 74.57
2021-11-04 14:02:16 valid 0000, loss 7.800e-01, top1 83.53, top5 92.94
2021-11-04 14:02:16 valid 0000, loss 7.800e-01, top1 83.53, top5 92.94
2021-11-04 14:02:16 valid 0000, loss 7.800e-01, top1 83.53, top5 92.94
2021-11-04 14:06:26 (JOBID 31649) epoch 7: train time 4244.16, inference time 259.30s, valid_top1 52.48 (best_top1 52.66), valid_top5 78.22
2021-11-04 14:06:45 (JOBID 31649) epoch 7: train time 4245.54, inference time 279.34s, valid_top1 52.48 (best_top1 52.66), valid_top5 78.22
2021-11-04 14:06:49 (JOBID 31649) epoch 7: train time 4245.60, inference time 283.19s, valid_top1 52.48 (best_top1 52.66), valid_top5 78.22
2021-11-04 14:07:00 train 0000, loss 2.169e+00, top1 47.06, top5 75.29
2021-11-04 14:06:39 train 0000, loss 2.775e+00, top1 38.82, top5 60.00
2021-11-04 14:07:02 train 0000, loss 2.258e+00, top1 49.41, top5 77.65
2021-11-04 14:20:54 train 1000, loss 2.195e+00, top1 50.65, top5 75.12
2021-11-04 14:20:54 train 1000, loss 2.205e+00, top1 50.34, top5 74.82
2021-11-04 14:20:54 train 1000, loss 2.197e+00, top1 50.44, top5 74.97
2021-11-04 14:34:49 train 2000, loss 2.205e+00, top1 50.49, top5 74.93
2021-11-04 14:34:49 train 2000, loss 2.220e+00, top1 50.14, top5 74.64
2021-11-04 14:34:49 train 2000, loss 2.203e+00, top1 50.32, top5 74.75
2021-11-04 14:48:40 train 3000, loss 2.213e+00, top1 50.36, top5 74.76
2021-11-04 14:48:40 train 3000, loss 2.223e+00, top1 50.03, top5 74.59
2021-11-04 14:48:40 train 3000, loss 2.208e+00, top1 50.27, top5 74.73
2021-11-04 15:02:43 train 4000, loss 2.218e+00, top1 50.31, top5 74.66
2021-11-04 15:02:43 train 4000, loss 2.223e+00, top1 50.05, top5 74.58
2021-11-04 15:02:43 train 4000, loss 2.213e+00, top1 50.23, top5 74.64
2021-11-04 15:16:30 train 5000, loss 2.214e+00, top1 50.24, top5 74.63
2021-11-04 15:16:30 train 5000, loss 2.225e+00, top1 50.03, top5 74.56
2021-11-04 15:16:30 train 5000, loss 2.222e+00, top1 50.25, top5 74.61
2021-11-04 15:17:01 valid 0000, loss 1.670e+00, top1 64.71, top5 77.65
2021-11-04 15:17:01 valid 0000, loss 1.670e+00, top1 64.71, top5 77.65
2021-11-04 15:17:01 valid 0000, loss 1.670e+00, top1 64.71, top5 77.65
2021-11-04 15:21:13 (JOBID 31649) epoch 8: train time 4224.58, inference time 262.55s, valid_top1 48.84 (best_top1 52.66), valid_top5 75.08
2021-11-04 15:21:29 (JOBID 31649) epoch 8: train time 4204.92, inference time 278.48s, valid_top1 48.84 (best_top1 52.66), valid_top5 75.08
2021-11-04 15:21:31 (JOBID 31649) epoch 8: train time 4201.04, inference time 280.97s, valid_top1 48.84 (best_top1 52.66), valid_top5 75.08
2021-11-04 15:21:43 train 0000, loss 2.205e+00, top1 50.59, top5 76.47
2021-11-04 15:21:27 train 0000, loss 2.045e+00, top1 58.82, top5 81.18
2021-11-04 15:21:45 train 0000, loss 1.824e+00, top1 58.82, top5 81.18
2021-11-04 15:35:39 train 1000, loss 2.200e+00, top1 50.66, top5 75.11
2021-11-04 15:35:39 train 1000, loss 2.200e+00, top1 50.35, top5 74.91
2021-11-04 15:35:39 train 1000, loss 2.205e+00, top1 50.46, top5 74.86
2021-11-04 15:49:38 train 2000, loss 2.213e+00, top1 50.38, top5 74.79
2021-11-04 15:49:38 train 2000, loss 2.213e+00, top1 50.14, top5 74.75
2021-11-04 15:49:38 train 2000, loss 2.211e+00, top1 50.41, top5 74.85
2021-11-04 16:03:30 train 3000, loss 2.216e+00, top1 50.25, top5 74.72
2021-11-04 16:03:30 train 3000, loss 2.218e+00, top1 50.14, top5 74.63
2021-11-04 16:03:31 train 3000, loss 2.219e+00, top1 50.27, top5 74.68
2021-11-04 16:17:28 train 4000, loss 2.219e+00, top1 50.14, top5 74.64
2021-11-04 16:17:28 train 4000, loss 2.222e+00, top1 50.17, top5 74.59
2021-11-04 16:17:28 train 4000, loss 2.220e+00, top1 50.15, top5 74.67
2021-11-04 16:31:32 train 5000, loss 2.223e+00, top1 50.09, top5 74.61
2021-11-04 16:31:33 train 5000, loss 2.222e+00, top1 50.15, top5 74.61
2021-11-04 16:31:33 train 5000, loss 2.221e+00, top1 50.11, top5 74.64
2021-11-04 16:32:04 valid 0000, loss 1.454e+00, top1 65.88, top5 84.71
2021-11-04 16:32:04 valid 0000, loss 1.454e+00, top1 65.88, top5 84.71
2021-11-04 16:32:04 valid 0000, loss 1.454e+00, top1 65.88, top5 84.71
2021-11-04 16:36:38 (JOBID 31649) epoch 9: train time 4224.35, inference time 285.24s, valid_top1 50.91 (best_top1 52.66), valid_top5 76.92
2021-11-04 16:36:38 (JOBID 31649) epoch 9: train time 4222.09, inference time 285.21s, valid_top1 50.91 (best_top1 52.66), valid_top5 76.92
2021-11-04 16:36:39 (JOBID 31649) epoch 9: train time 4239.93, inference time 285.26s, valid_top1 50.91 (best_top1 52.66), valid_top5 76.92
2021-11-04 16:36:53 train 0000, loss 1.900e+00, top1 54.12, top5 81.18
2021-11-04 16:36:53 train 0000, loss 2.347e+00, top1 50.59, top5 71.76
2021-11-04 16:36:53 train 0000, loss 2.419e+00, top1 51.76, top5 67.06
2021-11-04 16:50:47 train 1000, loss 2.209e+00, top1 50.44, top5 74.72
2021-11-04 16:50:47 train 1000, loss 2.222e+00, top1 50.06, top5 74.60
2021-11-04 16:50:47 train 1000, loss 2.205e+00, top1 50.48, top5 74.70
2021-11-04 17:04:47 train 2000, loss 2.209e+00, top1 50.27, top5 74.78
2021-11-04 17:04:47 train 2000, loss 2.216e+00, top1 50.20, top5 74.67
2021-11-04 17:04:47 train 2000, loss 2.209e+00, top1 50.31, top5 74.70
2021-11-04 17:18:46 train 3000, loss 2.211e+00, top1 50.24, top5 74.72
2021-11-04 17:18:46 train 3000, loss 2.214e+00, top1 50.22, top5 74.70
2021-11-04 17:18:47 train 3000, loss 2.217e+00, top1 50.20, top5 74.63
2021-11-04 17:32:45 train 4000, loss 2.215e+00, top1 50.21, top5 74.69
2021-11-04 17:32:45 train 4000, loss 2.217e+00, top1 50.20, top5 74.68
2021-11-04 17:32:45 train 4000, loss 2.222e+00, top1 50.11, top5 74.56
2021-11-04 17:46:43 train 5000, loss 2.219e+00, top1 50.14, top5 74.62
2021-11-04 17:46:43 train 5000, loss 2.224e+00, top1 50.05, top5 74.55
2021-11-04 17:46:43 train 5000, loss 2.219e+00, top1 50.17, top5 74.63
2021-11-04 17:47:13 valid 0000, loss 1.047e+00, top1 77.65, top5 88.24
2021-11-04 17:47:13 valid 0000, loss 1.047e+00, top1 77.65, top5 88.24
2021-11-04 17:47:13 valid 0000, loss 1.047e+00, top1 77.65, top5 88.24
2021-11-04 17:51:29 (JOBID 31649) epoch 10: train time 4224.45, inference time 266.09s, valid_top1 51.96 (best_top1 52.66), valid_top5 77.78
2021-11-04 17:51:41 (JOBID 31649) epoch 10: train time 4224.77, inference time 277.96s, valid_top1 51.96 (best_top1 52.66), valid_top5 77.78
2021-11-04 17:51:43 (JOBID 31649) epoch 10: train time 4224.03, inference time 279.23s, valid_top1 51.96 (best_top1 52.66), valid_top5 77.78
2021-11-04 17:51:55 train 0000, loss 2.101e+00, top1 50.59, top5 74.12
2021-11-04 17:51:44 train 0000, loss 2.043e+00, top1 55.29, top5 77.65
2021-11-04 17:51:56 train 0000, loss 2.583e+00, top1 40.00, top5 70.59
2021-11-04 18:05:55 train 1000, loss 2.208e+00, top1 50.27, top5 74.83
2021-11-04 18:05:55 train 1000, loss 2.204e+00, top1 50.58, top5 74.74
2021-11-04 18:05:55 train 1000, loss 2.176e+00, top1 51.01, top5 75.34
2021-11-04 18:19:53 train 2000, loss 2.210e+00, top1 50.26, top5 74.75
2021-11-04 18:19:53 train 2000, loss 2.192e+00, top1 50.67, top5 75.03
2021-11-04 18:19:53 train 2000, loss 2.211e+00, top1 50.28, top5 74.74
2021-11-04 18:33:51 train 3000, loss 2.215e+00, top1 50.26, top5 74.69
2021-11-04 18:33:51 train 3000, loss 2.204e+00, top1 50.47, top5 74.86
2021-11-04 18:33:51 train 3000, loss 2.214e+00, top1 50.21, top5 74.68
2021-11-04 18:47:47 train 4000, loss 2.212e+00, top1 50.36, top5 74.72
2021-11-04 18:47:47 train 4000, loss 2.217e+00, top1 50.20, top5 74.67
2021-11-04 18:47:47 train 4000, loss 2.220e+00, top1 50.11, top5 74.61
2021-11-04 19:01:44 train 5000, loss 2.220e+00, top1 50.17, top5 74.65
2021-11-04 19:01:44 train 5000, loss 2.217e+00, top1 50.25, top5 74.62
2021-11-04 19:01:44 train 5000, loss 2.221e+00, top1 50.08, top5 74.60
2021-11-04 19:02:14 valid 0000, loss 1.255e+00, top1 74.12, top5 87.06
2021-11-04 19:02:14 valid 0000, loss 1.255e+00, top1 74.12, top5 87.06
2021-11-04 19:02:14 valid 0000, loss 1.255e+00, top1 74.12, top5 87.06
2021-11-04 19:06:38 (JOBID 31649) epoch 11: train time 4223.19, inference time 274.22s, valid_top1 52.00 (best_top1 52.66), valid_top5 77.94
2021-11-04 19:06:45 (JOBID 31649) epoch 11: train time 4235.37, inference time 280.33s, valid_top1 52.00 (best_top1 52.66), valid_top5 77.94
2021-11-04 19:06:49 (JOBID 31649) epoch 11: train time 4221.63, inference time 283.74s, valid_top1 52.00 (best_top1 52.66), valid_top5 77.94
2021-11-04 19:06:58 train 0000, loss 2.234e+00, top1 57.65, top5 74.12
2021-11-04 19:06:52 train 0000, loss 2.614e+00, top1 41.18, top5 69.41
2021-11-04 19:07:03 train 0000, loss 2.031e+00, top1 56.47, top5 76.47
2021-11-04 19:21:05 train 1000, loss 2.196e+00, top1 50.57, top5 74.92
2021-11-04 19:21:05 train 1000, loss 2.202e+00, top1 50.58, top5 74.86
2021-11-04 19:21:05 train 1000, loss 2.215e+00, top1 50.47, top5 74.65
2021-11-04 19:35:06 train 2000, loss 2.207e+00, top1 50.43, top5 74.75
2021-11-04 19:35:06 train 2000, loss 2.210e+00, top1 50.39, top5 74.77
2021-11-04 19:35:06 train 2000, loss 2.213e+00, top1 50.38, top5 74.71
2021-11-04 19:49:16 train 3000, loss 2.212e+00, top1 50.38, top5 74.69
2021-11-04 19:49:16 train 3000, loss 2.216e+00, top1 50.21, top5 74.65
2021-11-04 19:49:16 train 3000, loss 2.213e+00, top1 50.27, top5 74.71
2021-11-04 20:03:26 train 4000, loss 2.218e+00, top1 50.25, top5 74.58
2021-11-04 20:03:26 train 4000, loss 2.220e+00, top1 50.17, top5 74.61
2021-11-04 20:03:26 train 4000, loss 2.216e+00, top1 50.20, top5 74.73
2021-11-04 20:17:37 train 5000, loss 2.225e+00, top1 50.12, top5 74.54
2021-11-04 20:17:37 train 5000, loss 2.222e+00, top1 50.17, top5 74.53
2021-11-04 20:17:37 train 5000, loss 2.221e+00, top1 50.11, top5 74.60
2021-11-04 20:18:07 valid 0000, loss 1.146e+00, top1 78.82, top5 85.88
2021-11-04 20:18:07 valid 0000, loss 1.146e+00, top1 78.82, top5 85.88
2021-11-04 20:18:07 valid 0000, loss 1.146e+00, top1 78.82, top5 85.88
2021-11-04 20:22:22 (JOBID 31649) epoch 12: train time 4278.25, inference time 265.24s, valid_top1 53.57 (best_top1 53.57), valid_top5 78.95
2021-11-04 20:22:37 (JOBID 31649) epoch 12: train time 4272.25, inference time 280.32s, valid_top1 53.57 (best_top1 53.57), valid_top5 78.95
2021-11-04 20:22:39 (JOBID 31649) epoch 12: train time 4268.15, inference time 281.31s, valid_top1 53.57 (best_top1 53.57), valid_top5 78.95
2021-11-04 20:22:52 train 0000, loss 2.089e+00, top1 55.29, top5 75.29
2021-11-04 20:22:36 train 0000, loss 2.132e+00, top1 48.24, top5 78.82
2021-11-04 20:22:52 train 0000, loss 2.376e+00, top1 50.59, top5 72.94
2021-11-04 20:36:45 train 1000, loss 2.207e+00, top1 50.24, top5 74.82
2021-11-04 20:36:45 train 1000, loss 2.196e+00, top1 50.65, top5 74.91
2021-11-04 20:36:45 train 1000, loss 2.201e+00, top1 50.67, top5 74.70
2021-11-04 20:50:47 train 2000, loss 2.212e+00, top1 50.41, top5 74.58
2021-11-04 20:50:47 train 2000, loss 2.208e+00, top1 50.24, top5 74.81
2021-11-04 20:50:48 train 2000, loss 2.210e+00, top1 50.43, top5 74.71
2021-11-04 21:04:57 train 3000, loss 2.216e+00, top1 50.32, top5 74.64
2021-11-04 21:04:57 train 3000, loss 2.213e+00, top1 50.33, top5 74.64
2021-11-04 21:04:57 train 3000, loss 2.212e+00, top1 50.27, top5 74.76
2021-11-04 21:18:47 train 4000, loss 2.220e+00, top1 50.28, top5 74.62
2021-11-04 21:18:47 train 4000, loss 2.219e+00, top1 50.14, top5 74.64
2021-11-04 21:18:47 train 4000, loss 2.219e+00, top1 50.22, top5 74.60
2021-11-04 21:32:45 train 5000, loss 2.222e+00, top1 50.05, top5 74.58
2021-11-04 21:32:45 train 5000, loss 2.221e+00, top1 50.24, top5 74.61
2021-11-04 21:32:46 train 5000, loss 2.221e+00, top1 50.19, top5 74.56
2021-11-04 21:33:16 valid 0000, loss 1.039e+00, top1 76.47, top5 91.76
2021-11-04 21:33:16 valid 0000, loss 1.039e+00, top1 76.47, top5 91.76
2021-11-04 21:33:16 valid 0000, loss 1.039e+00, top1 76.47, top5 91.76
2021-11-04 21:37:30 (JOBID 31649) epoch 13: train time 4228.31, inference time 264.38s, valid_top1 52.50 (best_top1 53.57), valid_top5 78.44
2021-11-04 21:37:46 (JOBID 31649) epoch 13: train time 4243.61, inference time 280.34s, valid_top1 52.50 (best_top1 53.57), valid_top5 78.44
2021-11-04 21:37:47 (JOBID 31649) epoch 13: train time 4226.91, inference time 281.02s, valid_top1 52.50 (best_top1 53.57), valid_top5 78.44
2021-11-04 21:37:45 train 0000, loss 1.790e+00, top1 62.35, top5 83.53
2021-11-04 21:38:00 train 0000, loss 2.448e+00, top1 47.06, top5 71.76
2021-11-04 21:38:00 train 0000, loss 2.080e+00, top1 51.76, top5 77.65
2021-11-04 21:52:05 train 1000, loss 2.195e+00, top1 50.48, top5 75.01
2021-11-04 21:52:05 train 1000, loss 2.207e+00, top1 50.41, top5 74.95
2021-11-04 21:52:05 train 1000, loss 2.195e+00, top1 50.70, top5 74.98
2021-11-04 22:06:01 train 2000, loss 2.210e+00, top1 50.39, top5 74.83
2021-11-04 22:06:01 train 2000, loss 2.206e+00, top1 50.33, top5 74.84
2021-11-04 22:06:01 train 2000, loss 2.207e+00, top1 50.45, top5 74.83
2021-11-04 22:19:59 train 3000, loss 2.214e+00, top1 50.24, top5 74.77
2021-11-04 22:19:59 train 3000, loss 2.213e+00, top1 50.29, top5 74.75
2021-11-04 22:19:59 train 3000, loss 2.212e+00, top1 50.41, top5 74.76
2021-11-04 22:34:03 train 4000, loss 2.217e+00, top1 50.20, top5 74.69
2021-11-04 22:34:03 train 4000, loss 2.214e+00, top1 50.28, top5 74.70
2021-11-04 22:34:03 train 4000, loss 2.215e+00, top1 50.33, top5 74.71
2021-11-04 22:48:08 train 5000, loss 2.218e+00, top1 50.22, top5 74.63
2021-11-04 22:48:08 train 5000, loss 2.220e+00, top1 50.20, top5 74.66
2021-11-04 22:48:08 train 5000, loss 2.219e+00, top1 50.25, top5 74.67
2021-11-04 22:48:39 valid 0000, loss 7.921e-01, top1 78.82, top5 96.47
2021-11-04 22:48:39 valid 0000, loss 7.921e-01, top1 78.82, top5 96.47
2021-11-04 22:48:39 valid 0000, loss 7.921e-01, top1 78.82, top5 96.47
2021-11-04 22:53:05 (JOBID 31649) epoch 14: train time 4241.22, inference time 276.17s, valid_top1 52.90 (best_top1 53.57), valid_top5 78.56
2021-11-04 22:53:15 (JOBID 31649) epoch 14: train time 4258.49, inference time 286.28s, valid_top1 52.90 (best_top1 53.57), valid_top5 78.56
2021-11-04 22:53:16 (JOBID 31649) epoch 14: train time 4242.51, inference time 287.76s, valid_top1 52.90 (best_top1 53.57), valid_top5 78.56
2021-11-04 22:53:29 train 0000, loss 1.904e+00, top1 57.65, top5 74.12
2021-11-04 22:53:20 train 0000, loss 1.708e+00, top1 55.29, top5 85.88
2021-11-04 22:53:30 train 0000, loss 1.846e+00, top1 58.82, top5 77.65
2021-11-04 23:07:28 train 1000, loss 2.203e+00, top1 50.45, top5 74.83
2021-11-04 23:07:28 train 1000, loss 2.200e+00, top1 50.60, top5 74.94
2021-11-04 23:07:29 train 1000, loss 2.195e+00, top1 50.60, top5 75.00
2021-11-04 23:21:41 train 2000, loss 2.209e+00, top1 50.37, top5 74.78
2021-11-04 23:21:41 train 2000, loss 2.205e+00, top1 50.51, top5 74.98
2021-11-04 23:21:41 train 2000, loss 2.203e+00, top1 50.48, top5 74.86
2021-11-04 23:35:46 train 3000, loss 2.211e+00, top1 50.45, top5 74.86
2021-11-04 23:35:46 train 3000, loss 2.216e+00, top1 50.22, top5 74.68
2021-11-04 23:35:46 train 3000, loss 2.209e+00, top1 50.35, top5 74.76
2021-11-04 23:49:46 train 4000, loss 2.213e+00, top1 50.36, top5 74.79
2021-11-04 23:49:46 train 4000, loss 2.221e+00, top1 50.15, top5 74.58
2021-11-04 23:49:46 train 4000, loss 2.215e+00, top1 50.25, top5 74.66
2021-11-05 00:03:58 train 5000, loss 2.225e+00, top1 50.10, top5 74.54
2021-11-05 00:03:58 train 5000, loss 2.217e+00, top1 50.31, top5 74.71
2021-11-05 00:03:58 train 5000, loss 2.220e+00, top1 50.19, top5 74.60
2021-11-05 00:04:28 valid 0000, loss 1.427e+00, top1 72.94, top5 83.53
2021-11-05 00:04:28 valid 0000, loss 1.427e+00, top1 72.94, top5 83.53
2021-11-05 00:04:28 valid 0000, loss 1.427e+00, top1 72.94, top5 83.53
2021-11-05 00:09:14 (JOBID 31649) epoch 15: train time 4263.38, inference time 296.01s, valid_top1 51.66 (best_top1 53.57), valid_top5 77.49
2021-11-05 00:09:15 (JOBID 31649) epoch 15: train time 4261.71, inference time 296.87s, valid_top1 51.66 (best_top1 53.57), valid_top5 77.49
2021-11-05 00:09:16 (JOBID 31649) epoch 15: train time 4272.80, inference time 298.08s, valid_top1 51.66 (best_top1 53.57), valid_top5 77.49
2021-11-05 00:09:29 train 0000, loss 2.222e+00, top1 48.24, top5 75.29
2021-11-05 00:09:29 train 0000, loss 2.119e+00, top1 52.94, top5 75.29
2021-11-05 00:09:31 train 0000, loss 2.001e+00, top1 58.82, top5 80.00
2021-11-05 00:23:36 train 1000, loss 2.189e+00, top1 50.62, top5 75.12
2021-11-05 00:23:36 train 1000, loss 2.193e+00, top1 50.77, top5 75.03
2021-11-05 00:23:36 train 1000, loss 2.198e+00, top1 50.51, top5 74.86
2021-11-05 00:37:46 train 2000, loss 2.203e+00, top1 50.51, top5 74.81
2021-11-05 00:37:46 train 2000, loss 2.205e+00, top1 50.43, top5 74.88
2021-11-05 00:37:46 train 2000, loss 2.206e+00, top1 50.25, top5 74.78
2021-11-05 00:52:10 train 3000, loss 2.212e+00, top1 50.28, top5 74.75
2021-11-05 00:52:10 train 3000, loss 2.212e+00, top1 50.35, top5 74.68
2021-11-05 00:52:10 train 3000, loss 2.212e+00, top1 50.17, top5 74.69
2021-11-05 01:06:27 train 4000, loss 2.216e+00, top1 50.22, top5 74.70
2021-11-05 01:06:27 train 4000, loss 2.214e+00, top1 50.34, top5 74.63
2021-11-05 01:06:27 train 4000, loss 2.220e+00, top1 50.09, top5 74.57
2021-11-05 01:20:52 train 5000, loss 2.216e+00, top1 50.21, top5 74.70
2021-11-05 01:20:52 train 5000, loss 2.215e+00, top1 50.36, top5 74.62
2021-11-05 01:20:52 train 5000, loss 2.222e+00, top1 50.06, top5 74.56
2021-11-05 01:21:23 valid 0000, loss 8.775e-01, top1 82.35, top5 91.76
2021-11-05 01:21:23 valid 0000, loss 8.775e-01, top1 82.35, top5 91.76
2021-11-05 01:21:23 valid 0000, loss 8.775e-01, top1 82.35, top5 91.76
2021-11-05 01:25:39 (JOBID 31649) epoch 16: train time 4318.20, inference time 266.27s, valid_top1 51.57 (best_top1 53.57), valid_top5 76.98
2021-11-05 01:25:53 (JOBID 31649) epoch 16: train time 4318.56, inference time 280.66s, valid_top1 51.57 (best_top1 53.57), valid_top5 76.98
2021-11-05 01:25:58 (JOBID 31649) epoch 16: train time 4316.36, inference time 284.32s, valid_top1 51.57 (best_top1 53.57), valid_top5 76.98
2021-11-05 01:26:08 train 0000, loss 2.130e+00, top1 49.41, top5 76.47
2021-11-05 01:25:53 train 0000, loss 1.721e+00, top1 60.00, top5 84.71
2021-11-05 01:26:12 train 0000, loss 2.114e+00, top1 51.76, top5 72.94
2021-11-05 01:40:31 train 1000, loss 2.197e+00, top1 50.41, top5 75.02
2021-11-05 01:40:31 train 1000, loss 2.194e+00, top1 50.69, top5 75.06
2021-11-05 01:40:31 train 1000, loss 2.202e+00, top1 50.49, top5 74.93
2021-11-05 01:54:46 train 2000, loss 2.206e+00, top1 50.25, top5 74.88
2021-11-05 01:54:46 train 2000, loss 2.208e+00, top1 50.46, top5 74.81
2021-11-05 01:54:46 train 2000, loss 2.214e+00, top1 50.36, top5 74.67
2021-11-05 02:09:00 train 3000, loss 2.212e+00, top1 50.19, top5 74.77
2021-11-05 02:09:00 train 3000, loss 2.208e+00, top1 50.37, top5 74.79
2021-11-05 02:09:00 train 3000, loss 2.216e+00, top1 50.36, top5 74.68
2021-11-05 02:23:19 train 4000, loss 2.214e+00, top1 50.18, top5 74.73
2021-11-05 02:23:19 train 4000, loss 2.214e+00, top1 50.29, top5 74.68
2021-11-05 02:23:20 train 4000, loss 2.214e+00, top1 50.38, top5 74.70
2021-11-05 02:37:42 train 5000, loss 2.217e+00, top1 50.23, top5 74.64
2021-11-05 02:37:42 train 5000, loss 2.217e+00, top1 50.16, top5 74.68
2021-11-05 02:37:42 train 5000, loss 2.218e+00, top1 50.30, top5 74.64
2021-11-05 02:38:13 valid 0000, loss 7.281e-01, top1 85.88, top5 94.12
2021-11-05 02:38:13 valid 0000, loss 7.281e-01, top1 85.88, top5 94.12
2021-11-05 02:38:13 valid 0000, loss 7.281e-01, top1 85.88, top5 94.12
2021-11-05 02:42:24 (JOBID 31649) epoch 17: train time 4343.42, inference time 261.14s, valid_top1 50.93 (best_top1 53.57), valid_top5 76.47
2021-11-05 02:42:44 (JOBID 31649) epoch 17: train time 4325.08, inference time 281.42s, valid_top1 50.93 (best_top1 53.57), valid_top5 76.47
2021-11-05 02:42:45 (JOBID 31649) epoch 17: train time 4329.52, inference time 282.30s, valid_top1 50.93 (best_top1 53.57), valid_top5 76.47
2021-11-05 02:42:39 train 0000, loss 2.515e+00, top1 41.18, top5 68.24
2021-11-05 02:42:59 train 0000, loss 2.248e+00, top1 47.06, top5 72.94
2021-11-05 02:42:59 train 0000, loss 1.945e+00, top1 54.12, top5 76.47
2021-11-05 02:57:21 train 1000, loss 2.204e+00, top1 50.50, top5 74.90
2021-11-05 02:57:21 train 1000, loss 2.200e+00, top1 50.43, top5 74.88
2021-11-05 02:57:21 train 1000, loss 2.205e+00, top1 50.44, top5 74.82
2021-11-05 03:11:50 train 2000, loss 2.206e+00, top1 50.44, top5 74.80
2021-11-05 03:11:50 train 2000, loss 2.202e+00, top1 50.50, top5 74.86
2021-11-05 03:11:51 train 2000, loss 2.204e+00, top1 50.49, top5 74.79
2021-11-05 03:26:19 train 3000, loss 2.209e+00, top1 50.43, top5 74.71
2021-11-05 03:26:19 train 3000, loss 2.204e+00, top1 50.47, top5 74.81
2021-11-05 03:26:20 train 3000, loss 2.208e+00, top1 50.41, top5 74.75
2021-11-05 03:40:42 train 4000, loss 2.215e+00, top1 50.32, top5 74.62
2021-11-05 03:40:42 train 4000, loss 2.211e+00, top1 50.36, top5 74.70
2021-11-05 03:40:43 train 4000, loss 2.215e+00, top1 50.30, top5 74.66
2021-11-05 03:55:01 train 5000, loss 2.219e+00, top1 50.28, top5 74.60
2021-11-05 03:55:01 train 5000, loss 2.213e+00, top1 50.34, top5 74.67
2021-11-05 03:55:01 train 5000, loss 2.216e+00, top1 50.30, top5 74.61
2021-11-05 03:55:33 valid 0000, loss 7.983e-01, top1 83.53, top5 94.12
2021-11-05 03:55:33 valid 0000, loss 7.983e-01, top1 83.53, top5 94.12
2021-11-05 03:55:33 valid 0000, loss 7.983e-01, top1 83.53, top5 94.12
2021-11-05 04:00:04 (JOBID 31649) epoch 18: train time 4356.86, inference time 281.62s, valid_top1 53.55 (best_top1 53.57), valid_top5 78.79
2021-11-05 04:00:04 (JOBID 31649) epoch 18: train time 4357.65, inference time 281.47s, valid_top1 53.55 (best_top1 53.57), valid_top5 78.79
2021-11-05 04:00:04 (JOBID 31649) epoch 18: train time 4378.26, inference time 282.10s, valid_top1 53.55 (best_top1 53.57), valid_top5 78.79
2021-11-05 04:00:18 train 0000, loss 3.028e+00, top1 36.47, top5 57.65
2021-11-05 04:00:18 train 0000, loss 2.016e+00, top1 54.12, top5 80.00
2021-11-05 04:00:20 train 0000, loss 2.445e+00, top1 44.71, top5 72.94
2021-11-05 04:14:45 train 1000, loss 2.191e+00, top1 50.82, top5 75.04
2021-11-05 04:14:45 train 1000, loss 2.178e+00, top1 50.81, top5 75.35
2021-11-05 04:14:45 train 1000, loss 2.199e+00, top1 50.56, top5 74.85
2021-11-05 04:29:00 train 2000, loss 2.199e+00, top1 50.63, top5 74.94
2021-11-05 04:29:00 train 2000, loss 2.201e+00, top1 50.44, top5 74.93
2021-11-05 04:29:01 train 2000, loss 2.208e+00, top1 50.24, top5 74.76
2021-11-05 04:43:16 train 3000, loss 2.209e+00, top1 50.34, top5 74.83
2021-11-05 04:43:16 train 3000, loss 2.214e+00, top1 50.20, top5 74.71
2021-11-05 04:43:17 train 3000, loss 2.205e+00, top1 50.57, top5 74.87
2021-11-05 04:57:42 train 4000, loss 2.215e+00, top1 50.23, top5 74.70
2021-11-05 04:57:42 train 4000, loss 2.210e+00, top1 50.51, top5 74.81
2021-11-05 04:57:42 train 4000, loss 2.215e+00, top1 50.24, top5 74.69
2021-11-05 05:12:07 train 5000, loss 2.220e+00, top1 50.16, top5 74.61
2021-11-05 05:12:07 train 5000, loss 2.215e+00, top1 50.37, top5 74.73
2021-11-05 05:12:07 train 5000, loss 2.218e+00, top1 50.18, top5 74.62
2021-11-05 05:12:38 valid 0000, loss 1.254e+00, top1 69.41, top5 87.06
2021-11-05 05:12:38 valid 0000, loss 1.254e+00, top1 69.41, top5 87.06
2021-11-05 05:12:38 valid 0000, loss 1.254e+00, top1 69.41, top5 87.06
2021-11-05 05:16:57 (JOBID 31649) epoch 19: train time 4343.96, inference time 268.45s, valid_top1 51.48 (best_top1 53.57), valid_top5 77.05
2021-11-05 05:17:08 (JOBID 31649) epoch 19: train time 4344.24, inference time 280.45s, valid_top1 51.48 (best_top1 53.57), valid_top5 77.05
2021-11-05 05:17:09 (JOBID 31649) epoch 19: train time 4343.88, inference time 281.30s, valid_top1 51.48 (best_top1 53.57), valid_top5 77.05
2021-11-05 05:17:13 train 0000, loss 2.182e+00, top1 45.88, top5 71.76
2021-11-05 05:17:23 train 0000, loss 2.562e+00, top1 43.53, top5 67.06
2021-11-05 05:17:23 train 0000, loss 1.971e+00, top1 61.18, top5 72.94
2021-11-05 05:31:34 train 1000, loss 2.197e+00, top1 50.57, top5 74.93
2021-11-05 05:31:34 train 1000, loss 2.195e+00, top1 50.67, top5 75.05
2021-11-05 05:31:35 train 1000, loss 2.206e+00, top1 50.29, top5 75.02
2021-11-05 05:45:50 train 2000, loss 2.204e+00, top1 50.37, top5 74.95
2021-11-05 05:45:50 train 2000, loss 2.198e+00, top1 50.61, top5 74.96
2021-11-05 05:45:50 train 2000, loss 2.205e+00, top1 50.45, top5 74.85
2021-11-05 06:00:13 train 3000, loss 2.205e+00, top1 50.55, top5 74.88
2021-11-05 06:00:13 train 3000, loss 2.213e+00, top1 50.31, top5 74.72
2021-11-05 06:00:14 train 3000, loss 2.206e+00, top1 50.42, top5 74.90
2021-11-05 06:14:29 train 4000, loss 2.210e+00, top1 50.42, top5 74.84
2021-11-05 06:14:29 train 4000, loss 2.218e+00, top1 50.27, top5 74.65
2021-11-05 06:14:29 train 4000, loss 2.212e+00, top1 50.31, top5 74.80
2021-11-05 06:28:42 train 5000, loss 2.213e+00, top1 50.37, top5 74.81
2021-11-05 06:28:42 train 5000, loss 2.220e+00, top1 50.23, top5 74.58
2021-11-05 06:28:42 train 5000, loss 2.217e+00, top1 50.20, top5 74.70
2021-11-05 06:29:14 valid 0000, loss 1.425e+00, top1 71.76, top5 82.35
2021-11-05 06:29:14 valid 0000, loss 1.425e+00, top1 71.76, top5 82.35
2021-11-05 06:29:14 valid 0000, loss 1.425e+00, top1 71.76, top5 82.35
2021-11-05 06:33:27 (JOBID 31649) epoch 20: train time 4313.91, inference time 264.48s, valid_top1 52.84 (best_top1 53.57), valid_top5 78.56
2021-11-05 06:33:43 (JOBID 31649) epoch 20: train time 4312.88, inference time 280.37s, valid_top1 52.84 (best_top1 53.57), valid_top5 78.56
2021-11-05 06:33:46 (JOBID 31649) epoch 20: train time 4325.61, inference time 283.24s, valid_top1 52.84 (best_top1 53.57), valid_top5 78.56
2021-11-05 06:33:57 train 0000, loss 1.869e+00, top1 57.65, top5 77.65
2021-11-05 06:33:43 train 0000, loss 1.745e+00, top1 57.65, top5 85.88
2021-11-05 06:34:00 train 0000, loss 2.377e+00, top1 41.18, top5 74.12
2021-11-05 06:48:38 train 1000, loss 2.207e+00, top1 50.41, top5 74.75
2021-11-05 06:48:38 train 1000, loss 2.199e+00, top1 50.58, top5 75.07
2021-11-05 06:48:39 train 1000, loss 2.195e+00, top1 50.55, top5 74.93
2021-11-05 07:02:54 train 2000, loss 2.204e+00, top1 50.43, top5 74.84
2021-11-05 07:02:54 train 2000, loss 2.206e+00, top1 50.43, top5 74.90
2021-11-05 07:02:55 train 2000, loss 2.205e+00, top1 50.37, top5 74.77
2021-11-05 07:17:17 train 3000, loss 2.208e+00, top1 50.37, top5 74.78
2021-11-05 07:17:17 train 3000, loss 2.213e+00, top1 50.29, top5 74.81
2021-11-05 07:17:17 train 3000, loss 2.210e+00, top1 50.28, top5 74.72
2021-11-05 07:31:44 train 4000, loss 2.213e+00, top1 50.32, top5 74.74
2021-11-05 07:31:44 train 4000, loss 2.217e+00, top1 50.20, top5 74.71
2021-11-05 07:31:45 train 4000, loss 2.217e+00, top1 50.21, top5 74.62
2021-11-05 07:46:23 train 5000, loss 2.216e+00, top1 50.31, top5 74.70
2021-11-05 07:46:23 train 5000, loss 2.219e+00, top1 50.20, top5 74.66
2021-11-05 07:46:23 train 5000, loss 2.219e+00, top1 50.19, top5 74.61
2021-11-05 07:46:53 valid 0000, loss 8.240e-01, top1 82.35, top5 91.76
2021-11-05 07:46:53 valid 0000, loss 8.240e-01, top1 82.35, top5 91.76
2021-11-05 07:46:53 valid 0000, loss 8.240e-01, top1 82.35, top5 91.76
2021-11-05 07:51:24 (JOBID 31649) epoch 21: train time 4380.66, inference time 281.09s, valid_top1 53.25 (best_top1 53.57), valid_top5 79.02
2021-11-05 07:51:25 (JOBID 31649) epoch 21: train time 4396.24, inference time 281.60s, valid_top1 53.25 (best_top1 53.57), valid_top5 79.02
2021-11-05 07:51:28 (JOBID 31649) epoch 21: train time 4377.03, inference time 284.69s, valid_top1 53.25 (best_top1 53.57), valid_top5 79.02
2021-11-05 07:51:41 train 0000, loss 2.538e+00, top1 44.71, top5 70.59
2021-11-05 07:51:41 train 0000, loss 2.229e+00, top1 50.59, top5 74.12
2021-11-05 07:51:44 train 0000, loss 1.860e+00, top1 56.47, top5 83.53
2021-11-05 08:05:33 train 1000, loss 2.186e+00, top1 50.50, top5 75.21
2021-11-05 08:05:33 train 1000, loss 2.188e+00, top1 50.68, top5 75.09
2021-11-05 08:05:33 train 1000, loss 2.197e+00, top1 50.56, top5 74.95
2021-11-05 08:19:22 train 2000, loss 2.208e+00, top1 50.49, top5 74.82
2021-11-05 08:19:22 train 2000, loss 2.202e+00, top1 50.46, top5 74.96
2021-11-05 08:19:22 train 2000, loss 2.193e+00, top1 50.63, top5 75.06
2021-11-05 08:33:12 train 3000, loss 2.209e+00, top1 50.48, top5 74.75
2021-11-05 08:33:12 train 3000, loss 2.209e+00, top1 50.35, top5 74.78
2021-11-05 08:33:12 train 3000, loss 2.204e+00, top1 50.51, top5 74.87
2021-11-05 08:47:02 train 4000, loss 2.213e+00, top1 50.38, top5 74.71
2021-11-05 08:47:02 train 4000, loss 2.212e+00, top1 50.28, top5 74.76
2021-11-05 08:47:02 train 4000, loss 2.210e+00, top1 50.35, top5 74.77
2021-11-05 09:00:45 train 5000, loss 2.214e+00, top1 50.28, top5 74.71
2021-11-05 09:00:45 train 5000, loss 2.217e+00, top1 50.28, top5 74.62
2021-11-05 09:00:46 train 5000, loss 2.215e+00, top1 50.30, top5 74.70
2021-11-05 09:01:17 valid 0000, loss 1.029e+00, top1 78.82, top5 89.41
2021-11-05 09:01:17 valid 0000, loss 1.029e+00, top1 78.82, top5 89.41
2021-11-05 09:01:17 valid 0000, loss 1.029e+00, top1 78.82, top5 89.41
2021-11-05 09:05:46 (JOBID 31649) epoch 22: train time 4180.61, inference time 280.86s, valid_top1 52.52 (best_top1 53.57), valid_top5 78.46
2021-11-05 09:05:47 (JOBID 31649) epoch 22: train time 4180.83, inference time 281.41s, valid_top1 52.52 (best_top1 53.57), valid_top5 78.46
2021-11-05 09:05:47 (JOBID 31649) epoch 22: train time 4177.13, inference time 281.82s, valid_top1 52.52 (best_top1 53.57), valid_top5 78.46
2021-11-05 09:06:03 train 0000, loss 2.446e+00, top1 49.41, top5 70.59
2021-11-05 09:06:03 train 0000, loss 1.952e+00, top1 47.06, top5 81.18
2021-11-05 09:06:03 train 0000, loss 1.819e+00, top1 56.47, top5 81.18
2021-11-05 09:19:50 train 1000, loss 2.186e+00, top1 50.79, top5 75.27
2021-11-05 09:19:50 train 1000, loss 2.187e+00, top1 50.66, top5 75.17
2021-11-05 09:19:50 train 1000, loss 2.206e+00, top1 50.22, top5 74.77
2021-11-05 09:33:37 train 2000, loss 2.213e+00, top1 50.19, top5 74.70
2021-11-05 09:33:37 train 2000, loss 2.197e+00, top1 50.59, top5 75.06
2021-11-05 09:33:38 train 2000, loss 2.196e+00, top1 50.55, top5 74.96
2021-11-05 09:47:19 train 3000, loss 2.213e+00, top1 50.30, top5 74.71
2021-11-05 09:47:19 train 3000, loss 2.204e+00, top1 50.41, top5 74.94
2021-11-05 09:47:19 train 3000, loss 2.203e+00, top1 50.39, top5 74.91
2021-11-05 10:01:07 train 4000, loss 2.215e+00, top1 50.29, top5 74.70
2021-11-05 10:01:07 train 4000, loss 2.208e+00, top1 50.33, top5 74.81
2021-11-05 10:01:07 train 4000, loss 2.210e+00, top1 50.31, top5 74.81
2021-11-05 10:14:59 train 5000, loss 2.216e+00, top1 50.25, top5 74.66
2021-11-05 10:14:59 train 5000, loss 2.211e+00, top1 50.32, top5 74.76
2021-11-05 10:14:59 train 5000, loss 2.215e+00, top1 50.23, top5 74.71
2021-11-05 10:15:30 valid 0000, loss 1.467e+00, top1 63.53, top5 89.41
2021-11-05 10:15:30 valid 0000, loss 1.467e+00, top1 63.53, top5 89.41
2021-11-05 10:15:30 valid 0000, loss 1.467e+00, top1 63.53, top5 89.41
2021-11-05 10:19:41 (JOBID 31649) epoch 23: train time 4171.76, inference time 261.63s, valid_top1 52.45 (best_top1 53.57), valid_top5 78.09
2021-11-05 10:20:01 (JOBID 31649) epoch 23: train time 4173.01, inference time 281.86s, valid_top1 52.45 (best_top1 53.57), valid_top5 78.09
2021-11-05 10:20:01 (JOBID 31649) epoch 23: train time 4172.57, inference time 281.98s, valid_top1 52.45 (best_top1 53.57), valid_top5 78.09
2021-11-05 10:19:55 train 0000, loss 2.261e+00, top1 44.71, top5 77.65
2021-11-05 10:20:15 train 0000, loss 1.806e+00, top1 57.65, top5 81.18
2021-11-05 10:20:15 train 0000, loss 2.488e+00, top1 36.47, top5 70.59
2021-11-05 10:33:57 train 1000, loss 2.187e+00, top1 50.71, top5 75.37
2021-11-05 10:33:57 train 1000, loss 2.203e+00, top1 50.65, top5 74.76
2021-11-05 10:33:57 train 1000, loss 2.191e+00, top1 50.65, top5 74.84
2021-11-05 10:47:49 train 2000, loss 2.207e+00, top1 50.30, top5 75.01
2021-11-05 10:47:49 train 2000, loss 2.206e+00, top1 50.54, top5 74.78
2021-11-05 10:47:49 train 2000, loss 2.201e+00, top1 50.47, top5 74.83
2021-11-05 11:01:41 train 3000, loss 2.208e+00, top1 50.32, top5 74.94
2021-11-05 11:01:41 train 3000, loss 2.212e+00, top1 50.47, top5 74.74
2021-11-05 11:01:41 train 3000, loss 2.209e+00, top1 50.37, top5 74.74
2021-11-05 11:15:26 train 4000, loss 2.211e+00, top1 50.24, top5 74.83
2021-11-05 11:15:26 train 4000, loss 2.214e+00, top1 50.39, top5 74.72
2021-11-05 11:15:27 train 4000, loss 2.215e+00, top1 50.26, top5 74.67
2021-11-05 11:29:11 train 5000, loss 2.216e+00, top1 50.32, top5 74.71
2021-11-05 11:29:11 train 5000, loss 2.213e+00, top1 50.26, top5 74.80
2021-11-05 11:29:12 train 5000, loss 2.217e+00, top1 50.24, top5 74.64
2021-11-05 11:29:41 valid 0000, loss 7.124e-01, top1 87.06, top5 91.76
2021-11-05 11:29:41 valid 0000, loss 7.124e-01, top1 87.06, top5 91.76
2021-11-05 11:29:41 valid 0000, loss 7.124e-01, top1 87.06, top5 91.76
2021-11-05 11:34:14 (JOBID 31649) epoch 24: train time 4169.98, inference time 283.04s, valid_top1 52.99 (best_top1 53.57), valid_top5 78.51
2021-11-05 11:34:15 (JOBID 31649) epoch 24: train time 4170.14, inference time 283.50s, valid_top1 52.99 (best_top1 53.57), valid_top5 78.51
2021-11-05 11:34:15 (JOBID 31649) epoch 24: train time 4189.95, inference time 283.34s, valid_top1 52.99 (best_top1 53.57), valid_top5 78.51
2021-11-05 11:34:29 train 0000, loss 2.172e+00, top1 45.88, top5 77.65
2021-11-05 11:34:29 train 0000, loss 2.506e+00, top1 41.18, top5 72.94
2021-11-05 11:34:29 train 0000, loss 2.042e+00, top1 50.59, top5 77.65
2021-11-05 11:48:22 train 1000, loss 2.211e+00, top1 50.22, top5 74.93
2021-11-05 11:48:22 train 1000, loss 2.198e+00, top1 50.74, top5 75.01
2021-11-05 11:48:22 train 1000, loss 2.193e+00, top1 50.83, top5 74.99
2021-11-05 12:02:29 train 2000, loss 2.206e+00, top1 50.56, top5 74.87
2021-11-05 12:02:29 train 2000, loss 2.215e+00, top1 50.14, top5 74.82
2021-11-05 12:02:29 train 2000, loss 2.207e+00, top1 50.52, top5 74.83
2021-11-05 12:16:14 train 3000, loss 2.208e+00, top1 50.52, top5 74.86
2021-11-05 12:16:14 train 3000, loss 2.212e+00, top1 50.25, top5 74.84
2021-11-05 12:16:14 train 3000, loss 2.211e+00, top1 50.39, top5 74.73
2021-11-05 12:30:04 train 4000, loss 2.217e+00, top1 50.19, top5 74.76
2021-11-05 12:30:04 train 4000, loss 2.212e+00, top1 50.33, top5 74.76
2021-11-05 12:30:04 train 4000, loss 2.211e+00, top1 50.46, top5 74.79
2021-11-05 12:43:54 train 5000, loss 2.219e+00, top1 50.21, top5 74.72
2021-11-05 12:43:54 train 5000, loss 2.213e+00, top1 50.35, top5 74.75
2021-11-05 12:43:54 train 5000, loss 2.213e+00, top1 50.42, top5 74.76
2021-11-05 12:44:25 valid 0000, loss 1.281e+00, top1 72.94, top5 88.24
2021-11-05 12:44:25 valid 0000, loss 1.281e+00, top1 72.94, top5 88.24
2021-11-05 12:44:25 valid 0000, loss 1.281e+00, top1 72.94, top5 88.24
2021-11-05 12:48:39 (JOBID 31649) epoch 25: train time 4199.21, inference time 264.98s, valid_top1 53.48 (best_top1 53.57), valid_top5 78.82
2021-11-05 12:48:59 (JOBID 31649) epoch 25: train time 4199.01, inference time 285.01s, valid_top1 53.48 (best_top1 53.57), valid_top5 78.82
2021-11-05 12:48:59 (JOBID 31649) epoch 25: train time 4199.56, inference time 285.58s, valid_top1 53.48 (best_top1 53.57), valid_top5 78.82
2021-11-05 12:48:53 train 0000, loss 2.294e+00, top1 47.06, top5 76.47
2021-11-05 12:49:13 train 0000, loss 2.197e+00, top1 41.18, top5 76.47
2021-11-05 12:49:13 train 0000, loss 2.101e+00, top1 48.24, top5 76.47
2021-11-05 13:03:02 train 1000, loss 2.193e+00, top1 50.61, top5 75.05
2021-11-05 13:03:02 train 1000, loss 2.218e+00, top1 50.30, top5 74.49
2021-11-05 13:03:03 train 1000, loss 2.192e+00, top1 50.79, top5 75.21
2021-11-05 13:16:50 train 2000, loss 2.207e+00, top1 50.31, top5 74.84
2021-11-05 13:16:50 train 2000, loss 2.212e+00, top1 50.49, top5 74.72
2021-11-05 13:16:50 train 2000, loss 2.201e+00, top1 50.61, top5 74.99
2021-11-05 13:30:40 train 3000, loss 2.214e+00, top1 50.20, top5 74.73
2021-11-05 13:30:40 train 3000, loss 2.212e+00, top1 50.45, top5 74.74
2021-11-05 13:30:41 train 3000, loss 2.208e+00, top1 50.47, top5 74.83
2021-11-05 13:44:34 train 4000, loss 2.214e+00, top1 50.23, top5 74.75
2021-11-05 13:44:34 train 4000, loss 2.217e+00, top1 50.36, top5 74.70
2021-11-05 13:44:34 train 4000, loss 2.211e+00, top1 50.39, top5 74.77
2021-11-05 13:58:22 train 5000, loss 2.216e+00, top1 50.24, top5 74.70
2021-11-05 13:58:22 train 5000, loss 2.220e+00, top1 50.30, top5 74.61
2021-11-05 13:58:23 train 5000, loss 2.215e+00, top1 50.32, top5 74.71
2021-11-05 13:58:55 valid 0000, loss 9.899e-01, top1 78.82, top5 92.94
2021-11-05 13:58:55 valid 0000, loss 9.899e-01, top1 78.82, top5 92.94
2021-11-05 13:58:55 valid 0000, loss 9.899e-01, top1 78.82, top5 92.94
2021-11-05 14:03:08 (JOBID 31649) epoch 26: train time 4183.54, inference time 265.39s, valid_top1 48.96 (best_top1 53.57), valid_top5 75.16
2021-11-05 14:03:25 (JOBID 31649) epoch 26: train time 4204.02, inference time 281.98s, valid_top1 48.96 (best_top1 53.57), valid_top5 75.16
2021-11-05 14:03:26 (JOBID 31649) epoch 26: train time 4183.74, inference time 282.56s, valid_top1 48.96 (best_top1 53.57), valid_top5 75.16
2021-11-05 14:03:23 train 0000, loss 2.192e+00, top1 51.76, top5 70.59
2021-11-05 14:03:39 train 0000, loss 2.051e+00, top1 57.65, top5 77.65
2021-11-05 14:03:39 train 0000, loss 2.011e+00, top1 48.24, top5 75.29
2021-11-05 14:17:34 train 1000, loss 2.195e+00, top1 50.65, top5 74.80
2021-11-05 14:17:34 train 1000, loss 2.194e+00, top1 50.62, top5 75.09
2021-11-05 14:17:35 train 1000, loss 2.192e+00, top1 50.63, top5 74.99
2021-11-05 14:31:29 train 2000, loss 2.202e+00, top1 50.60, top5 74.76
2021-11-05 14:31:29 train 2000, loss 2.203e+00, top1 50.50, top5 74.90
2021-11-05 14:31:29 train 2000, loss 2.202e+00, top1 50.48, top5 74.85
2021-11-05 14:34:52 CARME Slurm ID: 31649
2021-11-05 14:34:52 CARME Slurm ID: 31649
2021-11-05 14:34:52 CARME Slurm ID: 31649
2021-11-05 14:34:52 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=2, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-05 14:34:52 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=1, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-05 14:34:52 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=0, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-05 14:36:29 CARME Slurm ID: 31649
2021-11-05 14:36:29 CARME Slurm ID: 31649
2021-11-05 14:36:29 CARME Slurm ID: 31649
2021-11-05 14:36:29 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=1, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-05 14:36:29 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=0, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-05 14:36:29 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=2, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-05 14:36:41 Computational complexity:       2.02 GMac
2021-11-05 14:36:41 Number of parameters:           13.35 M 
2021-11-05 14:36:41 Computational complexity:       2.02 GMac
2021-11-05 14:36:41 => loading checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243'
2021-11-05 14:36:41 Computational complexity:       2.02 GMac
2021-11-05 14:36:41 Number of parameters:           13.35 M 
2021-11-05 14:36:41 Number of parameters:           13.35 M 
2021-11-05 14:36:41 => loading checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243'
2021-11-05 14:36:41 => loading checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243'
2021-11-05 14:36:41 => loaded checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243' (epoch 27)
2021-11-05 14:36:41 => loaded checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243' (epoch 27)
2021-11-05 14:36:41 => loaded checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243' (epoch 27)
2021-11-05 14:37:08 train 0000, loss 2.241e+00, top1 42.35, top5 75.29
2021-11-05 14:37:08 train 0000, loss 2.239e+00, top1 55.29, top5 70.59
2021-11-05 14:37:08 train 0000, loss 2.148e+00, top1 52.94, top5 75.29
2021-11-05 14:51:04 train 1000, loss 2.185e+00, top1 50.89, top5 75.06
2021-11-05 14:51:04 train 1000, loss 2.186e+00, top1 50.89, top5 75.02
2021-11-05 14:51:04 train 1000, loss 2.191e+00, top1 50.83, top5 75.02
2021-11-05 15:04:56 train 2000, loss 2.198e+00, top1 50.62, top5 74.95
2021-11-05 15:04:56 train 2000, loss 2.198e+00, top1 50.76, top5 74.94
2021-11-05 15:04:57 train 2000, loss 2.201e+00, top1 50.64, top5 74.84
2021-11-05 15:18:50 train 3000, loss 2.210e+00, top1 50.47, top5 74.82
2021-11-05 15:18:50 train 3000, loss 2.203e+00, top1 50.54, top5 74.90
2021-11-05 15:18:50 train 3000, loss 2.204e+00, top1 50.58, top5 74.86
2021-11-05 15:32:47 train 4000, loss 2.216e+00, top1 50.37, top5 74.72
2021-11-05 15:32:47 train 4000, loss 2.208e+00, top1 50.44, top5 74.81
2021-11-05 15:32:47 train 4000, loss 2.210e+00, top1 50.42, top5 74.79
2021-11-05 15:46:37 train 5000, loss 2.214e+00, top1 50.34, top5 74.75
2021-11-05 15:46:37 train 5000, loss 2.217e+00, top1 50.33, top5 74.69
2021-11-05 15:46:37 train 5000, loss 2.215e+00, top1 50.32, top5 74.73
2021-11-05 15:47:10 valid 0000, loss 7.516e-01, top1 82.35, top5 94.12
2021-11-05 15:47:10 valid 0000, loss 7.516e-01, top1 82.35, top5 94.12
2021-11-05 15:47:10 valid 0000, loss 7.516e-01, top1 82.35, top5 94.12
2021-11-05 15:51:41 (JOBID 31649) epoch 27: train time 4213.38, inference time 281.30s, valid_top1 52.49 (best_top1 53.57), valid_top5 78.50
2021-11-05 15:51:44 (JOBID 31649) epoch 27: train time 4213.38, inference time 284.43s, valid_top1 52.49 (best_top1 53.57), valid_top5 78.50
2021-11-05 15:51:47 (JOBID 31649) epoch 27: train time 4213.39, inference time 286.90s, valid_top1 52.49 (best_top1 53.57), valid_top5 78.50
2021-11-05 15:52:00 train 0000, loss 1.896e+00, top1 56.47, top5 82.35
2021-11-05 15:51:56 train 0000, loss 2.171e+00, top1 57.65, top5 78.82
2021-11-05 15:52:02 train 0000, loss 2.706e+00, top1 49.41, top5 63.53
2021-11-05 16:05:53 train 1000, loss 2.201e+00, top1 50.34, top5 74.96
2021-11-05 16:05:53 train 1000, loss 2.202e+00, top1 50.46, top5 74.90
2021-11-05 16:05:54 train 1000, loss 2.214e+00, top1 50.42, top5 74.74
2021-11-05 16:20:11 train 2000, loss 2.209e+00, top1 50.38, top5 74.85
2021-11-05 16:20:11 train 2000, loss 2.207e+00, top1 50.42, top5 74.84
2021-11-05 16:20:11 train 2000, loss 2.207e+00, top1 50.51, top5 74.84
2021-11-05 16:35:52 train 3000, loss 2.210e+00, top1 50.45, top5 74.79
2021-11-05 16:35:52 train 3000, loss 2.207e+00, top1 50.43, top5 74.81
2021-11-05 16:35:52 train 3000, loss 2.212e+00, top1 50.32, top5 74.77
2021-11-05 16:49:33 train 4000, loss 2.214e+00, top1 50.33, top5 74.74
2021-11-05 16:49:33 train 4000, loss 2.212e+00, top1 50.39, top5 74.75
2021-11-05 16:49:34 train 4000, loss 2.213e+00, top1 50.41, top5 74.72
2021-11-05 17:03:16 train 5000, loss 2.215e+00, top1 50.33, top5 74.68
2021-11-05 17:03:15 train 5000, loss 2.219e+00, top1 50.27, top5 74.67
2021-11-05 17:03:16 train 5000, loss 2.213e+00, top1 50.37, top5 74.71
2021-11-05 17:03:47 valid 0000, loss 1.417e+00, top1 69.41, top5 83.53
2021-11-05 17:03:47 valid 0000, loss 1.417e+00, top1 69.41, top5 83.53
2021-11-05 17:03:47 valid 0000, loss 1.417e+00, top1 69.41, top5 83.53
2021-11-05 17:07:59 (JOBID 31649) epoch 28: train time 4311.05, inference time 263.36s, valid_top1 52.44 (best_top1 53.57), valid_top5 77.80
2021-11-05 17:08:23 (JOBID 31649) epoch 28: train time 4308.59, inference time 287.77s, valid_top1 52.44 (best_top1 53.57), valid_top5 77.80
2021-11-05 17:08:25 (JOBID 31649) epoch 28: train time 4314.24, inference time 288.76s, valid_top1 52.44 (best_top1 53.57), valid_top5 77.80
2021-11-05 17:08:38 train 0000, loss 2.112e+00, top1 49.41, top5 72.94
2021-11-05 17:08:13 train 0000, loss 2.233e+00, top1 48.24, top5 75.29
2021-11-05 17:08:40 train 0000, loss 1.778e+00, top1 56.47, top5 83.53
2021-11-05 17:23:14 train 1000, loss 2.195e+00, top1 50.63, top5 74.99
2021-11-05 17:23:14 train 1000, loss 2.205e+00, top1 50.36, top5 74.90
2021-11-05 17:23:14 train 1000, loss 2.206e+00, top1 50.44, top5 74.74
2021-11-05 17:37:02 train 2000, loss 2.207e+00, top1 50.44, top5 74.85
2021-11-05 17:37:02 train 2000, loss 2.210e+00, top1 50.42, top5 74.76
2021-11-05 17:37:03 train 2000, loss 2.201e+00, top1 50.67, top5 74.92
2021-11-05 17:50:44 train 3000, loss 2.213e+00, top1 50.31, top5 74.71
2021-11-05 17:50:44 train 3000, loss 2.216e+00, top1 50.25, top5 74.77
2021-11-05 17:50:44 train 3000, loss 2.208e+00, top1 50.53, top5 74.74
2021-11-05 18:05:24 train 4000, loss 2.213e+00, top1 50.29, top5 74.72
2021-11-05 18:05:24 train 4000, loss 2.216e+00, top1 50.24, top5 74.77
2021-11-05 18:05:24 train 4000, loss 2.211e+00, top1 50.47, top5 74.65
2021-11-05 18:19:11 train 5000, loss 2.215e+00, top1 50.29, top5 74.68
2021-11-05 18:19:11 train 5000, loss 2.220e+00, top1 50.18, top5 74.70
2021-11-05 18:19:12 train 5000, loss 2.217e+00, top1 50.37, top5 74.60
2021-11-05 18:19:41 valid 0000, loss 1.321e+00, top1 72.94, top5 84.71
2021-11-05 18:19:41 valid 0000, loss 1.321e+00, top1 72.94, top5 84.71
2021-11-05 18:19:41 valid 0000, loss 1.321e+00, top1 72.94, top5 84.71
2021-11-05 18:24:13 (JOBID 31649) epoch 29: train time 4292.64, inference time 281.66s, valid_top1 53.89 (best_top1 53.89), valid_top5 79.19
2021-11-05 18:24:14 (JOBID 31649) epoch 29: train time 4266.63, inference time 282.00s, valid_top1 53.89 (best_top1 53.89), valid_top5 79.19
2021-11-05 18:24:15 (JOBID 31649) epoch 29: train time 4268.45, inference time 283.37s, valid_top1 53.89 (best_top1 53.89), valid_top5 79.19
2021-11-05 18:24:28 train 0000, loss 2.059e+00, top1 48.24, top5 75.29
2021-11-05 18:24:28 train 0000, loss 2.049e+00, top1 56.47, top5 80.00
2021-11-05 18:24:28 train 0000, loss 1.824e+00, top1 57.65, top5 77.65
2021-11-05 18:38:18 train 1000, loss 1.808e+00, top1 58.46, top5 80.63
2021-11-05 18:38:18 train 1000, loss 1.797e+00, top1 58.73, top5 80.78
2021-11-05 18:38:18 train 1000, loss 1.800e+00, top1 58.81, top5 80.79
2021-11-05 18:52:11 train 2000, loss 1.755e+00, top1 59.50, top5 81.41
2021-11-05 18:52:11 train 2000, loss 1.743e+00, top1 59.95, top5 81.50
2021-11-05 18:52:11 train 2000, loss 1.748e+00, top1 59.83, top5 81.49
2021-11-05 19:05:56 train 3000, loss 1.722e+00, top1 60.28, top5 81.89
2021-11-05 19:05:56 train 3000, loss 1.713e+00, top1 60.52, top5 81.97
2021-11-05 19:05:56 train 3000, loss 1.715e+00, top1 60.57, top5 81.96
2021-11-05 19:19:46 train 4000, loss 1.694e+00, top1 60.89, top5 82.24
2021-11-05 19:19:46 train 4000, loss 1.699e+00, top1 60.73, top5 82.22
2021-11-05 19:19:46 train 4000, loss 1.695e+00, top1 60.95, top5 82.21
2021-11-05 19:33:33 train 5000, loss 1.681e+00, top1 61.08, top5 82.46
2021-11-05 19:33:33 train 5000, loss 1.678e+00, top1 61.21, top5 82.46
2021-11-05 19:33:33 train 5000, loss 1.679e+00, top1 61.26, top5 82.45
2021-11-05 19:34:02 valid 0000, loss 6.417e-01, top1 84.71, top5 94.12
2021-11-05 19:34:02 valid 0000, loss 6.417e-01, top1 84.71, top5 94.12
2021-11-05 19:34:02 valid 0000, loss 6.417e-01, top1 84.71, top5 94.12
2021-11-05 19:38:34 (JOBID 31649) epoch 30: train time 4177.52, inference time 281.74s, valid_top1 67.64 (best_top1 67.64), valid_top5 88.28
2021-11-05 19:38:35 (JOBID 31649) epoch 30: train time 4178.54, inference time 282.23s, valid_top1 67.64 (best_top1 67.64), valid_top5 88.28
2021-11-05 19:38:38 (JOBID 31649) epoch 30: train time 4179.45, inference time 285.29s, valid_top1 67.64 (best_top1 67.64), valid_top5 88.28
2021-11-05 19:38:49 train 0000, loss 1.139e+00, top1 68.24, top5 90.59
2021-11-05 19:38:49 train 0000, loss 1.688e+00, top1 57.65, top5 81.18
2021-11-05 19:38:52 train 0000, loss 1.550e+00, top1 71.76, top5 85.88
2021-11-05 19:52:46 train 1000, loss 1.586e+00, top1 63.14, top5 83.76
2021-11-05 19:52:46 train 1000, loss 1.586e+00, top1 63.12, top5 83.68
2021-11-05 19:52:46 train 1000, loss 1.574e+00, top1 63.29, top5 83.84
2021-11-05 20:06:35 train 2000, loss 1.583e+00, top1 63.20, top5 83.76
2021-11-05 20:06:35 train 2000, loss 1.577e+00, top1 63.20, top5 83.85
2021-11-05 20:06:35 train 2000, loss 1.576e+00, top1 63.30, top5 83.85
2021-11-05 20:20:26 train 3000, loss 1.576e+00, top1 63.29, top5 83.83
2021-11-05 20:20:26 train 3000, loss 1.572e+00, top1 63.30, top5 83.89
2021-11-05 20:20:26 train 3000, loss 1.573e+00, top1 63.38, top5 83.87
2021-11-05 20:34:14 train 4000, loss 1.568e+00, top1 63.44, top5 83.97
2021-11-05 20:34:14 train 4000, loss 1.569e+00, top1 63.37, top5 83.95
2021-11-05 20:34:14 train 4000, loss 1.571e+00, top1 63.41, top5 83.91
2021-11-05 20:47:58 train 5000, loss 1.567e+00, top1 63.40, top5 83.98
2021-11-05 20:47:58 train 5000, loss 1.563e+00, top1 63.55, top5 84.05
2021-11-05 20:47:58 train 5000, loss 1.567e+00, top1 63.48, top5 83.97
2021-11-05 20:48:28 valid 0000, loss 6.265e-01, top1 84.71, top5 94.12
2021-11-05 20:48:28 valid 0000, loss 6.265e-01, top1 84.71, top5 94.12
2021-11-05 20:48:28 valid 0000, loss 6.265e-01, top1 84.71, top5 94.12
2021-11-05 20:52:41 (JOBID 31649) epoch 31: train time 4184.23, inference time 262.46s, valid_top1 68.92 (best_top1 68.92), valid_top5 89.08
2021-11-05 20:53:03 (JOBID 31649) epoch 31: train time 4180.69, inference time 284.26s, valid_top1 68.92 (best_top1 68.92), valid_top5 89.08
2021-11-05 20:53:04 (JOBID 31649) epoch 31: train time 4183.38, inference time 284.96s, valid_top1 68.92 (best_top1 68.92), valid_top5 89.08
2021-11-05 20:52:55 train 0000, loss 1.438e+00, top1 65.88, top5 84.71
2021-11-05 20:53:17 train 0000, loss 1.679e+00, top1 61.18, top5 81.18
2021-11-05 20:53:17 train 0000, loss 1.607e+00, top1 62.35, top5 85.88
2021-11-05 21:07:12 train 1000, loss 1.504e+00, top1 64.68, top5 84.87
2021-11-05 21:07:12 train 1000, loss 1.518e+00, top1 64.43, top5 84.70
2021-11-05 21:07:13 train 1000, loss 1.518e+00, top1 64.47, top5 84.67
2021-11-05 21:21:01 train 2000, loss 1.507e+00, top1 64.68, top5 84.74
2021-11-05 21:21:01 train 2000, loss 1.523e+00, top1 64.29, top5 84.64
2021-11-05 21:21:01 train 2000, loss 1.525e+00, top1 64.28, top5 84.57
2021-11-05 21:34:55 train 3000, loss 1.524e+00, top1 64.30, top5 84.64
2021-11-05 21:34:55 train 3000, loss 1.512e+00, top1 64.61, top5 84.68
2021-11-05 21:34:55 train 3000, loss 1.523e+00, top1 64.31, top5 84.63
2021-11-05 21:50:16 train 4000, loss 1.524e+00, top1 64.34, top5 84.62
2021-11-05 21:50:16 train 4000, loss 1.515e+00, top1 64.52, top5 84.65
2021-11-05 21:50:16 train 4000, loss 1.523e+00, top1 64.28, top5 84.63
2021-11-05 22:06:27 train 5000, loss 1.519e+00, top1 64.37, top5 84.68
2021-11-05 22:06:27 train 5000, loss 1.523e+00, top1 64.29, top5 84.64
2021-11-05 22:06:27 train 5000, loss 1.518e+00, top1 64.45, top5 84.62
2021-11-05 22:06:57 valid 0000, loss 5.793e-01, top1 87.06, top5 94.12
2021-11-05 22:06:57 valid 0000, loss 5.793e-01, top1 87.06, top5 94.12
2021-11-05 22:06:57 valid 0000, loss 5.793e-01, top1 87.06, top5 94.12
2021-11-05 22:11:07 (JOBID 31649) epoch 32: train time 4445.79, inference time 260.70s, valid_top1 68.95 (best_top1 68.95), valid_top5 89.24
2021-11-05 22:11:29 (JOBID 31649) epoch 32: train time 4424.00, inference time 282.20s, valid_top1 68.95 (best_top1 68.95), valid_top5 89.24
2021-11-05 22:11:36 (JOBID 31649) epoch 32: train time 4422.85, inference time 288.08s, valid_top1 68.95 (best_top1 68.95), valid_top5 89.24
2021-11-05 22:11:43 train 0000, loss 1.607e+00, top1 64.71, top5 83.53
2021-11-05 22:11:21 train 0000, loss 1.623e+00, top1 65.88, top5 82.35
2021-11-05 22:11:49 train 0000, loss 1.326e+00, top1 65.88, top5 88.24
2021-11-05 22:25:36 train 1000, loss 1.502e+00, top1 64.74, top5 84.89
2021-11-05 22:25:36 train 1000, loss 1.494e+00, top1 64.86, top5 85.04
2021-11-05 22:25:36 train 1000, loss 1.487e+00, top1 65.12, top5 85.26
2021-11-05 22:39:25 train 2000, loss 1.503e+00, top1 64.73, top5 84.89
2021-11-05 22:39:25 train 2000, loss 1.494e+00, top1 64.85, top5 85.05
2021-11-05 22:39:25 train 2000, loss 1.490e+00, top1 64.98, top5 85.15
2021-11-05 22:53:15 train 3000, loss 1.501e+00, top1 64.72, top5 84.93
2021-11-05 22:53:15 train 3000, loss 1.495e+00, top1 64.86, top5 85.02
2021-11-05 22:53:15 train 3000, loss 1.495e+00, top1 64.90, top5 85.06
2021-11-05 23:07:03 train 4000, loss 1.501e+00, top1 64.72, top5 84.93
2021-11-05 23:07:03 train 4000, loss 1.497e+00, top1 64.81, top5 84.99
2021-11-05 23:07:03 train 4000, loss 1.498e+00, top1 64.84, top5 85.00
2021-11-05 23:20:54 train 5000, loss 1.499e+00, top1 64.77, top5 84.93
2021-11-05 23:20:54 train 5000, loss 1.498e+00, top1 64.75, top5 84.96
2021-11-05 23:20:54 train 5000, loss 1.496e+00, top1 64.91, top5 85.03
2021-11-05 23:21:25 valid 0000, loss 4.648e-01, top1 91.76, top5 96.47
2021-11-05 23:21:25 valid 0000, loss 4.648e-01, top1 91.76, top5 96.47
2021-11-05 23:21:25 valid 0000, loss 4.648e-01, top1 91.76, top5 96.47
2021-11-05 23:25:54 (JOBID 31649) epoch 33: train time 4184.95, inference time 280.26s, valid_top1 69.24 (best_top1 69.24), valid_top5 89.17
2021-11-05 23:25:55 (JOBID 31649) epoch 33: train time 4206.52, inference time 281.39s, valid_top1 69.24 (best_top1 69.24), valid_top5 89.17
2021-11-05 23:25:56 (JOBID 31649) epoch 33: train time 4178.46, inference time 280.83s, valid_top1 69.24 (best_top1 69.24), valid_top5 89.17
2021-11-05 23:26:09 train 0000, loss 1.364e+00, top1 67.06, top5 85.88
2021-11-05 23:26:09 train 0000, loss 1.394e+00, top1 62.35, top5 88.24
2021-11-05 23:26:09 train 0000, loss 1.557e+00, top1 64.71, top5 87.06
2021-11-05 23:39:53 train 1000, loss 1.477e+00, top1 65.43, top5 85.20
2021-11-05 23:39:53 train 1000, loss 1.469e+00, top1 65.44, top5 85.40
2021-11-05 23:39:53 train 1000, loss 1.472e+00, top1 65.35, top5 85.31
2021-11-05 23:53:37 train 2000, loss 1.475e+00, top1 65.42, top5 85.31
2021-11-05 23:53:37 train 2000, loss 1.475e+00, top1 65.28, top5 85.26
2021-11-05 23:53:37 train 2000, loss 1.481e+00, top1 65.13, top5 85.14
2021-11-06 00:07:18 train 3000, loss 1.478e+00, top1 65.26, top5 85.25
2021-11-06 00:07:18 train 3000, loss 1.481e+00, top1 65.26, top5 85.22
2021-11-06 00:07:19 train 3000, loss 1.477e+00, top1 65.25, top5 85.21
2021-11-06 00:21:00 train 4000, loss 1.483e+00, top1 65.21, top5 85.17
2021-11-06 00:21:00 train 4000, loss 1.479e+00, top1 65.20, top5 85.27
2021-11-06 00:21:00 train 4000, loss 1.477e+00, top1 65.20, top5 85.19
2021-11-06 00:34:49 train 5000, loss 1.484e+00, top1 65.20, top5 85.15
2021-11-06 00:34:49 train 5000, loss 1.480e+00, top1 65.16, top5 85.25
2021-11-06 00:34:50 train 5000, loss 1.478e+00, top1 65.19, top5 85.19
2021-11-06 00:35:19 valid 0000, loss 5.572e-01, top1 87.06, top5 96.47
2021-11-06 00:35:19 valid 0000, loss 5.572e-01, top1 87.06, top5 96.47
2021-11-06 00:35:19 valid 0000, loss 5.572e-01, top1 87.06, top5 96.47
2021-11-06 00:39:49 (JOBID 31649) epoch 34: train time 4153.43, inference time 279.33s, valid_top1 69.35 (best_top1 69.35), valid_top5 89.40
2021-11-06 00:39:49 (JOBID 31649) epoch 34: train time 4153.68, inference time 280.16s, valid_top1 69.35 (best_top1 69.35), valid_top5 89.40
2021-11-06 00:39:50 (JOBID 31649) epoch 34: train time 4155.02, inference time 280.47s, valid_top1 69.35 (best_top1 69.35), valid_top5 89.40
2021-11-06 00:40:04 train 0000, loss 1.903e+00, top1 60.00, top5 76.47
2021-11-06 00:40:04 train 0000, loss 1.263e+00, top1 69.41, top5 88.24
2021-11-06 00:40:04 train 0000, loss 1.442e+00, top1 64.71, top5 88.24
2021-11-06 00:53:51 train 1000, loss 1.454e+00, top1 65.70, top5 85.54
2021-11-06 00:53:51 train 1000, loss 1.460e+00, top1 65.51, top5 85.62
2021-11-06 00:53:51 train 1000, loss 1.458e+00, top1 65.60, top5 85.49
2021-11-06 01:07:29 train 2000, loss 1.458e+00, top1 65.68, top5 85.47
2021-11-06 01:07:29 train 2000, loss 1.461e+00, top1 65.61, top5 85.45
2021-11-06 01:07:29 train 2000, loss 1.463e+00, top1 65.51, top5 85.54
2021-11-06 01:21:16 train 3000, loss 1.461e+00, top1 65.56, top5 85.47
2021-11-06 01:21:16 train 3000, loss 1.467e+00, top1 65.51, top5 85.39
2021-11-06 01:21:16 train 3000, loss 1.465e+00, top1 65.47, top5 85.49
2021-11-06 01:35:00 train 4000, loss 1.464e+00, top1 65.51, top5 85.45
2021-11-06 01:35:00 train 4000, loss 1.468e+00, top1 65.43, top5 85.39
2021-11-06 01:35:01 train 4000, loss 1.468e+00, top1 65.42, top5 85.43
2021-11-06 01:48:41 train 5000, loss 1.467e+00, top1 65.46, top5 85.39
2021-11-06 01:48:41 train 5000, loss 1.471e+00, top1 65.42, top5 85.32
2021-11-06 01:48:41 train 5000, loss 1.471e+00, top1 65.33, top5 85.40
2021-11-06 01:49:11 valid 0000, loss 5.789e-01, top1 89.41, top5 96.47
2021-11-06 01:49:11 valid 0000, loss 5.789e-01, top1 89.41, top5 96.47
2021-11-06 01:49:11 valid 0000, loss 5.789e-01, top1 89.41, top5 96.47
2021-11-06 01:53:41 (JOBID 31649) epoch 35: train time 4151.60, inference time 279.93s, valid_top1 69.64 (best_top1 69.64), valid_top5 89.57
2021-11-06 01:53:42 (JOBID 31649) epoch 35: train time 4152.00, inference time 280.17s, valid_top1 69.64 (best_top1 69.64), valid_top5 89.57
2021-11-06 01:53:43 (JOBID 31649) epoch 35: train time 4151.14, inference time 282.01s, valid_top1 69.64 (best_top1 69.64), valid_top5 89.57
2021-11-06 01:53:55 train 0000, loss 1.735e+00, top1 64.71, top5 83.53
2021-11-06 01:53:57 train 0000, loss 1.650e+00, top1 61.18, top5 80.00
2021-11-06 01:53:57 train 0000, loss 1.756e+00, top1 58.82, top5 80.00
2021-11-06 02:07:45 train 1000, loss 1.449e+00, top1 65.91, top5 85.69
2021-11-06 02:07:45 train 1000, loss 1.458e+00, top1 65.60, top5 85.54
2021-11-06 02:07:45 train 1000, loss 1.443e+00, top1 65.98, top5 85.77
2021-11-06 02:21:32 train 2000, loss 1.455e+00, top1 65.72, top5 85.49
2021-11-06 02:21:32 train 2000, loss 1.451e+00, top1 65.77, top5 85.67
2021-11-06 02:21:32 train 2000, loss 1.460e+00, top1 65.59, top5 85.53
2021-11-06 02:35:15 train 3000, loss 1.459e+00, top1 65.61, top5 85.47
2021-11-06 02:35:16 train 3000, loss 1.460e+00, top1 65.68, top5 85.50
2021-11-06 02:35:16 train 3000, loss 1.459e+00, top1 65.51, top5 85.59
2021-11-06 02:48:57 train 4000, loss 1.462e+00, top1 65.61, top5 85.46
2021-11-06 02:48:57 train 4000, loss 1.460e+00, top1 65.61, top5 85.43
2021-11-06 02:48:57 train 4000, loss 1.460e+00, top1 65.49, top5 85.57
2021-11-06 03:02:41 train 5000, loss 1.464e+00, top1 65.56, top5 85.42
2021-11-06 03:02:41 train 5000, loss 1.461e+00, top1 65.62, top5 85.43
2021-11-06 03:02:41 train 5000, loss 1.462e+00, top1 65.46, top5 85.54
2021-11-06 03:03:11 valid 0000, loss 5.050e-01, top1 90.59, top5 96.47
2021-11-06 03:03:11 valid 0000, loss 5.050e-01, top1 90.59, top5 96.47
2021-11-06 03:03:11 valid 0000, loss 5.050e-01, top1 90.59, top5 96.47
2021-11-06 03:07:55 (JOBID 31649) epoch 36: train time 4160.05, inference time 294.18s, valid_top1 69.66 (best_top1 69.66), valid_top5 89.57
2021-11-06 03:07:57 (JOBID 31649) epoch 36: train time 4159.09, inference time 295.12s, valid_top1 69.66 (best_top1 69.66), valid_top5 89.57
2021-11-06 03:07:57 (JOBID 31649) epoch 36: train time 4157.98, inference time 296.38s, valid_top1 69.66 (best_top1 69.66), valid_top5 89.57
2021-11-06 03:08:10 train 0000, loss 1.321e+00, top1 68.24, top5 89.41
2021-11-06 03:08:11 train 0000, loss 1.467e+00, top1 68.24, top5 88.24
2021-11-06 03:08:11 train 0000, loss 1.130e+00, top1 70.59, top5 88.24
2021-11-06 03:22:02 train 1000, loss 1.444e+00, top1 65.79, top5 85.75
2021-11-06 03:22:02 train 1000, loss 1.447e+00, top1 65.73, top5 85.81
2021-11-06 03:22:02 train 1000, loss 1.452e+00, top1 65.92, top5 85.65
2021-11-06 03:35:56 train 2000, loss 1.453e+00, top1 65.63, top5 85.61
2021-11-06 03:35:56 train 2000, loss 1.456e+00, top1 65.65, top5 85.61
2021-11-06 03:35:56 train 2000, loss 1.448e+00, top1 65.93, top5 85.60
2021-11-06 03:49:48 train 3000, loss 1.462e+00, top1 65.53, top5 85.49
2021-11-06 03:49:48 train 3000, loss 1.460e+00, top1 65.47, top5 85.54
2021-11-06 03:49:48 train 3000, loss 1.453e+00, top1 65.79, top5 85.54
2021-11-06 04:03:45 train 4000, loss 1.460e+00, top1 65.53, top5 85.50
2021-11-06 04:03:45 train 4000, loss 1.464e+00, top1 65.52, top5 85.45
2021-11-06 04:03:45 train 4000, loss 1.456e+00, top1 65.71, top5 85.51
2021-11-06 04:17:28 train 5000, loss 1.463e+00, top1 65.51, top5 85.46
2021-11-06 04:17:28 train 5000, loss 1.464e+00, top1 65.54, top5 85.43
2021-11-06 04:17:28 train 5000, loss 1.459e+00, top1 65.67, top5 85.47
2021-11-06 04:18:00 valid 0000, loss 7.112e-01, top1 84.71, top5 92.94
2021-11-06 04:18:00 valid 0000, loss 7.112e-01, top1 84.71, top5 92.94
2021-11-06 04:18:00 valid 0000, loss 7.112e-01, top1 84.71, top5 92.94
2021-11-06 04:22:04 (JOBID 31649) epoch 37: train time 4191.77, inference time 255.00s, valid_top1 69.24 (best_top1 69.66), valid_top5 89.29
2021-11-06 04:22:42 (JOBID 31649) epoch 37: train time 4191.48, inference time 293.46s, valid_top1 69.24 (best_top1 69.66), valid_top5 89.29
2021-11-06 04:22:43 (JOBID 31649) epoch 37: train time 4193.53, inference time 294.20s, valid_top1 69.24 (best_top1 69.66), valid_top5 89.29
2021-11-06 04:22:18 train 0000, loss 1.723e+00, top1 58.82, top5 87.06
2021-11-06 04:22:56 train 0000, loss 1.319e+00, top1 74.12, top5 89.41
2021-11-06 04:22:56 train 0000, loss 1.914e+00, top1 57.65, top5 77.65
2021-11-06 04:36:42 train 1000, loss 1.440e+00, top1 65.97, top5 85.73
2021-11-06 04:36:42 train 1000, loss 1.450e+00, top1 65.89, top5 85.59
2021-11-06 04:36:42 train 1000, loss 1.447e+00, top1 65.89, top5 85.66
2021-11-06 04:50:32 train 2000, loss 1.450e+00, top1 65.71, top5 85.67
2021-11-06 04:50:32 train 2000, loss 1.452e+00, top1 65.86, top5 85.54
2021-11-06 04:50:32 train 2000, loss 1.450e+00, top1 65.90, top5 85.61
2021-11-06 05:04:24 train 3000, loss 1.454e+00, top1 65.68, top5 85.59
2021-11-06 05:04:24 train 3000, loss 1.456e+00, top1 65.77, top5 85.49
2021-11-06 05:04:24 train 3000, loss 1.461e+00, top1 65.70, top5 85.45
2021-11-06 05:18:11 train 4000, loss 1.457e+00, top1 65.62, top5 85.55
2021-11-06 05:18:11 train 4000, loss 1.460e+00, top1 65.62, top5 85.46
2021-11-06 05:18:11 train 4000, loss 1.465e+00, top1 65.61, top5 85.39
2021-11-06 05:32:04 train 5000, loss 1.460e+00, top1 65.59, top5 85.47
2021-11-06 05:32:04 train 5000, loss 1.459e+00, top1 65.58, top5 85.54
2021-11-06 05:32:05 train 5000, loss 1.467e+00, top1 65.56, top5 85.38
2021-11-06 05:32:35 valid 0000, loss 5.047e-01, top1 89.41, top5 95.29
2021-11-06 05:32:35 valid 0000, loss 5.047e-01, top1 89.41, top5 95.29
2021-11-06 05:32:35 valid 0000, loss 5.047e-01, top1 89.41, top5 95.29
2021-11-06 05:36:52 (JOBID 31649) epoch 38: train time 4220.72, inference time 266.98s, valid_top1 69.38 (best_top1 69.66), valid_top5 89.31
2021-11-06 05:37:04 (JOBID 31649) epoch 38: train time 4181.73, inference time 280.13s, valid_top1 69.38 (best_top1 69.66), valid_top5 89.31
2021-11-06 05:37:09 (JOBID 31649) epoch 38: train time 4182.31, inference time 284.72s, valid_top1 69.38 (best_top1 69.66), valid_top5 89.31
2021-11-06 05:37:19 train 0000, loss 1.447e+00, top1 67.06, top5 85.88
2021-11-06 05:37:06 train 0000, loss 1.101e+00, top1 74.12, top5 85.88
2021-11-06 05:37:23 train 0000, loss 1.599e+00, top1 69.41, top5 82.35
2021-11-06 05:51:05 train 1000, loss 1.444e+00, top1 66.07, top5 85.86
2021-11-06 05:51:05 train 1000, loss 1.446e+00, top1 65.79, top5 85.55
2021-11-06 05:51:06 train 1000, loss 1.443e+00, top1 65.95, top5 85.74
2021-11-06 06:04:42 train 2000, loss 1.450e+00, top1 65.75, top5 85.64
2021-11-06 06:04:42 train 2000, loss 1.450e+00, top1 65.78, top5 85.75
2021-11-06 06:04:43 train 2000, loss 1.451e+00, top1 65.83, top5 85.57
2021-11-06 06:18:23 train 3000, loss 1.453e+00, top1 65.75, top5 85.67
2021-11-06 06:18:23 train 3000, loss 1.452e+00, top1 65.72, top5 85.64
2021-11-06 06:18:23 train 3000, loss 1.455e+00, top1 65.72, top5 85.54
2021-11-06 06:32:06 train 4000, loss 1.457e+00, top1 65.58, top5 85.55
2021-11-06 06:32:06 train 4000, loss 1.457e+00, top1 65.62, top5 85.50
2021-11-06 06:32:06 train 4000, loss 1.456e+00, top1 65.67, top5 85.66
2021-11-06 06:45:43 train 5000, loss 1.461e+00, top1 65.57, top5 85.47
2021-11-06 06:45:43 train 5000, loss 1.458e+00, top1 65.57, top5 85.63
2021-11-06 06:45:43 train 5000, loss 1.459e+00, top1 65.55, top5 85.52
2021-11-06 06:46:13 valid 0000, loss 4.007e-01, top1 91.76, top5 97.65
2021-11-06 06:46:13 valid 0000, loss 4.007e-01, top1 91.76, top5 97.65
2021-11-06 06:46:13 valid 0000, loss 4.007e-01, top1 91.76, top5 97.65
2021-11-06 06:50:50 (JOBID 31649) epoch 39: train time 4137.99, inference time 287.10s, valid_top1 68.51 (best_top1 69.66), valid_top5 89.01
2021-11-06 06:50:50 (JOBID 31649) epoch 39: train time 4133.35, inference time 287.15s, valid_top1 68.51 (best_top1 69.66), valid_top5 89.01
2021-11-06 06:50:50 (JOBID 31649) epoch 39: train time 4150.77, inference time 287.10s, valid_top1 68.51 (best_top1 69.66), valid_top5 89.01
2021-11-06 06:51:05 train 0000, loss 1.479e+00, top1 69.41, top5 85.88
2021-11-06 06:51:05 train 0000, loss 1.835e+00, top1 58.82, top5 78.82
2021-11-06 06:51:05 train 0000, loss 1.447e+00, top1 68.24, top5 82.35
2021-11-06 07:04:53 train 1000, loss 1.439e+00, top1 65.98, top5 85.88
2021-11-06 07:04:53 train 1000, loss 1.437e+00, top1 65.97, top5 85.90
2021-11-06 07:04:53 train 1000, loss 1.436e+00, top1 65.88, top5 85.80
2021-11-06 07:18:44 train 2000, loss 1.447e+00, top1 65.77, top5 85.73
2021-11-06 07:18:45 train 2000, loss 1.444e+00, top1 65.91, top5 85.78
2021-11-06 07:18:45 train 2000, loss 1.446e+00, top1 65.82, top5 85.58
2021-11-06 07:32:26 train 3000, loss 1.455e+00, top1 65.69, top5 85.63
2021-11-06 07:32:26 train 3000, loss 1.452e+00, top1 65.65, top5 85.65
2021-11-06 07:32:26 train 3000, loss 1.449e+00, top1 65.74, top5 85.55
2021-11-06 07:46:10 train 4000, loss 1.458e+00, top1 65.59, top5 85.52
2021-11-06 07:46:10 train 4000, loss 1.460e+00, top1 65.59, top5 85.52
2021-11-06 07:46:10 train 4000, loss 1.454e+00, top1 65.65, top5 85.52
2021-11-06 07:59:57 train 5000, loss 1.464e+00, top1 65.55, top5 85.45
2021-11-06 07:59:57 train 5000, loss 1.463e+00, top1 65.49, top5 85.47
2021-11-06 07:59:57 train 5000, loss 1.460e+00, top1 65.53, top5 85.46
2021-11-06 08:00:27 valid 0000, loss 6.237e-01, top1 85.88, top5 95.29
2021-11-06 08:00:27 valid 0000, loss 6.237e-01, top1 85.88, top5 95.29
2021-11-06 08:00:27 valid 0000, loss 6.237e-01, top1 85.88, top5 95.29
2021-11-06 08:05:05 (JOBID 31649) epoch 40: train time 4167.18, inference time 288.53s, valid_top1 68.82 (best_top1 69.66), valid_top5 89.01
2021-11-06 08:05:19 (JOBID 31649) epoch 40: train time 4167.01, inference time 301.39s, valid_top1 68.82 (best_top1 69.66), valid_top5 89.01
2021-11-06 08:05:21 (JOBID 31649) epoch 40: train time 4167.18, inference time 303.94s, valid_top1 68.82 (best_top1 69.66), valid_top5 89.01
2021-11-06 08:05:33 train 0000, loss 1.080e+00, top1 76.47, top5 91.76
2021-11-06 08:05:19 train 0000, loss 1.675e+00, top1 62.35, top5 88.24
2021-11-06 08:05:35 train 0000, loss 1.515e+00, top1 60.00, top5 85.88
2021-11-06 08:19:28 train 1000, loss 1.438e+00, top1 65.96, top5 85.74
2021-11-06 08:19:28 train 1000, loss 1.448e+00, top1 65.94, top5 85.56
2021-11-06 08:19:29 train 1000, loss 1.446e+00, top1 65.70, top5 85.69
2021-11-06 08:33:12 train 2000, loss 1.450e+00, top1 65.69, top5 85.64
2021-11-06 08:33:12 train 2000, loss 1.445e+00, top1 65.87, top5 85.67
2021-11-06 08:33:12 train 2000, loss 1.451e+00, top1 65.72, top5 85.67
2021-11-06 08:46:59 train 3000, loss 1.449e+00, top1 65.72, top5 85.65
2021-11-06 08:46:59 train 3000, loss 1.452e+00, top1 65.69, top5 85.63
2021-11-06 08:46:59 train 3000, loss 1.459e+00, top1 65.57, top5 85.58
2021-11-06 09:01:01 train 4000, loss 1.456e+00, top1 65.58, top5 85.54
2021-11-06 09:01:01 train 4000, loss 1.455e+00, top1 65.62, top5 85.55
2021-11-06 09:01:01 train 4000, loss 1.464e+00, top1 65.46, top5 85.49
2021-11-06 09:14:43 train 5000, loss 1.460e+00, top1 65.50, top5 85.49
2021-11-06 09:14:43 train 5000, loss 1.461e+00, top1 65.47, top5 85.47
2021-11-06 09:14:43 train 5000, loss 1.466e+00, top1 65.41, top5 85.44
2021-11-06 09:15:13 valid 0000, loss 4.921e-01, top1 87.06, top5 97.65
2021-11-06 09:15:13 valid 0000, loss 4.921e-01, top1 87.06, top5 97.65
2021-11-06 09:15:13 valid 0000, loss 4.921e-01, top1 87.06, top5 97.65
2021-11-06 09:19:34 (JOBID 31649) epoch 41: train time 4184.50, inference time 270.96s, valid_top1 69.13 (best_top1 69.66), valid_top5 89.15
2021-11-06 09:19:42 (JOBID 31649) epoch 41: train time 4197.67, inference time 279.07s, valid_top1 69.13 (best_top1 69.66), valid_top5 89.15
2021-11-06 09:19:43 (JOBID 31649) epoch 41: train time 4182.26, inference time 280.26s, valid_top1 69.13 (best_top1 69.66), valid_top5 89.15
2021-11-06 09:19:56 train 0000, loss 1.354e+00, top1 69.41, top5 88.24
2021-11-06 09:19:49 train 0000, loss 1.500e+00, top1 61.18, top5 82.35
2021-11-06 09:19:58 train 0000, loss 1.423e+00, top1 67.06, top5 88.24
2021-11-06 09:33:47 train 1000, loss 1.454e+00, top1 65.86, top5 85.52
2021-11-06 09:33:47 train 1000, loss 1.436e+00, top1 65.93, top5 85.78
2021-11-06 09:33:47 train 1000, loss 1.444e+00, top1 65.70, top5 85.82
2021-11-06 09:47:40 train 2000, loss 1.454e+00, top1 65.77, top5 85.61
2021-11-06 09:47:40 train 2000, loss 1.451e+00, top1 65.67, top5 85.65
2021-11-06 09:47:40 train 2000, loss 1.447e+00, top1 65.74, top5 85.70
2021-11-06 10:01:30 train 3000, loss 1.455e+00, top1 65.66, top5 85.63
2021-11-06 10:01:30 train 3000, loss 1.462e+00, top1 65.62, top5 85.48
2021-11-06 10:01:30 train 3000, loss 1.450e+00, top1 65.68, top5 85.68
2021-11-06 10:15:18 train 4000, loss 1.466e+00, top1 65.49, top5 85.46
2021-11-06 10:15:18 train 4000, loss 1.457e+00, top1 65.61, top5 85.59
2021-11-06 10:15:18 train 4000, loss 1.457e+00, top1 65.55, top5 85.61
2021-11-06 10:29:16 train 5000, loss 1.461e+00, top1 65.52, top5 85.51
2021-11-06 10:29:16 train 5000, loss 1.467e+00, top1 65.43, top5 85.46
2021-11-06 10:29:17 train 5000, loss 1.462e+00, top1 65.47, top5 85.53
2021-11-06 10:29:46 valid 0000, loss 4.489e-01, top1 89.41, top5 95.29
2021-11-06 10:29:46 valid 0000, loss 4.489e-01, top1 89.41, top5 95.29
2021-11-06 10:29:46 valid 0000, loss 4.489e-01, top1 89.41, top5 95.29
2021-11-06 10:34:06 (JOBID 31649) epoch 42: train time 4193.30, inference time 269.25s, valid_top1 68.17 (best_top1 69.66), valid_top5 88.59
2021-11-06 10:34:15 (JOBID 31649) epoch 42: train time 4194.31, inference time 278.98s, valid_top1 68.17 (best_top1 69.66), valid_top5 88.59
2021-11-06 10:34:18 (JOBID 31649) epoch 42: train time 4201.99, inference time 281.85s, valid_top1 68.17 (best_top1 69.66), valid_top5 88.59
2021-11-06 10:34:30 train 0000, loss 1.329e+00, top1 69.41, top5 87.06
2021-11-06 10:34:20 train 0000, loss 1.390e+00, top1 61.18, top5 88.24
2021-11-06 10:34:33 train 0000, loss 1.165e+00, top1 74.12, top5 85.88
2021-11-06 10:48:24 train 1000, loss 1.456e+00, top1 65.87, top5 85.53
2021-11-06 10:48:24 train 1000, loss 1.446e+00, top1 65.70, top5 85.74
2021-11-06 10:48:24 train 1000, loss 1.445e+00, top1 65.85, top5 85.66
2021-11-06 11:02:13 train 2000, loss 1.457e+00, top1 65.75, top5 85.52
2021-11-06 11:02:13 train 2000, loss 1.452e+00, top1 65.66, top5 85.59
2021-11-06 11:02:14 train 2000, loss 1.458e+00, top1 65.57, top5 85.46
2021-11-06 11:16:07 train 3000, loss 1.454e+00, top1 65.62, top5 85.58
2021-11-06 11:16:07 train 3000, loss 1.459e+00, top1 65.70, top5 85.51
2021-11-06 11:16:07 train 3000, loss 1.464e+00, top1 65.43, top5 85.46
2021-11-06 11:29:59 train 4000, loss 1.461e+00, top1 65.64, top5 85.50
2021-11-06 11:29:59 train 4000, loss 1.461e+00, top1 65.50, top5 85.49
2021-11-06 11:29:59 train 4000, loss 1.467e+00, top1 65.34, top5 85.43
2021-11-06 11:44:02 train 5000, loss 1.465e+00, top1 65.52, top5 85.44
2021-11-06 11:44:02 train 5000, loss 1.463e+00, top1 65.46, top5 85.47
2021-11-06 11:44:02 train 5000, loss 1.470e+00, top1 65.28, top5 85.38
2021-11-06 11:44:33 valid 0000, loss 3.814e-01, top1 91.76, top5 97.65
2021-11-06 11:44:33 valid 0000, loss 3.814e-01, top1 91.76, top5 97.65
2021-11-06 11:44:33 valid 0000, loss 3.814e-01, top1 91.76, top5 97.65
2021-11-06 11:48:47 (JOBID 31649) epoch 43: train time 4216.50, inference time 265.07s, valid_top1 68.56 (best_top1 69.66), valid_top5 88.85
2021-11-06 11:49:06 (JOBID 31649) epoch 43: train time 4204.05, inference time 283.28s, valid_top1 68.56 (best_top1 69.66), valid_top5 88.85
2021-11-06 11:49:08 (JOBID 31649) epoch 43: train time 4206.95, inference time 285.74s, valid_top1 68.56 (best_top1 69.66), valid_top5 88.85
2021-11-06 11:49:01 train 0000, loss 1.296e+00, top1 75.29, top5 89.41
2021-11-06 11:49:21 train 0000, loss 1.785e+00, top1 56.47, top5 80.00
2021-11-06 11:49:23 train 0000, loss 1.577e+00, top1 60.00, top5 87.06
2021-11-06 12:03:36 train 1000, loss 1.453e+00, top1 65.68, top5 85.71
2021-11-06 12:03:36 train 1000, loss 1.444e+00, top1 65.92, top5 85.84
2021-11-06 12:03:36 train 1000, loss 1.464e+00, top1 65.71, top5 85.32
2021-11-06 12:17:40 train 2000, loss 1.460e+00, top1 65.56, top5 85.54
2021-11-06 12:17:40 train 2000, loss 1.456e+00, top1 65.76, top5 85.61
2021-11-06 12:17:40 train 2000, loss 1.463e+00, top1 65.71, top5 85.37
2021-11-06 12:31:46 train 3000, loss 1.457e+00, top1 65.68, top5 85.64
2021-11-06 12:31:46 train 3000, loss 1.461e+00, top1 65.55, top5 85.52
2021-11-06 12:31:46 train 3000, loss 1.464e+00, top1 65.65, top5 85.40
2021-11-06 12:45:46 train 4000, loss 1.460e+00, top1 65.61, top5 85.59
2021-11-06 12:45:46 train 4000, loss 1.468e+00, top1 65.50, top5 85.37
2021-11-06 12:45:46 train 4000, loss 1.464e+00, top1 65.49, top5 85.50
2021-11-06 13:00:09 train 5000, loss 1.465e+00, top1 65.49, top5 85.51
2021-11-06 13:00:09 train 5000, loss 1.471e+00, top1 65.44, top5 85.35
2021-11-06 13:00:09 train 5000, loss 1.466e+00, top1 65.45, top5 85.46
2021-11-06 13:00:40 valid 0000, loss 4.824e-01, top1 89.41, top5 95.29
2021-11-06 13:00:40 valid 0000, loss 4.824e-01, top1 89.41, top5 95.29
2021-11-06 13:00:40 valid 0000, loss 4.824e-01, top1 89.41, top5 95.29
2021-11-06 13:05:12 (JOBID 31649) epoch 44: train time 4281.53, inference time 282.40s, valid_top1 68.91 (best_top1 69.66), valid_top5 89.27
2021-11-06 13:05:14 (JOBID 31649) epoch 44: train time 4302.20, inference time 284.29s, valid_top1 68.91 (best_top1 69.66), valid_top5 89.27
2021-11-06 13:05:14 (JOBID 31649) epoch 44: train time 4283.93, inference time 283.89s, valid_top1 68.91 (best_top1 69.66), valid_top5 89.27
2021-11-06 13:05:33 train 0000, loss 1.473e+00, top1 72.94, top5 83.53
2021-11-06 13:05:33 train 0000, loss 1.595e+00, top1 61.18, top5 87.06
2021-11-06 13:05:33 train 0000, loss 1.475e+00, top1 63.53, top5 83.53
2021-11-06 13:19:45 train 1000, loss 1.449e+00, top1 65.73, top5 85.67
2021-11-06 13:19:45 train 1000, loss 1.444e+00, top1 65.97, top5 85.72
2021-11-06 13:19:46 train 1000, loss 1.445e+00, top1 65.84, top5 85.78
2021-11-06 13:33:40 train 2000, loss 1.457e+00, top1 65.58, top5 85.55
2021-11-06 13:33:40 train 2000, loss 1.456e+00, top1 65.72, top5 85.56
2021-11-06 13:33:41 train 2000, loss 1.444e+00, top1 65.78, top5 85.77
2021-11-06 13:47:55 train 3000, loss 1.462e+00, top1 65.50, top5 85.54
2021-11-06 13:47:55 train 3000, loss 1.461e+00, top1 65.61, top5 85.47
2021-11-06 13:47:55 train 3000, loss 1.454e+00, top1 65.62, top5 85.60
2021-11-06 14:01:56 train 4000, loss 1.465e+00, top1 65.42, top5 85.50
2021-11-06 14:01:56 train 4000, loss 1.466e+00, top1 65.50, top5 85.40
2021-11-06 14:01:56 train 4000, loss 1.463e+00, top1 65.43, top5 85.49
2021-11-06 14:15:57 train 5000, loss 1.468e+00, top1 65.37, top5 85.43
2021-11-06 14:15:57 train 5000, loss 1.470e+00, top1 65.41, top5 85.34
2021-11-06 14:15:57 train 5000, loss 1.470e+00, top1 65.31, top5 85.38
2021-11-06 14:16:27 valid 0000, loss 3.797e-01, top1 91.76, top5 97.65
2021-11-06 14:16:27 valid 0000, loss 3.797e-01, top1 91.76, top5 97.65
2021-11-06 14:16:27 valid 0000, loss 3.797e-01, top1 91.76, top5 97.65
2021-11-06 14:21:16 (JOBID 31649) epoch 45: train time 4264.77, inference time 299.37s, valid_top1 68.42 (best_top1 69.66), valid_top5 88.88
2021-11-06 14:21:16 (JOBID 31649) epoch 45: train time 4262.88, inference time 299.38s, valid_top1 68.42 (best_top1 69.66), valid_top5 88.88
2021-11-06 14:21:16 (JOBID 31649) epoch 45: train time 4263.02, inference time 299.10s, valid_top1 68.42 (best_top1 69.66), valid_top5 88.88
2021-11-06 14:21:31 train 0000, loss 1.510e+00, top1 65.88, top5 87.06
2021-11-06 14:21:31 train 0000, loss 1.136e+00, top1 75.29, top5 90.59
2021-11-06 14:21:31 train 0000, loss 1.270e+00, top1 74.12, top5 84.71
2021-11-06 14:35:37 train 1000, loss 1.440e+00, top1 65.96, top5 85.84
2021-11-06 14:35:37 train 1000, loss 1.460e+00, top1 65.68, top5 85.54
2021-11-06 14:35:37 train 1000, loss 1.440e+00, top1 65.99, top5 85.78
2021-11-06 14:49:36 train 2000, loss 1.468e+00, top1 65.46, top5 85.38
2021-11-06 14:49:36 train 2000, loss 1.448e+00, top1 65.85, top5 85.73
2021-11-06 14:49:36 train 2000, loss 1.459e+00, top1 65.59, top5 85.56
2021-11-06 15:03:35 train 3000, loss 1.469e+00, top1 65.40, top5 85.40
2021-11-06 15:03:35 train 3000, loss 1.459e+00, top1 65.59, top5 85.58
2021-11-06 15:03:36 train 3000, loss 1.453e+00, top1 65.73, top5 85.69
2021-11-06 15:17:39 train 4000, loss 1.464e+00, top1 65.46, top5 85.51
2021-11-06 15:17:39 train 4000, loss 1.470e+00, top1 65.38, top5 85.40
2021-11-06 15:17:39 train 4000, loss 1.458e+00, top1 65.59, top5 85.58
2021-11-06 15:31:46 train 5000, loss 1.473e+00, top1 65.29, top5 85.35
2021-11-06 15:31:46 train 5000, loss 1.467e+00, top1 65.39, top5 85.45
2021-11-06 15:31:47 train 5000, loss 1.465e+00, top1 65.41, top5 85.49
2021-11-06 15:32:17 valid 0000, loss 5.239e-01, top1 90.59, top5 96.47
2021-11-06 15:32:17 valid 0000, loss 5.239e-01, top1 90.59, top5 96.47
2021-11-06 15:32:17 valid 0000, loss 5.239e-01, top1 90.59, top5 96.47
2021-11-06 15:36:37 (JOBID 31649) epoch 46: train time 4250.08, inference time 270.14s, valid_top1 68.83 (best_top1 69.66), valid_top5 89.15
2021-11-06 15:36:49 (JOBID 31649) epoch 46: train time 4250.32, inference time 282.71s, valid_top1 68.83 (best_top1 69.66), valid_top5 89.15
2021-11-06 15:36:51 (JOBID 31649) epoch 46: train time 4250.31, inference time 284.25s, valid_top1 68.83 (best_top1 69.66), valid_top5 89.15
2021-11-06 15:37:05 train 0000, loss 1.459e+00, top1 62.35, top5 87.06
2021-11-06 15:36:51 train 0000, loss 1.387e+00, top1 65.88, top5 85.88
2021-11-06 15:37:05 train 0000, loss 1.364e+00, top1 65.88, top5 89.41
2021-11-06 15:51:09 train 1000, loss 1.442e+00, top1 65.92, top5 85.72
2021-11-06 15:51:09 train 1000, loss 1.446e+00, top1 65.99, top5 85.67
2021-11-06 15:51:10 train 1000, loss 1.456e+00, top1 65.67, top5 85.53
2021-11-06 16:04:58 train 2000, loss 1.449e+00, top1 65.82, top5 85.70
2021-11-06 16:04:58 train 2000, loss 1.457e+00, top1 65.72, top5 85.54
2021-11-06 16:04:58 train 2000, loss 1.461e+00, top1 65.49, top5 85.55
2021-11-06 16:18:43 train 3000, loss 1.456e+00, top1 65.67, top5 85.62
2021-11-06 16:18:43 train 3000, loss 1.462e+00, top1 65.53, top5 85.47
2021-11-06 16:18:43 train 3000, loss 1.467e+00, top1 65.36, top5 85.46
2021-11-06 16:32:24 train 4000, loss 1.467e+00, top1 65.40, top5 85.44
2021-11-06 16:32:24 train 4000, loss 1.460e+00, top1 65.58, top5 85.54
2021-11-06 16:32:25 train 4000, loss 1.467e+00, top1 65.41, top5 85.41
2021-11-06 16:46:14 train 5000, loss 1.465e+00, top1 65.46, top5 85.44
2021-11-06 16:46:14 train 5000, loss 1.468e+00, top1 65.35, top5 85.40
2021-11-06 16:46:14 train 5000, loss 1.472e+00, top1 65.30, top5 85.36
2021-11-06 16:46:44 valid 0000, loss 4.922e-01, top1 87.06, top5 97.65
2021-11-06 16:46:44 valid 0000, loss 4.922e-01, top1 87.06, top5 97.65
2021-11-06 16:46:44 valid 0000, loss 4.922e-01, top1 87.06, top5 97.65
2021-11-06 16:51:03 (JOBID 31649) epoch 47: train time 4197.11, inference time 268.79s, valid_top1 68.82 (best_top1 69.66), valid_top5 89.15
2021-11-06 16:51:19 (JOBID 31649) epoch 47: train time 4184.72, inference time 284.75s, valid_top1 68.82 (best_top1 69.66), valid_top5 89.15
2021-11-06 16:51:19 (JOBID 31649) epoch 47: train time 4183.18, inference time 285.46s, valid_top1 68.82 (best_top1 69.66), valid_top5 89.15
2021-11-06 16:51:17 train 0000, loss 1.741e+00, top1 56.47, top5 82.35
2021-11-06 16:51:34 train 0000, loss 1.807e+00, top1 57.65, top5 80.00
2021-11-06 16:51:34 train 0000, loss 1.019e+00, top1 72.94, top5 92.94
2021-11-06 17:05:22 train 1000, loss 1.455e+00, top1 65.54, top5 85.62
2021-11-06 17:05:22 train 1000, loss 1.449e+00, top1 65.85, top5 85.55
2021-11-06 17:05:22 train 1000, loss 1.447e+00, top1 65.76, top5 85.73
2021-11-06 17:19:03 train 2000, loss 1.464e+00, top1 65.36, top5 85.48
2021-11-06 17:19:03 train 2000, loss 1.459e+00, top1 65.52, top5 85.46
2021-11-06 17:19:04 train 2000, loss 1.456e+00, top1 65.58, top5 85.55
2021-11-06 17:32:48 train 3000, loss 1.466e+00, top1 65.34, top5 85.49
2021-11-06 17:32:48 train 3000, loss 1.463e+00, top1 65.47, top5 85.41
2021-11-06 17:32:48 train 3000, loss 1.467e+00, top1 65.36, top5 85.41
2021-11-06 17:46:38 train 4000, loss 1.468e+00, top1 65.34, top5 85.41
2021-11-06 17:46:38 train 4000, loss 1.464e+00, top1 65.44, top5 85.40
2021-11-06 17:46:38 train 4000, loss 1.469e+00, top1 65.31, top5 85.39
2021-11-06 18:00:26 train 5000, loss 1.471e+00, top1 65.26, top5 85.36
2021-11-06 18:00:26 train 5000, loss 1.468e+00, top1 65.35, top5 85.33
2021-11-06 18:00:26 train 5000, loss 1.470e+00, top1 65.26, top5 85.41
2021-11-06 18:00:56 valid 0000, loss 3.735e-01, top1 92.94, top5 97.65
2021-11-06 18:00:56 valid 0000, loss 3.735e-01, top1 92.94, top5 97.65
2021-11-06 18:00:56 valid 0000, loss 3.735e-01, top1 92.94, top5 97.65
2021-11-06 18:05:28 (JOBID 31649) epoch 48: train time 4166.95, inference time 282.72s, valid_top1 68.73 (best_top1 69.66), valid_top5 88.85
2021-11-06 18:05:29 (JOBID 31649) epoch 48: train time 4182.91, inference time 283.07s, valid_top1 68.73 (best_top1 69.66), valid_top5 88.85
2021-11-06 18:05:30 (JOBID 31649) epoch 48: train time 4166.24, inference time 284.82s, valid_top1 68.73 (best_top1 69.66), valid_top5 88.85
2021-11-06 18:05:44 train 0000, loss 1.551e+00, top1 65.88, top5 88.24
2021-11-06 18:05:44 train 0000, loss 1.478e+00, top1 62.35, top5 87.06
2021-11-06 18:05:46 train 0000, loss 1.227e+00, top1 68.24, top5 83.53
2021-11-06 18:19:28 train 1000, loss 1.457e+00, top1 65.48, top5 85.52
2021-11-06 18:19:28 train 1000, loss 1.437e+00, top1 66.21, top5 85.82
2021-11-06 18:19:28 train 1000, loss 1.448e+00, top1 65.83, top5 85.80
2021-11-06 18:33:13 train 2000, loss 1.451e+00, top1 65.83, top5 85.65
2021-11-06 18:33:13 train 2000, loss 1.465e+00, top1 65.24, top5 85.44
2021-11-06 18:33:14 train 2000, loss 1.453e+00, top1 65.67, top5 85.71
2021-11-06 18:46:59 train 3000, loss 1.461e+00, top1 65.55, top5 85.53
2021-11-06 18:46:59 train 3000, loss 1.467e+00, top1 65.25, top5 85.41
2021-11-06 18:46:59 train 3000, loss 1.460e+00, top1 65.46, top5 85.60
2021-11-06 19:00:43 train 4000, loss 1.470e+00, top1 65.44, top5 85.39
2021-11-06 19:00:43 train 4000, loss 1.469e+00, top1 65.22, top5 85.38
2021-11-06 19:00:43 train 4000, loss 1.464e+00, top1 65.40, top5 85.50
2021-11-06 19:14:26 train 5000, loss 1.473e+00, top1 65.17, top5 85.36
2021-11-06 19:14:26 train 5000, loss 1.473e+00, top1 65.33, top5 85.34
2021-11-06 19:14:27 train 5000, loss 1.466e+00, top1 65.38, top5 85.49
2021-11-06 19:14:56 valid 0000, loss 6.958e-01, top1 84.71, top5 90.59
2021-11-06 19:14:56 valid 0000, loss 6.958e-01, top1 84.71, top5 90.59
2021-11-06 19:14:56 valid 0000, loss 6.958e-01, top1 84.71, top5 90.59
2021-11-06 19:19:27 (JOBID 31649) epoch 49: train time 4157.13, inference time 280.49s, valid_top1 68.70 (best_top1 69.66), valid_top5 88.94
2021-11-06 19:19:28 (JOBID 31649) epoch 49: train time 4157.84, inference time 281.87s, valid_top1 68.70 (best_top1 69.66), valid_top5 88.94
2021-11-06 19:19:28 (JOBID 31649) epoch 49: train time 4155.75, inference time 282.07s, valid_top1 68.70 (best_top1 69.66), valid_top5 88.94
2021-11-06 19:19:42 train 0000, loss 1.460e+00, top1 69.41, top5 82.35
2021-11-06 19:19:42 train 0000, loss 1.551e+00, top1 64.71, top5 85.88
2021-11-06 19:19:42 train 0000, loss 1.427e+00, top1 68.24, top5 90.59
2021-11-06 19:33:26 train 1000, loss 1.453e+00, top1 65.79, top5 85.57
2021-11-06 19:33:26 train 1000, loss 1.449e+00, top1 65.73, top5 85.75
2021-11-06 19:33:26 train 1000, loss 1.454e+00, top1 65.86, top5 85.57
2021-11-06 19:47:07 train 2000, loss 1.458e+00, top1 65.56, top5 85.52
2021-11-06 19:47:07 train 2000, loss 1.457e+00, top1 65.56, top5 85.66
2021-11-06 19:47:08 train 2000, loss 1.459e+00, top1 65.67, top5 85.54
2021-11-06 20:00:51 train 3000, loss 1.464e+00, top1 65.47, top5 85.54
2021-11-06 20:00:51 train 3000, loss 1.465e+00, top1 65.42, top5 85.42
2021-11-06 20:00:51 train 3000, loss 1.461e+00, top1 65.58, top5 85.51
2021-11-06 20:14:37 train 4000, loss 1.467e+00, top1 65.33, top5 85.39
2021-11-06 20:14:37 train 4000, loss 1.466e+00, top1 65.45, top5 85.48
2021-11-06 20:14:37 train 4000, loss 1.464e+00, top1 65.52, top5 85.46
2021-11-06 20:28:22 train 5000, loss 1.472e+00, top1 65.24, top5 85.33
2021-11-06 20:28:22 train 5000, loss 1.468e+00, top1 65.37, top5 85.46
2021-11-06 20:28:22 train 5000, loss 1.468e+00, top1 65.43, top5 85.40
2021-11-06 20:28:52 valid 0000, loss 5.639e-01, top1 89.41, top5 94.12
2021-11-06 20:28:52 valid 0000, loss 5.639e-01, top1 89.41, top5 94.12
2021-11-06 20:28:52 valid 0000, loss 5.639e-01, top1 89.41, top5 94.12
2021-11-06 20:33:12 (JOBID 31649) epoch 50: train time 4154.57, inference time 270.37s, valid_top1 68.84 (best_top1 69.66), valid_top5 89.19
2021-11-06 20:33:26 (JOBID 31649) epoch 50: train time 4153.23, inference time 284.62s, valid_top1 68.84 (best_top1 69.66), valid_top5 89.19
2021-11-06 20:33:27 (JOBID 31649) epoch 50: train time 4153.43, inference time 285.68s, valid_top1 68.84 (best_top1 69.66), valid_top5 89.19
2021-11-06 20:33:29 train 0000, loss 1.406e+00, top1 71.76, top5 83.53
2021-11-06 20:33:44 train 0000, loss 1.101e+00, top1 68.24, top5 88.24
2021-11-06 20:33:44 train 0000, loss 1.433e+00, top1 70.59, top5 84.71
2021-11-06 20:49:14 train 1000, loss 1.453e+00, top1 65.63, top5 85.62
2021-11-06 20:49:14 train 1000, loss 1.455e+00, top1 65.68, top5 85.56
2021-11-06 20:49:15 train 1000, loss 1.438e+00, top1 66.09, top5 85.75
2021-11-06 21:03:06 train 2000, loss 1.459e+00, top1 65.59, top5 85.49
2021-11-06 21:03:06 train 2000, loss 1.457e+00, top1 65.53, top5 85.58
2021-11-06 21:03:06 train 2000, loss 1.450e+00, top1 65.74, top5 85.65
2021-11-06 21:16:54 train 3000, loss 1.458e+00, top1 65.54, top5 85.58
2021-11-06 21:16:54 train 3000, loss 1.463e+00, top1 65.56, top5 85.44
2021-11-06 21:16:54 train 3000, loss 1.458e+00, top1 65.54, top5 85.59
2021-11-06 21:30:39 train 4000, loss 1.463e+00, top1 65.47, top5 85.52
2021-11-06 21:30:39 train 4000, loss 1.469e+00, top1 65.39, top5 85.36
2021-11-06 21:30:39 train 4000, loss 1.464e+00, top1 65.40, top5 85.52
2021-11-06 23:19:45 CARME Slurm ID: 31694
2021-11-06 23:19:45 CARME Slurm ID: 31694
2021-11-06 23:19:45 CARME Slurm ID: 31694
2021-11-06 23:19:45 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=0, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-06 23:19:45 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=2, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-06 23:19:45 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=1, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-06 23:19:59 Computational complexity:       2.02 GMac
2021-11-06 23:19:59 Computational complexity:       2.02 GMac
2021-11-06 23:19:59 Computational complexity:       2.02 GMac
2021-11-06 23:19:59 Number of parameters:           13.35 M 
2021-11-06 23:19:59 Number of parameters:           13.35 M 
2021-11-06 23:19:59 Number of parameters:           13.35 M 
2021-11-06 23:19:59 => loading checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243'
2021-11-06 23:19:59 => loading checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243'
2021-11-06 23:19:59 => loading checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243'
2021-11-06 23:20:00 => loaded checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243' (epoch 51)
2021-11-06 23:20:00 => loaded checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243' (epoch 51)
2021-11-06 23:20:00 => loaded checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243' (epoch 51)
2021-11-06 23:20:27 train 0000, loss 1.260e+00, top1 71.76, top5 88.24
2021-11-06 23:20:27 train 0000, loss 1.405e+00, top1 68.24, top5 87.06
2021-11-06 23:20:27 train 0000, loss 1.499e+00, top1 68.24, top5 83.53
2021-11-06 23:34:18 train 1000, loss 1.442e+00, top1 65.83, top5 85.79
2021-11-06 23:34:18 train 1000, loss 1.426e+00, top1 66.22, top5 86.03
2021-11-06 23:34:18 train 1000, loss 1.450e+00, top1 65.66, top5 85.62
2021-11-06 23:48:08 train 2000, loss 1.449e+00, top1 65.69, top5 85.67
2021-11-06 23:48:08 train 2000, loss 1.441e+00, top1 65.78, top5 85.81
2021-11-06 23:48:08 train 2000, loss 1.457e+00, top1 65.59, top5 85.54
2021-11-07 00:02:02 train 3000, loss 1.456e+00, top1 65.60, top5 85.54
2021-11-07 00:02:02 train 3000, loss 1.449e+00, top1 65.59, top5 85.75
2021-11-07 00:02:02 train 3000, loss 1.463e+00, top1 65.53, top5 85.48
2021-11-07 00:15:53 train 4000, loss 1.462e+00, top1 65.46, top5 85.50
2021-11-07 00:15:53 train 4000, loss 1.455e+00, top1 65.51, top5 85.66
2021-11-07 00:15:53 train 4000, loss 1.468e+00, top1 65.38, top5 85.43
2021-11-07 00:29:42 train 5000, loss 1.466e+00, top1 65.35, top5 85.46
2021-11-07 00:29:42 train 5000, loss 1.459e+00, top1 65.45, top5 85.59
2021-11-07 00:29:43 train 5000, loss 1.470e+00, top1 65.32, top5 85.41
2021-11-07 00:30:15 valid 0000, loss 6.845e-01, top1 83.53, top5 94.12
2021-11-07 00:30:15 valid 0000, loss 6.845e-01, top1 83.53, top5 94.12
2021-11-07 00:30:15 valid 0000, loss 6.845e-01, top1 83.53, top5 94.12
2021-11-07 00:34:42 (JOBID 31694) epoch 51: train time 4200.48, inference time 276.40s, valid_top1 68.67 (best_top1 69.66), valid_top5 88.89
2021-11-07 00:34:42 (JOBID 31694) epoch 51: train time 4200.59, inference time 277.05s, valid_top1 68.67 (best_top1 69.66), valid_top5 88.89
2021-11-07 00:34:46 (JOBID 31694) epoch 51: train time 4200.65, inference time 280.45s, valid_top1 68.67 (best_top1 69.66), valid_top5 88.89
2021-11-07 00:34:56 train 0000, loss 1.698e+00, top1 56.47, top5 81.18
2021-11-07 00:34:56 train 0000, loss 1.358e+00, top1 67.06, top5 88.24
2021-11-07 00:35:00 train 0000, loss 1.259e+00, top1 67.06, top5 90.59
2021-11-07 00:48:39 train 1000, loss 1.451e+00, top1 65.74, top5 85.61
2021-11-07 00:48:39 train 1000, loss 1.449e+00, top1 65.51, top5 85.74
2021-11-07 00:48:39 train 1000, loss 1.445e+00, top1 65.73, top5 85.84
2021-11-07 01:02:26 train 2000, loss 1.454e+00, top1 65.54, top5 85.59
2021-11-07 01:02:26 train 2000, loss 1.455e+00, top1 65.69, top5 85.60
2021-11-07 01:02:26 train 2000, loss 1.448e+00, top1 65.72, top5 85.72
2021-11-07 01:16:13 train 3000, loss 1.461e+00, top1 65.38, top5 85.51
2021-11-07 01:16:13 train 3000, loss 1.464e+00, top1 65.52, top5 85.49
2021-11-07 01:16:13 train 3000, loss 1.457e+00, top1 65.51, top5 85.55
2021-11-07 01:30:04 train 4000, loss 1.465e+00, top1 65.34, top5 85.46
2021-11-07 01:30:04 train 4000, loss 1.469e+00, top1 65.38, top5 85.41
2021-11-07 01:30:04 train 4000, loss 1.462e+00, top1 65.44, top5 85.49
2021-11-07 01:43:56 train 5000, loss 1.468e+00, top1 65.30, top5 85.41
2021-11-07 01:43:56 train 5000, loss 1.473e+00, top1 65.31, top5 85.37
2021-11-07 01:43:57 train 5000, loss 1.465e+00, top1 65.39, top5 85.44
2021-11-07 01:44:27 valid 0000, loss 4.486e-01, top1 90.59, top5 97.65
2021-11-07 01:44:27 valid 0000, loss 4.486e-01, top1 90.59, top5 97.65
2021-11-07 01:44:27 valid 0000, loss 4.486e-01, top1 90.59, top5 97.65
2021-11-07 01:49:15 (JOBID 31694) epoch 52: train time 4175.06, inference time 298.11s, valid_top1 66.01 (best_top1 69.66), valid_top5 87.35
2021-11-07 01:49:15 (JOBID 31694) epoch 52: train time 4170.44, inference time 298.54s, valid_top1 66.01 (best_top1 69.66), valid_top5 87.35
2021-11-07 01:49:16 (JOBID 31694) epoch 52: train time 4174.19, inference time 299.69s, valid_top1 66.01 (best_top1 69.66), valid_top5 87.35
2021-11-07 01:49:30 train 0000, loss 1.350e+00, top1 68.24, top5 89.41
2021-11-07 01:49:30 train 0000, loss 1.435e+00, top1 69.41, top5 85.88
2021-11-07 01:49:30 train 0000, loss 1.693e+00, top1 65.88, top5 83.53
2021-11-07 02:03:25 train 1000, loss 1.449e+00, top1 65.77, top5 85.68
2021-11-07 02:03:25 train 1000, loss 1.432e+00, top1 65.86, top5 85.90
2021-11-07 02:03:25 train 1000, loss 1.442e+00, top1 65.94, top5 85.65
2021-11-07 02:17:20 train 2000, loss 1.456e+00, top1 65.63, top5 85.50
2021-11-07 02:17:20 train 2000, loss 1.447e+00, top1 65.61, top5 85.72
2021-11-07 02:17:20 train 2000, loss 1.448e+00, top1 65.77, top5 85.66
2021-11-07 02:31:17 train 3000, loss 1.455e+00, top1 65.47, top5 85.64
2021-11-07 02:31:17 train 3000, loss 1.458e+00, top1 65.55, top5 85.51
2021-11-07 02:31:17 train 3000, loss 1.454e+00, top1 65.63, top5 85.56
2021-11-07 02:45:09 train 4000, loss 1.457e+00, top1 65.42, top5 85.61
2021-11-07 02:45:09 train 4000, loss 1.461e+00, top1 65.42, top5 85.48
2021-11-07 02:45:09 train 4000, loss 1.458e+00, top1 65.63, top5 85.52
2021-11-07 02:59:05 train 5000, loss 1.462e+00, top1 65.35, top5 85.52
2021-11-07 02:59:05 train 5000, loss 1.464e+00, top1 65.38, top5 85.47
2021-11-07 02:59:05 train 5000, loss 1.462e+00, top1 65.54, top5 85.48
2021-11-07 02:59:36 valid 0000, loss 4.689e-01, top1 90.59, top5 96.47
2021-11-07 02:59:36 valid 0000, loss 4.689e-01, top1 90.59, top5 96.47
2021-11-07 02:59:36 valid 0000, loss 4.689e-01, top1 90.59, top5 96.47
2021-11-07 03:04:11 (JOBID 31694) epoch 53: train time 4209.57, inference time 285.79s, valid_top1 69.21 (best_top1 69.66), valid_top5 89.34
2021-11-07 03:04:11 (JOBID 31694) epoch 53: train time 4211.07, inference time 285.69s, valid_top1 69.21 (best_top1 69.66), valid_top5 89.34
2021-11-07 03:04:12 (JOBID 31694) epoch 53: train time 4210.44, inference time 286.04s, valid_top1 69.21 (best_top1 69.66), valid_top5 89.34
2021-11-07 03:04:26 train 0000, loss 1.174e+00, top1 71.76, top5 90.59
2021-11-07 03:04:26 train 0000, loss 1.245e+00, top1 68.24, top5 90.59
2021-11-07 03:04:26 train 0000, loss 1.576e+00, top1 60.00, top5 78.82
2021-11-07 03:18:21 train 1000, loss 1.447e+00, top1 65.72, top5 85.70
2021-11-07 03:18:21 train 1000, loss 1.439e+00, top1 65.92, top5 85.82
2021-11-07 03:18:21 train 1000, loss 1.432e+00, top1 66.03, top5 85.84
2021-11-07 03:32:10 train 2000, loss 1.448e+00, top1 65.70, top5 85.71
2021-11-07 03:32:10 train 2000, loss 1.454e+00, top1 65.62, top5 85.63
2021-11-07 03:32:10 train 2000, loss 1.444e+00, top1 65.81, top5 85.71
2021-11-07 03:46:00 train 3000, loss 1.459e+00, top1 65.49, top5 85.56
2021-11-07 03:46:00 train 3000, loss 1.458e+00, top1 65.54, top5 85.56
2021-11-07 03:46:01 train 3000, loss 1.456e+00, top1 65.56, top5 85.58
2021-11-07 03:59:58 train 4000, loss 1.461e+00, top1 65.51, top5 85.52
2021-11-07 03:59:58 train 4000, loss 1.462e+00, top1 65.48, top5 85.53
2021-11-07 03:59:58 train 4000, loss 1.458e+00, top1 65.47, top5 85.54
2021-11-07 04:13:52 train 5000, loss 1.465e+00, top1 65.45, top5 85.47
2021-11-07 04:13:52 train 5000, loss 1.465e+00, top1 65.41, top5 85.48
2021-11-07 04:13:52 train 5000, loss 1.461e+00, top1 65.40, top5 85.50
2021-11-07 04:14:22 valid 0000, loss 3.820e-01, top1 91.76, top5 98.82
2021-11-07 04:14:22 valid 0000, loss 3.820e-01, top1 91.76, top5 98.82
2021-11-07 04:14:22 valid 0000, loss 3.820e-01, top1 91.76, top5 98.82
2021-11-07 04:18:36 (JOBID 31694) epoch 54: train time 4200.28, inference time 264.22s, valid_top1 68.66 (best_top1 69.66), valid_top5 89.04
2021-11-07 04:18:56 (JOBID 31694) epoch 54: train time 4199.81, inference time 283.74s, valid_top1 68.66 (best_top1 69.66), valid_top5 89.04
2021-11-07 04:18:57 (JOBID 31694) epoch 54: train time 4200.39, inference time 285.02s, valid_top1 68.66 (best_top1 69.66), valid_top5 89.04
2021-11-07 04:18:50 train 0000, loss 1.474e+00, top1 64.71, top5 85.88
2021-11-07 04:19:10 train 0000, loss 1.193e+00, top1 72.94, top5 89.41
2021-11-07 04:19:10 train 0000, loss 1.439e+00, top1 62.35, top5 89.41
2021-11-07 04:32:57 train 1000, loss 1.446e+00, top1 65.99, top5 85.62
2021-11-07 04:32:57 train 1000, loss 1.435e+00, top1 66.01, top5 85.79
2021-11-07 04:32:57 train 1000, loss 1.436e+00, top1 66.09, top5 85.79
2021-11-07 04:46:48 train 2000, loss 1.447e+00, top1 65.85, top5 85.66
2021-11-07 04:46:48 train 2000, loss 1.450e+00, top1 65.65, top5 85.61
2021-11-07 04:46:48 train 2000, loss 1.442e+00, top1 65.87, top5 85.80
2021-11-07 05:00:39 train 3000, loss 1.449e+00, top1 65.70, top5 85.65
2021-11-07 05:00:39 train 3000, loss 1.459e+00, top1 65.61, top5 85.49
2021-11-07 05:00:39 train 3000, loss 1.457e+00, top1 65.54, top5 85.53
2021-11-07 05:14:24 train 4000, loss 1.462e+00, top1 65.49, top5 85.48
2021-11-07 05:14:24 train 4000, loss 1.458e+00, top1 65.53, top5 85.52
2021-11-07 05:14:24 train 4000, loss 1.453e+00, top1 65.61, top5 85.61
2021-11-07 05:28:11 train 5000, loss 1.461e+00, top1 65.51, top5 85.47
2021-11-07 05:28:11 train 5000, loss 1.466e+00, top1 65.40, top5 85.41
2021-11-07 05:28:11 train 5000, loss 1.457e+00, top1 65.56, top5 85.57
2021-11-07 05:28:42 valid 0000, loss 6.133e-01, top1 87.06, top5 94.12
2021-11-07 05:28:42 valid 0000, loss 6.133e-01, top1 87.06, top5 94.12
2021-11-07 05:28:42 valid 0000, loss 6.133e-01, top1 87.06, top5 94.12
2021-11-07 05:33:12 (JOBID 31694) epoch 55: train time 4173.87, inference time 281.20s, valid_top1 68.69 (best_top1 69.66), valid_top5 89.22
2021-11-07 05:33:13 (JOBID 31694) epoch 55: train time 4174.91, inference time 281.90s, valid_top1 68.69 (best_top1 69.66), valid_top5 89.22
2021-11-07 05:33:13 (JOBID 31694) epoch 55: train time 4194.71, inference time 282.49s, valid_top1 68.69 (best_top1 69.66), valid_top5 89.22
2021-11-07 05:33:27 train 0000, loss 1.616e+00, top1 61.18, top5 82.35
2021-11-07 05:33:28 train 0000, loss 1.582e+00, top1 63.53, top5 81.18
2021-11-07 05:33:28 train 0000, loss 1.759e+00, top1 61.18, top5 80.00
2021-11-07 05:47:25 train 1000, loss 1.453e+00, top1 65.68, top5 85.68
2021-11-07 05:47:25 train 1000, loss 1.437e+00, top1 65.95, top5 85.77
2021-11-07 05:47:25 train 1000, loss 1.440e+00, top1 66.06, top5 85.62
2021-11-07 06:01:18 train 2000, loss 1.452e+00, top1 65.67, top5 85.62
2021-11-07 06:01:18 train 2000, loss 1.438e+00, top1 65.82, top5 85.79
2021-11-07 06:01:18 train 2000, loss 1.447e+00, top1 65.86, top5 85.65
2021-11-07 06:15:08 train 3000, loss 1.447e+00, top1 65.71, top5 85.74
2021-11-07 06:15:08 train 3000, loss 1.456e+00, top1 65.58, top5 85.55
2021-11-07 06:15:08 train 3000, loss 1.454e+00, top1 65.66, top5 85.51
2021-11-07 06:29:06 train 4000, loss 1.457e+00, top1 65.58, top5 85.56
2021-11-07 06:29:06 train 4000, loss 1.451e+00, top1 65.63, top5 85.65
2021-11-07 06:29:06 train 4000, loss 1.458e+00, top1 65.54, top5 85.52
2021-11-07 06:42:58 train 5000, loss 1.458e+00, top1 65.51, top5 85.55
2021-11-07 06:42:58 train 5000, loss 1.461e+00, top1 65.46, top5 85.50
2021-11-07 06:42:59 train 5000, loss 1.464e+00, top1 65.43, top5 85.45
2021-11-07 06:43:29 valid 0000, loss 5.552e-01, top1 85.88, top5 97.65
2021-11-07 06:43:29 valid 0000, loss 5.552e-01, top1 85.88, top5 97.65
2021-11-07 06:43:29 valid 0000, loss 5.552e-01, top1 85.88, top5 97.65
2021-11-07 06:47:57 (JOBID 31694) epoch 56: train time 4207.01, inference time 278.13s, valid_top1 68.53 (best_top1 69.66), valid_top5 89.10
2021-11-07 06:47:58 (JOBID 31694) epoch 56: train time 4206.06, inference time 278.86s, valid_top1 68.53 (best_top1 69.66), valid_top5 89.10
2021-11-07 06:48:02 (JOBID 31694) epoch 56: train time 4205.68, inference time 282.99s, valid_top1 68.53 (best_top1 69.66), valid_top5 89.10
2021-11-07 06:48:12 train 0000, loss 1.120e+00, top1 74.12, top5 88.24
2021-11-07 06:48:12 train 0000, loss 1.793e+00, top1 63.53, top5 78.82
2021-11-07 06:48:16 train 0000, loss 1.838e+00, top1 60.00, top5 80.00
2021-11-07 07:02:02 train 1000, loss 1.438e+00, top1 65.94, top5 85.83
2021-11-07 07:02:02 train 1000, loss 1.432e+00, top1 66.06, top5 85.86
2021-11-07 07:02:03 train 1000, loss 1.434e+00, top1 66.01, top5 85.87
2021-11-07 07:15:51 train 2000, loss 1.451e+00, top1 65.69, top5 85.68
2021-11-07 07:15:51 train 2000, loss 1.441e+00, top1 65.90, top5 85.80
2021-11-07 07:15:52 train 2000, loss 1.447e+00, top1 65.80, top5 85.73
2021-11-07 07:29:48 train 3000, loss 1.450e+00, top1 65.67, top5 85.65
2021-11-07 07:29:48 train 3000, loss 1.450e+00, top1 65.69, top5 85.64
2021-11-07 07:29:48 train 3000, loss 1.449e+00, top1 65.73, top5 85.71
2021-11-07 07:43:39 train 4000, loss 1.454e+00, top1 65.55, top5 85.60
2021-11-07 07:43:39 train 4000, loss 1.455e+00, top1 65.60, top5 85.59
2021-11-07 07:43:39 train 4000, loss 1.455e+00, top1 65.59, top5 85.62
2021-11-07 07:57:20 train 5000, loss 1.459e+00, top1 65.48, top5 85.56
2021-11-07 07:57:20 train 5000, loss 1.459e+00, top1 65.53, top5 85.56
2021-11-07 07:57:20 train 5000, loss 1.459e+00, top1 65.50, top5 85.58
2021-11-07 07:57:50 valid 0000, loss 5.936e-01, top1 85.88, top5 95.29
2021-11-07 07:57:50 valid 0000, loss 5.936e-01, top1 85.88, top5 95.29
2021-11-07 07:57:50 valid 0000, loss 5.936e-01, top1 85.88, top5 95.29
2021-11-07 08:02:21 (JOBID 31694) epoch 57: train time 4177.68, inference time 281.45s, valid_top1 68.91 (best_top1 69.66), valid_top5 89.17
2021-11-07 08:02:29 (JOBID 31694) epoch 57: train time 4182.62, inference time 288.99s, valid_top1 68.91 (best_top1 69.66), valid_top5 89.17
2021-11-07 08:02:33 (JOBID 31694) epoch 57: train time 4181.56, inference time 292.93s, valid_top1 68.91 (best_top1 69.66), valid_top5 89.17
2021-11-07 08:02:44 train 0000, loss 1.476e+00, top1 65.88, top5 87.06
2021-11-07 08:02:36 train 0000, loss 1.445e+00, top1 69.41, top5 85.88
2021-11-07 08:02:47 train 0000, loss 1.670e+00, top1 64.71, top5 83.53
2021-11-07 08:16:41 train 1000, loss 1.436e+00, top1 65.96, top5 85.86
2021-11-07 08:16:41 train 1000, loss 1.439e+00, top1 65.64, top5 85.86
2021-11-07 08:16:42 train 1000, loss 1.431e+00, top1 65.98, top5 85.94
2021-11-07 08:30:29 train 2000, loss 1.450e+00, top1 65.61, top5 85.66
2021-11-07 08:30:29 train 2000, loss 1.444e+00, top1 65.83, top5 85.79
2021-11-07 08:30:29 train 2000, loss 1.441e+00, top1 65.89, top5 85.79
2021-11-07 08:44:23 train 3000, loss 1.453e+00, top1 65.65, top5 85.59
2021-11-07 08:44:23 train 3000, loss 1.450e+00, top1 65.74, top5 85.70
2021-11-07 08:44:23 train 3000, loss 1.447e+00, top1 65.73, top5 85.71
2021-11-07 08:58:19 train 4000, loss 1.454e+00, top1 65.65, top5 85.62
2021-11-07 08:58:19 train 4000, loss 1.454e+00, top1 65.57, top5 85.62
2021-11-07 08:58:20 train 4000, loss 1.453e+00, top1 65.63, top5 85.63
2021-11-07 09:12:20 train 5000, loss 1.457e+00, top1 65.48, top5 85.59
2021-11-07 09:12:20 train 5000, loss 1.459e+00, top1 65.53, top5 85.55
2021-11-07 09:12:21 train 5000, loss 1.459e+00, top1 65.50, top5 85.57
2021-11-07 09:12:51 valid 0000, loss 5.465e-01, top1 89.41, top5 92.94
2021-11-07 09:12:51 valid 0000, loss 5.465e-01, top1 89.41, top5 92.94
2021-11-07 09:12:51 valid 0000, loss 5.465e-01, top1 89.41, top5 92.94
2021-11-07 09:17:26 (JOBID 31694) epoch 58: train time 4207.61, inference time 285.59s, valid_top1 69.39 (best_top1 69.66), valid_top5 89.44
2021-11-07 09:17:26 (JOBID 31694) epoch 58: train time 4211.76, inference time 285.57s, valid_top1 69.39 (best_top1 69.66), valid_top5 89.44
2021-11-07 09:17:26 (JOBID 31694) epoch 58: train time 4219.35, inference time 286.14s, valid_top1 69.39 (best_top1 69.66), valid_top5 89.44
2021-11-07 09:17:41 train 0000, loss 1.708e+00, top1 63.53, top5 84.71
2021-11-07 09:17:41 train 0000, loss 1.751e+00, top1 62.35, top5 81.18
2021-11-07 09:17:41 train 0000, loss 1.330e+00, top1 64.71, top5 90.59
2021-11-07 09:31:39 train 1000, loss 1.435e+00, top1 66.06, top5 85.82
2021-11-07 09:31:39 train 1000, loss 1.440e+00, top1 65.88, top5 85.75
2021-11-07 09:31:40 train 1000, loss 1.443e+00, top1 65.69, top5 85.86
2021-11-07 09:45:36 train 2000, loss 1.447e+00, top1 65.83, top5 85.73
2021-11-07 09:45:36 train 2000, loss 1.446e+00, top1 65.71, top5 85.64
2021-11-07 09:45:36 train 2000, loss 1.449e+00, top1 65.63, top5 85.68
2021-11-07 09:59:41 train 3000, loss 1.450e+00, top1 65.68, top5 85.61
2021-11-07 09:59:41 train 3000, loss 1.448e+00, top1 65.79, top5 85.69
2021-11-07 09:59:41 train 3000, loss 1.456e+00, top1 65.55, top5 85.58
2021-11-07 10:13:32 train 4000, loss 1.453e+00, top1 65.72, top5 85.60
2021-11-07 10:13:32 train 4000, loss 1.454e+00, top1 65.61, top5 85.57
2021-11-07 10:13:32 train 4000, loss 1.461e+00, top1 65.46, top5 85.48
2021-11-07 10:27:39 train 5000, loss 1.455e+00, top1 65.58, top5 85.55
2021-11-07 10:27:39 train 5000, loss 1.456e+00, top1 65.63, top5 85.55
2021-11-07 10:27:39 train 5000, loss 1.461e+00, top1 65.49, top5 85.49
2021-11-07 10:28:19 valid 0000, loss 5.465e-01, top1 88.24, top5 96.47
2021-11-07 10:28:19 valid 0000, loss 5.465e-01, top1 88.24, top5 96.47
2021-11-07 10:28:19 valid 0000, loss 5.465e-01, top1 88.24, top5 96.47
2021-11-07 10:32:47 (JOBID 31694) epoch 59: train time 4233.99, inference time 286.51s, valid_top1 68.93 (best_top1 69.66), valid_top5 89.14
2021-11-07 10:32:48 (JOBID 31694) epoch 59: train time 4234.41, inference time 287.09s, valid_top1 68.93 (best_top1 69.66), valid_top5 89.14
2021-11-07 10:32:52 (JOBID 31694) epoch 59: train time 4234.31, inference time 290.62s, valid_top1 68.93 (best_top1 69.66), valid_top5 89.14
2021-11-07 10:33:14 train 0000, loss 1.184e+00, top1 70.59, top5 89.41
2021-11-07 10:33:14 train 0000, loss 1.606e+00, top1 67.06, top5 83.53
2021-11-07 10:33:16 train 0000, loss 1.659e+00, top1 62.35, top5 82.35
2021-11-07 10:47:06 train 1000, loss 1.301e+00, top1 69.09, top5 87.48
2021-11-07 10:47:06 train 1000, loss 1.319e+00, top1 68.65, top5 87.15
2021-11-07 10:47:06 train 1000, loss 1.312e+00, top1 68.77, top5 87.43
2021-11-07 11:01:00 train 2000, loss 1.278e+00, top1 69.58, top5 87.80
2021-11-07 11:01:00 train 2000, loss 1.299e+00, top1 69.14, top5 87.45
2021-11-07 11:01:00 train 2000, loss 1.296e+00, top1 69.13, top5 87.66
2021-11-07 11:14:55 train 3000, loss 1.281e+00, top1 69.53, top5 87.72
2021-11-07 11:14:55 train 3000, loss 1.273e+00, top1 69.72, top5 87.87
2021-11-07 11:14:55 train 3000, loss 1.282e+00, top1 69.47, top5 87.81
2021-11-07 11:28:46 train 4000, loss 1.269e+00, top1 69.77, top5 87.88
2021-11-07 11:28:46 train 4000, loss 1.262e+00, top1 69.95, top5 88.03
2021-11-07 11:28:47 train 4000, loss 1.271e+00, top1 69.72, top5 87.93
2021-11-07 11:42:41 train 5000, loss 1.263e+00, top1 69.93, top5 87.99
2021-11-07 11:42:41 train 5000, loss 1.256e+00, top1 70.03, top5 88.11
2021-11-07 11:42:41 train 5000, loss 1.264e+00, top1 69.89, top5 88.01
2021-11-07 11:43:12 valid 0000, loss 4.112e-01, top1 92.94, top5 97.65
2021-11-07 11:43:12 valid 0000, loss 4.112e-01, top1 92.94, top5 97.65
2021-11-07 11:43:12 valid 0000, loss 4.112e-01, top1 92.94, top5 97.65
2021-11-07 11:47:57 (JOBID 31694) epoch 60: train time 4213.83, inference time 296.28s, valid_top1 73.18 (best_top1 73.18), valid_top5 91.48
2021-11-07 11:47:57 (JOBID 31694) epoch 60: train time 4213.11, inference time 296.75s, valid_top1 73.18 (best_top1 73.18), valid_top5 91.48
2021-11-07 11:47:58 (JOBID 31694) epoch 60: train time 4209.16, inference time 296.92s, valid_top1 73.18 (best_top1 73.18), valid_top5 91.48
2021-11-07 11:48:14 train 0000, loss 1.165e+00, top1 74.12, top5 91.76
2021-11-07 11:48:14 train 0000, loss 1.106e+00, top1 71.76, top5 90.59
2021-11-07 11:48:14 train 0000, loss 1.448e+00, top1 70.59, top5 81.18
2021-11-07 12:02:04 train 1000, loss 1.222e+00, top1 70.81, top5 88.57
2021-11-07 12:02:04 train 1000, loss 1.223e+00, top1 70.81, top5 88.39
2021-11-07 12:02:04 train 1000, loss 1.218e+00, top1 70.93, top5 88.74
2021-11-07 12:16:03 train 2000, loss 1.217e+00, top1 70.86, top5 88.61
2021-11-07 12:16:03 train 2000, loss 1.220e+00, top1 70.85, top5 88.52
2021-11-07 12:16:03 train 2000, loss 1.214e+00, top1 70.97, top5 88.72
2021-11-07 12:30:00 train 3000, loss 1.212e+00, top1 70.98, top5 88.66
2021-11-07 12:30:00 train 3000, loss 1.215e+00, top1 70.96, top5 88.63
2021-11-07 12:30:01 train 3000, loss 1.211e+00, top1 71.04, top5 88.75
2021-11-07 12:43:58 train 4000, loss 1.209e+00, top1 71.06, top5 88.68
2021-11-07 12:43:58 train 4000, loss 1.213e+00, top1 71.05, top5 88.63
2021-11-07 12:43:58 train 4000, loss 1.212e+00, top1 71.03, top5 88.73
2021-11-07 12:57:49 train 5000, loss 1.208e+00, top1 71.10, top5 88.70
2021-11-07 12:57:49 train 5000, loss 1.212e+00, top1 71.01, top5 88.65
2021-11-07 12:57:50 train 5000, loss 1.211e+00, top1 71.06, top5 88.73
2021-11-07 12:58:20 valid 0000, loss 3.499e-01, top1 95.29, top5 97.65
2021-11-07 12:58:20 valid 0000, loss 3.499e-01, top1 95.29, top5 97.65
2021-11-07 12:58:20 valid 0000, loss 3.499e-01, top1 95.29, top5 97.65
2021-11-07 13:02:33 (JOBID 31694) epoch 61: train time 4211.19, inference time 262.64s, valid_top1 73.42 (best_top1 73.42), valid_top5 91.55
2021-11-07 13:03:06 (JOBID 31694) epoch 61: train time 4212.34, inference time 296.27s, valid_top1 73.42 (best_top1 73.42), valid_top5 91.55
2021-11-07 13:03:07 (JOBID 31694) epoch 61: train time 4212.48, inference time 297.89s, valid_top1 73.42 (best_top1 73.42), valid_top5 91.55
2021-11-07 13:03:21 train 0000, loss 1.148e+00, top1 69.41, top5 92.94
2021-11-07 13:02:47 train 0000, loss 1.303e+00, top1 70.59, top5 88.24
2021-11-07 13:03:22 train 0000, loss 1.292e+00, top1 69.41, top5 88.24
2021-11-07 13:17:22 train 1000, loss 1.191e+00, top1 71.50, top5 88.99
2021-11-07 13:17:22 train 1000, loss 1.199e+00, top1 71.47, top5 88.92
2021-11-07 13:17:22 train 1000, loss 1.192e+00, top1 71.36, top5 88.97
2021-11-07 13:31:30 train 2000, loss 1.192e+00, top1 71.49, top5 88.94
2021-11-07 13:31:30 train 2000, loss 1.193e+00, top1 71.46, top5 88.96
2021-11-07 13:31:30 train 2000, loss 1.192e+00, top1 71.31, top5 88.97
2021-11-07 13:45:34 train 3000, loss 1.196e+00, top1 71.39, top5 88.86
2021-11-07 13:45:34 train 3000, loss 1.189e+00, top1 71.52, top5 88.99
2021-11-07 13:45:34 train 3000, loss 1.196e+00, top1 71.26, top5 88.91
2021-11-07 13:59:43 train 4000, loss 1.189e+00, top1 71.54, top5 88.95
2021-11-07 13:59:43 train 4000, loss 1.195e+00, top1 71.37, top5 88.85
2021-11-07 13:59:43 train 4000, loss 1.194e+00, top1 71.30, top5 88.91
2021-11-07 14:13:46 train 5000, loss 1.189e+00, top1 71.56, top5 88.94
2021-11-07 14:13:46 train 5000, loss 1.193e+00, top1 71.41, top5 88.86
2021-11-07 14:13:46 train 5000, loss 1.194e+00, top1 71.35, top5 88.90
2021-11-07 14:14:17 valid 0000, loss 3.660e-01, top1 92.94, top5 97.65
2021-11-07 14:14:17 valid 0000, loss 3.660e-01, top1 92.94, top5 97.65
2021-11-07 14:14:17 valid 0000, loss 3.660e-01, top1 92.94, top5 97.65
2021-11-07 14:18:47 (JOBID 31694) epoch 62: train time 4293.57, inference time 279.67s, valid_top1 73.64 (best_top1 73.64), valid_top5 91.65
2021-11-07 14:18:47 (JOBID 31694) epoch 62: train time 4260.62, inference time 280.03s, valid_top1 73.64 (best_top1 73.64), valid_top5 91.65
2021-11-07 14:18:47 (JOBID 31694) epoch 62: train time 4258.97, inference time 280.79s, valid_top1 73.64 (best_top1 73.64), valid_top5 91.65
2021-11-07 14:19:02 train 0000, loss 9.955e-01, top1 74.12, top5 89.41
2021-11-07 14:19:02 train 0000, loss 1.030e+00, top1 72.94, top5 94.12
2021-11-07 14:19:02 train 0000, loss 1.031e+00, top1 75.29, top5 92.94
2021-11-07 14:33:05 train 1000, loss 1.179e+00, top1 71.73, top5 89.01
2021-11-07 14:33:05 train 1000, loss 1.185e+00, top1 71.41, top5 88.96
2021-11-07 14:33:05 train 1000, loss 1.176e+00, top1 71.87, top5 89.10
2021-11-07 14:47:08 train 2000, loss 1.180e+00, top1 71.70, top5 88.96
2021-11-07 14:47:08 train 2000, loss 1.184e+00, top1 71.56, top5 89.01
2021-11-07 14:47:08 train 2000, loss 1.177e+00, top1 71.83, top5 89.11
2021-11-07 15:01:09 train 3000, loss 1.180e+00, top1 71.68, top5 89.00
2021-11-07 15:01:09 train 3000, loss 1.181e+00, top1 71.63, top5 89.04
2021-11-07 15:01:09 train 3000, loss 1.175e+00, top1 71.86, top5 89.13
2021-11-07 15:15:12 train 4000, loss 1.178e+00, top1 71.73, top5 89.03
2021-11-07 15:15:12 train 4000, loss 1.179e+00, top1 71.72, top5 89.06
2021-11-07 15:15:12 train 4000, loss 1.177e+00, top1 71.79, top5 89.10
2021-11-07 15:29:11 train 5000, loss 1.178e+00, top1 71.69, top5 89.02
2021-11-07 15:29:11 train 5000, loss 1.180e+00, top1 71.69, top5 89.06
2021-11-07 15:29:11 train 5000, loss 1.177e+00, top1 71.81, top5 89.12
2021-11-07 15:29:41 valid 0000, loss 4.199e-01, top1 89.41, top5 97.65
2021-11-07 15:29:41 valid 0000, loss 4.199e-01, top1 89.41, top5 97.65
2021-11-07 15:29:41 valid 0000, loss 4.199e-01, top1 89.41, top5 97.65
2021-11-07 15:34:08 (JOBID 31694) epoch 63: train time 4244.05, inference time 276.76s, valid_top1 73.74 (best_top1 73.74), valid_top5 91.78
2021-11-07 15:34:14 (JOBID 31694) epoch 63: train time 4244.22, inference time 283.55s, valid_top1 73.74 (best_top1 73.74), valid_top5 91.78
2021-11-07 15:34:17 (JOBID 31694) epoch 63: train time 4243.49, inference time 286.00s, valid_top1 73.74 (best_top1 73.74), valid_top5 91.78
2021-11-07 15:34:29 train 0000, loss 1.366e+00, top1 65.88, top5 89.41
2021-11-07 15:34:23 train 0000, loss 1.176e+00, top1 75.29, top5 89.41
2021-11-07 15:34:31 train 0000, loss 1.314e+00, top1 71.76, top5 88.24
2021-11-07 15:48:14 train 1000, loss 1.159e+00, top1 72.21, top5 89.38
2021-11-07 15:48:14 train 1000, loss 1.171e+00, top1 71.98, top5 89.17
2021-11-07 15:48:14 train 1000, loss 1.170e+00, top1 71.93, top5 89.20
2021-11-07 16:02:00 train 2000, loss 1.161e+00, top1 72.14, top5 89.32
2021-11-07 16:02:00 train 2000, loss 1.172e+00, top1 71.91, top5 89.15
2021-11-07 16:02:00 train 2000, loss 1.168e+00, top1 71.94, top5 89.22
2021-11-07 16:15:56 train 3000, loss 1.169e+00, top1 72.01, top5 89.22
2021-11-07 16:15:56 train 3000, loss 1.170e+00, top1 71.94, top5 89.18
2021-11-07 16:15:56 train 3000, loss 1.167e+00, top1 71.97, top5 89.20
2021-11-07 16:29:52 train 4000, loss 1.169e+00, top1 71.94, top5 89.23
2021-11-07 16:29:52 train 4000, loss 1.168e+00, top1 71.95, top5 89.23
2021-11-07 16:29:52 train 4000, loss 1.167e+00, top1 71.95, top5 89.21
2021-11-07 16:43:47 train 5000, loss 1.167e+00, top1 71.97, top5 89.25
2021-11-07 16:43:47 train 5000, loss 1.167e+00, top1 71.97, top5 89.26
2021-11-07 16:43:48 train 5000, loss 1.167e+00, top1 71.93, top5 89.17
2021-11-07 16:44:17 valid 0000, loss 4.083e-01, top1 92.94, top5 96.47
2021-11-07 16:44:17 valid 0000, loss 4.083e-01, top1 92.94, top5 96.47
2021-11-07 16:44:17 valid 0000, loss 4.083e-01, top1 92.94, top5 96.47
2021-11-07 16:48:28 (JOBID 31694) epoch 64: train time 4190.39, inference time 261.19s, valid_top1 73.84 (best_top1 73.84), valid_top5 91.78
2021-11-07 16:48:47 (JOBID 31694) epoch 64: train time 4199.08, inference time 279.80s, valid_top1 73.84 (best_top1 73.84), valid_top5 91.78
2021-11-07 16:48:49 (JOBID 31694) epoch 64: train time 4192.82, inference time 281.36s, valid_top1 73.84 (best_top1 73.84), valid_top5 91.78
2021-11-07 16:48:42 train 0000, loss 1.384e+00, top1 68.24, top5 83.53
2021-11-07 16:49:02 train 0000, loss 9.661e-01, top1 78.82, top5 90.59
2021-11-07 16:49:02 train 0000, loss 1.092e+00, top1 72.94, top5 90.59
2021-11-07 17:02:59 train 1000, loss 1.159e+00, top1 72.23, top5 89.26
2021-11-07 17:02:59 train 1000, loss 1.153e+00, top1 72.32, top5 89.41
2021-11-07 17:02:59 train 1000, loss 1.161e+00, top1 72.01, top5 89.24
2021-11-07 17:16:51 train 2000, loss 1.166e+00, top1 71.91, top5 89.24
2021-11-07 17:16:51 train 2000, loss 1.155e+00, top1 72.25, top5 89.40
2021-11-07 17:16:51 train 2000, loss 1.162e+00, top1 72.09, top5 89.24
2021-11-07 17:30:45 train 3000, loss 1.162e+00, top1 72.08, top5 89.23
2021-11-07 17:30:45 train 3000, loss 1.159e+00, top1 72.18, top5 89.33
2021-11-07 17:30:45 train 3000, loss 1.165e+00, top1 71.98, top5 89.22
2021-11-07 17:44:41 train 4000, loss 1.161e+00, top1 72.16, top5 89.33
2021-11-07 17:44:41 train 4000, loss 1.160e+00, top1 72.12, top5 89.25
2021-11-07 17:44:41 train 4000, loss 1.161e+00, top1 72.09, top5 89.25
2021-11-07 17:58:37 train 5000, loss 1.161e+00, top1 72.15, top5 89.34
2021-11-07 17:58:38 train 5000, loss 1.162e+00, top1 72.10, top5 89.25
2021-11-07 17:58:38 train 5000, loss 1.159e+00, top1 72.15, top5 89.26
2021-11-07 17:59:09 valid 0000, loss 4.564e-01, top1 90.59, top5 97.65
2021-11-07 17:59:09 valid 0000, loss 4.564e-01, top1 90.59, top5 97.65
2021-11-07 17:59:09 valid 0000, loss 4.564e-01, top1 90.59, top5 97.65
2021-11-07 18:03:29 (JOBID 31694) epoch 65: train time 4229.52, inference time 271.34s, valid_top1 73.83 (best_top1 73.84), valid_top5 91.82
2021-11-07 18:03:34 (JOBID 31694) epoch 65: train time 4210.24, inference time 276.31s, valid_top1 73.83 (best_top1 73.84), valid_top5 91.82
2021-11-07 18:03:36 (JOBID 31694) epoch 65: train time 4209.14, inference time 278.32s, valid_top1 73.83 (best_top1 73.84), valid_top5 91.82
2021-11-07 18:03:49 train 0000, loss 1.148e+00, top1 75.29, top5 90.59
2021-11-07 18:03:43 train 0000, loss 8.474e-01, top1 75.29, top5 94.12
2021-11-07 18:03:51 train 0000, loss 1.336e+00, top1 71.76, top5 88.24
2021-11-07 18:17:43 train 1000, loss 1.154e+00, top1 72.28, top5 89.35
2021-11-07 18:17:43 train 1000, loss 1.153e+00, top1 72.35, top5 89.41
2021-11-07 18:17:43 train 1000, loss 1.146e+00, top1 72.32, top5 89.41
2021-11-07 18:31:26 train 2000, loss 1.146e+00, top1 72.42, top5 89.48
2021-11-07 18:31:26 train 2000, loss 1.150e+00, top1 72.29, top5 89.43
2021-11-07 18:31:26 train 2000, loss 1.156e+00, top1 72.30, top5 89.34
2021-11-07 18:45:07 train 3000, loss 1.144e+00, top1 72.46, top5 89.49
2021-11-07 18:45:07 train 3000, loss 1.154e+00, top1 72.29, top5 89.39
2021-11-07 18:45:08 train 3000, loss 1.156e+00, top1 72.31, top5 89.30
2021-11-07 18:58:53 train 4000, loss 1.146e+00, top1 72.44, top5 89.48
2021-11-07 18:58:53 train 4000, loss 1.152e+00, top1 72.35, top5 89.39
2021-11-07 18:58:53 train 4000, loss 1.156e+00, top1 72.30, top5 89.30
2021-11-07 19:12:41 train 5000, loss 1.147e+00, top1 72.43, top5 89.46
2021-11-07 19:12:41 train 5000, loss 1.152e+00, top1 72.33, top5 89.39
2021-11-07 19:12:41 train 5000, loss 1.155e+00, top1 72.31, top5 89.32
2021-11-07 19:13:11 valid 0000, loss 4.155e-01, top1 89.41, top5 98.82
2021-11-07 19:13:11 valid 0000, loss 4.155e-01, top1 89.41, top5 98.82
2021-11-07 19:13:11 valid 0000, loss 4.155e-01, top1 89.41, top5 98.82
2021-11-07 19:17:40 (JOBID 31694) epoch 66: train time 4166.76, inference time 278.21s, valid_top1 74.00 (best_top1 74.00), valid_top5 91.86
2021-11-07 19:17:44 (JOBID 31694) epoch 66: train time 4164.95, inference time 282.81s, valid_top1 74.00 (best_top1 74.00), valid_top5 91.86
2021-11-07 19:17:48 (JOBID 31694) epoch 66: train time 4171.88, inference time 287.02s, valid_top1 74.00 (best_top1 74.00), valid_top5 91.86
2021-11-07 19:17:58 train 0000, loss 1.059e+00, top1 71.76, top5 91.76
2021-11-07 19:17:54 train 0000, loss 1.572e+00, top1 63.53, top5 82.35
2021-11-07 19:18:02 train 0000, loss 1.104e+00, top1 71.76, top5 90.59
2021-11-07 19:32:02 train 1000, loss 1.145e+00, top1 72.40, top5 89.45
2021-11-07 19:32:02 train 1000, loss 1.128e+00, top1 72.87, top5 89.57
2021-11-07 19:32:03 train 1000, loss 1.140e+00, top1 72.61, top5 89.52
2021-11-07 19:45:52 train 2000, loss 1.147e+00, top1 72.38, top5 89.46
2021-11-07 19:45:52 train 2000, loss 1.136e+00, top1 72.64, top5 89.55
2021-11-07 19:45:53 train 2000, loss 1.140e+00, top1 72.59, top5 89.53
2021-11-07 19:59:37 train 3000, loss 1.149e+00, top1 72.36, top5 89.42
2021-11-07 19:59:37 train 3000, loss 1.140e+00, top1 72.61, top5 89.53
2021-11-07 19:59:37 train 3000, loss 1.138e+00, top1 72.59, top5 89.59
2021-11-07 20:13:31 train 4000, loss 1.149e+00, top1 72.40, top5 89.43
2021-11-07 20:13:31 train 4000, loss 1.142e+00, top1 72.53, top5 89.52
2021-11-07 20:13:31 train 4000, loss 1.142e+00, top1 72.53, top5 89.51
2021-11-07 20:27:22 train 5000, loss 1.151e+00, top1 72.34, top5 89.42
2021-11-07 20:27:22 train 5000, loss 1.144e+00, top1 72.48, top5 89.50
2021-11-07 20:27:22 train 5000, loss 1.143e+00, top1 72.51, top5 89.49
2021-11-07 20:27:53 valid 0000, loss 3.927e-01, top1 92.94, top5 97.65
2021-11-07 20:27:53 valid 0000, loss 3.927e-01, top1 92.94, top5 97.65
2021-11-07 20:27:53 valid 0000, loss 3.927e-01, top1 92.94, top5 97.65
2021-11-07 20:32:12 (JOBID 31694) epoch 67: train time 4198.24, inference time 269.71s, valid_top1 74.11 (best_top1 74.11), valid_top5 91.94
2021-11-07 20:32:28 (JOBID 31694) epoch 67: train time 4202.26, inference time 285.27s, valid_top1 74.11 (best_top1 74.11), valid_top5 91.94
2021-11-07 20:32:30 (JOBID 31694) epoch 67: train time 4193.95, inference time 288.10s, valid_top1 74.11 (best_top1 74.11), valid_top5 91.94
2021-11-07 20:32:43 train 0000, loss 1.149e+00, top1 67.06, top5 87.06
2021-11-07 20:32:27 train 0000, loss 8.815e-01, top1 82.35, top5 94.12
2021-11-07 20:32:45 train 0000, loss 1.261e+00, top1 72.94, top5 84.71
2021-11-07 20:46:25 train 1000, loss 1.130e+00, top1 72.83, top5 89.62
2021-11-07 20:46:25 train 1000, loss 1.137e+00, top1 72.70, top5 89.71
2021-11-07 20:46:25 train 1000, loss 1.131e+00, top1 72.98, top5 89.68
2021-11-07 21:00:10 train 2000, loss 1.140e+00, top1 72.61, top5 89.56
2021-11-07 21:00:10 train 2000, loss 1.130e+00, top1 72.75, top5 89.68
2021-11-07 21:00:10 train 2000, loss 1.132e+00, top1 72.86, top5 89.64
2021-11-07 21:13:55 train 3000, loss 1.138e+00, top1 72.57, top5 89.59
2021-11-07 21:13:55 train 3000, loss 1.136e+00, top1 72.74, top5 89.61
2021-11-07 21:13:55 train 3000, loss 1.133e+00, top1 72.68, top5 89.64
2021-11-07 21:27:36 train 4000, loss 1.135e+00, top1 72.62, top5 89.60
2021-11-07 21:27:36 train 4000, loss 1.140e+00, top1 72.55, top5 89.56
2021-11-07 21:27:36 train 4000, loss 1.139e+00, top1 72.62, top5 89.58
2021-11-07 21:41:12 train 5000, loss 1.137e+00, top1 72.57, top5 89.57
2021-11-07 21:41:12 train 5000, loss 1.140e+00, top1 72.55, top5 89.55
2021-11-07 21:41:12 train 5000, loss 1.140e+00, top1 72.58, top5 89.56
2021-11-07 21:41:42 valid 0000, loss 4.428e-01, top1 88.24, top5 97.65
2021-11-07 21:41:42 valid 0000, loss 4.428e-01, top1 88.24, top5 97.65
2021-11-07 21:41:42 valid 0000, loss 4.428e-01, top1 88.24, top5 97.65
2021-11-07 21:45:44 (JOBID 31694) epoch 68: train time 4159.81, inference time 251.84s, valid_top1 74.04 (best_top1 74.11), valid_top5 91.90
2021-11-07 21:46:29 (JOBID 31694) epoch 68: train time 4141.32, inference time 297.05s, valid_top1 74.04 (best_top1 74.11), valid_top5 91.90
2021-11-07 21:46:29 (JOBID 31694) epoch 68: train time 4143.38, inference time 297.09s, valid_top1 74.04 (best_top1 74.11), valid_top5 91.90
2021-11-07 21:46:43 train 0000, loss 1.073e+00, top1 76.47, top5 90.59
2021-11-07 21:45:58 train 0000, loss 9.967e-01, top1 70.59, top5 92.94
2021-11-07 21:46:43 train 0000, loss 1.218e+00, top1 74.12, top5 85.88
2021-11-07 22:00:33 train 1000, loss 1.128e+00, top1 73.09, top5 89.69
2021-11-07 22:00:33 train 1000, loss 1.130e+00, top1 72.83, top5 89.70
2021-11-07 22:00:34 train 1000, loss 1.127e+00, top1 72.85, top5 89.79
2021-11-07 22:14:09 train 2000, loss 1.131e+00, top1 72.93, top5 89.60
2021-11-07 22:14:09 train 2000, loss 1.134e+00, top1 72.73, top5 89.67
2021-11-07 22:14:09 train 2000, loss 1.128e+00, top1 72.84, top5 89.73
2021-11-07 22:27:48 train 3000, loss 1.133e+00, top1 72.84, top5 89.61
2021-11-07 22:27:48 train 3000, loss 1.132e+00, top1 72.73, top5 89.67
2021-11-07 22:27:48 train 3000, loss 1.130e+00, top1 72.80, top5 89.69
2021-11-07 22:41:33 train 4000, loss 1.129e+00, top1 72.83, top5 89.67
2021-11-07 22:41:33 train 4000, loss 1.132e+00, top1 72.81, top5 89.64
2021-11-07 22:41:33 train 4000, loss 1.131e+00, top1 72.74, top5 89.67
2021-11-07 22:55:10 train 5000, loss 1.132e+00, top1 72.68, top5 89.65
2021-11-07 22:55:10 train 5000, loss 1.132e+00, top1 72.75, top5 89.63
2021-11-07 22:55:10 train 5000, loss 1.133e+00, top1 72.78, top5 89.64
2021-11-07 22:55:40 valid 0000, loss 4.297e-01, top1 88.24, top5 98.82
2021-11-07 22:55:40 valid 0000, loss 4.297e-01, top1 88.24, top5 98.82
2021-11-07 22:55:40 valid 0000, loss 4.297e-01, top1 88.24, top5 98.82
2021-11-07 23:00:09 (JOBID 31694) epoch 69: train time 4186.77, inference time 278.40s, valid_top1 74.26 (best_top1 74.26), valid_top5 92.02
2021-11-07 23:00:13 (JOBID 31694) epoch 69: train time 4141.34, inference time 282.37s, valid_top1 74.26 (best_top1 74.26), valid_top5 92.02
2021-11-07 23:00:15 (JOBID 31694) epoch 69: train time 4141.67, inference time 285.08s, valid_top1 74.26 (best_top1 74.26), valid_top5 92.02
2021-11-07 23:00:24 train 0000, loss 1.392e+00, top1 65.88, top5 82.35
2021-11-07 23:00:28 train 0000, loss 1.026e+00, top1 75.29, top5 91.76
2021-11-07 23:00:29 train 0000, loss 7.997e-01, top1 82.35, top5 95.29
2021-11-07 23:14:16 train 1000, loss 1.122e+00, top1 72.98, top5 89.77
2021-11-07 23:14:16 train 1000, loss 1.129e+00, top1 72.70, top5 89.64
2021-11-07 23:14:16 train 1000, loss 1.129e+00, top1 72.84, top5 89.55
2021-11-07 23:28:09 train 2000, loss 1.124e+00, top1 72.89, top5 89.82
2021-11-07 23:28:09 train 2000, loss 1.129e+00, top1 72.73, top5 89.63
2021-11-07 23:28:09 train 2000, loss 1.132e+00, top1 72.74, top5 89.58
2021-11-07 23:42:04 train 3000, loss 1.123e+00, top1 72.94, top5 89.82
2021-11-07 23:42:04 train 3000, loss 1.128e+00, top1 72.75, top5 89.62
2021-11-07 23:42:04 train 3000, loss 1.132e+00, top1 72.72, top5 89.61
2021-11-07 23:56:00 train 4000, loss 1.124e+00, top1 72.93, top5 89.79
2021-11-07 23:56:00 train 4000, loss 1.129e+00, top1 72.76, top5 89.62
2021-11-07 23:56:00 train 4000, loss 1.132e+00, top1 72.72, top5 89.61
2021-11-08 00:10:05 train 5000, loss 1.126e+00, top1 72.91, top5 89.76
2021-11-08 00:10:05 train 5000, loss 1.131e+00, top1 72.73, top5 89.61
2021-11-08 00:10:05 train 5000, loss 1.132e+00, top1 72.72, top5 89.62
2021-11-08 00:10:35 valid 0000, loss 4.177e-01, top1 89.41, top5 96.47
2021-11-08 00:10:35 valid 0000, loss 4.177e-01, top1 89.41, top5 96.47
2021-11-08 00:10:35 valid 0000, loss 4.177e-01, top1 89.41, top5 96.47
2021-11-08 00:15:07 (JOBID 31694) epoch 70: train time 4211.51, inference time 281.39s, valid_top1 74.20 (best_top1 74.26), valid_top5 92.04
2021-11-08 00:15:08 (JOBID 31694) epoch 70: train time 4216.45, inference time 282.72s, valid_top1 74.20 (best_top1 74.26), valid_top5 92.04
2021-11-08 00:15:11 (JOBID 31694) epoch 70: train time 4209.59, inference time 286.04s, valid_top1 74.20 (best_top1 74.26), valid_top5 92.04
2021-11-08 00:15:22 train 0000, loss 1.060e+00, top1 80.00, top5 91.76
2021-11-08 00:15:22 train 0000, loss 8.836e-01, top1 83.53, top5 90.59
2021-11-08 00:15:25 train 0000, loss 8.595e-01, top1 77.65, top5 95.29
2021-11-08 00:29:07 train 1000, loss 1.116e+00, top1 73.05, top5 89.83
2021-11-08 00:29:07 train 1000, loss 1.128e+00, top1 72.93, top5 89.74
2021-11-08 00:29:07 train 1000, loss 1.119e+00, top1 73.03, top5 89.81
2021-11-08 00:42:51 train 2000, loss 1.124e+00, top1 73.02, top5 89.81
2021-11-08 00:42:51 train 2000, loss 1.118e+00, top1 73.01, top5 89.76
2021-11-08 00:42:51 train 2000, loss 1.121e+00, top1 72.89, top5 89.76
2021-11-08 00:56:33 train 3000, loss 1.120e+00, top1 73.05, top5 89.72
2021-11-08 00:56:33 train 3000, loss 1.129e+00, top1 72.86, top5 89.71
2021-11-08 00:56:33 train 3000, loss 1.121e+00, top1 72.94, top5 89.79
2021-11-08 01:10:21 train 4000, loss 1.119e+00, top1 73.03, top5 89.73
2021-11-08 01:10:21 train 4000, loss 1.129e+00, top1 72.87, top5 89.72
2021-11-08 01:10:22 train 4000, loss 1.123e+00, top1 72.91, top5 89.76
2021-11-08 01:24:16 train 5000, loss 1.130e+00, top1 72.85, top5 89.68
2021-11-08 01:24:16 train 5000, loss 1.122e+00, top1 73.00, top5 89.71
2021-11-08 01:24:16 train 5000, loss 1.123e+00, top1 72.91, top5 89.76
2021-11-08 01:24:46 valid 0000, loss 4.354e-01, top1 85.88, top5 97.65
2021-11-08 01:24:46 valid 0000, loss 4.354e-01, top1 85.88, top5 97.65
2021-11-08 01:24:46 valid 0000, loss 4.354e-01, top1 85.88, top5 97.65
2021-11-08 01:29:12 (JOBID 31694) epoch 71: train time 4168.53, inference time 275.37s, valid_top1 74.28 (best_top1 74.28), valid_top5 92.08
2021-11-08 01:29:22 (JOBID 31694) epoch 71: train time 4169.65, inference time 285.19s, valid_top1 74.28 (best_top1 74.28), valid_top5 92.08
2021-11-08 01:29:26 (JOBID 31694) epoch 71: train time 4165.26, inference time 289.78s, valid_top1 74.28 (best_top1 74.28), valid_top5 92.08
2021-11-08 01:29:25 train 0000, loss 1.444e+00, top1 70.59, top5 84.71
2021-11-08 01:29:37 train 0000, loss 9.066e-01, top1 77.65, top5 94.12
2021-11-08 01:29:41 train 0000, loss 1.319e+00, top1 68.24, top5 84.71
2021-11-08 01:43:36 train 1000, loss 1.115e+00, top1 73.07, top5 89.85
2021-11-08 01:43:36 train 1000, loss 1.115e+00, top1 73.15, top5 89.88
2021-11-08 01:43:36 train 1000, loss 1.105e+00, top1 73.32, top5 89.94
2021-11-08 01:57:34 train 2000, loss 1.115e+00, top1 73.04, top5 89.89
2021-11-08 01:57:34 train 2000, loss 1.117e+00, top1 73.19, top5 89.86
2021-11-08 01:57:35 train 2000, loss 1.115e+00, top1 73.11, top5 89.82
2021-11-08 02:11:36 train 3000, loss 1.119e+00, top1 72.99, top5 89.83
2021-11-08 02:11:35 train 3000, loss 1.115e+00, top1 73.18, top5 89.87
2021-11-08 02:11:36 train 3000, loss 1.121e+00, top1 73.00, top5 89.76
2021-11-08 02:25:39 train 4000, loss 1.121e+00, top1 72.93, top5 89.79
2021-11-08 02:25:39 train 4000, loss 1.117e+00, top1 73.13, top5 89.85
2021-11-08 02:25:40 train 4000, loss 1.124e+00, top1 72.97, top5 89.73
2021-11-08 02:39:40 train 5000, loss 1.120e+00, top1 72.96, top5 89.78
2021-11-08 02:39:40 train 5000, loss 1.118e+00, top1 73.10, top5 89.84
2021-11-08 02:39:40 train 5000, loss 1.124e+00, top1 72.94, top5 89.72
2021-11-08 02:40:10 valid 0000, loss 4.252e-01, top1 87.06, top5 97.65
2021-11-08 02:40:10 valid 0000, loss 4.252e-01, top1 87.06, top5 97.65
2021-11-08 02:40:10 valid 0000, loss 4.252e-01, top1 87.06, top5 97.65
2021-11-08 02:44:14 (JOBID 31694) epoch 72: train time 4233.90, inference time 254.44s, valid_top1 74.14 (best_top1 74.28), valid_top5 91.96
2021-11-08 02:44:49 (JOBID 31694) epoch 72: train time 4248.37, inference time 289.08s, valid_top1 74.14 (best_top1 74.28), valid_top5 91.96
2021-11-08 02:44:52 (JOBID 31694) epoch 72: train time 4237.84, inference time 291.53s, valid_top1 74.14 (best_top1 74.28), valid_top5 91.96
2021-11-08 02:45:03 train 0000, loss 1.081e+00, top1 68.24, top5 89.41
2021-11-08 02:44:28 train 0000, loss 9.374e-01, top1 76.47, top5 91.76
2021-11-08 02:45:06 train 0000, loss 9.594e-01, top1 74.12, top5 91.76
2021-11-08 02:58:56 train 1000, loss 1.115e+00, top1 73.19, top5 89.84
2021-11-08 02:58:56 train 1000, loss 1.104e+00, top1 73.62, top5 90.03
2021-11-08 02:58:56 train 1000, loss 1.116e+00, top1 73.18, top5 89.88
2021-11-08 03:12:40 train 2000, loss 1.113e+00, top1 73.26, top5 89.87
2021-11-08 03:12:40 train 2000, loss 1.114e+00, top1 73.24, top5 89.84
2021-11-08 03:12:40 train 2000, loss 1.108e+00, top1 73.29, top5 89.99
2021-11-08 03:26:20 train 3000, loss 1.116e+00, top1 73.16, top5 89.80
2021-11-08 03:26:20 train 3000, loss 1.114e+00, top1 73.17, top5 89.88
2021-11-08 03:26:20 train 3000, loss 1.112e+00, top1 73.24, top5 89.90
2021-11-08 03:39:55 train 4000, loss 1.115e+00, top1 73.14, top5 89.87
2021-11-08 03:39:55 train 4000, loss 1.117e+00, top1 73.07, top5 89.82
2021-11-08 03:39:56 train 4000, loss 1.113e+00, top1 73.19, top5 89.89
2021-11-08 03:53:37 train 5000, loss 1.117e+00, top1 73.03, top5 89.82
2021-11-08 03:53:37 train 5000, loss 1.119e+00, top1 73.04, top5 89.83
2021-11-08 03:53:37 train 5000, loss 1.113e+00, top1 73.15, top5 89.90
2021-11-08 03:54:07 valid 0000, loss 3.566e-01, top1 91.76, top5 98.82
2021-11-08 03:54:07 valid 0000, loss 3.566e-01, top1 91.76, top5 98.82
2021-11-08 03:54:07 valid 0000, loss 3.566e-01, top1 91.76, top5 98.82
2021-11-08 03:58:20 (JOBID 31694) epoch 73: train time 4182.82, inference time 262.62s, valid_top1 74.28 (best_top1 74.28), valid_top5 92.05
2021-11-08 03:58:40 (JOBID 31694) epoch 73: train time 4145.51, inference time 283.11s, valid_top1 74.28 (best_top1 74.28), valid_top5 92.05
2021-11-08 03:58:41 (JOBID 31694) epoch 73: train time 4147.91, inference time 284.16s, valid_top1 74.28 (best_top1 74.28), valid_top5 92.05
2021-11-08 03:58:34 train 0000, loss 1.569e+00, top1 67.06, top5 81.18
2021-11-08 03:58:55 train 0000, loss 1.122e+00, top1 72.94, top5 90.59
2021-11-08 03:58:55 train 0000, loss 1.014e+00, top1 78.82, top5 90.59
2021-11-08 04:12:42 train 1000, loss 1.113e+00, top1 73.07, top5 89.89
2021-11-08 04:12:42 train 1000, loss 1.108e+00, top1 73.39, top5 89.94
2021-11-08 04:12:42 train 1000, loss 1.117e+00, top1 73.15, top5 89.83
2021-11-08 04:26:37 train 2000, loss 1.114e+00, top1 73.22, top5 89.87
2021-11-08 04:26:37 train 2000, loss 1.112e+00, top1 73.12, top5 89.88
2021-11-08 04:26:37 train 2000, loss 1.117e+00, top1 73.19, top5 89.79
2021-11-08 04:40:27 train 3000, loss 1.116e+00, top1 73.19, top5 89.82
2021-11-08 04:40:27 train 3000, loss 1.113e+00, top1 73.13, top5 89.85
2021-11-08 04:40:27 train 3000, loss 1.114e+00, top1 73.24, top5 89.87
2021-11-08 04:54:23 train 4000, loss 1.114e+00, top1 73.23, top5 89.85
2021-11-08 04:54:23 train 4000, loss 1.115e+00, top1 73.10, top5 89.81
2021-11-08 04:54:23 train 4000, loss 1.114e+00, top1 73.20, top5 89.84
2021-11-08 05:08:18 train 5000, loss 1.114e+00, top1 73.22, top5 89.86
2021-11-08 05:08:18 train 5000, loss 1.114e+00, top1 73.13, top5 89.83
2021-11-08 05:08:18 train 5000, loss 1.113e+00, top1 73.20, top5 89.86
2021-11-08 05:08:49 valid 0000, loss 4.140e-01, top1 89.41, top5 97.65
2021-11-08 05:08:49 valid 0000, loss 4.140e-01, top1 89.41, top5 97.65
2021-11-08 05:08:49 valid 0000, loss 4.140e-01, top1 89.41, top5 97.65
2021-11-08 05:13:37 (JOBID 31694) epoch 74: train time 4218.58, inference time 298.36s, valid_top1 74.21 (best_top1 74.28), valid_top5 92.09
2021-11-08 05:13:37 (JOBID 31694) epoch 74: train time 4197.29, inference time 298.11s, valid_top1 74.21 (best_top1 74.28), valid_top5 92.09
2021-11-08 05:13:37 (JOBID 31694) epoch 74: train time 4197.87, inference time 298.35s, valid_top1 74.21 (best_top1 74.28), valid_top5 92.09
2021-11-08 05:13:51 train 0000, loss 1.233e+00, top1 69.41, top5 87.06
2021-11-08 05:13:51 train 0000, loss 9.723e-01, top1 76.47, top5 91.76
2021-11-08 05:13:51 train 0000, loss 1.190e+00, top1 70.59, top5 88.24
2021-11-08 05:27:38 train 1000, loss 1.104e+00, top1 73.49, top5 90.08
2021-11-08 05:27:38 train 1000, loss 1.089e+00, top1 73.68, top5 90.20
2021-11-08 05:27:38 train 1000, loss 1.110e+00, top1 73.18, top5 89.88
2021-11-08 05:41:30 train 2000, loss 1.101e+00, top1 73.59, top5 90.08
2021-11-08 05:41:30 train 2000, loss 1.095e+00, top1 73.63, top5 90.13
2021-11-08 05:41:30 train 2000, loss 1.108e+00, top1 73.14, top5 89.91
2021-11-08 05:55:33 train 3000, loss 1.101e+00, top1 73.55, top5 90.04
2021-11-08 05:55:33 train 3000, loss 1.102e+00, top1 73.45, top5 90.03
2021-11-08 05:55:33 train 3000, loss 1.105e+00, top1 73.25, top5 89.96
2021-11-08 06:09:22 train 4000, loss 1.102e+00, top1 73.49, top5 90.04
2021-11-08 06:09:22 train 4000, loss 1.103e+00, top1 73.44, top5 90.01
2021-11-08 06:09:22 train 4000, loss 1.108e+00, top1 73.17, top5 89.93
2021-11-08 06:23:15 train 5000, loss 1.103e+00, top1 73.44, top5 90.02
2021-11-08 06:23:15 train 5000, loss 1.106e+00, top1 73.37, top5 89.96
2021-11-08 06:23:15 train 5000, loss 1.109e+00, top1 73.19, top5 89.92
2021-11-08 06:23:45 valid 0000, loss 3.498e-01, top1 94.12, top5 97.65
2021-11-08 06:23:45 valid 0000, loss 3.498e-01, top1 94.12, top5 97.65
2021-11-08 06:23:45 valid 0000, loss 3.498e-01, top1 94.12, top5 97.65
2021-11-08 06:27:59 (JOBID 31694) epoch 75: train time 4197.91, inference time 263.95s, valid_top1 74.39 (best_top1 74.39), valid_top5 92.11
2021-11-08 06:28:19 (JOBID 31694) epoch 75: train time 4197.79, inference time 283.42s, valid_top1 74.39 (best_top1 74.39), valid_top5 92.11
2021-11-08 06:28:19 (JOBID 31694) epoch 75: train time 4198.09, inference time 284.27s, valid_top1 74.39 (best_top1 74.39), valid_top5 92.11
2021-11-08 06:28:12 train 0000, loss 9.026e-01, top1 77.65, top5 90.59
2021-11-08 06:28:33 train 0000, loss 1.218e+00, top1 70.59, top5 89.41
2021-11-08 06:28:33 train 0000, loss 1.428e+00, top1 68.24, top5 87.06
2021-11-08 06:42:21 train 1000, loss 1.109e+00, top1 73.34, top5 89.94
2021-11-08 06:42:21 train 1000, loss 1.102e+00, top1 73.61, top5 89.98
2021-11-08 06:42:21 train 1000, loss 1.093e+00, top1 73.59, top5 90.11
2021-11-08 06:56:04 train 2000, loss 1.101e+00, top1 73.42, top5 90.02
2021-11-08 06:56:04 train 2000, loss 1.110e+00, top1 73.32, top5 89.93
2021-11-08 06:56:04 train 2000, loss 1.100e+00, top1 73.49, top5 89.98
2021-11-08 07:09:44 train 3000, loss 1.106e+00, top1 73.40, top5 89.94
2021-11-08 07:09:44 train 3000, loss 1.103e+00, top1 73.37, top5 90.00
2021-11-08 07:09:44 train 3000, loss 1.102e+00, top1 73.46, top5 89.98
2021-11-08 07:23:31 train 4000, loss 1.107e+00, top1 73.37, top5 89.94
2021-11-08 07:23:31 train 4000, loss 1.106e+00, top1 73.29, top5 89.95
2021-11-08 07:23:31 train 4000, loss 1.101e+00, top1 73.49, top5 90.00
2021-11-08 07:37:20 train 5000, loss 1.104e+00, top1 73.42, top5 89.98
2021-11-08 07:37:20 train 5000, loss 1.106e+00, top1 73.29, top5 89.97
2021-11-08 07:37:20 train 5000, loss 1.103e+00, top1 73.39, top5 90.00
2021-11-08 07:37:50 valid 0000, loss 3.904e-01, top1 89.41, top5 97.65
2021-11-08 07:37:50 valid 0000, loss 3.904e-01, top1 89.41, top5 97.65
2021-11-08 07:37:50 valid 0000, loss 3.904e-01, top1 89.41, top5 97.65
2021-11-08 07:42:03 (JOBID 31694) epoch 76: train time 4161.41, inference time 262.28s, valid_top1 74.30 (best_top1 74.39), valid_top5 92.03
2021-11-08 07:42:21 (JOBID 31694) epoch 76: train time 4161.19, inference time 280.55s, valid_top1 74.30 (best_top1 74.39), valid_top5 92.03
2021-11-08 07:42:23 (JOBID 31694) epoch 76: train time 4181.49, inference time 282.81s, valid_top1 74.30 (best_top1 74.39), valid_top5 92.03
2021-11-08 07:42:35 train 0000, loss 9.544e-01, top1 75.29, top5 91.76
2021-11-08 07:42:16 train 0000, loss 7.873e-01, top1 78.82, top5 95.29
2021-11-08 07:42:38 train 0000, loss 1.320e+00, top1 65.88, top5 88.24
2021-11-08 07:56:30 train 1000, loss 1.096e+00, top1 73.44, top5 90.16
2021-11-08 07:56:30 train 1000, loss 1.084e+00, top1 73.79, top5 90.25
2021-11-08 07:56:30 train 1000, loss 1.102e+00, top1 73.38, top5 89.96
2021-11-08 08:10:25 train 2000, loss 1.096e+00, top1 73.46, top5 90.15
2021-11-08 08:10:25 train 2000, loss 1.086e+00, top1 73.79, top5 90.23
2021-11-08 08:10:25 train 2000, loss 1.101e+00, top1 73.41, top5 90.02
2021-11-08 08:24:22 train 3000, loss 1.088e+00, top1 73.76, top5 90.17
2021-11-08 08:24:22 train 3000, loss 1.097e+00, top1 73.44, top5 90.12
2021-11-08 08:24:22 train 3000, loss 1.101e+00, top1 73.41, top5 90.01
2021-11-08 08:38:18 train 4000, loss 1.093e+00, top1 73.67, top5 90.13
2021-11-08 08:38:18 train 4000, loss 1.100e+00, top1 73.42, top5 90.07
2021-11-08 08:38:18 train 4000, loss 1.104e+00, top1 73.34, top5 89.95
2021-11-08 08:52:15 train 5000, loss 1.101e+00, top1 73.41, top5 90.05
2021-11-08 08:52:15 train 5000, loss 1.094e+00, top1 73.64, top5 90.11
2021-11-08 08:52:15 train 5000, loss 1.106e+00, top1 73.29, top5 89.91
2021-11-08 08:52:45 valid 0000, loss 3.423e-01, top1 94.12, top5 97.65
2021-11-08 08:52:45 valid 0000, loss 3.423e-01, top1 94.12, top5 97.65
2021-11-08 08:52:45 valid 0000, loss 3.423e-01, top1 94.12, top5 97.65
2021-11-08 08:57:20 (JOBID 31694) epoch 77: train time 4214.61, inference time 284.29s, valid_top1 74.19 (best_top1 74.39), valid_top5 92.00
2021-11-08 08:57:20 (JOBID 31694) epoch 77: train time 4212.40, inference time 284.45s, valid_top1 74.19 (best_top1 74.39), valid_top5 92.00
2021-11-08 08:57:20 (JOBID 31694) epoch 77: train time 4232.73, inference time 284.43s, valid_top1 74.19 (best_top1 74.39), valid_top5 92.00
2021-11-08 08:57:34 train 0000, loss 1.073e+00, top1 72.94, top5 91.76
2021-11-08 08:57:34 train 0000, loss 1.258e+00, top1 70.59, top5 90.59
2021-11-08 08:57:34 train 0000, loss 1.260e+00, top1 65.88, top5 90.59
2021-11-08 09:11:23 train 1000, loss 1.107e+00, top1 73.21, top5 90.00
2021-11-08 09:11:23 train 1000, loss 1.101e+00, top1 73.50, top5 89.95
2021-11-08 09:11:23 train 1000, loss 1.094e+00, top1 73.55, top5 90.06
2021-11-08 09:25:13 train 2000, loss 1.103e+00, top1 73.39, top5 90.02
2021-11-08 09:25:13 train 2000, loss 1.098e+00, top1 73.49, top5 90.04
2021-11-08 09:25:14 train 2000, loss 1.098e+00, top1 73.53, top5 89.98
2021-11-08 09:38:57 train 3000, loss 1.102e+00, top1 73.44, top5 90.03
2021-11-08 09:38:57 train 3000, loss 1.100e+00, top1 73.44, top5 90.00
2021-11-08 09:38:57 train 3000, loss 1.100e+00, top1 73.50, top5 90.00
2021-11-08 09:52:48 train 4000, loss 1.099e+00, top1 73.56, top5 90.06
2021-11-08 09:52:48 train 4000, loss 1.098e+00, top1 73.49, top5 90.05
2021-11-08 09:52:48 train 4000, loss 1.098e+00, top1 73.56, top5 90.03
2021-11-08 10:06:37 train 5000, loss 1.098e+00, top1 73.55, top5 90.06
2021-11-08 10:06:37 train 5000, loss 1.100e+00, top1 73.44, top5 90.05
2021-11-08 10:06:37 train 5000, loss 1.098e+00, top1 73.54, top5 90.03
2021-11-08 10:07:07 valid 0000, loss 3.587e-01, top1 92.94, top5 98.82
2021-11-08 10:07:07 valid 0000, loss 3.587e-01, top1 92.94, top5 98.82
2021-11-08 10:07:07 valid 0000, loss 3.587e-01, top1 92.94, top5 98.82
2021-11-08 10:11:23 (JOBID 31694) epoch 78: train time 4177.35, inference time 265.49s, valid_top1 74.33 (best_top1 74.39), valid_top5 92.10
2021-11-08 10:11:38 (JOBID 31694) epoch 78: train time 4177.36, inference time 280.80s, valid_top1 74.33 (best_top1 74.39), valid_top5 92.10
2021-11-08 10:11:40 (JOBID 31694) epoch 78: train time 4177.14, inference time 283.15s, valid_top1 74.33 (best_top1 74.39), valid_top5 92.10
2021-11-08 10:11:53 train 0000, loss 1.364e+00, top1 68.24, top5 85.88
2021-11-08 10:11:36 train 0000, loss 1.493e+00, top1 62.35, top5 85.88
2021-11-08 10:11:55 train 0000, loss 1.200e+00, top1 74.12, top5 89.41
2021-11-08 10:25:43 train 1000, loss 1.089e+00, top1 73.68, top5 90.10
2021-11-08 10:25:43 train 1000, loss 1.081e+00, top1 73.78, top5 90.16
2021-11-08 10:25:44 train 1000, loss 1.098e+00, top1 73.61, top5 90.03
2021-11-08 10:39:32 train 2000, loss 1.089e+00, top1 73.56, top5 90.12
2021-11-08 10:39:32 train 2000, loss 1.094e+00, top1 73.62, top5 90.01
2021-11-08 10:39:32 train 2000, loss 1.097e+00, top1 73.60, top5 90.05
2021-11-08 10:53:23 train 3000, loss 1.089e+00, top1 73.62, top5 90.16
2021-11-08 10:53:23 train 3000, loss 1.099e+00, top1 73.47, top5 89.96
2021-11-08 10:53:24 train 3000, loss 1.094e+00, top1 73.64, top5 90.11
2021-11-08 11:07:17 train 4000, loss 1.097e+00, top1 73.50, top5 90.02
2021-11-08 11:07:17 train 4000, loss 1.092e+00, top1 73.57, top5 90.13
2021-11-08 11:07:17 train 4000, loss 1.091e+00, top1 73.69, top5 90.14
2021-11-08 11:21:07 train 5000, loss 1.096e+00, top1 73.52, top5 90.08
2021-11-08 11:21:08 train 5000, loss 1.100e+00, top1 73.46, top5 89.97
2021-11-08 11:21:08 train 5000, loss 1.091e+00, top1 73.68, top5 90.13
2021-11-08 11:21:37 valid 0000, loss 3.447e-01, top1 92.94, top5 97.65
2021-11-08 11:21:37 valid 0000, loss 3.447e-01, top1 92.94, top5 97.65
2021-11-08 11:21:37 valid 0000, loss 3.447e-01, top1 92.94, top5 97.65
2021-11-08 11:25:50 (JOBID 31694) epoch 79: train time 4186.63, inference time 263.11s, valid_top1 74.21 (best_top1 74.39), valid_top5 92.05
2021-11-08 11:26:08 (JOBID 31694) epoch 79: train time 4204.66, inference time 280.75s, valid_top1 74.21 (best_top1 74.39), valid_top5 92.05
2021-11-08 11:26:11 (JOBID 31694) epoch 79: train time 4189.37, inference time 283.65s, valid_top1 74.21 (best_top1 74.39), valid_top5 92.05
2021-11-08 11:26:23 train 0000, loss 1.210e+00, top1 71.76, top5 89.41
2021-11-08 11:26:04 train 0000, loss 1.166e+00, top1 72.94, top5 88.24
2021-11-08 11:26:25 train 0000, loss 1.264e+00, top1 68.24, top5 84.71
2021-11-08 11:40:10 train 1000, loss 1.090e+00, top1 73.67, top5 90.09
2021-11-08 11:40:10 train 1000, loss 1.083e+00, top1 73.82, top5 90.16
2021-11-08 11:40:10 train 1000, loss 1.100e+00, top1 73.53, top5 90.05
2021-11-08 11:53:57 train 2000, loss 1.088e+00, top1 73.74, top5 90.16
2021-11-08 11:53:57 train 2000, loss 1.089e+00, top1 73.73, top5 90.09
2021-11-08 11:53:57 train 2000, loss 1.093e+00, top1 73.66, top5 90.11
2021-11-08 12:08:02 train 3000, loss 1.090e+00, top1 73.70, top5 90.10
2021-11-08 12:08:02 train 3000, loss 1.090e+00, top1 73.68, top5 90.13
2021-11-08 12:08:02 train 3000, loss 1.092e+00, top1 73.68, top5 90.12
2021-11-08 12:21:43 train 4000, loss 1.089e+00, top1 73.71, top5 90.17
2021-11-08 12:21:43 train 4000, loss 1.092e+00, top1 73.63, top5 90.08
2021-11-08 12:21:43 train 4000, loss 1.092e+00, top1 73.64, top5 90.12
2021-11-08 12:35:25 train 5000, loss 1.088e+00, top1 73.73, top5 90.19
2021-11-08 12:35:25 train 5000, loss 1.092e+00, top1 73.61, top5 90.10
2021-11-08 12:35:25 train 5000, loss 1.093e+00, top1 73.61, top5 90.11
2021-11-08 12:35:55 valid 0000, loss 3.558e-01, top1 91.76, top5 97.65
2021-11-08 12:35:55 valid 0000, loss 3.558e-01, top1 91.76, top5 97.65
2021-11-08 12:35:55 valid 0000, loss 3.558e-01, top1 91.76, top5 97.65
2021-11-08 12:40:21 (JOBID 31694) epoch 80: train time 4173.79, inference time 276.50s, valid_top1 74.27 (best_top1 74.39), valid_top5 92.16
2021-11-08 12:40:27 (JOBID 31694) epoch 80: train time 4176.67, inference time 282.66s, valid_top1 74.27 (best_top1 74.39), valid_top5 92.16
2021-11-08 12:40:29 (JOBID 31694) epoch 80: train time 4194.07, inference time 283.85s, valid_top1 74.27 (best_top1 74.39), valid_top5 92.16
2021-11-08 12:40:42 train 0000, loss 9.480e-01, top1 70.59, top5 89.41
2021-11-08 12:40:36 train 0000, loss 1.200e+00, top1 75.29, top5 88.24
2021-11-08 12:40:43 train 0000, loss 7.923e-01, top1 83.53, top5 92.94
2021-11-08 12:54:44 train 1000, loss 1.081e+00, top1 73.80, top5 90.32
2021-11-08 12:54:44 train 1000, loss 1.089e+00, top1 73.81, top5 90.19
2021-11-08 12:54:44 train 1000, loss 1.078e+00, top1 73.92, top5 90.26
2021-11-08 13:08:37 train 2000, loss 1.077e+00, top1 73.93, top5 90.36
2021-11-08 13:08:37 train 2000, loss 1.088e+00, top1 73.77, top5 90.24
2021-11-08 13:08:37 train 2000, loss 1.076e+00, top1 73.96, top5 90.34
2021-11-08 13:22:31 train 3000, loss 1.082e+00, top1 73.82, top5 90.25
2021-11-08 13:22:31 train 3000, loss 1.089e+00, top1 73.70, top5 90.23
2021-11-08 13:22:31 train 3000, loss 1.079e+00, top1 73.93, top5 90.32
2021-11-08 13:36:31 train 4000, loss 1.085e+00, top1 73.76, top5 90.24
2021-11-08 13:36:31 train 4000, loss 1.090e+00, top1 73.67, top5 90.21
2021-11-08 13:36:31 train 4000, loss 1.079e+00, top1 73.91, top5 90.31
2021-11-08 13:50:28 train 5000, loss 1.087e+00, top1 73.70, top5 90.21
2021-11-08 13:50:28 train 5000, loss 1.091e+00, top1 73.68, top5 90.17
2021-11-08 13:50:28 train 5000, loss 1.082e+00, top1 73.83, top5 90.27
2021-11-08 13:50:59 valid 0000, loss 3.949e-01, top1 91.76, top5 96.47
2021-11-08 13:50:59 valid 0000, loss 3.949e-01, top1 91.76, top5 96.47
2021-11-08 13:50:59 valid 0000, loss 3.949e-01, top1 91.76, top5 96.47
2021-11-08 13:55:16 (JOBID 31694) epoch 81: train time 4226.54, inference time 268.04s, valid_top1 74.44 (best_top1 74.44), valid_top5 92.06
2021-11-08 13:55:30 (JOBID 31694) epoch 81: train time 4219.03, inference time 282.04s, valid_top1 74.44 (best_top1 74.44), valid_top5 92.06
2021-11-08 13:55:31 (JOBID 31694) epoch 81: train time 4220.42, inference time 283.44s, valid_top1 74.44 (best_top1 74.44), valid_top5 92.06
2021-11-08 13:55:30 train 0000, loss 1.336e+00, top1 71.76, top5 85.88
2021-11-08 13:55:44 train 0000, loss 8.747e-01, top1 81.18, top5 89.41
2021-11-08 13:55:44 train 0000, loss 8.647e-01, top1 75.29, top5 94.12
2021-11-08 14:09:24 train 1000, loss 1.073e+00, top1 74.15, top5 90.41
2021-11-08 14:09:24 train 1000, loss 1.087e+00, top1 73.71, top5 90.19
2021-11-08 14:09:25 train 1000, loss 1.079e+00, top1 73.89, top5 90.34
2021-11-08 14:23:06 train 2000, loss 1.085e+00, top1 73.74, top5 90.18
2021-11-08 14:23:06 train 2000, loss 1.078e+00, top1 73.98, top5 90.33
2021-11-08 14:23:06 train 2000, loss 1.082e+00, top1 73.82, top5 90.28
2021-11-08 14:37:11 train 3000, loss 1.085e+00, top1 73.77, top5 90.23
2021-11-08 14:37:11 train 3000, loss 1.079e+00, top1 73.89, top5 90.27
2021-11-08 14:37:11 train 3000, loss 1.085e+00, top1 73.78, top5 90.18
2021-11-08 14:51:00 train 4000, loss 1.081e+00, top1 73.87, top5 90.25
2021-11-08 14:51:00 train 4000, loss 1.085e+00, top1 73.76, top5 90.21
2021-11-08 14:51:00 train 4000, loss 1.084e+00, top1 73.74, top5 90.25
2021-11-08 15:04:51 train 5000, loss 1.086e+00, top1 73.76, top5 90.21
2021-11-08 15:04:51 train 5000, loss 1.088e+00, top1 73.74, top5 90.17
2021-11-08 15:04:52 train 5000, loss 1.088e+00, top1 73.64, top5 90.19
2021-11-08 15:05:22 valid 0000, loss 3.956e-01, top1 91.76, top5 96.47
2021-11-08 15:05:22 valid 0000, loss 3.956e-01, top1 91.76, top5 96.47
2021-11-08 15:05:22 valid 0000, loss 3.956e-01, top1 91.76, top5 96.47
2021-11-08 15:09:37 (JOBID 31694) epoch 82: train time 4180.63, inference time 264.72s, valid_top1 74.43 (best_top1 74.44), valid_top5 92.16
2021-11-08 15:09:54 (JOBID 31694) epoch 82: train time 4196.10, inference time 281.69s, valid_top1 74.43 (best_top1 74.44), valid_top5 92.16
2021-11-08 15:09:55 (JOBID 31694) epoch 82: train time 4181.48, inference time 283.32s, valid_top1 74.43 (best_top1 74.44), valid_top5 92.16
2021-11-08 15:10:09 train 0000, loss 8.413e-01, top1 80.00, top5 90.59
2021-11-08 15:09:50 train 0000, loss 1.242e+00, top1 69.41, top5 87.06
2021-11-08 15:10:10 train 0000, loss 1.119e+00, top1 71.76, top5 90.59
2021-11-08 15:24:28 train 1000, loss 1.079e+00, top1 73.95, top5 90.45
2021-11-08 15:24:28 train 1000, loss 1.082e+00, top1 73.90, top5 90.17
2021-11-08 15:24:29 train 1000, loss 1.076e+00, top1 73.98, top5 90.38
2021-11-08 15:38:31 train 2000, loss 1.077e+00, top1 74.01, top5 90.39
2021-11-08 15:38:31 train 2000, loss 1.079e+00, top1 73.96, top5 90.24
2021-11-08 15:38:31 train 2000, loss 1.086e+00, top1 73.76, top5 90.15
2021-11-08 15:52:34 train 3000, loss 1.077e+00, top1 73.97, top5 90.39
2021-11-08 15:52:34 train 3000, loss 1.080e+00, top1 73.93, top5 90.24
2021-11-08 15:52:35 train 3000, loss 1.084e+00, top1 73.72, top5 90.20
2021-11-08 16:06:30 train 4000, loss 1.081e+00, top1 73.87, top5 90.34
2021-11-08 16:06:30 train 4000, loss 1.080e+00, top1 73.91, top5 90.23
2021-11-08 16:06:30 train 4000, loss 1.085e+00, top1 73.72, top5 90.19
2021-11-08 16:20:35 train 5000, loss 1.084e+00, top1 73.82, top5 90.29
2021-11-08 16:20:35 train 5000, loss 1.082e+00, top1 73.86, top5 90.23
2021-11-08 16:20:35 train 5000, loss 1.086e+00, top1 73.71, top5 90.18
2021-11-08 16:21:06 valid 0000, loss 4.049e-01, top1 91.76, top5 97.65
2021-11-08 16:21:06 valid 0000, loss 4.049e-01, top1 91.76, top5 97.65
2021-11-08 16:21:06 valid 0000, loss 4.049e-01, top1 91.76, top5 97.65
2021-11-08 16:25:31 (JOBID 31694) epoch 83: train time 4278.94, inference time 275.97s, valid_top1 74.48 (best_top1 74.48), valid_top5 92.17
2021-11-08 16:25:38 (JOBID 31694) epoch 83: train time 4262.06, inference time 282.35s, valid_top1 74.48 (best_top1 74.48), valid_top5 92.17
2021-11-08 16:25:41 (JOBID 31694) epoch 83: train time 4260.05, inference time 284.79s, valid_top1 74.48 (best_top1 74.48), valid_top5 92.17
2021-11-08 16:25:46 train 0000, loss 6.489e-01, top1 76.47, top5 96.47
2021-11-08 16:25:52 train 0000, loss 1.123e+00, top1 74.12, top5 89.41
2021-11-08 16:25:56 train 0000, loss 7.957e-01, top1 80.00, top5 94.12
2021-11-08 16:39:57 train 1000, loss 1.069e+00, top1 74.04, top5 90.48
2021-11-08 16:39:57 train 1000, loss 1.065e+00, top1 74.36, top5 90.47
2021-11-08 16:39:57 train 1000, loss 1.081e+00, top1 73.76, top5 90.24
2021-11-08 16:53:58 train 2000, loss 1.076e+00, top1 73.88, top5 90.34
2021-11-08 16:53:58 train 2000, loss 1.073e+00, top1 74.10, top5 90.34
2021-11-08 16:53:58 train 2000, loss 1.079e+00, top1 73.91, top5 90.24
2021-11-08 17:08:15 train 3000, loss 1.078e+00, top1 73.84, top5 90.31
2021-11-08 17:08:15 train 3000, loss 1.075e+00, top1 74.07, top5 90.30
2021-11-08 17:08:16 train 3000, loss 1.083e+00, top1 73.82, top5 90.17
2021-11-08 17:22:21 train 4000, loss 1.077e+00, top1 73.85, top5 90.32
2021-11-08 17:22:21 train 4000, loss 1.074e+00, top1 74.09, top5 90.33
2021-11-08 17:22:22 train 4000, loss 1.084e+00, top1 73.77, top5 90.20
2021-11-08 17:36:30 train 5000, loss 1.079e+00, top1 73.81, top5 90.30
2021-11-08 17:36:30 train 5000, loss 1.077e+00, top1 74.03, top5 90.30
2021-11-08 17:36:30 train 5000, loss 1.085e+00, top1 73.75, top5 90.19
2021-11-08 17:37:01 valid 0000, loss 3.898e-01, top1 90.59, top5 96.47
2021-11-08 17:37:01 valid 0000, loss 3.898e-01, top1 90.59, top5 96.47
2021-11-08 17:37:01 valid 0000, loss 3.898e-01, top1 90.59, top5 96.47
2021-11-08 17:41:32 (JOBID 31694) epoch 84: train time 4269.51, inference time 280.91s, valid_top1 74.29 (best_top1 74.48), valid_top5 92.09
2021-11-08 17:41:32 (JOBID 31694) epoch 84: train time 4272.60, inference time 281.44s, valid_top1 74.29 (best_top1 74.48), valid_top5 92.09
2021-11-08 17:41:34 (JOBID 31694) epoch 84: train time 4278.93, inference time 283.44s, valid_top1 74.29 (best_top1 74.48), valid_top5 92.09
2021-11-08 17:41:46 train 0000, loss 1.203e+00, top1 69.41, top5 87.06
2021-11-08 17:41:46 train 0000, loss 8.257e-01, top1 77.65, top5 92.94
2021-11-08 17:41:49 train 0000, loss 9.696e-01, top1 77.65, top5 94.12
2021-11-08 17:55:51 train 1000, loss 1.077e+00, top1 73.90, top5 90.23
2021-11-08 17:55:51 train 1000, loss 1.081e+00, top1 73.96, top5 90.22
2021-11-08 17:55:51 train 1000, loss 1.074e+00, top1 74.05, top5 90.33
2021-11-08 18:10:00 train 2000, loss 1.081e+00, top1 73.94, top5 90.21
2021-11-08 18:10:00 train 2000, loss 1.074e+00, top1 74.03, top5 90.29
2021-11-08 18:10:00 train 2000, loss 1.079e+00, top1 73.85, top5 90.23
2021-11-08 18:24:22 train 3000, loss 1.081e+00, top1 73.97, top5 90.19
2021-11-08 18:24:22 train 3000, loss 1.080e+00, top1 73.81, top5 90.25
2021-11-08 18:24:22 train 3000, loss 1.076e+00, top1 73.94, top5 90.29
2021-11-08 18:39:05 train 4000, loss 1.081e+00, top1 73.82, top5 90.26
2021-11-08 18:39:05 train 4000, loss 1.080e+00, top1 74.01, top5 90.21
2021-11-08 18:39:06 train 4000, loss 1.077e+00, top1 73.98, top5 90.30
2021-11-08 18:53:42 train 5000, loss 1.079e+00, top1 73.97, top5 90.23
2021-11-08 18:53:42 train 5000, loss 1.082e+00, top1 73.80, top5 90.23
2021-11-08 18:53:42 train 5000, loss 1.079e+00, top1 73.97, top5 90.27
2021-11-08 18:54:13 valid 0000, loss 3.707e-01, top1 91.76, top5 98.82
2021-11-08 18:54:13 valid 0000, loss 3.707e-01, top1 91.76, top5 98.82
2021-11-08 18:54:13 valid 0000, loss 3.707e-01, top1 91.76, top5 98.82
2021-11-08 18:58:30 (JOBID 31694) epoch 85: train time 4349.08, inference time 266.65s, valid_top1 74.37 (best_top1 74.48), valid_top5 92.15
2021-11-08 18:58:47 (JOBID 31694) epoch 85: train time 4351.33, inference time 283.64s, valid_top1 74.37 (best_top1 74.48), valid_top5 92.15
2021-11-08 18:58:49 (JOBID 31694) epoch 85: train time 4350.79, inference time 286.09s, valid_top1 74.37 (best_top1 74.48), valid_top5 92.15
2021-11-08 18:58:44 train 0000, loss 1.050e+00, top1 70.59, top5 90.59
2021-11-08 18:59:02 train 0000, loss 1.120e+00, top1 75.29, top5 94.12
2021-11-08 18:59:04 train 0000, loss 7.618e-01, top1 81.18, top5 95.29
2021-11-08 19:13:27 train 1000, loss 1.066e+00, top1 74.10, top5 90.52
2021-11-08 19:13:27 train 1000, loss 1.075e+00, top1 74.18, top5 90.31
2021-11-08 19:13:27 train 1000, loss 1.071e+00, top1 74.02, top5 90.50
2021-11-08 19:27:58 train 2000, loss 1.077e+00, top1 74.11, top5 90.31
2021-11-08 19:27:58 train 2000, loss 1.071e+00, top1 73.93, top5 90.42
2021-11-08 19:27:58 train 2000, loss 1.069e+00, top1 74.05, top5 90.50
2021-11-08 19:42:26 train 3000, loss 1.078e+00, top1 74.07, top5 90.31
2021-11-08 19:42:26 train 3000, loss 1.077e+00, top1 73.88, top5 90.34
2021-11-08 19:42:26 train 3000, loss 1.071e+00, top1 74.02, top5 90.43
2021-11-08 19:56:47 train 4000, loss 1.078e+00, top1 74.01, top5 90.30
2021-11-08 19:56:47 train 4000, loss 1.079e+00, top1 73.86, top5 90.29
2021-11-08 19:56:48 train 4000, loss 1.073e+00, top1 73.98, top5 90.40
2021-11-08 20:11:18 train 5000, loss 1.081e+00, top1 73.85, top5 90.27
2021-11-08 20:11:18 train 5000, loss 1.078e+00, top1 73.94, top5 90.29
2021-11-08 20:11:18 train 5000, loss 1.075e+00, top1 73.97, top5 90.34
2021-11-08 20:11:49 valid 0000, loss 4.555e-01, top1 87.06, top5 97.65
2021-11-08 20:11:49 valid 0000, loss 4.555e-01, top1 87.06, top5 97.65
2021-11-08 20:11:49 valid 0000, loss 4.555e-01, top1 87.06, top5 97.65
2021-11-08 20:16:33 (JOBID 31694) epoch 86: train time 4389.03, inference time 294.70s, valid_top1 74.43 (best_top1 74.48), valid_top5 92.16
2021-11-08 20:16:34 (JOBID 31694) epoch 86: train time 4369.74, inference time 295.07s, valid_top1 74.43 (best_top1 74.48), valid_top5 92.16
2021-11-08 20:16:38 (JOBID 31694) epoch 86: train time 4371.75, inference time 299.30s, valid_top1 74.43 (best_top1 74.48), valid_top5 92.16
2021-11-08 20:16:47 train 0000, loss 1.039e+00, top1 77.65, top5 89.41
2021-11-08 20:16:47 train 0000, loss 1.231e+00, top1 76.47, top5 87.06
2021-11-08 20:16:53 train 0000, loss 1.006e+00, top1 78.82, top5 88.24
2021-11-08 20:31:07 train 1000, loss 1.058e+00, top1 74.38, top5 90.55
2021-11-08 20:31:07 train 1000, loss 1.067e+00, top1 74.17, top5 90.49
2021-11-08 20:31:07 train 1000, loss 1.068e+00, top1 74.01, top5 90.46
2021-11-08 20:45:40 train 2000, loss 1.069e+00, top1 74.17, top5 90.39
2021-11-08 20:45:40 train 2000, loss 1.065e+00, top1 74.21, top5 90.42
2021-11-08 20:45:40 train 2000, loss 1.071e+00, top1 73.97, top5 90.44
2021-11-08 21:00:03 train 3000, loss 1.071e+00, top1 74.03, top5 90.39
2021-11-08 21:00:03 train 3000, loss 1.073e+00, top1 74.06, top5 90.31
2021-11-08 21:00:03 train 3000, loss 1.071e+00, top1 73.98, top5 90.36
2021-11-08 21:14:32 train 4000, loss 1.075e+00, top1 74.03, top5 90.30
2021-11-08 21:14:32 train 4000, loss 1.074e+00, top1 73.95, top5 90.35
2021-11-08 21:14:33 train 4000, loss 1.074e+00, top1 73.97, top5 90.32
2021-11-08 21:28:56 train 5000, loss 1.074e+00, top1 73.95, top5 90.34
2021-11-08 21:28:56 train 5000, loss 1.077e+00, top1 73.97, top5 90.28
2021-11-08 21:28:56 train 5000, loss 1.075e+00, top1 73.91, top5 90.28
2021-11-08 21:29:27 valid 0000, loss 4.278e-01, top1 89.41, top5 97.65
2021-11-08 21:29:27 valid 0000, loss 4.278e-01, top1 89.41, top5 97.65
2021-11-08 21:29:27 valid 0000, loss 4.278e-01, top1 89.41, top5 97.65
2021-11-08 21:33:43 (JOBID 31694) epoch 87: train time 4363.35, inference time 266.68s, valid_top1 74.60 (best_top1 74.60), valid_top5 92.19
2021-11-08 21:34:01 (JOBID 31694) epoch 87: train time 4362.90, inference time 284.53s, valid_top1 74.60 (best_top1 74.60), valid_top5 92.19
2021-11-08 21:34:05 (JOBID 31694) epoch 87: train time 4358.21, inference time 287.72s, valid_top1 74.60 (best_top1 74.60), valid_top5 92.19
2021-11-08 21:33:58 train 0000, loss 1.329e+00, top1 69.41, top5 84.71
2021-11-08 21:34:17 train 0000, loss 9.920e-01, top1 72.94, top5 91.76
2021-11-08 21:34:20 train 0000, loss 1.104e+00, top1 76.47, top5 89.41
2021-11-08 21:48:49 train 1000, loss 1.061e+00, top1 74.14, top5 90.47
2021-11-08 21:48:49 train 1000, loss 1.067e+00, top1 74.19, top5 90.48
2021-11-08 21:48:50 train 1000, loss 1.070e+00, top1 73.96, top5 90.50
2021-11-08 22:03:35 train 2000, loss 1.066e+00, top1 74.13, top5 90.42
2021-11-08 22:03:35 train 2000, loss 1.074e+00, top1 74.05, top5 90.36
2021-11-08 22:03:35 train 2000, loss 1.067e+00, top1 74.13, top5 90.45
2021-11-08 22:18:01 train 3000, loss 1.069e+00, top1 74.07, top5 90.36
2021-11-08 22:18:01 train 3000, loss 1.076e+00, top1 73.98, top5 90.33
2021-11-08 22:18:01 train 3000, loss 1.068e+00, top1 74.11, top5 90.45
2021-11-08 22:32:23 train 4000, loss 1.070e+00, top1 74.04, top5 90.37
2021-11-08 22:32:23 train 4000, loss 1.079e+00, top1 73.92, top5 90.29
2021-11-08 22:32:23 train 4000, loss 1.068e+00, top1 74.11, top5 90.44
2021-11-08 22:46:44 train 5000, loss 1.079e+00, top1 73.93, top5 90.27
2021-11-08 22:46:44 train 5000, loss 1.070e+00, top1 74.04, top5 90.40
2021-11-08 22:46:44 train 5000, loss 1.068e+00, top1 74.13, top5 90.45
2021-11-08 22:47:15 valid 0000, loss 3.488e-01, top1 94.12, top5 97.65
2021-11-08 22:47:15 valid 0000, loss 3.488e-01, top1 94.12, top5 97.65
2021-11-08 22:47:15 valid 0000, loss 3.488e-01, top1 94.12, top5 97.65
2021-11-08 22:51:49 (JOBID 31694) epoch 88: train time 4383.60, inference time 284.34s, valid_top1 74.50 (best_top1 74.60), valid_top5 92.06
2021-11-08 22:51:50 (JOBID 31694) epoch 88: train time 4401.28, inference time 285.29s, valid_top1 74.50 (best_top1 74.60), valid_top5 92.06
2021-11-08 22:51:51 (JOBID 31694) epoch 88: train time 4379.61, inference time 286.13s, valid_top1 74.50 (best_top1 74.60), valid_top5 92.06
2021-11-08 22:52:05 train 0000, loss 1.224e+00, top1 70.59, top5 90.59
2021-11-08 22:52:05 train 0000, loss 9.445e-01, top1 82.35, top5 92.94
2021-11-08 22:52:07 train 0000, loss 1.179e+00, top1 69.41, top5 90.59
2021-11-08 23:06:36 train 1000, loss 1.072e+00, top1 74.12, top5 90.45
2021-11-08 23:06:36 train 1000, loss 1.064e+00, top1 74.22, top5 90.52
2021-11-08 23:06:37 train 1000, loss 1.073e+00, top1 74.09, top5 90.36
2021-11-08 23:21:00 train 2000, loss 1.070e+00, top1 74.12, top5 90.44
2021-11-08 23:21:00 train 2000, loss 1.066e+00, top1 74.13, top5 90.45
2021-11-08 23:21:00 train 2000, loss 1.070e+00, top1 74.02, top5 90.38
2021-11-08 23:35:22 train 3000, loss 1.068e+00, top1 74.15, top5 90.44
2021-11-08 23:35:22 train 3000, loss 1.066e+00, top1 74.13, top5 90.41
2021-11-08 23:35:22 train 3000, loss 1.069e+00, top1 74.04, top5 90.38
2021-11-08 23:49:40 train 4000, loss 1.067e+00, top1 74.16, top5 90.39
2021-11-08 23:49:40 train 4000, loss 1.072e+00, top1 74.09, top5 90.38
2021-11-08 23:49:41 train 4000, loss 1.072e+00, top1 73.99, top5 90.35
2021-11-09 00:04:00 train 5000, loss 1.068e+00, top1 74.14, top5 90.39
2021-11-09 00:04:00 train 5000, loss 1.073e+00, top1 74.08, top5 90.34
2021-11-09 00:04:00 train 5000, loss 1.071e+00, top1 74.05, top5 90.36
2021-11-09 00:04:31 valid 0000, loss 3.613e-01, top1 92.94, top5 97.65
2021-11-09 00:04:31 valid 0000, loss 3.613e-01, top1 92.94, top5 97.65
2021-11-09 00:04:31 valid 0000, loss 3.613e-01, top1 92.94, top5 97.65
2021-11-09 00:08:43 (JOBID 31694) epoch 89: train time 4349.61, inference time 262.48s, valid_top1 74.27 (best_top1 74.60), valid_top5 92.09
2021-11-09 00:09:00 (JOBID 31694) epoch 89: train time 4350.74, inference time 278.84s, valid_top1 74.27 (best_top1 74.60), valid_top5 92.09
2021-11-09 00:09:01 (JOBID 31694) epoch 89: train time 4351.78, inference time 280.36s, valid_top1 74.27 (best_top1 74.60), valid_top5 92.09
