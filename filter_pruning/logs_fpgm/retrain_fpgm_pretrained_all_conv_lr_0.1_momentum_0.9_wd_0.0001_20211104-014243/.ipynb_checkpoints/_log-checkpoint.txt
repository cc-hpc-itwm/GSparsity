2021-11-04 01:42:49 CARME Slurm ID: 31649
2021-11-04 01:42:49 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=0, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 01:42:49 CARME Slurm ID: 31649
2021-11-04 01:42:49 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=1, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 01:42:49 CARME Slurm ID: 31649
2021-11-04 01:42:49 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=2, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 01:42:56 => loading baseline model '_fgpm_pretrained_best.resnet50.2018-07-16-4310/small_model_all_conv_1e-06.pth.tar'
2021-11-04 01:42:56 => loading baseline model '_fgpm_pretrained_best.resnet50.2018-07-16-4310/small_model_all_conv_1e-06.pth.tar'
2021-11-04 01:42:56 => loading baseline model '_fgpm_pretrained_best.resnet50.2018-07-16-4310/small_model_all_conv_1e-06.pth.tar'
2021-11-04 01:42:56 => loaded baseline model '_fgpm_pretrained_best.resnet50.2018-07-16-4310/small_model_all_conv_1e-06.pth.tar'
2021-11-04 01:42:56 => loaded baseline model '_fgpm_pretrained_best.resnet50.2018-07-16-4310/small_model_all_conv_1e-06.pth.tar'
2021-11-04 01:42:56 => loaded baseline model '_fgpm_pretrained_best.resnet50.2018-07-16-4310/small_model_all_conv_1e-06.pth.tar'
2021-11-04 01:43:04 Computational complexity:       2.02 GMac
2021-11-04 01:43:04 Computational complexity:       2.02 GMac
2021-11-04 01:43:04 Computational complexity:       2.02 GMac
2021-11-04 01:43:04 Number of parameters:           13.35 M 
2021-11-04 01:43:04 Number of parameters:           13.35 M 
2021-11-04 01:43:04 Number of parameters:           13.35 M 
2021-11-04 01:43:21 valid 0000, loss 6.437e-01, top1 88.24, top5 95.29
2021-11-04 01:43:22 valid 0000, loss 6.437e-01, top1 88.24, top5 95.29
2021-11-04 01:43:22 valid 0000, loss 6.437e-01, top1 88.24, top5 95.29
2021-11-04 01:47:44 (JOBID 31649) epoch -1: valid_top1 69.59, valid_top5 89.52, inference time 275.75
2021-11-04 01:47:48 (JOBID 31649) epoch -1: valid_top1 69.59, valid_top5 89.52, inference time 279.07
2021-11-04 01:47:49 (JOBID 31649) epoch -1: valid_top1 69.59, valid_top5 89.52, inference time 279.73
2021-11-04 01:48:07 train 0000, loss 7.761e-01, top1 82.35, top5 94.12
2021-11-04 01:48:07 train 0000, loss 6.772e-01, top1 80.00, top5 92.94
2021-11-04 01:48:07 train 0000, loss 9.533e-01, top1 80.00, top5 90.59
2021-11-04 02:02:14 train 1000, loss 3.288e+00, top1 31.74, top5 56.50
2021-11-04 02:02:14 train 1000, loss 3.282e+00, top1 31.93, top5 56.65
2021-11-04 02:02:14 train 1000, loss 3.274e+00, top1 32.16, top5 56.89
2021-11-04 02:16:23 train 2000, loss 2.959e+00, top1 37.21, top5 62.30
2021-11-04 02:16:23 train 2000, loss 2.958e+00, top1 37.13, top5 62.35
2021-11-04 02:16:23 train 2000, loss 2.950e+00, top1 37.30, top5 62.54
2021-11-04 02:30:33 train 3000, loss 2.796e+00, top1 39.94, top5 65.03
2021-11-04 02:30:33 train 3000, loss 2.797e+00, top1 39.77, top5 65.13
2021-11-04 02:30:33 train 3000, loss 2.789e+00, top1 40.03, top5 65.31
2021-11-04 02:44:47 train 4000, loss 2.695e+00, top1 41.70, top5 66.75
2021-11-04 02:44:47 train 4000, loss 2.695e+00, top1 41.58, top5 66.84
2021-11-04 02:44:47 train 4000, loss 2.690e+00, top1 41.72, top5 66.95
2021-11-04 02:58:56 train 5000, loss 2.628e+00, top1 42.82, top5 67.89
2021-11-04 02:58:56 train 5000, loss 2.624e+00, top1 42.86, top5 68.00
2021-11-04 02:58:56 train 5000, loss 2.621e+00, top1 42.91, top5 68.11
2021-11-04 02:59:29 valid 0000, loss 1.216e+00, top1 76.47, top5 84.71
2021-11-04 02:59:29 valid 0000, loss 1.216e+00, top1 76.47, top5 84.71
2021-11-04 02:59:29 valid 0000, loss 1.216e+00, top1 76.47, top5 84.71
2021-11-04 03:04:11 (JOBID 31649) epoch 0: train time 4290.58, inference time 291.89s, valid_top1 50.65 (best_top1 50.65), valid_top5 76.99
2021-11-04 03:04:13 (JOBID 31649) epoch 0: train time 4291.25, inference time 293.55s, valid_top1 50.65 (best_top1 50.65), valid_top5 76.99
2021-11-04 03:04:15 (JOBID 31649) epoch 0: train time 4294.79, inference time 294.51s, valid_top1 50.65 (best_top1 50.65), valid_top5 76.99
2021-11-04 03:04:26 train 0000, loss 2.506e+00, top1 45.88, top5 69.41
2021-11-04 03:04:26 train 0000, loss 1.882e+00, top1 58.82, top5 84.71
2021-11-04 03:04:29 train 0000, loss 2.099e+00, top1 55.29, top5 70.59
2021-11-04 03:18:41 train 1000, loss 2.266e+00, top1 49.06, top5 73.82
2021-11-04 03:18:41 train 1000, loss 2.282e+00, top1 48.87, top5 73.65
2021-11-04 03:18:42 train 1000, loss 2.279e+00, top1 48.97, top5 73.74
2021-11-04 03:32:56 train 2000, loss 2.275e+00, top1 48.96, top5 73.70
2021-11-04 03:32:56 train 2000, loss 2.279e+00, top1 48.97, top5 73.74
2021-11-04 03:32:56 train 2000, loss 2.281e+00, top1 48.91, top5 73.72
2021-11-04 03:47:04 train 3000, loss 2.280e+00, top1 48.85, top5 73.69
2021-11-04 03:47:04 train 3000, loss 2.277e+00, top1 49.05, top5 73.70
2021-11-04 03:47:04 train 3000, loss 2.276e+00, top1 48.95, top5 73.80
2021-11-04 04:01:12 train 4000, loss 2.275e+00, top1 49.00, top5 73.78
2021-11-04 04:01:12 train 4000, loss 2.275e+00, top1 49.09, top5 73.71
2021-11-04 04:01:12 train 4000, loss 2.272e+00, top1 49.08, top5 73.89
2021-11-04 04:15:25 train 5000, loss 2.272e+00, top1 49.09, top5 73.80
2021-11-04 04:15:25 train 5000, loss 2.272e+00, top1 49.16, top5 73.76
2021-11-04 04:15:25 train 5000, loss 2.271e+00, top1 49.13, top5 73.91
2021-11-04 04:15:55 valid 0000, loss 1.425e+00, top1 75.29, top5 84.71
2021-11-04 04:15:55 valid 0000, loss 1.425e+00, top1 75.29, top5 84.71
2021-11-04 04:15:55 valid 0000, loss 1.425e+00, top1 75.29, top5 84.71
2021-11-04 04:20:18 (JOBID 31649) epoch 1: train time 4292.87, inference time 272.58s, valid_top1 51.11 (best_top1 51.11), valid_top5 77.06
2021-11-04 04:20:22 (JOBID 31649) epoch 1: train time 4294.17, inference time 276.61s, valid_top1 51.11 (best_top1 51.11), valid_top5 77.06
2021-11-04 04:20:30 (JOBID 31649) epoch 1: train time 4290.73, inference time 283.80s, valid_top1 51.11 (best_top1 51.11), valid_top5 77.06
2021-11-04 04:20:33 train 0000, loss 2.504e+00, top1 43.53, top5 70.59
2021-11-04 04:20:36 train 0000, loss 1.952e+00, top1 54.12, top5 78.82
2021-11-04 04:20:44 train 0000, loss 2.273e+00, top1 51.76, top5 71.76
2021-11-04 04:34:50 train 1000, loss 2.203e+00, top1 50.41, top5 74.89
2021-11-04 04:34:50 train 1000, loss 2.241e+00, top1 49.68, top5 74.31
2021-11-04 04:34:50 train 1000, loss 2.219e+00, top1 50.16, top5 74.52
2021-11-04 04:48:58 train 2000, loss 2.217e+00, top1 50.13, top5 74.73
2021-11-04 04:48:58 train 2000, loss 2.234e+00, top1 49.82, top5 74.39
2021-11-04 04:48:59 train 2000, loss 2.231e+00, top1 49.95, top5 74.36
2021-11-04 05:03:08 train 3000, loss 2.236e+00, top1 49.88, top5 74.39
2021-11-04 05:03:08 train 3000, loss 2.236e+00, top1 49.85, top5 74.34
2021-11-04 05:03:08 train 3000, loss 2.226e+00, top1 49.94, top5 74.59
2021-11-04 05:17:12 train 4000, loss 2.240e+00, top1 49.74, top5 74.27
2021-11-04 05:17:12 train 4000, loss 2.237e+00, top1 49.88, top5 74.35
2021-11-04 05:17:12 train 4000, loss 2.232e+00, top1 49.89, top5 74.46
2021-11-04 05:31:17 train 5000, loss 2.239e+00, top1 49.74, top5 74.28
2021-11-04 05:31:17 train 5000, loss 2.238e+00, top1 49.83, top5 74.35
2021-11-04 05:31:17 train 5000, loss 2.232e+00, top1 49.86, top5 74.46
2021-11-04 05:31:48 valid 0000, loss 1.537e+00, top1 69.41, top5 78.82
2021-11-04 05:31:48 valid 0000, loss 1.537e+00, top1 69.41, top5 78.82
2021-11-04 05:31:48 valid 0000, loss 1.537e+00, top1 69.41, top5 78.82
2021-11-04 05:36:09 (JOBID 31649) epoch 2: train time 4268.36, inference time 270.78s, valid_top1 51.87 (best_top1 51.87), valid_top5 77.66
2021-11-04 05:36:19 (JOBID 31649) epoch 2: train time 4280.23, inference time 280.40s, valid_top1 51.87 (best_top1 51.87), valid_top5 77.66
2021-11-04 05:36:19 (JOBID 31649) epoch 2: train time 4276.16, inference time 280.71s, valid_top1 51.87 (best_top1 51.87), valid_top5 77.66
2021-11-04 05:36:23 train 0000, loss 2.362e+00, top1 50.59, top5 74.12
2021-11-04 05:36:32 train 0000, loss 2.040e+00, top1 54.12, top5 78.82
2021-11-04 05:36:32 train 0000, loss 2.115e+00, top1 51.76, top5 72.94
2021-11-04 05:50:40 train 1000, loss 2.207e+00, top1 50.08, top5 74.82
2021-11-04 05:50:40 train 1000, loss 2.199e+00, top1 50.66, top5 74.89
2021-11-04 05:50:40 train 1000, loss 2.208e+00, top1 50.17, top5 74.94
2021-11-04 06:04:44 train 2000, loss 2.210e+00, top1 50.32, top5 74.72
2021-11-04 06:04:44 train 2000, loss 2.220e+00, top1 49.99, top5 74.58
2021-11-04 06:04:44 train 2000, loss 2.211e+00, top1 50.27, top5 74.83
2021-11-04 06:18:51 train 3000, loss 2.223e+00, top1 49.97, top5 74.56
2021-11-04 06:18:51 train 3000, loss 2.219e+00, top1 50.18, top5 74.56
2021-11-04 06:18:51 train 3000, loss 2.220e+00, top1 50.14, top5 74.67
2021-11-04 06:32:59 train 4000, loss 2.222e+00, top1 50.04, top5 74.56
2021-11-04 06:32:59 train 4000, loss 2.222e+00, top1 50.10, top5 74.51
2021-11-04 06:32:59 train 4000, loss 2.223e+00, top1 50.12, top5 74.64
2021-11-04 06:47:09 train 5000, loss 2.224e+00, top1 50.07, top5 74.51
2021-11-04 06:47:09 train 5000, loss 2.225e+00, top1 50.06, top5 74.51
2021-11-04 06:47:09 train 5000, loss 2.225e+00, top1 50.08, top5 74.58
2021-11-04 06:47:40 valid 0000, loss 7.968e-01, top1 80.00, top5 94.12
2021-11-04 06:47:40 valid 0000, loss 7.968e-01, top1 80.00, top5 94.12
2021-11-04 06:47:40 valid 0000, loss 7.968e-01, top1 80.00, top5 94.12
2021-11-04 06:52:23 (JOBID 31649) epoch 3: train time 4271.13, inference time 292.75s, valid_top1 52.22 (best_top1 52.22), valid_top5 78.43
2021-11-04 06:52:23 (JOBID 31649) epoch 3: train time 4280.36, inference time 293.07s, valid_top1 52.22 (best_top1 52.22), valid_top5 78.43
2021-11-04 06:52:23 (JOBID 31649) epoch 3: train time 4270.86, inference time 293.71s, valid_top1 52.22 (best_top1 52.22), valid_top5 78.43
2021-11-04 06:52:37 train 0000, loss 1.761e+00, top1 51.76, top5 83.53
2021-11-04 06:52:37 train 0000, loss 2.655e+00, top1 44.71, top5 67.06
2021-11-04 06:52:37 train 0000, loss 2.415e+00, top1 47.06, top5 77.65
2021-11-04 07:06:42 train 1000, loss 2.201e+00, top1 50.42, top5 74.93
2021-11-04 07:06:42 train 1000, loss 2.201e+00, top1 50.50, top5 74.85
2021-11-04 07:06:42 train 1000, loss 2.197e+00, top1 50.56, top5 75.07
2021-11-04 07:20:48 train 2000, loss 2.215e+00, top1 50.21, top5 74.72
2021-11-04 07:20:48 train 2000, loss 2.209e+00, top1 50.34, top5 74.69
2021-11-04 07:20:48 train 2000, loss 2.209e+00, top1 50.32, top5 74.74
2021-11-04 07:34:52 train 3000, loss 2.215e+00, top1 50.27, top5 74.67
2021-11-04 07:34:52 train 3000, loss 2.215e+00, top1 50.29, top5 74.62
2021-11-04 07:34:52 train 3000, loss 2.216e+00, top1 50.23, top5 74.70
2021-11-04 07:48:58 train 4000, loss 2.218e+00, top1 50.19, top5 74.65
2021-11-04 07:48:58 train 4000, loss 2.219e+00, top1 50.17, top5 74.57
2021-11-04 07:48:59 train 4000, loss 2.221e+00, top1 50.16, top5 74.62
2021-11-04 08:03:01 train 5000, loss 2.225e+00, top1 50.09, top5 74.56
2021-11-04 08:03:01 train 5000, loss 2.222e+00, top1 50.11, top5 74.55
2021-11-04 08:03:01 train 5000, loss 2.225e+00, top1 50.09, top5 74.57
2021-11-04 08:03:31 valid 0000, loss 1.042e+00, top1 81.18, top5 88.24
2021-11-04 08:03:31 valid 0000, loss 1.042e+00, top1 81.18, top5 88.24
2021-11-04 08:03:31 valid 0000, loss 1.042e+00, top1 81.18, top5 88.24
2021-11-04 08:08:25 (JOBID 31649) epoch 4: train time 4258.07, inference time 303.08s, valid_top1 52.54 (best_top1 52.54), valid_top5 78.04
2021-11-04 08:08:25 (JOBID 31649) epoch 4: train time 4258.71, inference time 304.08s, valid_top1 52.54 (best_top1 52.54), valid_top5 78.04
2021-11-04 08:08:28 (JOBID 31649) epoch 4: train time 4258.11, inference time 306.99s, valid_top1 52.54 (best_top1 52.54), valid_top5 78.04
2021-11-04 08:08:40 train 0000, loss 2.306e+00, top1 43.53, top5 65.88
2021-11-04 08:08:40 train 0000, loss 1.901e+00, top1 61.18, top5 81.18
2021-11-04 08:08:43 train 0000, loss 2.583e+00, top1 44.71, top5 69.41
2021-11-04 08:44:45 CARME Slurm ID: 31649
2021-11-04 08:44:45 CARME Slurm ID: 31649
2021-11-04 08:44:45 CARME Slurm ID: 31649
2021-11-04 08:44:45 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=0, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 08:44:45 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=2, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 08:44:45 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=1, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 08:44:58 Computational complexity:       2.02 GMac
2021-11-04 08:44:58 Number of parameters:           13.35 M 
2021-11-04 08:44:58 => loading checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243'
2021-11-04 08:44:58 Computational complexity:       2.02 GMac
2021-11-04 08:44:58 Number of parameters:           13.35 M 
2021-11-04 08:44:58 => loading checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243'
2021-11-04 08:44:58 Computational complexity:       2.02 GMac
2021-11-04 08:44:58 Number of parameters:           13.35 M 
2021-11-04 08:44:58 => loading checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243'
2021-11-04 08:44:58 => loaded checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243' (epoch 5)
2021-11-04 08:44:58 => loaded checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243' (epoch 5)
2021-11-04 08:44:58 => loaded checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243' (epoch 5)
2021-11-04 08:45:17 valid 0000, loss 1.042e+00, top1 81.18, top5 88.24
2021-11-04 08:45:17 valid 0000, loss 1.042e+00, top1 81.18, top5 88.24
2021-11-04 08:45:17 valid 0000, loss 1.042e+00, top1 81.18, top5 88.24
2021-11-04 08:49:20 (JOBID 31649) epoch -1: valid_top1 52.54, valid_top5 78.04, inference time 255.93
2021-11-04 08:50:00 (JOBID 31649) epoch -1: valid_top1 52.54, valid_top5 78.04, inference time 296.64
2021-11-04 08:50:03 (JOBID 31649) epoch -1: valid_top1 52.54, valid_top5 78.04, inference time 298.94
2021-11-04 08:50:21 train 0000, loss 1.948e+00, top1 57.65, top5 83.53
2021-11-04 08:50:21 train 0000, loss 2.473e+00, top1 47.06, top5 65.88
2021-11-04 08:50:21 train 0000, loss 2.111e+00, top1 45.88, top5 74.12
2021-11-04 09:04:51 train 1000, loss 2.191e+00, top1 50.56, top5 75.07
2021-11-04 09:04:51 train 1000, loss 2.196e+00, top1 50.56, top5 75.00
2021-11-04 09:04:51 train 1000, loss 2.184e+00, top1 50.85, top5 75.24
2021-11-04 09:19:19 train 2000, loss 2.206e+00, top1 50.35, top5 74.85
2021-11-04 09:19:19 train 2000, loss 2.207e+00, top1 50.39, top5 74.84
2021-11-04 09:19:19 train 2000, loss 2.195e+00, top1 50.65, top5 75.02
2021-11-04 09:33:36 train 3000, loss 2.212e+00, top1 50.28, top5 74.78
2021-11-04 09:33:36 train 3000, loss 2.212e+00, top1 50.33, top5 74.75
2021-11-04 09:33:36 train 3000, loss 2.206e+00, top1 50.43, top5 74.89
2021-11-04 09:48:00 train 4000, loss 2.223e+00, top1 50.13, top5 74.61
2021-11-04 09:48:00 train 4000, loss 2.219e+00, top1 50.16, top5 74.62
2021-11-04 09:48:01 train 4000, loss 2.213e+00, top1 50.30, top5 74.74
2021-11-04 10:02:21 train 5000, loss 2.222e+00, top1 50.09, top5 74.59
2021-11-04 10:02:21 train 5000, loss 2.223e+00, top1 50.12, top5 74.59
2021-11-04 10:02:21 train 5000, loss 2.218e+00, top1 50.18, top5 74.68
2021-11-04 10:02:54 valid 0000, loss 1.210e+00, top1 78.82, top5 83.53
2021-11-04 10:02:55 valid 0000, loss 1.210e+00, top1 78.82, top5 83.53
2021-11-04 10:02:55 valid 0000, loss 1.210e+00, top1 78.82, top5 83.53
2021-11-04 10:07:23 (JOBID 31649) epoch 5: train time 4404.76, inference time 278.73s, valid_top1 52.66 (best_top1 52.66), valid_top5 78.67
2021-11-04 10:07:30 (JOBID 31649) epoch 5: train time 4364.05, inference time 284.82s, valid_top1 52.66 (best_top1 52.66), valid_top5 78.67
2021-11-04 10:07:33 (JOBID 31649) epoch 5: train time 4361.76, inference time 289.03s, valid_top1 52.66 (best_top1 52.66), valid_top5 78.67
2021-11-04 10:07:44 train 0000, loss 1.946e+00, top1 51.76, top5 74.12
2021-11-04 10:07:38 train 0000, loss 2.907e+00, top1 36.47, top5 61.18
2021-11-04 10:07:47 train 0000, loss 2.474e+00, top1 49.41, top5 70.59
2021-11-04 10:22:02 train 1000, loss 2.209e+00, top1 50.35, top5 74.74
2021-11-04 10:22:02 train 1000, loss 2.189e+00, top1 50.90, top5 75.19
2021-11-04 10:22:02 train 1000, loss 2.206e+00, top1 50.51, top5 74.80
2021-11-04 10:36:16 train 2000, loss 2.207e+00, top1 50.53, top5 74.94
2021-11-04 10:36:16 train 2000, loss 2.218e+00, top1 50.13, top5 74.66
2021-11-04 10:36:16 train 2000, loss 2.205e+00, top1 50.31, top5 74.84
2021-11-04 10:50:34 train 3000, loss 2.219e+00, top1 50.15, top5 74.67
2021-11-04 10:50:34 train 3000, loss 2.213e+00, top1 50.35, top5 74.81
2021-11-04 10:50:34 train 3000, loss 2.210e+00, top1 50.24, top5 74.83
2021-11-04 11:35:28 CARME Slurm ID: 31649
2021-11-04 11:35:28 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=2, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 11:35:28 CARME Slurm ID: 31649
2021-11-04 11:35:28 CARME Slurm ID: 31649
2021-11-04 11:35:28 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=0, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 11:35:28 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=1, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 11:35:42 Computational complexity:       2.02 GMac
2021-11-04 11:35:42 Number of parameters:           13.35 M 
2021-11-04 11:35:42 Computational complexity:       2.02 GMac
2021-11-04 11:35:42 Number of parameters:           13.35 M 
2021-11-04 11:35:42 => loading checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243'
2021-11-04 11:35:42 => loading checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243'
2021-11-04 11:35:42 Computational complexity:       2.02 GMac
2021-11-04 11:35:42 Number of parameters:           13.35 M 
2021-11-04 11:35:42 => loading checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243'
2021-11-04 11:35:42 => loaded checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243' (epoch 6)
2021-11-04 11:35:42 => loaded checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243' (epoch 6)
2021-11-04 11:35:42 => loaded checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243' (epoch 6)
2021-11-04 11:36:09 train 0000, loss 2.935e+00, top1 36.47, top5 61.18
2021-11-04 11:36:09 train 0000, loss 1.935e+00, top1 52.94, top5 77.65
2021-11-04 11:36:10 train 0000, loss 2.339e+00, top1 52.94, top5 70.59
2021-11-04 11:50:07 train 1000, loss 2.205e+00, top1 50.47, top5 74.79
2021-11-04 11:50:07 train 1000, loss 2.197e+00, top1 50.68, top5 74.87
2021-11-04 11:50:07 train 1000, loss 2.212e+00, top1 50.55, top5 74.81
2021-11-04 12:04:03 train 2000, loss 2.214e+00, top1 50.22, top5 74.63
2021-11-04 12:04:03 train 2000, loss 2.215e+00, top1 50.24, top5 74.68
2021-11-04 12:04:03 train 2000, loss 2.202e+00, top1 50.52, top5 74.92
2021-11-04 12:18:06 train 3000, loss 2.216e+00, top1 50.24, top5 74.61
2021-11-04 12:18:06 train 3000, loss 2.220e+00, top1 50.17, top5 74.63
2021-11-04 12:18:06 train 3000, loss 2.211e+00, top1 50.31, top5 74.81
2021-11-04 12:32:12 train 4000, loss 2.220e+00, top1 50.21, top5 74.59
2021-11-04 12:32:12 train 4000, loss 2.223e+00, top1 50.13, top5 74.62
2021-11-04 12:32:13 train 4000, loss 2.214e+00, top1 50.28, top5 74.72
2021-11-04 12:46:14 train 5000, loss 2.223e+00, top1 50.14, top5 74.57
2021-11-04 12:46:14 train 5000, loss 2.227e+00, top1 50.06, top5 74.55
2021-11-04 12:46:14 train 5000, loss 2.220e+00, top1 50.20, top5 74.63
2021-11-04 12:46:47 valid 0000, loss 6.315e-01, top1 89.41, top5 96.47
2021-11-04 12:46:47 valid 0000, loss 6.315e-01, top1 89.41, top5 96.47
2021-11-04 12:46:47 valid 0000, loss 6.315e-01, top1 89.41, top5 96.47
2021-11-04 12:51:20 (JOBID 31649) epoch 6: train time 4249.36, inference time 283.87s, valid_top1 52.55 (best_top1 52.66), valid_top5 77.99
2021-11-04 12:51:20 (JOBID 31649) epoch 6: train time 4249.41, inference time 283.89s, valid_top1 52.55 (best_top1 52.66), valid_top5 77.99
2021-11-04 12:51:22 (JOBID 31649) epoch 6: train time 4249.23, inference time 285.02s, valid_top1 52.55 (best_top1 52.66), valid_top5 77.99
2021-11-04 12:51:35 train 0000, loss 2.885e+00, top1 34.12, top5 64.71
2021-11-04 12:51:35 train 0000, loss 2.354e+00, top1 51.76, top5 75.29
2021-11-04 12:51:38 train 0000, loss 1.900e+00, top1 57.65, top5 82.35
2021-11-04 13:05:42 train 1000, loss 2.205e+00, top1 50.43, top5 74.86
2021-11-04 13:05:42 train 1000, loss 2.206e+00, top1 50.36, top5 74.79
2021-11-04 13:05:42 train 1000, loss 2.205e+00, top1 50.61, top5 74.93
2021-11-04 13:19:48 train 2000, loss 2.211e+00, top1 50.32, top5 74.74
2021-11-04 13:19:48 train 2000, loss 2.209e+00, top1 50.37, top5 74.78
2021-11-04 13:19:49 train 2000, loss 2.207e+00, top1 50.50, top5 74.92
2021-11-04 13:33:49 train 3000, loss 2.218e+00, top1 50.23, top5 74.69
2021-11-04 13:33:49 train 3000, loss 2.215e+00, top1 50.26, top5 74.69
2021-11-04 13:33:49 train 3000, loss 2.213e+00, top1 50.38, top5 74.79
2021-11-04 13:47:43 train 4000, loss 2.220e+00, top1 50.23, top5 74.67
2021-11-04 13:47:43 train 4000, loss 2.218e+00, top1 50.14, top5 74.64
2021-11-04 13:47:43 train 4000, loss 2.216e+00, top1 50.31, top5 74.70
2021-11-04 14:01:46 train 5000, loss 2.223e+00, top1 50.16, top5 74.62
2021-11-04 14:01:46 train 5000, loss 2.221e+00, top1 50.05, top5 74.60
2021-11-04 14:01:46 train 5000, loss 2.222e+00, top1 50.18, top5 74.57
2021-11-04 14:02:16 valid 0000, loss 7.800e-01, top1 83.53, top5 92.94
2021-11-04 14:02:16 valid 0000, loss 7.800e-01, top1 83.53, top5 92.94
2021-11-04 14:02:16 valid 0000, loss 7.800e-01, top1 83.53, top5 92.94
2021-11-04 14:06:26 (JOBID 31649) epoch 7: train time 4244.16, inference time 259.30s, valid_top1 52.48 (best_top1 52.66), valid_top5 78.22
2021-11-04 14:06:45 (JOBID 31649) epoch 7: train time 4245.54, inference time 279.34s, valid_top1 52.48 (best_top1 52.66), valid_top5 78.22
2021-11-04 14:06:49 (JOBID 31649) epoch 7: train time 4245.60, inference time 283.19s, valid_top1 52.48 (best_top1 52.66), valid_top5 78.22
2021-11-04 14:07:00 train 0000, loss 2.169e+00, top1 47.06, top5 75.29
2021-11-04 14:06:39 train 0000, loss 2.775e+00, top1 38.82, top5 60.00
2021-11-04 14:07:02 train 0000, loss 2.258e+00, top1 49.41, top5 77.65
2021-11-04 14:20:54 train 1000, loss 2.195e+00, top1 50.65, top5 75.12
2021-11-04 14:20:54 train 1000, loss 2.205e+00, top1 50.34, top5 74.82
2021-11-04 14:20:54 train 1000, loss 2.197e+00, top1 50.44, top5 74.97
2021-11-04 14:34:49 train 2000, loss 2.205e+00, top1 50.49, top5 74.93
2021-11-04 14:34:49 train 2000, loss 2.220e+00, top1 50.14, top5 74.64
2021-11-04 14:34:49 train 2000, loss 2.203e+00, top1 50.32, top5 74.75
2021-11-04 14:48:40 train 3000, loss 2.213e+00, top1 50.36, top5 74.76
2021-11-04 14:48:40 train 3000, loss 2.223e+00, top1 50.03, top5 74.59
2021-11-04 14:48:40 train 3000, loss 2.208e+00, top1 50.27, top5 74.73
2021-11-04 15:02:43 train 4000, loss 2.218e+00, top1 50.31, top5 74.66
2021-11-04 15:02:43 train 4000, loss 2.223e+00, top1 50.05, top5 74.58
2021-11-04 15:02:43 train 4000, loss 2.213e+00, top1 50.23, top5 74.64
2021-11-04 15:16:30 train 5000, loss 2.214e+00, top1 50.24, top5 74.63
2021-11-04 15:16:30 train 5000, loss 2.225e+00, top1 50.03, top5 74.56
2021-11-04 15:16:30 train 5000, loss 2.222e+00, top1 50.25, top5 74.61
2021-11-04 15:17:01 valid 0000, loss 1.670e+00, top1 64.71, top5 77.65
2021-11-04 15:17:01 valid 0000, loss 1.670e+00, top1 64.71, top5 77.65
2021-11-04 15:17:01 valid 0000, loss 1.670e+00, top1 64.71, top5 77.65
2021-11-04 15:21:13 (JOBID 31649) epoch 8: train time 4224.58, inference time 262.55s, valid_top1 48.84 (best_top1 52.66), valid_top5 75.08
2021-11-04 15:21:29 (JOBID 31649) epoch 8: train time 4204.92, inference time 278.48s, valid_top1 48.84 (best_top1 52.66), valid_top5 75.08
2021-11-04 15:21:31 (JOBID 31649) epoch 8: train time 4201.04, inference time 280.97s, valid_top1 48.84 (best_top1 52.66), valid_top5 75.08
2021-11-04 15:21:43 train 0000, loss 2.205e+00, top1 50.59, top5 76.47
2021-11-04 15:21:27 train 0000, loss 2.045e+00, top1 58.82, top5 81.18
2021-11-04 15:21:45 train 0000, loss 1.824e+00, top1 58.82, top5 81.18
2021-11-04 15:35:39 train 1000, loss 2.200e+00, top1 50.66, top5 75.11
2021-11-04 15:35:39 train 1000, loss 2.200e+00, top1 50.35, top5 74.91
2021-11-04 15:35:39 train 1000, loss 2.205e+00, top1 50.46, top5 74.86
2021-11-04 15:49:38 train 2000, loss 2.213e+00, top1 50.38, top5 74.79
2021-11-04 15:49:38 train 2000, loss 2.213e+00, top1 50.14, top5 74.75
2021-11-04 15:49:38 train 2000, loss 2.211e+00, top1 50.41, top5 74.85
2021-11-04 16:03:30 train 3000, loss 2.216e+00, top1 50.25, top5 74.72
2021-11-04 16:03:30 train 3000, loss 2.218e+00, top1 50.14, top5 74.63
2021-11-04 16:03:31 train 3000, loss 2.219e+00, top1 50.27, top5 74.68
2021-11-04 16:17:28 train 4000, loss 2.219e+00, top1 50.14, top5 74.64
2021-11-04 16:17:28 train 4000, loss 2.222e+00, top1 50.17, top5 74.59
2021-11-04 16:17:28 train 4000, loss 2.220e+00, top1 50.15, top5 74.67
2021-11-04 16:31:32 train 5000, loss 2.223e+00, top1 50.09, top5 74.61
2021-11-04 16:31:33 train 5000, loss 2.222e+00, top1 50.15, top5 74.61
2021-11-04 16:31:33 train 5000, loss 2.221e+00, top1 50.11, top5 74.64
2021-11-04 16:32:04 valid 0000, loss 1.454e+00, top1 65.88, top5 84.71
2021-11-04 16:32:04 valid 0000, loss 1.454e+00, top1 65.88, top5 84.71
2021-11-04 16:32:04 valid 0000, loss 1.454e+00, top1 65.88, top5 84.71
2021-11-04 16:36:38 (JOBID 31649) epoch 9: train time 4224.35, inference time 285.24s, valid_top1 50.91 (best_top1 52.66), valid_top5 76.92
2021-11-04 16:36:38 (JOBID 31649) epoch 9: train time 4222.09, inference time 285.21s, valid_top1 50.91 (best_top1 52.66), valid_top5 76.92
2021-11-04 16:36:39 (JOBID 31649) epoch 9: train time 4239.93, inference time 285.26s, valid_top1 50.91 (best_top1 52.66), valid_top5 76.92
2021-11-04 16:36:53 train 0000, loss 1.900e+00, top1 54.12, top5 81.18
2021-11-04 16:36:53 train 0000, loss 2.347e+00, top1 50.59, top5 71.76
2021-11-04 16:36:53 train 0000, loss 2.419e+00, top1 51.76, top5 67.06
2021-11-04 16:50:47 train 1000, loss 2.209e+00, top1 50.44, top5 74.72
2021-11-04 16:50:47 train 1000, loss 2.222e+00, top1 50.06, top5 74.60
2021-11-04 16:50:47 train 1000, loss 2.205e+00, top1 50.48, top5 74.70
2021-11-04 17:04:47 train 2000, loss 2.209e+00, top1 50.27, top5 74.78
2021-11-04 17:04:47 train 2000, loss 2.216e+00, top1 50.20, top5 74.67
2021-11-04 17:04:47 train 2000, loss 2.209e+00, top1 50.31, top5 74.70
2021-11-04 17:18:46 train 3000, loss 2.211e+00, top1 50.24, top5 74.72
2021-11-04 17:18:46 train 3000, loss 2.214e+00, top1 50.22, top5 74.70
2021-11-04 17:18:47 train 3000, loss 2.217e+00, top1 50.20, top5 74.63
2021-11-04 17:32:45 train 4000, loss 2.215e+00, top1 50.21, top5 74.69
2021-11-04 17:32:45 train 4000, loss 2.217e+00, top1 50.20, top5 74.68
2021-11-04 17:32:45 train 4000, loss 2.222e+00, top1 50.11, top5 74.56
2021-11-04 17:46:43 train 5000, loss 2.219e+00, top1 50.14, top5 74.62
2021-11-04 17:46:43 train 5000, loss 2.224e+00, top1 50.05, top5 74.55
2021-11-04 17:46:43 train 5000, loss 2.219e+00, top1 50.17, top5 74.63
2021-11-04 17:47:13 valid 0000, loss 1.047e+00, top1 77.65, top5 88.24
2021-11-04 17:47:13 valid 0000, loss 1.047e+00, top1 77.65, top5 88.24
2021-11-04 17:47:13 valid 0000, loss 1.047e+00, top1 77.65, top5 88.24
2021-11-04 17:51:29 (JOBID 31649) epoch 10: train time 4224.45, inference time 266.09s, valid_top1 51.96 (best_top1 52.66), valid_top5 77.78
2021-11-04 17:51:41 (JOBID 31649) epoch 10: train time 4224.77, inference time 277.96s, valid_top1 51.96 (best_top1 52.66), valid_top5 77.78
2021-11-04 17:51:43 (JOBID 31649) epoch 10: train time 4224.03, inference time 279.23s, valid_top1 51.96 (best_top1 52.66), valid_top5 77.78
2021-11-04 17:51:55 train 0000, loss 2.101e+00, top1 50.59, top5 74.12
2021-11-04 17:51:44 train 0000, loss 2.043e+00, top1 55.29, top5 77.65
2021-11-04 17:51:56 train 0000, loss 2.583e+00, top1 40.00, top5 70.59
2021-11-04 18:05:55 train 1000, loss 2.208e+00, top1 50.27, top5 74.83
2021-11-04 18:05:55 train 1000, loss 2.204e+00, top1 50.58, top5 74.74
2021-11-04 18:05:55 train 1000, loss 2.176e+00, top1 51.01, top5 75.34
2021-11-04 18:19:53 train 2000, loss 2.210e+00, top1 50.26, top5 74.75
2021-11-04 18:19:53 train 2000, loss 2.192e+00, top1 50.67, top5 75.03
2021-11-04 18:19:53 train 2000, loss 2.211e+00, top1 50.28, top5 74.74
2021-11-04 18:33:51 train 3000, loss 2.215e+00, top1 50.26, top5 74.69
2021-11-04 18:33:51 train 3000, loss 2.204e+00, top1 50.47, top5 74.86
2021-11-04 18:33:51 train 3000, loss 2.214e+00, top1 50.21, top5 74.68
2021-11-04 18:47:47 train 4000, loss 2.212e+00, top1 50.36, top5 74.72
2021-11-04 18:47:47 train 4000, loss 2.217e+00, top1 50.20, top5 74.67
2021-11-04 18:47:47 train 4000, loss 2.220e+00, top1 50.11, top5 74.61
2021-11-04 19:01:44 train 5000, loss 2.220e+00, top1 50.17, top5 74.65
2021-11-04 19:01:44 train 5000, loss 2.217e+00, top1 50.25, top5 74.62
2021-11-04 19:01:44 train 5000, loss 2.221e+00, top1 50.08, top5 74.60
2021-11-04 19:02:14 valid 0000, loss 1.255e+00, top1 74.12, top5 87.06
2021-11-04 19:02:14 valid 0000, loss 1.255e+00, top1 74.12, top5 87.06
2021-11-04 19:02:14 valid 0000, loss 1.255e+00, top1 74.12, top5 87.06
2021-11-04 19:06:38 (JOBID 31649) epoch 11: train time 4223.19, inference time 274.22s, valid_top1 52.00 (best_top1 52.66), valid_top5 77.94
2021-11-04 19:06:45 (JOBID 31649) epoch 11: train time 4235.37, inference time 280.33s, valid_top1 52.00 (best_top1 52.66), valid_top5 77.94
2021-11-04 19:06:49 (JOBID 31649) epoch 11: train time 4221.63, inference time 283.74s, valid_top1 52.00 (best_top1 52.66), valid_top5 77.94
2021-11-04 19:06:58 train 0000, loss 2.234e+00, top1 57.65, top5 74.12
2021-11-04 19:06:52 train 0000, loss 2.614e+00, top1 41.18, top5 69.41
2021-11-04 19:07:03 train 0000, loss 2.031e+00, top1 56.47, top5 76.47
2021-11-04 19:21:05 train 1000, loss 2.196e+00, top1 50.57, top5 74.92
2021-11-04 19:21:05 train 1000, loss 2.202e+00, top1 50.58, top5 74.86
2021-11-04 19:21:05 train 1000, loss 2.215e+00, top1 50.47, top5 74.65
2021-11-04 19:35:06 train 2000, loss 2.207e+00, top1 50.43, top5 74.75
2021-11-04 19:35:06 train 2000, loss 2.210e+00, top1 50.39, top5 74.77
2021-11-04 19:35:06 train 2000, loss 2.213e+00, top1 50.38, top5 74.71
2021-11-04 19:49:16 train 3000, loss 2.212e+00, top1 50.38, top5 74.69
2021-11-04 19:49:16 train 3000, loss 2.216e+00, top1 50.21, top5 74.65
2021-11-04 19:49:16 train 3000, loss 2.213e+00, top1 50.27, top5 74.71
2021-11-04 20:03:26 train 4000, loss 2.218e+00, top1 50.25, top5 74.58
2021-11-04 20:03:26 train 4000, loss 2.220e+00, top1 50.17, top5 74.61
2021-11-04 20:03:26 train 4000, loss 2.216e+00, top1 50.20, top5 74.73
2021-11-04 20:17:37 train 5000, loss 2.225e+00, top1 50.12, top5 74.54
2021-11-04 20:17:37 train 5000, loss 2.222e+00, top1 50.17, top5 74.53
2021-11-04 20:17:37 train 5000, loss 2.221e+00, top1 50.11, top5 74.60
2021-11-04 20:18:07 valid 0000, loss 1.146e+00, top1 78.82, top5 85.88
2021-11-04 20:18:07 valid 0000, loss 1.146e+00, top1 78.82, top5 85.88
2021-11-04 20:18:07 valid 0000, loss 1.146e+00, top1 78.82, top5 85.88
2021-11-04 20:22:22 (JOBID 31649) epoch 12: train time 4278.25, inference time 265.24s, valid_top1 53.57 (best_top1 53.57), valid_top5 78.95
2021-11-04 20:22:37 (JOBID 31649) epoch 12: train time 4272.25, inference time 280.32s, valid_top1 53.57 (best_top1 53.57), valid_top5 78.95
2021-11-04 20:22:39 (JOBID 31649) epoch 12: train time 4268.15, inference time 281.31s, valid_top1 53.57 (best_top1 53.57), valid_top5 78.95
2021-11-04 20:22:52 train 0000, loss 2.089e+00, top1 55.29, top5 75.29
2021-11-04 20:22:36 train 0000, loss 2.132e+00, top1 48.24, top5 78.82
2021-11-04 20:22:52 train 0000, loss 2.376e+00, top1 50.59, top5 72.94
2021-11-04 20:36:45 train 1000, loss 2.207e+00, top1 50.24, top5 74.82
2021-11-04 20:36:45 train 1000, loss 2.196e+00, top1 50.65, top5 74.91
2021-11-04 20:36:45 train 1000, loss 2.201e+00, top1 50.67, top5 74.70
2021-11-04 20:50:47 train 2000, loss 2.212e+00, top1 50.41, top5 74.58
2021-11-04 20:50:47 train 2000, loss 2.208e+00, top1 50.24, top5 74.81
2021-11-04 20:50:48 train 2000, loss 2.210e+00, top1 50.43, top5 74.71
2021-11-04 21:04:57 train 3000, loss 2.216e+00, top1 50.32, top5 74.64
2021-11-04 21:04:57 train 3000, loss 2.213e+00, top1 50.33, top5 74.64
2021-11-04 21:04:57 train 3000, loss 2.212e+00, top1 50.27, top5 74.76
2021-11-04 21:18:47 train 4000, loss 2.220e+00, top1 50.28, top5 74.62
2021-11-04 21:18:47 train 4000, loss 2.219e+00, top1 50.14, top5 74.64
2021-11-04 21:18:47 train 4000, loss 2.219e+00, top1 50.22, top5 74.60
2021-11-04 21:32:45 train 5000, loss 2.222e+00, top1 50.05, top5 74.58
2021-11-04 21:32:45 train 5000, loss 2.221e+00, top1 50.24, top5 74.61
2021-11-04 21:32:46 train 5000, loss 2.221e+00, top1 50.19, top5 74.56
2021-11-04 21:33:16 valid 0000, loss 1.039e+00, top1 76.47, top5 91.76
2021-11-04 21:33:16 valid 0000, loss 1.039e+00, top1 76.47, top5 91.76
2021-11-04 21:33:16 valid 0000, loss 1.039e+00, top1 76.47, top5 91.76
2021-11-04 21:37:30 (JOBID 31649) epoch 13: train time 4228.31, inference time 264.38s, valid_top1 52.50 (best_top1 53.57), valid_top5 78.44
2021-11-04 21:37:46 (JOBID 31649) epoch 13: train time 4243.61, inference time 280.34s, valid_top1 52.50 (best_top1 53.57), valid_top5 78.44
2021-11-04 21:37:47 (JOBID 31649) epoch 13: train time 4226.91, inference time 281.02s, valid_top1 52.50 (best_top1 53.57), valid_top5 78.44
2021-11-04 21:37:45 train 0000, loss 1.790e+00, top1 62.35, top5 83.53
2021-11-04 21:38:00 train 0000, loss 2.448e+00, top1 47.06, top5 71.76
2021-11-04 21:38:00 train 0000, loss 2.080e+00, top1 51.76, top5 77.65
2021-11-04 21:52:05 train 1000, loss 2.195e+00, top1 50.48, top5 75.01
2021-11-04 21:52:05 train 1000, loss 2.207e+00, top1 50.41, top5 74.95
2021-11-04 21:52:05 train 1000, loss 2.195e+00, top1 50.70, top5 74.98
2021-11-04 22:06:01 train 2000, loss 2.210e+00, top1 50.39, top5 74.83
2021-11-04 22:06:01 train 2000, loss 2.206e+00, top1 50.33, top5 74.84
2021-11-04 22:06:01 train 2000, loss 2.207e+00, top1 50.45, top5 74.83
2021-11-04 22:19:59 train 3000, loss 2.214e+00, top1 50.24, top5 74.77
2021-11-04 22:19:59 train 3000, loss 2.213e+00, top1 50.29, top5 74.75
2021-11-04 22:19:59 train 3000, loss 2.212e+00, top1 50.41, top5 74.76
2021-11-04 22:34:03 train 4000, loss 2.217e+00, top1 50.20, top5 74.69
2021-11-04 22:34:03 train 4000, loss 2.214e+00, top1 50.28, top5 74.70
2021-11-04 22:34:03 train 4000, loss 2.215e+00, top1 50.33, top5 74.71
2021-11-04 22:48:08 train 5000, loss 2.218e+00, top1 50.22, top5 74.63
2021-11-04 22:48:08 train 5000, loss 2.220e+00, top1 50.20, top5 74.66
2021-11-04 22:48:08 train 5000, loss 2.219e+00, top1 50.25, top5 74.67
2021-11-04 22:48:39 valid 0000, loss 7.921e-01, top1 78.82, top5 96.47
2021-11-04 22:48:39 valid 0000, loss 7.921e-01, top1 78.82, top5 96.47
2021-11-04 22:48:39 valid 0000, loss 7.921e-01, top1 78.82, top5 96.47
2021-11-04 22:53:05 (JOBID 31649) epoch 14: train time 4241.22, inference time 276.17s, valid_top1 52.90 (best_top1 53.57), valid_top5 78.56
2021-11-04 22:53:15 (JOBID 31649) epoch 14: train time 4258.49, inference time 286.28s, valid_top1 52.90 (best_top1 53.57), valid_top5 78.56
2021-11-04 22:53:16 (JOBID 31649) epoch 14: train time 4242.51, inference time 287.76s, valid_top1 52.90 (best_top1 53.57), valid_top5 78.56
2021-11-04 22:53:29 train 0000, loss 1.904e+00, top1 57.65, top5 74.12
2021-11-04 22:53:20 train 0000, loss 1.708e+00, top1 55.29, top5 85.88
2021-11-04 22:53:30 train 0000, loss 1.846e+00, top1 58.82, top5 77.65
2021-11-04 23:07:28 train 1000, loss 2.203e+00, top1 50.45, top5 74.83
2021-11-04 23:07:28 train 1000, loss 2.200e+00, top1 50.60, top5 74.94
2021-11-04 23:07:29 train 1000, loss 2.195e+00, top1 50.60, top5 75.00
2021-11-04 23:21:41 train 2000, loss 2.209e+00, top1 50.37, top5 74.78
2021-11-04 23:21:41 train 2000, loss 2.205e+00, top1 50.51, top5 74.98
2021-11-04 23:21:41 train 2000, loss 2.203e+00, top1 50.48, top5 74.86
2021-11-04 23:35:46 train 3000, loss 2.211e+00, top1 50.45, top5 74.86
2021-11-04 23:35:46 train 3000, loss 2.216e+00, top1 50.22, top5 74.68
2021-11-04 23:35:46 train 3000, loss 2.209e+00, top1 50.35, top5 74.76
2021-11-04 23:49:46 train 4000, loss 2.213e+00, top1 50.36, top5 74.79
2021-11-04 23:49:46 train 4000, loss 2.221e+00, top1 50.15, top5 74.58
2021-11-04 23:49:46 train 4000, loss 2.215e+00, top1 50.25, top5 74.66
2021-11-05 00:03:58 train 5000, loss 2.225e+00, top1 50.10, top5 74.54
2021-11-05 00:03:58 train 5000, loss 2.217e+00, top1 50.31, top5 74.71
2021-11-05 00:03:58 train 5000, loss 2.220e+00, top1 50.19, top5 74.60
2021-11-05 00:04:28 valid 0000, loss 1.427e+00, top1 72.94, top5 83.53
2021-11-05 00:04:28 valid 0000, loss 1.427e+00, top1 72.94, top5 83.53
2021-11-05 00:04:28 valid 0000, loss 1.427e+00, top1 72.94, top5 83.53
2021-11-05 00:09:14 (JOBID 31649) epoch 15: train time 4263.38, inference time 296.01s, valid_top1 51.66 (best_top1 53.57), valid_top5 77.49
2021-11-05 00:09:15 (JOBID 31649) epoch 15: train time 4261.71, inference time 296.87s, valid_top1 51.66 (best_top1 53.57), valid_top5 77.49
2021-11-05 00:09:16 (JOBID 31649) epoch 15: train time 4272.80, inference time 298.08s, valid_top1 51.66 (best_top1 53.57), valid_top5 77.49
2021-11-05 00:09:29 train 0000, loss 2.222e+00, top1 48.24, top5 75.29
2021-11-05 00:09:29 train 0000, loss 2.119e+00, top1 52.94, top5 75.29
2021-11-05 00:09:31 train 0000, loss 2.001e+00, top1 58.82, top5 80.00
2021-11-05 00:23:36 train 1000, loss 2.189e+00, top1 50.62, top5 75.12
2021-11-05 00:23:36 train 1000, loss 2.193e+00, top1 50.77, top5 75.03
2021-11-05 00:23:36 train 1000, loss 2.198e+00, top1 50.51, top5 74.86
2021-11-05 00:37:46 train 2000, loss 2.203e+00, top1 50.51, top5 74.81
2021-11-05 00:37:46 train 2000, loss 2.205e+00, top1 50.43, top5 74.88
2021-11-05 00:37:46 train 2000, loss 2.206e+00, top1 50.25, top5 74.78
2021-11-05 00:52:10 train 3000, loss 2.212e+00, top1 50.28, top5 74.75
2021-11-05 00:52:10 train 3000, loss 2.212e+00, top1 50.35, top5 74.68
2021-11-05 00:52:10 train 3000, loss 2.212e+00, top1 50.17, top5 74.69
2021-11-05 01:06:27 train 4000, loss 2.216e+00, top1 50.22, top5 74.70
2021-11-05 01:06:27 train 4000, loss 2.214e+00, top1 50.34, top5 74.63
2021-11-05 01:06:27 train 4000, loss 2.220e+00, top1 50.09, top5 74.57
2021-11-05 01:20:52 train 5000, loss 2.216e+00, top1 50.21, top5 74.70
2021-11-05 01:20:52 train 5000, loss 2.215e+00, top1 50.36, top5 74.62
2021-11-05 01:20:52 train 5000, loss 2.222e+00, top1 50.06, top5 74.56
2021-11-05 01:21:23 valid 0000, loss 8.775e-01, top1 82.35, top5 91.76
2021-11-05 01:21:23 valid 0000, loss 8.775e-01, top1 82.35, top5 91.76
2021-11-05 01:21:23 valid 0000, loss 8.775e-01, top1 82.35, top5 91.76
2021-11-05 01:25:39 (JOBID 31649) epoch 16: train time 4318.20, inference time 266.27s, valid_top1 51.57 (best_top1 53.57), valid_top5 76.98
2021-11-05 01:25:53 (JOBID 31649) epoch 16: train time 4318.56, inference time 280.66s, valid_top1 51.57 (best_top1 53.57), valid_top5 76.98
2021-11-05 01:25:58 (JOBID 31649) epoch 16: train time 4316.36, inference time 284.32s, valid_top1 51.57 (best_top1 53.57), valid_top5 76.98
2021-11-05 01:26:08 train 0000, loss 2.130e+00, top1 49.41, top5 76.47
2021-11-05 01:25:53 train 0000, loss 1.721e+00, top1 60.00, top5 84.71
2021-11-05 01:26:12 train 0000, loss 2.114e+00, top1 51.76, top5 72.94
2021-11-05 01:40:31 train 1000, loss 2.197e+00, top1 50.41, top5 75.02
2021-11-05 01:40:31 train 1000, loss 2.194e+00, top1 50.69, top5 75.06
2021-11-05 01:40:31 train 1000, loss 2.202e+00, top1 50.49, top5 74.93
2021-11-05 01:54:46 train 2000, loss 2.206e+00, top1 50.25, top5 74.88
2021-11-05 01:54:46 train 2000, loss 2.208e+00, top1 50.46, top5 74.81
2021-11-05 01:54:46 train 2000, loss 2.214e+00, top1 50.36, top5 74.67
2021-11-05 02:09:00 train 3000, loss 2.212e+00, top1 50.19, top5 74.77
2021-11-05 02:09:00 train 3000, loss 2.208e+00, top1 50.37, top5 74.79
2021-11-05 02:09:00 train 3000, loss 2.216e+00, top1 50.36, top5 74.68
2021-11-05 02:23:19 train 4000, loss 2.214e+00, top1 50.18, top5 74.73
2021-11-05 02:23:19 train 4000, loss 2.214e+00, top1 50.29, top5 74.68
2021-11-05 02:23:20 train 4000, loss 2.214e+00, top1 50.38, top5 74.70
2021-11-05 02:37:42 train 5000, loss 2.217e+00, top1 50.23, top5 74.64
2021-11-05 02:37:42 train 5000, loss 2.217e+00, top1 50.16, top5 74.68
2021-11-05 02:37:42 train 5000, loss 2.218e+00, top1 50.30, top5 74.64
2021-11-05 02:38:13 valid 0000, loss 7.281e-01, top1 85.88, top5 94.12
2021-11-05 02:38:13 valid 0000, loss 7.281e-01, top1 85.88, top5 94.12
2021-11-05 02:38:13 valid 0000, loss 7.281e-01, top1 85.88, top5 94.12
2021-11-05 02:42:24 (JOBID 31649) epoch 17: train time 4343.42, inference time 261.14s, valid_top1 50.93 (best_top1 53.57), valid_top5 76.47
2021-11-05 02:42:44 (JOBID 31649) epoch 17: train time 4325.08, inference time 281.42s, valid_top1 50.93 (best_top1 53.57), valid_top5 76.47
2021-11-05 02:42:45 (JOBID 31649) epoch 17: train time 4329.52, inference time 282.30s, valid_top1 50.93 (best_top1 53.57), valid_top5 76.47
2021-11-05 02:42:39 train 0000, loss 2.515e+00, top1 41.18, top5 68.24
2021-11-05 02:42:59 train 0000, loss 2.248e+00, top1 47.06, top5 72.94
2021-11-05 02:42:59 train 0000, loss 1.945e+00, top1 54.12, top5 76.47
2021-11-05 02:57:21 train 1000, loss 2.204e+00, top1 50.50, top5 74.90
2021-11-05 02:57:21 train 1000, loss 2.200e+00, top1 50.43, top5 74.88
2021-11-05 02:57:21 train 1000, loss 2.205e+00, top1 50.44, top5 74.82
2021-11-05 03:11:50 train 2000, loss 2.206e+00, top1 50.44, top5 74.80
2021-11-05 03:11:50 train 2000, loss 2.202e+00, top1 50.50, top5 74.86
2021-11-05 03:11:51 train 2000, loss 2.204e+00, top1 50.49, top5 74.79
2021-11-05 03:26:19 train 3000, loss 2.209e+00, top1 50.43, top5 74.71
2021-11-05 03:26:19 train 3000, loss 2.204e+00, top1 50.47, top5 74.81
2021-11-05 03:26:20 train 3000, loss 2.208e+00, top1 50.41, top5 74.75
2021-11-05 03:40:42 train 4000, loss 2.215e+00, top1 50.32, top5 74.62
2021-11-05 03:40:42 train 4000, loss 2.211e+00, top1 50.36, top5 74.70
2021-11-05 03:40:43 train 4000, loss 2.215e+00, top1 50.30, top5 74.66
2021-11-05 03:55:01 train 5000, loss 2.219e+00, top1 50.28, top5 74.60
2021-11-05 03:55:01 train 5000, loss 2.213e+00, top1 50.34, top5 74.67
2021-11-05 03:55:01 train 5000, loss 2.216e+00, top1 50.30, top5 74.61
2021-11-05 03:55:33 valid 0000, loss 7.983e-01, top1 83.53, top5 94.12
2021-11-05 03:55:33 valid 0000, loss 7.983e-01, top1 83.53, top5 94.12
2021-11-05 03:55:33 valid 0000, loss 7.983e-01, top1 83.53, top5 94.12
2021-11-05 04:00:04 (JOBID 31649) epoch 18: train time 4356.86, inference time 281.62s, valid_top1 53.55 (best_top1 53.57), valid_top5 78.79
2021-11-05 04:00:04 (JOBID 31649) epoch 18: train time 4357.65, inference time 281.47s, valid_top1 53.55 (best_top1 53.57), valid_top5 78.79
2021-11-05 04:00:04 (JOBID 31649) epoch 18: train time 4378.26, inference time 282.10s, valid_top1 53.55 (best_top1 53.57), valid_top5 78.79
2021-11-05 04:00:18 train 0000, loss 3.028e+00, top1 36.47, top5 57.65
2021-11-05 04:00:18 train 0000, loss 2.016e+00, top1 54.12, top5 80.00
2021-11-05 04:00:20 train 0000, loss 2.445e+00, top1 44.71, top5 72.94
2021-11-05 04:14:45 train 1000, loss 2.191e+00, top1 50.82, top5 75.04
2021-11-05 04:14:45 train 1000, loss 2.178e+00, top1 50.81, top5 75.35
2021-11-05 04:14:45 train 1000, loss 2.199e+00, top1 50.56, top5 74.85
2021-11-05 04:29:00 train 2000, loss 2.199e+00, top1 50.63, top5 74.94
2021-11-05 04:29:00 train 2000, loss 2.201e+00, top1 50.44, top5 74.93
2021-11-05 04:29:01 train 2000, loss 2.208e+00, top1 50.24, top5 74.76
2021-11-05 04:43:16 train 3000, loss 2.209e+00, top1 50.34, top5 74.83
2021-11-05 04:43:16 train 3000, loss 2.214e+00, top1 50.20, top5 74.71
2021-11-05 04:43:17 train 3000, loss 2.205e+00, top1 50.57, top5 74.87
2021-11-05 04:57:42 train 4000, loss 2.215e+00, top1 50.23, top5 74.70
2021-11-05 04:57:42 train 4000, loss 2.210e+00, top1 50.51, top5 74.81
2021-11-05 04:57:42 train 4000, loss 2.215e+00, top1 50.24, top5 74.69
2021-11-05 05:12:07 train 5000, loss 2.220e+00, top1 50.16, top5 74.61
2021-11-05 05:12:07 train 5000, loss 2.215e+00, top1 50.37, top5 74.73
2021-11-05 05:12:07 train 5000, loss 2.218e+00, top1 50.18, top5 74.62
2021-11-05 05:12:38 valid 0000, loss 1.254e+00, top1 69.41, top5 87.06
2021-11-05 05:12:38 valid 0000, loss 1.254e+00, top1 69.41, top5 87.06
2021-11-05 05:12:38 valid 0000, loss 1.254e+00, top1 69.41, top5 87.06
2021-11-05 05:16:57 (JOBID 31649) epoch 19: train time 4343.96, inference time 268.45s, valid_top1 51.48 (best_top1 53.57), valid_top5 77.05
2021-11-05 05:17:08 (JOBID 31649) epoch 19: train time 4344.24, inference time 280.45s, valid_top1 51.48 (best_top1 53.57), valid_top5 77.05
2021-11-05 05:17:09 (JOBID 31649) epoch 19: train time 4343.88, inference time 281.30s, valid_top1 51.48 (best_top1 53.57), valid_top5 77.05
2021-11-05 05:17:13 train 0000, loss 2.182e+00, top1 45.88, top5 71.76
2021-11-05 05:17:23 train 0000, loss 2.562e+00, top1 43.53, top5 67.06
2021-11-05 05:17:23 train 0000, loss 1.971e+00, top1 61.18, top5 72.94
2021-11-05 05:31:34 train 1000, loss 2.197e+00, top1 50.57, top5 74.93
2021-11-05 05:31:34 train 1000, loss 2.195e+00, top1 50.67, top5 75.05
2021-11-05 05:31:35 train 1000, loss 2.206e+00, top1 50.29, top5 75.02
2021-11-05 05:45:50 train 2000, loss 2.204e+00, top1 50.37, top5 74.95
2021-11-05 05:45:50 train 2000, loss 2.198e+00, top1 50.61, top5 74.96
2021-11-05 05:45:50 train 2000, loss 2.205e+00, top1 50.45, top5 74.85
2021-11-05 06:00:13 train 3000, loss 2.205e+00, top1 50.55, top5 74.88
2021-11-05 06:00:13 train 3000, loss 2.213e+00, top1 50.31, top5 74.72
2021-11-05 06:00:14 train 3000, loss 2.206e+00, top1 50.42, top5 74.90
2021-11-05 06:14:29 train 4000, loss 2.210e+00, top1 50.42, top5 74.84
2021-11-05 06:14:29 train 4000, loss 2.218e+00, top1 50.27, top5 74.65
2021-11-05 06:14:29 train 4000, loss 2.212e+00, top1 50.31, top5 74.80
2021-11-05 06:28:42 train 5000, loss 2.213e+00, top1 50.37, top5 74.81
2021-11-05 06:28:42 train 5000, loss 2.220e+00, top1 50.23, top5 74.58
2021-11-05 06:28:42 train 5000, loss 2.217e+00, top1 50.20, top5 74.70
2021-11-05 06:29:14 valid 0000, loss 1.425e+00, top1 71.76, top5 82.35
2021-11-05 06:29:14 valid 0000, loss 1.425e+00, top1 71.76, top5 82.35
2021-11-05 06:29:14 valid 0000, loss 1.425e+00, top1 71.76, top5 82.35
2021-11-05 06:33:27 (JOBID 31649) epoch 20: train time 4313.91, inference time 264.48s, valid_top1 52.84 (best_top1 53.57), valid_top5 78.56
2021-11-05 06:33:43 (JOBID 31649) epoch 20: train time 4312.88, inference time 280.37s, valid_top1 52.84 (best_top1 53.57), valid_top5 78.56
2021-11-05 06:33:46 (JOBID 31649) epoch 20: train time 4325.61, inference time 283.24s, valid_top1 52.84 (best_top1 53.57), valid_top5 78.56
2021-11-05 06:33:57 train 0000, loss 1.869e+00, top1 57.65, top5 77.65
2021-11-05 06:33:43 train 0000, loss 1.745e+00, top1 57.65, top5 85.88
2021-11-05 06:34:00 train 0000, loss 2.377e+00, top1 41.18, top5 74.12
2021-11-05 06:48:38 train 1000, loss 2.207e+00, top1 50.41, top5 74.75
2021-11-05 06:48:38 train 1000, loss 2.199e+00, top1 50.58, top5 75.07
2021-11-05 06:48:39 train 1000, loss 2.195e+00, top1 50.55, top5 74.93
2021-11-05 07:02:54 train 2000, loss 2.204e+00, top1 50.43, top5 74.84
2021-11-05 07:02:54 train 2000, loss 2.206e+00, top1 50.43, top5 74.90
2021-11-05 07:02:55 train 2000, loss 2.205e+00, top1 50.37, top5 74.77
2021-11-05 07:17:17 train 3000, loss 2.208e+00, top1 50.37, top5 74.78
2021-11-05 07:17:17 train 3000, loss 2.213e+00, top1 50.29, top5 74.81
2021-11-05 07:17:17 train 3000, loss 2.210e+00, top1 50.28, top5 74.72
2021-11-05 07:31:44 train 4000, loss 2.213e+00, top1 50.32, top5 74.74
2021-11-05 07:31:44 train 4000, loss 2.217e+00, top1 50.20, top5 74.71
2021-11-05 07:31:45 train 4000, loss 2.217e+00, top1 50.21, top5 74.62
2021-11-05 07:46:23 train 5000, loss 2.216e+00, top1 50.31, top5 74.70
2021-11-05 07:46:23 train 5000, loss 2.219e+00, top1 50.20, top5 74.66
2021-11-05 07:46:23 train 5000, loss 2.219e+00, top1 50.19, top5 74.61
2021-11-05 07:46:53 valid 0000, loss 8.240e-01, top1 82.35, top5 91.76
2021-11-05 07:46:53 valid 0000, loss 8.240e-01, top1 82.35, top5 91.76
2021-11-05 07:46:53 valid 0000, loss 8.240e-01, top1 82.35, top5 91.76
2021-11-05 07:51:24 (JOBID 31649) epoch 21: train time 4380.66, inference time 281.09s, valid_top1 53.25 (best_top1 53.57), valid_top5 79.02
2021-11-05 07:51:25 (JOBID 31649) epoch 21: train time 4396.24, inference time 281.60s, valid_top1 53.25 (best_top1 53.57), valid_top5 79.02
2021-11-05 07:51:28 (JOBID 31649) epoch 21: train time 4377.03, inference time 284.69s, valid_top1 53.25 (best_top1 53.57), valid_top5 79.02
2021-11-05 07:51:41 train 0000, loss 2.538e+00, top1 44.71, top5 70.59
2021-11-05 07:51:41 train 0000, loss 2.229e+00, top1 50.59, top5 74.12
2021-11-05 07:51:44 train 0000, loss 1.860e+00, top1 56.47, top5 83.53
2021-11-05 08:05:33 train 1000, loss 2.186e+00, top1 50.50, top5 75.21
2021-11-05 08:05:33 train 1000, loss 2.188e+00, top1 50.68, top5 75.09
2021-11-05 08:05:33 train 1000, loss 2.197e+00, top1 50.56, top5 74.95
2021-11-05 08:19:22 train 2000, loss 2.208e+00, top1 50.49, top5 74.82
2021-11-05 08:19:22 train 2000, loss 2.202e+00, top1 50.46, top5 74.96
2021-11-05 08:19:22 train 2000, loss 2.193e+00, top1 50.63, top5 75.06
2021-11-05 08:33:12 train 3000, loss 2.209e+00, top1 50.48, top5 74.75
2021-11-05 08:33:12 train 3000, loss 2.209e+00, top1 50.35, top5 74.78
2021-11-05 08:33:12 train 3000, loss 2.204e+00, top1 50.51, top5 74.87
2021-11-05 08:47:02 train 4000, loss 2.213e+00, top1 50.38, top5 74.71
2021-11-05 08:47:02 train 4000, loss 2.212e+00, top1 50.28, top5 74.76
2021-11-05 08:47:02 train 4000, loss 2.210e+00, top1 50.35, top5 74.77
2021-11-05 09:00:45 train 5000, loss 2.214e+00, top1 50.28, top5 74.71
2021-11-05 09:00:45 train 5000, loss 2.217e+00, top1 50.28, top5 74.62
2021-11-05 09:00:46 train 5000, loss 2.215e+00, top1 50.30, top5 74.70
2021-11-05 09:01:17 valid 0000, loss 1.029e+00, top1 78.82, top5 89.41
2021-11-05 09:01:17 valid 0000, loss 1.029e+00, top1 78.82, top5 89.41
2021-11-05 09:01:17 valid 0000, loss 1.029e+00, top1 78.82, top5 89.41
2021-11-05 09:05:46 (JOBID 31649) epoch 22: train time 4180.61, inference time 280.86s, valid_top1 52.52 (best_top1 53.57), valid_top5 78.46
2021-11-05 09:05:47 (JOBID 31649) epoch 22: train time 4180.83, inference time 281.41s, valid_top1 52.52 (best_top1 53.57), valid_top5 78.46
2021-11-05 09:05:47 (JOBID 31649) epoch 22: train time 4177.13, inference time 281.82s, valid_top1 52.52 (best_top1 53.57), valid_top5 78.46
2021-11-05 09:06:03 train 0000, loss 2.446e+00, top1 49.41, top5 70.59
2021-11-05 09:06:03 train 0000, loss 1.952e+00, top1 47.06, top5 81.18
2021-11-05 09:06:03 train 0000, loss 1.819e+00, top1 56.47, top5 81.18
2021-11-05 09:19:50 train 1000, loss 2.186e+00, top1 50.79, top5 75.27
2021-11-05 09:19:50 train 1000, loss 2.187e+00, top1 50.66, top5 75.17
2021-11-05 09:19:50 train 1000, loss 2.206e+00, top1 50.22, top5 74.77
2021-11-05 09:33:37 train 2000, loss 2.213e+00, top1 50.19, top5 74.70
2021-11-05 09:33:37 train 2000, loss 2.197e+00, top1 50.59, top5 75.06
2021-11-05 09:33:38 train 2000, loss 2.196e+00, top1 50.55, top5 74.96
2021-11-05 09:47:19 train 3000, loss 2.213e+00, top1 50.30, top5 74.71
2021-11-05 09:47:19 train 3000, loss 2.204e+00, top1 50.41, top5 74.94
2021-11-05 09:47:19 train 3000, loss 2.203e+00, top1 50.39, top5 74.91
2021-11-05 10:01:07 train 4000, loss 2.215e+00, top1 50.29, top5 74.70
2021-11-05 10:01:07 train 4000, loss 2.208e+00, top1 50.33, top5 74.81
2021-11-05 10:01:07 train 4000, loss 2.210e+00, top1 50.31, top5 74.81
2021-11-05 10:14:59 train 5000, loss 2.216e+00, top1 50.25, top5 74.66
2021-11-05 10:14:59 train 5000, loss 2.211e+00, top1 50.32, top5 74.76
2021-11-05 10:14:59 train 5000, loss 2.215e+00, top1 50.23, top5 74.71
2021-11-05 10:15:30 valid 0000, loss 1.467e+00, top1 63.53, top5 89.41
2021-11-05 10:15:30 valid 0000, loss 1.467e+00, top1 63.53, top5 89.41
2021-11-05 10:15:30 valid 0000, loss 1.467e+00, top1 63.53, top5 89.41
2021-11-05 10:19:41 (JOBID 31649) epoch 23: train time 4171.76, inference time 261.63s, valid_top1 52.45 (best_top1 53.57), valid_top5 78.09
2021-11-05 10:20:01 (JOBID 31649) epoch 23: train time 4173.01, inference time 281.86s, valid_top1 52.45 (best_top1 53.57), valid_top5 78.09
2021-11-05 10:20:01 (JOBID 31649) epoch 23: train time 4172.57, inference time 281.98s, valid_top1 52.45 (best_top1 53.57), valid_top5 78.09
2021-11-05 10:19:55 train 0000, loss 2.261e+00, top1 44.71, top5 77.65
2021-11-05 10:20:15 train 0000, loss 1.806e+00, top1 57.65, top5 81.18
2021-11-05 10:20:15 train 0000, loss 2.488e+00, top1 36.47, top5 70.59
2021-11-05 10:33:57 train 1000, loss 2.187e+00, top1 50.71, top5 75.37
2021-11-05 10:33:57 train 1000, loss 2.203e+00, top1 50.65, top5 74.76
2021-11-05 10:33:57 train 1000, loss 2.191e+00, top1 50.65, top5 74.84
2021-11-05 10:47:49 train 2000, loss 2.207e+00, top1 50.30, top5 75.01
2021-11-05 10:47:49 train 2000, loss 2.206e+00, top1 50.54, top5 74.78
2021-11-05 10:47:49 train 2000, loss 2.201e+00, top1 50.47, top5 74.83
2021-11-05 11:01:41 train 3000, loss 2.208e+00, top1 50.32, top5 74.94
2021-11-05 11:01:41 train 3000, loss 2.212e+00, top1 50.47, top5 74.74
2021-11-05 11:01:41 train 3000, loss 2.209e+00, top1 50.37, top5 74.74
2021-11-05 11:15:26 train 4000, loss 2.211e+00, top1 50.24, top5 74.83
2021-11-05 11:15:26 train 4000, loss 2.214e+00, top1 50.39, top5 74.72
2021-11-05 11:15:27 train 4000, loss 2.215e+00, top1 50.26, top5 74.67
2021-11-05 11:29:11 train 5000, loss 2.216e+00, top1 50.32, top5 74.71
2021-11-05 11:29:11 train 5000, loss 2.213e+00, top1 50.26, top5 74.80
2021-11-05 11:29:12 train 5000, loss 2.217e+00, top1 50.24, top5 74.64
2021-11-05 11:29:41 valid 0000, loss 7.124e-01, top1 87.06, top5 91.76
2021-11-05 11:29:41 valid 0000, loss 7.124e-01, top1 87.06, top5 91.76
2021-11-05 11:29:41 valid 0000, loss 7.124e-01, top1 87.06, top5 91.76
2021-11-05 11:34:14 (JOBID 31649) epoch 24: train time 4169.98, inference time 283.04s, valid_top1 52.99 (best_top1 53.57), valid_top5 78.51
2021-11-05 11:34:15 (JOBID 31649) epoch 24: train time 4170.14, inference time 283.50s, valid_top1 52.99 (best_top1 53.57), valid_top5 78.51
2021-11-05 11:34:15 (JOBID 31649) epoch 24: train time 4189.95, inference time 283.34s, valid_top1 52.99 (best_top1 53.57), valid_top5 78.51
2021-11-05 11:34:29 train 0000, loss 2.172e+00, top1 45.88, top5 77.65
2021-11-05 11:34:29 train 0000, loss 2.506e+00, top1 41.18, top5 72.94
2021-11-05 11:34:29 train 0000, loss 2.042e+00, top1 50.59, top5 77.65
2021-11-05 11:48:22 train 1000, loss 2.211e+00, top1 50.22, top5 74.93
2021-11-05 11:48:22 train 1000, loss 2.198e+00, top1 50.74, top5 75.01
2021-11-05 11:48:22 train 1000, loss 2.193e+00, top1 50.83, top5 74.99
2021-11-05 12:02:29 train 2000, loss 2.206e+00, top1 50.56, top5 74.87
2021-11-05 12:02:29 train 2000, loss 2.215e+00, top1 50.14, top5 74.82
2021-11-05 12:02:29 train 2000, loss 2.207e+00, top1 50.52, top5 74.83
2021-11-05 12:16:14 train 3000, loss 2.208e+00, top1 50.52, top5 74.86
2021-11-05 12:16:14 train 3000, loss 2.212e+00, top1 50.25, top5 74.84
2021-11-05 12:16:14 train 3000, loss 2.211e+00, top1 50.39, top5 74.73
2021-11-05 12:30:04 train 4000, loss 2.217e+00, top1 50.19, top5 74.76
2021-11-05 12:30:04 train 4000, loss 2.212e+00, top1 50.33, top5 74.76
2021-11-05 12:30:04 train 4000, loss 2.211e+00, top1 50.46, top5 74.79
2021-11-05 12:43:54 train 5000, loss 2.219e+00, top1 50.21, top5 74.72
2021-11-05 12:43:54 train 5000, loss 2.213e+00, top1 50.35, top5 74.75
2021-11-05 12:43:54 train 5000, loss 2.213e+00, top1 50.42, top5 74.76
2021-11-05 12:44:25 valid 0000, loss 1.281e+00, top1 72.94, top5 88.24
2021-11-05 12:44:25 valid 0000, loss 1.281e+00, top1 72.94, top5 88.24
2021-11-05 12:44:25 valid 0000, loss 1.281e+00, top1 72.94, top5 88.24
2021-11-05 12:48:39 (JOBID 31649) epoch 25: train time 4199.21, inference time 264.98s, valid_top1 53.48 (best_top1 53.57), valid_top5 78.82
2021-11-05 12:48:59 (JOBID 31649) epoch 25: train time 4199.01, inference time 285.01s, valid_top1 53.48 (best_top1 53.57), valid_top5 78.82
2021-11-05 12:48:59 (JOBID 31649) epoch 25: train time 4199.56, inference time 285.58s, valid_top1 53.48 (best_top1 53.57), valid_top5 78.82
2021-11-05 12:48:53 train 0000, loss 2.294e+00, top1 47.06, top5 76.47
2021-11-05 12:49:13 train 0000, loss 2.197e+00, top1 41.18, top5 76.47
2021-11-05 12:49:13 train 0000, loss 2.101e+00, top1 48.24, top5 76.47
2021-11-05 13:03:02 train 1000, loss 2.193e+00, top1 50.61, top5 75.05
2021-11-05 13:03:02 train 1000, loss 2.218e+00, top1 50.30, top5 74.49
2021-11-05 13:03:03 train 1000, loss 2.192e+00, top1 50.79, top5 75.21
2021-11-05 13:16:50 train 2000, loss 2.207e+00, top1 50.31, top5 74.84
2021-11-05 13:16:50 train 2000, loss 2.212e+00, top1 50.49, top5 74.72
2021-11-05 13:16:50 train 2000, loss 2.201e+00, top1 50.61, top5 74.99
2021-11-05 13:30:40 train 3000, loss 2.214e+00, top1 50.20, top5 74.73
2021-11-05 13:30:40 train 3000, loss 2.212e+00, top1 50.45, top5 74.74
2021-11-05 13:30:41 train 3000, loss 2.208e+00, top1 50.47, top5 74.83
2021-11-05 13:44:34 train 4000, loss 2.214e+00, top1 50.23, top5 74.75
2021-11-05 13:44:34 train 4000, loss 2.217e+00, top1 50.36, top5 74.70
2021-11-05 13:44:34 train 4000, loss 2.211e+00, top1 50.39, top5 74.77
2021-11-05 13:58:22 train 5000, loss 2.216e+00, top1 50.24, top5 74.70
2021-11-05 13:58:22 train 5000, loss 2.220e+00, top1 50.30, top5 74.61
2021-11-05 13:58:23 train 5000, loss 2.215e+00, top1 50.32, top5 74.71
2021-11-05 13:58:55 valid 0000, loss 9.899e-01, top1 78.82, top5 92.94
2021-11-05 13:58:55 valid 0000, loss 9.899e-01, top1 78.82, top5 92.94
2021-11-05 13:58:55 valid 0000, loss 9.899e-01, top1 78.82, top5 92.94
2021-11-05 14:03:08 (JOBID 31649) epoch 26: train time 4183.54, inference time 265.39s, valid_top1 48.96 (best_top1 53.57), valid_top5 75.16
2021-11-05 14:03:25 (JOBID 31649) epoch 26: train time 4204.02, inference time 281.98s, valid_top1 48.96 (best_top1 53.57), valid_top5 75.16
2021-11-05 14:03:26 (JOBID 31649) epoch 26: train time 4183.74, inference time 282.56s, valid_top1 48.96 (best_top1 53.57), valid_top5 75.16
2021-11-05 14:03:23 train 0000, loss 2.192e+00, top1 51.76, top5 70.59
2021-11-05 14:03:39 train 0000, loss 2.051e+00, top1 57.65, top5 77.65
2021-11-05 14:03:39 train 0000, loss 2.011e+00, top1 48.24, top5 75.29
2021-11-05 14:17:34 train 1000, loss 2.195e+00, top1 50.65, top5 74.80
2021-11-05 14:17:34 train 1000, loss 2.194e+00, top1 50.62, top5 75.09
2021-11-05 14:17:35 train 1000, loss 2.192e+00, top1 50.63, top5 74.99
2021-11-05 14:31:29 train 2000, loss 2.202e+00, top1 50.60, top5 74.76
2021-11-05 14:31:29 train 2000, loss 2.203e+00, top1 50.50, top5 74.90
2021-11-05 14:31:29 train 2000, loss 2.202e+00, top1 50.48, top5 74.85
2021-11-05 14:34:52 CARME Slurm ID: 31649
2021-11-05 14:34:52 CARME Slurm ID: 31649
2021-11-05 14:34:52 CARME Slurm ID: 31649
2021-11-05 14:34:52 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=2, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-05 14:34:52 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=1, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-05 14:34:52 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=0, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-05 14:36:29 CARME Slurm ID: 31649
2021-11-05 14:36:29 CARME Slurm ID: 31649
2021-11-05 14:36:29 CARME Slurm ID: 31649
2021-11-05 14:36:29 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=1, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-05 14:36:29 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=0, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-05 14:36:29 args = Namespace(arch='resnet50', baseline_model='fpgm_pretrained_all_conv', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.40:23456', distributed=True, epochs=90, evaluate=False, gpu=2, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', path_to_save='retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-05 14:36:41 Computational complexity:       2.02 GMac
2021-11-05 14:36:41 Number of parameters:           13.35 M 
2021-11-05 14:36:41 Computational complexity:       2.02 GMac
2021-11-05 14:36:41 => loading checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243'
2021-11-05 14:36:41 Computational complexity:       2.02 GMac
2021-11-05 14:36:41 Number of parameters:           13.35 M 
2021-11-05 14:36:41 Number of parameters:           13.35 M 
2021-11-05 14:36:41 => loading checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243'
2021-11-05 14:36:41 => loading checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243'
2021-11-05 14:36:41 => loaded checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243' (epoch 27)
2021-11-05 14:36:41 => loaded checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243' (epoch 27)
2021-11-05 14:36:41 => loaded checkpoint 'retrain_fpgm_pretrained_all_conv_lr_0.1_momentum_0.9_wd_0.0001_20211104-014243' (epoch 27)
2021-11-05 14:37:08 train 0000, loss 2.241e+00, top1 42.35, top5 75.29
2021-11-05 14:37:08 train 0000, loss 2.239e+00, top1 55.29, top5 70.59
2021-11-05 14:37:08 train 0000, loss 2.148e+00, top1 52.94, top5 75.29
2021-11-05 14:51:04 train 1000, loss 2.185e+00, top1 50.89, top5 75.06
2021-11-05 14:51:04 train 1000, loss 2.186e+00, top1 50.89, top5 75.02
2021-11-05 14:51:04 train 1000, loss 2.191e+00, top1 50.83, top5 75.02
2021-11-05 15:04:56 train 2000, loss 2.198e+00, top1 50.62, top5 74.95
2021-11-05 15:04:56 train 2000, loss 2.198e+00, top1 50.76, top5 74.94
2021-11-05 15:04:57 train 2000, loss 2.201e+00, top1 50.64, top5 74.84
2021-11-05 15:18:50 train 3000, loss 2.210e+00, top1 50.47, top5 74.82
2021-11-05 15:18:50 train 3000, loss 2.203e+00, top1 50.54, top5 74.90
2021-11-05 15:18:50 train 3000, loss 2.204e+00, top1 50.58, top5 74.86
2021-11-05 15:32:47 train 4000, loss 2.216e+00, top1 50.37, top5 74.72
2021-11-05 15:32:47 train 4000, loss 2.208e+00, top1 50.44, top5 74.81
2021-11-05 15:32:47 train 4000, loss 2.210e+00, top1 50.42, top5 74.79
2021-11-05 15:46:37 train 5000, loss 2.214e+00, top1 50.34, top5 74.75
2021-11-05 15:46:37 train 5000, loss 2.217e+00, top1 50.33, top5 74.69
2021-11-05 15:46:37 train 5000, loss 2.215e+00, top1 50.32, top5 74.73
2021-11-05 15:47:10 valid 0000, loss 7.516e-01, top1 82.35, top5 94.12
2021-11-05 15:47:10 valid 0000, loss 7.516e-01, top1 82.35, top5 94.12
2021-11-05 15:47:10 valid 0000, loss 7.516e-01, top1 82.35, top5 94.12
2021-11-05 15:51:41 (JOBID 31649) epoch 27: train time 4213.38, inference time 281.30s, valid_top1 52.49 (best_top1 53.57), valid_top5 78.50
2021-11-05 15:51:44 (JOBID 31649) epoch 27: train time 4213.38, inference time 284.43s, valid_top1 52.49 (best_top1 53.57), valid_top5 78.50
2021-11-05 15:51:47 (JOBID 31649) epoch 27: train time 4213.39, inference time 286.90s, valid_top1 52.49 (best_top1 53.57), valid_top5 78.50
2021-11-05 15:52:00 train 0000, loss 1.896e+00, top1 56.47, top5 82.35
2021-11-05 15:51:56 train 0000, loss 2.171e+00, top1 57.65, top5 78.82
2021-11-05 15:52:02 train 0000, loss 2.706e+00, top1 49.41, top5 63.53
2021-11-05 16:05:53 train 1000, loss 2.201e+00, top1 50.34, top5 74.96
2021-11-05 16:05:53 train 1000, loss 2.202e+00, top1 50.46, top5 74.90
2021-11-05 16:05:54 train 1000, loss 2.214e+00, top1 50.42, top5 74.74
2021-11-05 16:20:11 train 2000, loss 2.209e+00, top1 50.38, top5 74.85
2021-11-05 16:20:11 train 2000, loss 2.207e+00, top1 50.42, top5 74.84
2021-11-05 16:20:11 train 2000, loss 2.207e+00, top1 50.51, top5 74.84
2021-11-05 16:35:52 train 3000, loss 2.210e+00, top1 50.45, top5 74.79
2021-11-05 16:35:52 train 3000, loss 2.207e+00, top1 50.43, top5 74.81
2021-11-05 16:35:52 train 3000, loss 2.212e+00, top1 50.32, top5 74.77
2021-11-05 16:49:33 train 4000, loss 2.214e+00, top1 50.33, top5 74.74
2021-11-05 16:49:33 train 4000, loss 2.212e+00, top1 50.39, top5 74.75
2021-11-05 16:49:34 train 4000, loss 2.213e+00, top1 50.41, top5 74.72
2021-11-05 17:03:16 train 5000, loss 2.215e+00, top1 50.33, top5 74.68
2021-11-05 17:03:15 train 5000, loss 2.219e+00, top1 50.27, top5 74.67
2021-11-05 17:03:16 train 5000, loss 2.213e+00, top1 50.37, top5 74.71
2021-11-05 17:03:47 valid 0000, loss 1.417e+00, top1 69.41, top5 83.53
2021-11-05 17:03:47 valid 0000, loss 1.417e+00, top1 69.41, top5 83.53
2021-11-05 17:03:47 valid 0000, loss 1.417e+00, top1 69.41, top5 83.53
2021-11-05 17:07:59 (JOBID 31649) epoch 28: train time 4311.05, inference time 263.36s, valid_top1 52.44 (best_top1 53.57), valid_top5 77.80
2021-11-05 17:08:23 (JOBID 31649) epoch 28: train time 4308.59, inference time 287.77s, valid_top1 52.44 (best_top1 53.57), valid_top5 77.80
2021-11-05 17:08:25 (JOBID 31649) epoch 28: train time 4314.24, inference time 288.76s, valid_top1 52.44 (best_top1 53.57), valid_top5 77.80
2021-11-05 17:08:38 train 0000, loss 2.112e+00, top1 49.41, top5 72.94
2021-11-05 17:08:13 train 0000, loss 2.233e+00, top1 48.24, top5 75.29
2021-11-05 17:08:40 train 0000, loss 1.778e+00, top1 56.47, top5 83.53
2021-11-05 17:23:14 train 1000, loss 2.195e+00, top1 50.63, top5 74.99
2021-11-05 17:23:14 train 1000, loss 2.205e+00, top1 50.36, top5 74.90
2021-11-05 17:23:14 train 1000, loss 2.206e+00, top1 50.44, top5 74.74
2021-11-05 17:37:02 train 2000, loss 2.207e+00, top1 50.44, top5 74.85
2021-11-05 17:37:02 train 2000, loss 2.210e+00, top1 50.42, top5 74.76
2021-11-05 17:37:03 train 2000, loss 2.201e+00, top1 50.67, top5 74.92
2021-11-05 17:50:44 train 3000, loss 2.213e+00, top1 50.31, top5 74.71
2021-11-05 17:50:44 train 3000, loss 2.216e+00, top1 50.25, top5 74.77
2021-11-05 17:50:44 train 3000, loss 2.208e+00, top1 50.53, top5 74.74
2021-11-05 18:05:24 train 4000, loss 2.213e+00, top1 50.29, top5 74.72
2021-11-05 18:05:24 train 4000, loss 2.216e+00, top1 50.24, top5 74.77
2021-11-05 18:05:24 train 4000, loss 2.211e+00, top1 50.47, top5 74.65
2021-11-05 18:19:11 train 5000, loss 2.215e+00, top1 50.29, top5 74.68
2021-11-05 18:19:11 train 5000, loss 2.220e+00, top1 50.18, top5 74.70
2021-11-05 18:19:12 train 5000, loss 2.217e+00, top1 50.37, top5 74.60
2021-11-05 18:19:41 valid 0000, loss 1.321e+00, top1 72.94, top5 84.71
2021-11-05 18:19:41 valid 0000, loss 1.321e+00, top1 72.94, top5 84.71
2021-11-05 18:19:41 valid 0000, loss 1.321e+00, top1 72.94, top5 84.71
2021-11-05 18:24:13 (JOBID 31649) epoch 29: train time 4292.64, inference time 281.66s, valid_top1 53.89 (best_top1 53.89), valid_top5 79.19
2021-11-05 18:24:14 (JOBID 31649) epoch 29: train time 4266.63, inference time 282.00s, valid_top1 53.89 (best_top1 53.89), valid_top5 79.19
2021-11-05 18:24:15 (JOBID 31649) epoch 29: train time 4268.45, inference time 283.37s, valid_top1 53.89 (best_top1 53.89), valid_top5 79.19
2021-11-05 18:24:28 train 0000, loss 2.059e+00, top1 48.24, top5 75.29
2021-11-05 18:24:28 train 0000, loss 2.049e+00, top1 56.47, top5 80.00
2021-11-05 18:24:28 train 0000, loss 1.824e+00, top1 57.65, top5 77.65
2021-11-05 18:38:18 train 1000, loss 1.808e+00, top1 58.46, top5 80.63
2021-11-05 18:38:18 train 1000, loss 1.797e+00, top1 58.73, top5 80.78
2021-11-05 18:38:18 train 1000, loss 1.800e+00, top1 58.81, top5 80.79
2021-11-05 18:52:11 train 2000, loss 1.755e+00, top1 59.50, top5 81.41
2021-11-05 18:52:11 train 2000, loss 1.743e+00, top1 59.95, top5 81.50
2021-11-05 18:52:11 train 2000, loss 1.748e+00, top1 59.83, top5 81.49
2021-11-05 19:05:56 train 3000, loss 1.722e+00, top1 60.28, top5 81.89
2021-11-05 19:05:56 train 3000, loss 1.713e+00, top1 60.52, top5 81.97
2021-11-05 19:05:56 train 3000, loss 1.715e+00, top1 60.57, top5 81.96
2021-11-05 19:19:46 train 4000, loss 1.694e+00, top1 60.89, top5 82.24
2021-11-05 19:19:46 train 4000, loss 1.699e+00, top1 60.73, top5 82.22
2021-11-05 19:19:46 train 4000, loss 1.695e+00, top1 60.95, top5 82.21
2021-11-05 19:33:33 train 5000, loss 1.681e+00, top1 61.08, top5 82.46
2021-11-05 19:33:33 train 5000, loss 1.678e+00, top1 61.21, top5 82.46
2021-11-05 19:33:33 train 5000, loss 1.679e+00, top1 61.26, top5 82.45
2021-11-05 19:34:02 valid 0000, loss 6.417e-01, top1 84.71, top5 94.12
2021-11-05 19:34:02 valid 0000, loss 6.417e-01, top1 84.71, top5 94.12
2021-11-05 19:34:02 valid 0000, loss 6.417e-01, top1 84.71, top5 94.12
2021-11-05 19:38:34 (JOBID 31649) epoch 30: train time 4177.52, inference time 281.74s, valid_top1 67.64 (best_top1 67.64), valid_top5 88.28
2021-11-05 19:38:35 (JOBID 31649) epoch 30: train time 4178.54, inference time 282.23s, valid_top1 67.64 (best_top1 67.64), valid_top5 88.28
2021-11-05 19:38:38 (JOBID 31649) epoch 30: train time 4179.45, inference time 285.29s, valid_top1 67.64 (best_top1 67.64), valid_top5 88.28
2021-11-05 19:38:49 train 0000, loss 1.139e+00, top1 68.24, top5 90.59
2021-11-05 19:38:49 train 0000, loss 1.688e+00, top1 57.65, top5 81.18
2021-11-05 19:38:52 train 0000, loss 1.550e+00, top1 71.76, top5 85.88
2021-11-05 19:52:46 train 1000, loss 1.586e+00, top1 63.14, top5 83.76
2021-11-05 19:52:46 train 1000, loss 1.586e+00, top1 63.12, top5 83.68
2021-11-05 19:52:46 train 1000, loss 1.574e+00, top1 63.29, top5 83.84
2021-11-05 20:06:35 train 2000, loss 1.583e+00, top1 63.20, top5 83.76
2021-11-05 20:06:35 train 2000, loss 1.577e+00, top1 63.20, top5 83.85
2021-11-05 20:06:35 train 2000, loss 1.576e+00, top1 63.30, top5 83.85
2021-11-05 20:20:26 train 3000, loss 1.576e+00, top1 63.29, top5 83.83
2021-11-05 20:20:26 train 3000, loss 1.572e+00, top1 63.30, top5 83.89
2021-11-05 20:20:26 train 3000, loss 1.573e+00, top1 63.38, top5 83.87
2021-11-05 20:34:14 train 4000, loss 1.568e+00, top1 63.44, top5 83.97
2021-11-05 20:34:14 train 4000, loss 1.569e+00, top1 63.37, top5 83.95
2021-11-05 20:34:14 train 4000, loss 1.571e+00, top1 63.41, top5 83.91
2021-11-05 20:47:58 train 5000, loss 1.567e+00, top1 63.40, top5 83.98
2021-11-05 20:47:58 train 5000, loss 1.563e+00, top1 63.55, top5 84.05
2021-11-05 20:47:58 train 5000, loss 1.567e+00, top1 63.48, top5 83.97
2021-11-05 20:48:28 valid 0000, loss 6.265e-01, top1 84.71, top5 94.12
2021-11-05 20:48:28 valid 0000, loss 6.265e-01, top1 84.71, top5 94.12
2021-11-05 20:48:28 valid 0000, loss 6.265e-01, top1 84.71, top5 94.12
2021-11-05 20:52:41 (JOBID 31649) epoch 31: train time 4184.23, inference time 262.46s, valid_top1 68.92 (best_top1 68.92), valid_top5 89.08
2021-11-05 20:53:03 (JOBID 31649) epoch 31: train time 4180.69, inference time 284.26s, valid_top1 68.92 (best_top1 68.92), valid_top5 89.08
2021-11-05 20:53:04 (JOBID 31649) epoch 31: train time 4183.38, inference time 284.96s, valid_top1 68.92 (best_top1 68.92), valid_top5 89.08
2021-11-05 20:52:55 train 0000, loss 1.438e+00, top1 65.88, top5 84.71
2021-11-05 20:53:17 train 0000, loss 1.679e+00, top1 61.18, top5 81.18
2021-11-05 20:53:17 train 0000, loss 1.607e+00, top1 62.35, top5 85.88
2021-11-05 21:07:12 train 1000, loss 1.504e+00, top1 64.68, top5 84.87
2021-11-05 21:07:12 train 1000, loss 1.518e+00, top1 64.43, top5 84.70
2021-11-05 21:07:13 train 1000, loss 1.518e+00, top1 64.47, top5 84.67
2021-11-05 21:21:01 train 2000, loss 1.507e+00, top1 64.68, top5 84.74
2021-11-05 21:21:01 train 2000, loss 1.523e+00, top1 64.29, top5 84.64
2021-11-05 21:21:01 train 2000, loss 1.525e+00, top1 64.28, top5 84.57
2021-11-05 21:34:55 train 3000, loss 1.524e+00, top1 64.30, top5 84.64
2021-11-05 21:34:55 train 3000, loss 1.512e+00, top1 64.61, top5 84.68
2021-11-05 21:34:55 train 3000, loss 1.523e+00, top1 64.31, top5 84.63
2021-11-05 21:50:16 train 4000, loss 1.524e+00, top1 64.34, top5 84.62
2021-11-05 21:50:16 train 4000, loss 1.515e+00, top1 64.52, top5 84.65
2021-11-05 21:50:16 train 4000, loss 1.523e+00, top1 64.28, top5 84.63
2021-11-05 22:06:27 train 5000, loss 1.519e+00, top1 64.37, top5 84.68
2021-11-05 22:06:27 train 5000, loss 1.523e+00, top1 64.29, top5 84.64
2021-11-05 22:06:27 train 5000, loss 1.518e+00, top1 64.45, top5 84.62
2021-11-05 22:06:57 valid 0000, loss 5.793e-01, top1 87.06, top5 94.12
2021-11-05 22:06:57 valid 0000, loss 5.793e-01, top1 87.06, top5 94.12
2021-11-05 22:06:57 valid 0000, loss 5.793e-01, top1 87.06, top5 94.12
2021-11-05 22:11:07 (JOBID 31649) epoch 32: train time 4445.79, inference time 260.70s, valid_top1 68.95 (best_top1 68.95), valid_top5 89.24
2021-11-05 22:11:29 (JOBID 31649) epoch 32: train time 4424.00, inference time 282.20s, valid_top1 68.95 (best_top1 68.95), valid_top5 89.24
2021-11-05 22:11:36 (JOBID 31649) epoch 32: train time 4422.85, inference time 288.08s, valid_top1 68.95 (best_top1 68.95), valid_top5 89.24
2021-11-05 22:11:43 train 0000, loss 1.607e+00, top1 64.71, top5 83.53
2021-11-05 22:11:21 train 0000, loss 1.623e+00, top1 65.88, top5 82.35
2021-11-05 22:11:49 train 0000, loss 1.326e+00, top1 65.88, top5 88.24
2021-11-05 22:25:36 train 1000, loss 1.502e+00, top1 64.74, top5 84.89
2021-11-05 22:25:36 train 1000, loss 1.494e+00, top1 64.86, top5 85.04
2021-11-05 22:25:36 train 1000, loss 1.487e+00, top1 65.12, top5 85.26
2021-11-05 22:39:25 train 2000, loss 1.503e+00, top1 64.73, top5 84.89
2021-11-05 22:39:25 train 2000, loss 1.494e+00, top1 64.85, top5 85.05
2021-11-05 22:39:25 train 2000, loss 1.490e+00, top1 64.98, top5 85.15
2021-11-05 22:53:15 train 3000, loss 1.501e+00, top1 64.72, top5 84.93
2021-11-05 22:53:15 train 3000, loss 1.495e+00, top1 64.86, top5 85.02
2021-11-05 22:53:15 train 3000, loss 1.495e+00, top1 64.90, top5 85.06
2021-11-05 23:07:03 train 4000, loss 1.501e+00, top1 64.72, top5 84.93
2021-11-05 23:07:03 train 4000, loss 1.497e+00, top1 64.81, top5 84.99
2021-11-05 23:07:03 train 4000, loss 1.498e+00, top1 64.84, top5 85.00
2021-11-05 23:20:54 train 5000, loss 1.499e+00, top1 64.77, top5 84.93
2021-11-05 23:20:54 train 5000, loss 1.498e+00, top1 64.75, top5 84.96
2021-11-05 23:20:54 train 5000, loss 1.496e+00, top1 64.91, top5 85.03
2021-11-05 23:21:25 valid 0000, loss 4.648e-01, top1 91.76, top5 96.47
2021-11-05 23:21:25 valid 0000, loss 4.648e-01, top1 91.76, top5 96.47
2021-11-05 23:21:25 valid 0000, loss 4.648e-01, top1 91.76, top5 96.47
2021-11-05 23:25:54 (JOBID 31649) epoch 33: train time 4184.95, inference time 280.26s, valid_top1 69.24 (best_top1 69.24), valid_top5 89.17
2021-11-05 23:25:55 (JOBID 31649) epoch 33: train time 4206.52, inference time 281.39s, valid_top1 69.24 (best_top1 69.24), valid_top5 89.17
2021-11-05 23:25:56 (JOBID 31649) epoch 33: train time 4178.46, inference time 280.83s, valid_top1 69.24 (best_top1 69.24), valid_top5 89.17
2021-11-05 23:26:09 train 0000, loss 1.364e+00, top1 67.06, top5 85.88
2021-11-05 23:26:09 train 0000, loss 1.394e+00, top1 62.35, top5 88.24
2021-11-05 23:26:09 train 0000, loss 1.557e+00, top1 64.71, top5 87.06
2021-11-05 23:39:53 train 1000, loss 1.477e+00, top1 65.43, top5 85.20
2021-11-05 23:39:53 train 1000, loss 1.469e+00, top1 65.44, top5 85.40
2021-11-05 23:39:53 train 1000, loss 1.472e+00, top1 65.35, top5 85.31
2021-11-05 23:53:37 train 2000, loss 1.475e+00, top1 65.42, top5 85.31
2021-11-05 23:53:37 train 2000, loss 1.475e+00, top1 65.28, top5 85.26
2021-11-05 23:53:37 train 2000, loss 1.481e+00, top1 65.13, top5 85.14
2021-11-06 00:07:18 train 3000, loss 1.478e+00, top1 65.26, top5 85.25
2021-11-06 00:07:18 train 3000, loss 1.481e+00, top1 65.26, top5 85.22
2021-11-06 00:07:19 train 3000, loss 1.477e+00, top1 65.25, top5 85.21
2021-11-06 00:21:00 train 4000, loss 1.483e+00, top1 65.21, top5 85.17
2021-11-06 00:21:00 train 4000, loss 1.479e+00, top1 65.20, top5 85.27
2021-11-06 00:21:00 train 4000, loss 1.477e+00, top1 65.20, top5 85.19
2021-11-06 00:34:49 train 5000, loss 1.484e+00, top1 65.20, top5 85.15
2021-11-06 00:34:49 train 5000, loss 1.480e+00, top1 65.16, top5 85.25
2021-11-06 00:34:50 train 5000, loss 1.478e+00, top1 65.19, top5 85.19
2021-11-06 00:35:19 valid 0000, loss 5.572e-01, top1 87.06, top5 96.47
2021-11-06 00:35:19 valid 0000, loss 5.572e-01, top1 87.06, top5 96.47
2021-11-06 00:35:19 valid 0000, loss 5.572e-01, top1 87.06, top5 96.47
2021-11-06 00:39:49 (JOBID 31649) epoch 34: train time 4153.43, inference time 279.33s, valid_top1 69.35 (best_top1 69.35), valid_top5 89.40
2021-11-06 00:39:49 (JOBID 31649) epoch 34: train time 4153.68, inference time 280.16s, valid_top1 69.35 (best_top1 69.35), valid_top5 89.40
2021-11-06 00:39:50 (JOBID 31649) epoch 34: train time 4155.02, inference time 280.47s, valid_top1 69.35 (best_top1 69.35), valid_top5 89.40
2021-11-06 00:40:04 train 0000, loss 1.903e+00, top1 60.00, top5 76.47
2021-11-06 00:40:04 train 0000, loss 1.263e+00, top1 69.41, top5 88.24
2021-11-06 00:40:04 train 0000, loss 1.442e+00, top1 64.71, top5 88.24
2021-11-06 00:53:51 train 1000, loss 1.454e+00, top1 65.70, top5 85.54
2021-11-06 00:53:51 train 1000, loss 1.460e+00, top1 65.51, top5 85.62
2021-11-06 00:53:51 train 1000, loss 1.458e+00, top1 65.60, top5 85.49
2021-11-06 01:07:29 train 2000, loss 1.458e+00, top1 65.68, top5 85.47
2021-11-06 01:07:29 train 2000, loss 1.461e+00, top1 65.61, top5 85.45
2021-11-06 01:07:29 train 2000, loss 1.463e+00, top1 65.51, top5 85.54
2021-11-06 01:21:16 train 3000, loss 1.461e+00, top1 65.56, top5 85.47
2021-11-06 01:21:16 train 3000, loss 1.467e+00, top1 65.51, top5 85.39
2021-11-06 01:21:16 train 3000, loss 1.465e+00, top1 65.47, top5 85.49
2021-11-06 01:35:00 train 4000, loss 1.464e+00, top1 65.51, top5 85.45
2021-11-06 01:35:00 train 4000, loss 1.468e+00, top1 65.43, top5 85.39
2021-11-06 01:35:01 train 4000, loss 1.468e+00, top1 65.42, top5 85.43
2021-11-06 01:48:41 train 5000, loss 1.467e+00, top1 65.46, top5 85.39
2021-11-06 01:48:41 train 5000, loss 1.471e+00, top1 65.42, top5 85.32
2021-11-06 01:48:41 train 5000, loss 1.471e+00, top1 65.33, top5 85.40
2021-11-06 01:49:11 valid 0000, loss 5.789e-01, top1 89.41, top5 96.47
2021-11-06 01:49:11 valid 0000, loss 5.789e-01, top1 89.41, top5 96.47
2021-11-06 01:49:11 valid 0000, loss 5.789e-01, top1 89.41, top5 96.47
2021-11-06 01:53:41 (JOBID 31649) epoch 35: train time 4151.60, inference time 279.93s, valid_top1 69.64 (best_top1 69.64), valid_top5 89.57
2021-11-06 01:53:42 (JOBID 31649) epoch 35: train time 4152.00, inference time 280.17s, valid_top1 69.64 (best_top1 69.64), valid_top5 89.57
2021-11-06 01:53:43 (JOBID 31649) epoch 35: train time 4151.14, inference time 282.01s, valid_top1 69.64 (best_top1 69.64), valid_top5 89.57
2021-11-06 01:53:55 train 0000, loss 1.735e+00, top1 64.71, top5 83.53
2021-11-06 01:53:57 train 0000, loss 1.650e+00, top1 61.18, top5 80.00
2021-11-06 01:53:57 train 0000, loss 1.756e+00, top1 58.82, top5 80.00
2021-11-06 02:07:45 train 1000, loss 1.449e+00, top1 65.91, top5 85.69
2021-11-06 02:07:45 train 1000, loss 1.458e+00, top1 65.60, top5 85.54
2021-11-06 02:07:45 train 1000, loss 1.443e+00, top1 65.98, top5 85.77
2021-11-06 02:21:32 train 2000, loss 1.455e+00, top1 65.72, top5 85.49
2021-11-06 02:21:32 train 2000, loss 1.451e+00, top1 65.77, top5 85.67
2021-11-06 02:21:32 train 2000, loss 1.460e+00, top1 65.59, top5 85.53
2021-11-06 02:35:15 train 3000, loss 1.459e+00, top1 65.61, top5 85.47
2021-11-06 02:35:16 train 3000, loss 1.460e+00, top1 65.68, top5 85.50
2021-11-06 02:35:16 train 3000, loss 1.459e+00, top1 65.51, top5 85.59
2021-11-06 02:48:57 train 4000, loss 1.462e+00, top1 65.61, top5 85.46
2021-11-06 02:48:57 train 4000, loss 1.460e+00, top1 65.61, top5 85.43
2021-11-06 02:48:57 train 4000, loss 1.460e+00, top1 65.49, top5 85.57
2021-11-06 03:02:41 train 5000, loss 1.464e+00, top1 65.56, top5 85.42
2021-11-06 03:02:41 train 5000, loss 1.461e+00, top1 65.62, top5 85.43
2021-11-06 03:02:41 train 5000, loss 1.462e+00, top1 65.46, top5 85.54
2021-11-06 03:03:11 valid 0000, loss 5.050e-01, top1 90.59, top5 96.47
2021-11-06 03:03:11 valid 0000, loss 5.050e-01, top1 90.59, top5 96.47
2021-11-06 03:03:11 valid 0000, loss 5.050e-01, top1 90.59, top5 96.47
2021-11-06 03:07:55 (JOBID 31649) epoch 36: train time 4160.05, inference time 294.18s, valid_top1 69.66 (best_top1 69.66), valid_top5 89.57
2021-11-06 03:07:57 (JOBID 31649) epoch 36: train time 4159.09, inference time 295.12s, valid_top1 69.66 (best_top1 69.66), valid_top5 89.57
2021-11-06 03:07:57 (JOBID 31649) epoch 36: train time 4157.98, inference time 296.38s, valid_top1 69.66 (best_top1 69.66), valid_top5 89.57
2021-11-06 03:08:10 train 0000, loss 1.321e+00, top1 68.24, top5 89.41
2021-11-06 03:08:11 train 0000, loss 1.467e+00, top1 68.24, top5 88.24
2021-11-06 03:08:11 train 0000, loss 1.130e+00, top1 70.59, top5 88.24
2021-11-06 03:22:02 train 1000, loss 1.444e+00, top1 65.79, top5 85.75
2021-11-06 03:22:02 train 1000, loss 1.447e+00, top1 65.73, top5 85.81
2021-11-06 03:22:02 train 1000, loss 1.452e+00, top1 65.92, top5 85.65
2021-11-06 03:35:56 train 2000, loss 1.453e+00, top1 65.63, top5 85.61
2021-11-06 03:35:56 train 2000, loss 1.456e+00, top1 65.65, top5 85.61
2021-11-06 03:35:56 train 2000, loss 1.448e+00, top1 65.93, top5 85.60
2021-11-06 03:49:48 train 3000, loss 1.462e+00, top1 65.53, top5 85.49
2021-11-06 03:49:48 train 3000, loss 1.460e+00, top1 65.47, top5 85.54
2021-11-06 03:49:48 train 3000, loss 1.453e+00, top1 65.79, top5 85.54
2021-11-06 04:03:45 train 4000, loss 1.460e+00, top1 65.53, top5 85.50
2021-11-06 04:03:45 train 4000, loss 1.464e+00, top1 65.52, top5 85.45
2021-11-06 04:03:45 train 4000, loss 1.456e+00, top1 65.71, top5 85.51
2021-11-06 04:17:28 train 5000, loss 1.463e+00, top1 65.51, top5 85.46
2021-11-06 04:17:28 train 5000, loss 1.464e+00, top1 65.54, top5 85.43
2021-11-06 04:17:28 train 5000, loss 1.459e+00, top1 65.67, top5 85.47
2021-11-06 04:18:00 valid 0000, loss 7.112e-01, top1 84.71, top5 92.94
2021-11-06 04:18:00 valid 0000, loss 7.112e-01, top1 84.71, top5 92.94
2021-11-06 04:18:00 valid 0000, loss 7.112e-01, top1 84.71, top5 92.94
2021-11-06 04:22:04 (JOBID 31649) epoch 37: train time 4191.77, inference time 255.00s, valid_top1 69.24 (best_top1 69.66), valid_top5 89.29
2021-11-06 04:22:42 (JOBID 31649) epoch 37: train time 4191.48, inference time 293.46s, valid_top1 69.24 (best_top1 69.66), valid_top5 89.29
2021-11-06 04:22:43 (JOBID 31649) epoch 37: train time 4193.53, inference time 294.20s, valid_top1 69.24 (best_top1 69.66), valid_top5 89.29
2021-11-06 04:22:18 train 0000, loss 1.723e+00, top1 58.82, top5 87.06
2021-11-06 04:22:56 train 0000, loss 1.319e+00, top1 74.12, top5 89.41
2021-11-06 04:22:56 train 0000, loss 1.914e+00, top1 57.65, top5 77.65
2021-11-06 04:36:42 train 1000, loss 1.440e+00, top1 65.97, top5 85.73
2021-11-06 04:36:42 train 1000, loss 1.450e+00, top1 65.89, top5 85.59
2021-11-06 04:36:42 train 1000, loss 1.447e+00, top1 65.89, top5 85.66
2021-11-06 04:50:32 train 2000, loss 1.450e+00, top1 65.71, top5 85.67
2021-11-06 04:50:32 train 2000, loss 1.452e+00, top1 65.86, top5 85.54
2021-11-06 04:50:32 train 2000, loss 1.450e+00, top1 65.90, top5 85.61
2021-11-06 05:04:24 train 3000, loss 1.454e+00, top1 65.68, top5 85.59
2021-11-06 05:04:24 train 3000, loss 1.456e+00, top1 65.77, top5 85.49
2021-11-06 05:04:24 train 3000, loss 1.461e+00, top1 65.70, top5 85.45
2021-11-06 05:18:11 train 4000, loss 1.457e+00, top1 65.62, top5 85.55
2021-11-06 05:18:11 train 4000, loss 1.460e+00, top1 65.62, top5 85.46
2021-11-06 05:18:11 train 4000, loss 1.465e+00, top1 65.61, top5 85.39
2021-11-06 05:32:04 train 5000, loss 1.460e+00, top1 65.59, top5 85.47
2021-11-06 05:32:04 train 5000, loss 1.459e+00, top1 65.58, top5 85.54
2021-11-06 05:32:05 train 5000, loss 1.467e+00, top1 65.56, top5 85.38
2021-11-06 05:32:35 valid 0000, loss 5.047e-01, top1 89.41, top5 95.29
2021-11-06 05:32:35 valid 0000, loss 5.047e-01, top1 89.41, top5 95.29
2021-11-06 05:32:35 valid 0000, loss 5.047e-01, top1 89.41, top5 95.29
2021-11-06 05:36:52 (JOBID 31649) epoch 38: train time 4220.72, inference time 266.98s, valid_top1 69.38 (best_top1 69.66), valid_top5 89.31
2021-11-06 05:37:04 (JOBID 31649) epoch 38: train time 4181.73, inference time 280.13s, valid_top1 69.38 (best_top1 69.66), valid_top5 89.31
2021-11-06 05:37:09 (JOBID 31649) epoch 38: train time 4182.31, inference time 284.72s, valid_top1 69.38 (best_top1 69.66), valid_top5 89.31
2021-11-06 05:37:19 train 0000, loss 1.447e+00, top1 67.06, top5 85.88
2021-11-06 05:37:06 train 0000, loss 1.101e+00, top1 74.12, top5 85.88
2021-11-06 05:37:23 train 0000, loss 1.599e+00, top1 69.41, top5 82.35
2021-11-06 05:51:05 train 1000, loss 1.444e+00, top1 66.07, top5 85.86
2021-11-06 05:51:05 train 1000, loss 1.446e+00, top1 65.79, top5 85.55
2021-11-06 05:51:06 train 1000, loss 1.443e+00, top1 65.95, top5 85.74
2021-11-06 06:04:42 train 2000, loss 1.450e+00, top1 65.75, top5 85.64
2021-11-06 06:04:42 train 2000, loss 1.450e+00, top1 65.78, top5 85.75
2021-11-06 06:04:43 train 2000, loss 1.451e+00, top1 65.83, top5 85.57
2021-11-06 06:18:23 train 3000, loss 1.453e+00, top1 65.75, top5 85.67
2021-11-06 06:18:23 train 3000, loss 1.452e+00, top1 65.72, top5 85.64
2021-11-06 06:18:23 train 3000, loss 1.455e+00, top1 65.72, top5 85.54
2021-11-06 06:32:06 train 4000, loss 1.457e+00, top1 65.58, top5 85.55
2021-11-06 06:32:06 train 4000, loss 1.457e+00, top1 65.62, top5 85.50
2021-11-06 06:32:06 train 4000, loss 1.456e+00, top1 65.67, top5 85.66
2021-11-06 06:45:43 train 5000, loss 1.461e+00, top1 65.57, top5 85.47
2021-11-06 06:45:43 train 5000, loss 1.458e+00, top1 65.57, top5 85.63
2021-11-06 06:45:43 train 5000, loss 1.459e+00, top1 65.55, top5 85.52
2021-11-06 06:46:13 valid 0000, loss 4.007e-01, top1 91.76, top5 97.65
2021-11-06 06:46:13 valid 0000, loss 4.007e-01, top1 91.76, top5 97.65
2021-11-06 06:46:13 valid 0000, loss 4.007e-01, top1 91.76, top5 97.65
2021-11-06 06:50:50 (JOBID 31649) epoch 39: train time 4137.99, inference time 287.10s, valid_top1 68.51 (best_top1 69.66), valid_top5 89.01
2021-11-06 06:50:50 (JOBID 31649) epoch 39: train time 4133.35, inference time 287.15s, valid_top1 68.51 (best_top1 69.66), valid_top5 89.01
2021-11-06 06:50:50 (JOBID 31649) epoch 39: train time 4150.77, inference time 287.10s, valid_top1 68.51 (best_top1 69.66), valid_top5 89.01
2021-11-06 06:51:05 train 0000, loss 1.479e+00, top1 69.41, top5 85.88
2021-11-06 06:51:05 train 0000, loss 1.835e+00, top1 58.82, top5 78.82
2021-11-06 06:51:05 train 0000, loss 1.447e+00, top1 68.24, top5 82.35
2021-11-06 07:04:53 train 1000, loss 1.439e+00, top1 65.98, top5 85.88
2021-11-06 07:04:53 train 1000, loss 1.437e+00, top1 65.97, top5 85.90
2021-11-06 07:04:53 train 1000, loss 1.436e+00, top1 65.88, top5 85.80
2021-11-06 07:18:44 train 2000, loss 1.447e+00, top1 65.77, top5 85.73
2021-11-06 07:18:45 train 2000, loss 1.444e+00, top1 65.91, top5 85.78
2021-11-06 07:18:45 train 2000, loss 1.446e+00, top1 65.82, top5 85.58
2021-11-06 07:32:26 train 3000, loss 1.455e+00, top1 65.69, top5 85.63
2021-11-06 07:32:26 train 3000, loss 1.452e+00, top1 65.65, top5 85.65
2021-11-06 07:32:26 train 3000, loss 1.449e+00, top1 65.74, top5 85.55
2021-11-06 07:46:10 train 4000, loss 1.458e+00, top1 65.59, top5 85.52
2021-11-06 07:46:10 train 4000, loss 1.460e+00, top1 65.59, top5 85.52
2021-11-06 07:46:10 train 4000, loss 1.454e+00, top1 65.65, top5 85.52
2021-11-06 07:59:57 train 5000, loss 1.464e+00, top1 65.55, top5 85.45
2021-11-06 07:59:57 train 5000, loss 1.463e+00, top1 65.49, top5 85.47
2021-11-06 07:59:57 train 5000, loss 1.460e+00, top1 65.53, top5 85.46
2021-11-06 08:00:27 valid 0000, loss 6.237e-01, top1 85.88, top5 95.29
2021-11-06 08:00:27 valid 0000, loss 6.237e-01, top1 85.88, top5 95.29
2021-11-06 08:00:27 valid 0000, loss 6.237e-01, top1 85.88, top5 95.29
2021-11-06 08:05:05 (JOBID 31649) epoch 40: train time 4167.18, inference time 288.53s, valid_top1 68.82 (best_top1 69.66), valid_top5 89.01
2021-11-06 08:05:19 (JOBID 31649) epoch 40: train time 4167.01, inference time 301.39s, valid_top1 68.82 (best_top1 69.66), valid_top5 89.01
2021-11-06 08:05:21 (JOBID 31649) epoch 40: train time 4167.18, inference time 303.94s, valid_top1 68.82 (best_top1 69.66), valid_top5 89.01
2021-11-06 08:05:33 train 0000, loss 1.080e+00, top1 76.47, top5 91.76
2021-11-06 08:05:19 train 0000, loss 1.675e+00, top1 62.35, top5 88.24
2021-11-06 08:05:35 train 0000, loss 1.515e+00, top1 60.00, top5 85.88
2021-11-06 08:19:28 train 1000, loss 1.438e+00, top1 65.96, top5 85.74
2021-11-06 08:19:28 train 1000, loss 1.448e+00, top1 65.94, top5 85.56
2021-11-06 08:19:29 train 1000, loss 1.446e+00, top1 65.70, top5 85.69
2021-11-06 08:33:12 train 2000, loss 1.450e+00, top1 65.69, top5 85.64
2021-11-06 08:33:12 train 2000, loss 1.445e+00, top1 65.87, top5 85.67
2021-11-06 08:33:12 train 2000, loss 1.451e+00, top1 65.72, top5 85.67
2021-11-06 08:46:59 train 3000, loss 1.449e+00, top1 65.72, top5 85.65
2021-11-06 08:46:59 train 3000, loss 1.452e+00, top1 65.69, top5 85.63
2021-11-06 08:46:59 train 3000, loss 1.459e+00, top1 65.57, top5 85.58
2021-11-06 09:01:01 train 4000, loss 1.456e+00, top1 65.58, top5 85.54
2021-11-06 09:01:01 train 4000, loss 1.455e+00, top1 65.62, top5 85.55
2021-11-06 09:01:01 train 4000, loss 1.464e+00, top1 65.46, top5 85.49
2021-11-06 09:14:43 train 5000, loss 1.460e+00, top1 65.50, top5 85.49
2021-11-06 09:14:43 train 5000, loss 1.461e+00, top1 65.47, top5 85.47
2021-11-06 09:14:43 train 5000, loss 1.466e+00, top1 65.41, top5 85.44
2021-11-06 09:15:13 valid 0000, loss 4.921e-01, top1 87.06, top5 97.65
2021-11-06 09:15:13 valid 0000, loss 4.921e-01, top1 87.06, top5 97.65
2021-11-06 09:15:13 valid 0000, loss 4.921e-01, top1 87.06, top5 97.65
2021-11-06 09:19:34 (JOBID 31649) epoch 41: train time 4184.50, inference time 270.96s, valid_top1 69.13 (best_top1 69.66), valid_top5 89.15
2021-11-06 09:19:42 (JOBID 31649) epoch 41: train time 4197.67, inference time 279.07s, valid_top1 69.13 (best_top1 69.66), valid_top5 89.15
2021-11-06 09:19:43 (JOBID 31649) epoch 41: train time 4182.26, inference time 280.26s, valid_top1 69.13 (best_top1 69.66), valid_top5 89.15
2021-11-06 09:19:56 train 0000, loss 1.354e+00, top1 69.41, top5 88.24
2021-11-06 09:19:49 train 0000, loss 1.500e+00, top1 61.18, top5 82.35
2021-11-06 09:19:58 train 0000, loss 1.423e+00, top1 67.06, top5 88.24
2021-11-06 09:33:47 train 1000, loss 1.454e+00, top1 65.86, top5 85.52
2021-11-06 09:33:47 train 1000, loss 1.436e+00, top1 65.93, top5 85.78
2021-11-06 09:33:47 train 1000, loss 1.444e+00, top1 65.70, top5 85.82
2021-11-06 09:47:40 train 2000, loss 1.454e+00, top1 65.77, top5 85.61
2021-11-06 09:47:40 train 2000, loss 1.451e+00, top1 65.67, top5 85.65
2021-11-06 09:47:40 train 2000, loss 1.447e+00, top1 65.74, top5 85.70
2021-11-06 10:01:30 train 3000, loss 1.455e+00, top1 65.66, top5 85.63
2021-11-06 10:01:30 train 3000, loss 1.462e+00, top1 65.62, top5 85.48
2021-11-06 10:01:30 train 3000, loss 1.450e+00, top1 65.68, top5 85.68
2021-11-06 10:15:18 train 4000, loss 1.466e+00, top1 65.49, top5 85.46
2021-11-06 10:15:18 train 4000, loss 1.457e+00, top1 65.61, top5 85.59
2021-11-06 10:15:18 train 4000, loss 1.457e+00, top1 65.55, top5 85.61
2021-11-06 10:29:16 train 5000, loss 1.461e+00, top1 65.52, top5 85.51
2021-11-06 10:29:16 train 5000, loss 1.467e+00, top1 65.43, top5 85.46
2021-11-06 10:29:17 train 5000, loss 1.462e+00, top1 65.47, top5 85.53
2021-11-06 10:29:46 valid 0000, loss 4.489e-01, top1 89.41, top5 95.29
2021-11-06 10:29:46 valid 0000, loss 4.489e-01, top1 89.41, top5 95.29
2021-11-06 10:29:46 valid 0000, loss 4.489e-01, top1 89.41, top5 95.29
2021-11-06 10:34:06 (JOBID 31649) epoch 42: train time 4193.30, inference time 269.25s, valid_top1 68.17 (best_top1 69.66), valid_top5 88.59
2021-11-06 10:34:15 (JOBID 31649) epoch 42: train time 4194.31, inference time 278.98s, valid_top1 68.17 (best_top1 69.66), valid_top5 88.59
2021-11-06 10:34:18 (JOBID 31649) epoch 42: train time 4201.99, inference time 281.85s, valid_top1 68.17 (best_top1 69.66), valid_top5 88.59
2021-11-06 10:34:30 train 0000, loss 1.329e+00, top1 69.41, top5 87.06
2021-11-06 10:34:20 train 0000, loss 1.390e+00, top1 61.18, top5 88.24
2021-11-06 10:34:33 train 0000, loss 1.165e+00, top1 74.12, top5 85.88
2021-11-06 10:48:24 train 1000, loss 1.456e+00, top1 65.87, top5 85.53
2021-11-06 10:48:24 train 1000, loss 1.446e+00, top1 65.70, top5 85.74
2021-11-06 10:48:24 train 1000, loss 1.445e+00, top1 65.85, top5 85.66
2021-11-06 11:02:13 train 2000, loss 1.457e+00, top1 65.75, top5 85.52
2021-11-06 11:02:13 train 2000, loss 1.452e+00, top1 65.66, top5 85.59
2021-11-06 11:02:14 train 2000, loss 1.458e+00, top1 65.57, top5 85.46
2021-11-06 11:16:07 train 3000, loss 1.454e+00, top1 65.62, top5 85.58
2021-11-06 11:16:07 train 3000, loss 1.459e+00, top1 65.70, top5 85.51
2021-11-06 11:16:07 train 3000, loss 1.464e+00, top1 65.43, top5 85.46
2021-11-06 11:29:59 train 4000, loss 1.461e+00, top1 65.64, top5 85.50
2021-11-06 11:29:59 train 4000, loss 1.461e+00, top1 65.50, top5 85.49
2021-11-06 11:29:59 train 4000, loss 1.467e+00, top1 65.34, top5 85.43
2021-11-06 11:44:02 train 5000, loss 1.465e+00, top1 65.52, top5 85.44
2021-11-06 11:44:02 train 5000, loss 1.463e+00, top1 65.46, top5 85.47
2021-11-06 11:44:02 train 5000, loss 1.470e+00, top1 65.28, top5 85.38
2021-11-06 11:44:33 valid 0000, loss 3.814e-01, top1 91.76, top5 97.65
2021-11-06 11:44:33 valid 0000, loss 3.814e-01, top1 91.76, top5 97.65
2021-11-06 11:44:33 valid 0000, loss 3.814e-01, top1 91.76, top5 97.65
2021-11-06 11:48:47 (JOBID 31649) epoch 43: train time 4216.50, inference time 265.07s, valid_top1 68.56 (best_top1 69.66), valid_top5 88.85
2021-11-06 11:49:06 (JOBID 31649) epoch 43: train time 4204.05, inference time 283.28s, valid_top1 68.56 (best_top1 69.66), valid_top5 88.85
2021-11-06 11:49:08 (JOBID 31649) epoch 43: train time 4206.95, inference time 285.74s, valid_top1 68.56 (best_top1 69.66), valid_top5 88.85
2021-11-06 11:49:01 train 0000, loss 1.296e+00, top1 75.29, top5 89.41
2021-11-06 11:49:21 train 0000, loss 1.785e+00, top1 56.47, top5 80.00
2021-11-06 11:49:23 train 0000, loss 1.577e+00, top1 60.00, top5 87.06
2021-11-06 12:03:36 train 1000, loss 1.453e+00, top1 65.68, top5 85.71
2021-11-06 12:03:36 train 1000, loss 1.444e+00, top1 65.92, top5 85.84
2021-11-06 12:03:36 train 1000, loss 1.464e+00, top1 65.71, top5 85.32
2021-11-06 12:17:40 train 2000, loss 1.460e+00, top1 65.56, top5 85.54
2021-11-06 12:17:40 train 2000, loss 1.456e+00, top1 65.76, top5 85.61
2021-11-06 12:17:40 train 2000, loss 1.463e+00, top1 65.71, top5 85.37
2021-11-06 12:31:46 train 3000, loss 1.457e+00, top1 65.68, top5 85.64
2021-11-06 12:31:46 train 3000, loss 1.461e+00, top1 65.55, top5 85.52
2021-11-06 12:31:46 train 3000, loss 1.464e+00, top1 65.65, top5 85.40
2021-11-06 12:45:46 train 4000, loss 1.460e+00, top1 65.61, top5 85.59
2021-11-06 12:45:46 train 4000, loss 1.468e+00, top1 65.50, top5 85.37
2021-11-06 12:45:46 train 4000, loss 1.464e+00, top1 65.49, top5 85.50
2021-11-06 13:00:09 train 5000, loss 1.465e+00, top1 65.49, top5 85.51
2021-11-06 13:00:09 train 5000, loss 1.471e+00, top1 65.44, top5 85.35
2021-11-06 13:00:09 train 5000, loss 1.466e+00, top1 65.45, top5 85.46
2021-11-06 13:00:40 valid 0000, loss 4.824e-01, top1 89.41, top5 95.29
2021-11-06 13:00:40 valid 0000, loss 4.824e-01, top1 89.41, top5 95.29
2021-11-06 13:00:40 valid 0000, loss 4.824e-01, top1 89.41, top5 95.29
2021-11-06 13:05:12 (JOBID 31649) epoch 44: train time 4281.53, inference time 282.40s, valid_top1 68.91 (best_top1 69.66), valid_top5 89.27
2021-11-06 13:05:14 (JOBID 31649) epoch 44: train time 4302.20, inference time 284.29s, valid_top1 68.91 (best_top1 69.66), valid_top5 89.27
2021-11-06 13:05:14 (JOBID 31649) epoch 44: train time 4283.93, inference time 283.89s, valid_top1 68.91 (best_top1 69.66), valid_top5 89.27
2021-11-06 13:05:33 train 0000, loss 1.473e+00, top1 72.94, top5 83.53
2021-11-06 13:05:33 train 0000, loss 1.595e+00, top1 61.18, top5 87.06
2021-11-06 13:05:33 train 0000, loss 1.475e+00, top1 63.53, top5 83.53
2021-11-06 13:19:45 train 1000, loss 1.449e+00, top1 65.73, top5 85.67
2021-11-06 13:19:45 train 1000, loss 1.444e+00, top1 65.97, top5 85.72
2021-11-06 13:19:46 train 1000, loss 1.445e+00, top1 65.84, top5 85.78
2021-11-06 13:33:40 train 2000, loss 1.457e+00, top1 65.58, top5 85.55
2021-11-06 13:33:40 train 2000, loss 1.456e+00, top1 65.72, top5 85.56
2021-11-06 13:33:41 train 2000, loss 1.444e+00, top1 65.78, top5 85.77
2021-11-06 13:47:55 train 3000, loss 1.462e+00, top1 65.50, top5 85.54
2021-11-06 13:47:55 train 3000, loss 1.461e+00, top1 65.61, top5 85.47
2021-11-06 13:47:55 train 3000, loss 1.454e+00, top1 65.62, top5 85.60
2021-11-06 14:01:56 train 4000, loss 1.465e+00, top1 65.42, top5 85.50
2021-11-06 14:01:56 train 4000, loss 1.466e+00, top1 65.50, top5 85.40
2021-11-06 14:01:56 train 4000, loss 1.463e+00, top1 65.43, top5 85.49
2021-11-06 14:15:57 train 5000, loss 1.468e+00, top1 65.37, top5 85.43
2021-11-06 14:15:57 train 5000, loss 1.470e+00, top1 65.41, top5 85.34
2021-11-06 14:15:57 train 5000, loss 1.470e+00, top1 65.31, top5 85.38
2021-11-06 14:16:27 valid 0000, loss 3.797e-01, top1 91.76, top5 97.65
2021-11-06 14:16:27 valid 0000, loss 3.797e-01, top1 91.76, top5 97.65
2021-11-06 14:16:27 valid 0000, loss 3.797e-01, top1 91.76, top5 97.65
2021-11-06 14:21:16 (JOBID 31649) epoch 45: train time 4264.77, inference time 299.37s, valid_top1 68.42 (best_top1 69.66), valid_top5 88.88
2021-11-06 14:21:16 (JOBID 31649) epoch 45: train time 4262.88, inference time 299.38s, valid_top1 68.42 (best_top1 69.66), valid_top5 88.88
2021-11-06 14:21:16 (JOBID 31649) epoch 45: train time 4263.02, inference time 299.10s, valid_top1 68.42 (best_top1 69.66), valid_top5 88.88
2021-11-06 14:21:31 train 0000, loss 1.510e+00, top1 65.88, top5 87.06
2021-11-06 14:21:31 train 0000, loss 1.136e+00, top1 75.29, top5 90.59
2021-11-06 14:21:31 train 0000, loss 1.270e+00, top1 74.12, top5 84.71
2021-11-06 14:35:37 train 1000, loss 1.440e+00, top1 65.96, top5 85.84
2021-11-06 14:35:37 train 1000, loss 1.460e+00, top1 65.68, top5 85.54
2021-11-06 14:35:37 train 1000, loss 1.440e+00, top1 65.99, top5 85.78
2021-11-06 14:49:36 train 2000, loss 1.468e+00, top1 65.46, top5 85.38
2021-11-06 14:49:36 train 2000, loss 1.448e+00, top1 65.85, top5 85.73
2021-11-06 14:49:36 train 2000, loss 1.459e+00, top1 65.59, top5 85.56
2021-11-06 15:03:35 train 3000, loss 1.469e+00, top1 65.40, top5 85.40
2021-11-06 15:03:35 train 3000, loss 1.459e+00, top1 65.59, top5 85.58
2021-11-06 15:03:36 train 3000, loss 1.453e+00, top1 65.73, top5 85.69
2021-11-06 15:17:39 train 4000, loss 1.464e+00, top1 65.46, top5 85.51
2021-11-06 15:17:39 train 4000, loss 1.470e+00, top1 65.38, top5 85.40
2021-11-06 15:17:39 train 4000, loss 1.458e+00, top1 65.59, top5 85.58
2021-11-06 15:31:46 train 5000, loss 1.473e+00, top1 65.29, top5 85.35
2021-11-06 15:31:46 train 5000, loss 1.467e+00, top1 65.39, top5 85.45
2021-11-06 15:31:47 train 5000, loss 1.465e+00, top1 65.41, top5 85.49
2021-11-06 15:32:17 valid 0000, loss 5.239e-01, top1 90.59, top5 96.47
2021-11-06 15:32:17 valid 0000, loss 5.239e-01, top1 90.59, top5 96.47
2021-11-06 15:32:17 valid 0000, loss 5.239e-01, top1 90.59, top5 96.47
2021-11-06 15:36:37 (JOBID 31649) epoch 46: train time 4250.08, inference time 270.14s, valid_top1 68.83 (best_top1 69.66), valid_top5 89.15
2021-11-06 15:36:49 (JOBID 31649) epoch 46: train time 4250.32, inference time 282.71s, valid_top1 68.83 (best_top1 69.66), valid_top5 89.15
2021-11-06 15:36:51 (JOBID 31649) epoch 46: train time 4250.31, inference time 284.25s, valid_top1 68.83 (best_top1 69.66), valid_top5 89.15
2021-11-06 15:37:05 train 0000, loss 1.459e+00, top1 62.35, top5 87.06
2021-11-06 15:36:51 train 0000, loss 1.387e+00, top1 65.88, top5 85.88
2021-11-06 15:37:05 train 0000, loss 1.364e+00, top1 65.88, top5 89.41
2021-11-06 15:51:09 train 1000, loss 1.442e+00, top1 65.92, top5 85.72
2021-11-06 15:51:09 train 1000, loss 1.446e+00, top1 65.99, top5 85.67
2021-11-06 15:51:10 train 1000, loss 1.456e+00, top1 65.67, top5 85.53
2021-11-06 16:04:58 train 2000, loss 1.449e+00, top1 65.82, top5 85.70
2021-11-06 16:04:58 train 2000, loss 1.457e+00, top1 65.72, top5 85.54
2021-11-06 16:04:58 train 2000, loss 1.461e+00, top1 65.49, top5 85.55
2021-11-06 16:18:43 train 3000, loss 1.456e+00, top1 65.67, top5 85.62
2021-11-06 16:18:43 train 3000, loss 1.462e+00, top1 65.53, top5 85.47
2021-11-06 16:18:43 train 3000, loss 1.467e+00, top1 65.36, top5 85.46
2021-11-06 16:32:24 train 4000, loss 1.467e+00, top1 65.40, top5 85.44
2021-11-06 16:32:24 train 4000, loss 1.460e+00, top1 65.58, top5 85.54
2021-11-06 16:32:25 train 4000, loss 1.467e+00, top1 65.41, top5 85.41
2021-11-06 16:46:14 train 5000, loss 1.465e+00, top1 65.46, top5 85.44
2021-11-06 16:46:14 train 5000, loss 1.468e+00, top1 65.35, top5 85.40
2021-11-06 16:46:14 train 5000, loss 1.472e+00, top1 65.30, top5 85.36
2021-11-06 16:46:44 valid 0000, loss 4.922e-01, top1 87.06, top5 97.65
2021-11-06 16:46:44 valid 0000, loss 4.922e-01, top1 87.06, top5 97.65
2021-11-06 16:46:44 valid 0000, loss 4.922e-01, top1 87.06, top5 97.65
2021-11-06 16:51:03 (JOBID 31649) epoch 47: train time 4197.11, inference time 268.79s, valid_top1 68.82 (best_top1 69.66), valid_top5 89.15
2021-11-06 16:51:19 (JOBID 31649) epoch 47: train time 4184.72, inference time 284.75s, valid_top1 68.82 (best_top1 69.66), valid_top5 89.15
2021-11-06 16:51:19 (JOBID 31649) epoch 47: train time 4183.18, inference time 285.46s, valid_top1 68.82 (best_top1 69.66), valid_top5 89.15
2021-11-06 16:51:17 train 0000, loss 1.741e+00, top1 56.47, top5 82.35
2021-11-06 16:51:34 train 0000, loss 1.807e+00, top1 57.65, top5 80.00
2021-11-06 16:51:34 train 0000, loss 1.019e+00, top1 72.94, top5 92.94
2021-11-06 17:05:22 train 1000, loss 1.455e+00, top1 65.54, top5 85.62
2021-11-06 17:05:22 train 1000, loss 1.449e+00, top1 65.85, top5 85.55
2021-11-06 17:05:22 train 1000, loss 1.447e+00, top1 65.76, top5 85.73
2021-11-06 17:19:03 train 2000, loss 1.464e+00, top1 65.36, top5 85.48
2021-11-06 17:19:03 train 2000, loss 1.459e+00, top1 65.52, top5 85.46
2021-11-06 17:19:04 train 2000, loss 1.456e+00, top1 65.58, top5 85.55
2021-11-06 17:32:48 train 3000, loss 1.466e+00, top1 65.34, top5 85.49
2021-11-06 17:32:48 train 3000, loss 1.463e+00, top1 65.47, top5 85.41
2021-11-06 17:32:48 train 3000, loss 1.467e+00, top1 65.36, top5 85.41
2021-11-06 17:46:38 train 4000, loss 1.468e+00, top1 65.34, top5 85.41
2021-11-06 17:46:38 train 4000, loss 1.464e+00, top1 65.44, top5 85.40
2021-11-06 17:46:38 train 4000, loss 1.469e+00, top1 65.31, top5 85.39
2021-11-06 18:00:26 train 5000, loss 1.471e+00, top1 65.26, top5 85.36
2021-11-06 18:00:26 train 5000, loss 1.468e+00, top1 65.35, top5 85.33
2021-11-06 18:00:26 train 5000, loss 1.470e+00, top1 65.26, top5 85.41
2021-11-06 18:00:56 valid 0000, loss 3.735e-01, top1 92.94, top5 97.65
2021-11-06 18:00:56 valid 0000, loss 3.735e-01, top1 92.94, top5 97.65
2021-11-06 18:00:56 valid 0000, loss 3.735e-01, top1 92.94, top5 97.65
2021-11-06 18:05:28 (JOBID 31649) epoch 48: train time 4166.95, inference time 282.72s, valid_top1 68.73 (best_top1 69.66), valid_top5 88.85
2021-11-06 18:05:29 (JOBID 31649) epoch 48: train time 4182.91, inference time 283.07s, valid_top1 68.73 (best_top1 69.66), valid_top5 88.85
2021-11-06 18:05:30 (JOBID 31649) epoch 48: train time 4166.24, inference time 284.82s, valid_top1 68.73 (best_top1 69.66), valid_top5 88.85
2021-11-06 18:05:44 train 0000, loss 1.551e+00, top1 65.88, top5 88.24
2021-11-06 18:05:44 train 0000, loss 1.478e+00, top1 62.35, top5 87.06
2021-11-06 18:05:46 train 0000, loss 1.227e+00, top1 68.24, top5 83.53
2021-11-06 18:19:28 train 1000, loss 1.457e+00, top1 65.48, top5 85.52
2021-11-06 18:19:28 train 1000, loss 1.437e+00, top1 66.21, top5 85.82
2021-11-06 18:19:28 train 1000, loss 1.448e+00, top1 65.83, top5 85.80
2021-11-06 18:33:13 train 2000, loss 1.451e+00, top1 65.83, top5 85.65
2021-11-06 18:33:13 train 2000, loss 1.465e+00, top1 65.24, top5 85.44
2021-11-06 18:33:14 train 2000, loss 1.453e+00, top1 65.67, top5 85.71
2021-11-06 18:46:59 train 3000, loss 1.461e+00, top1 65.55, top5 85.53
2021-11-06 18:46:59 train 3000, loss 1.467e+00, top1 65.25, top5 85.41
2021-11-06 18:46:59 train 3000, loss 1.460e+00, top1 65.46, top5 85.60
2021-11-06 19:00:43 train 4000, loss 1.470e+00, top1 65.44, top5 85.39
2021-11-06 19:00:43 train 4000, loss 1.469e+00, top1 65.22, top5 85.38
2021-11-06 19:00:43 train 4000, loss 1.464e+00, top1 65.40, top5 85.50
2021-11-06 19:14:26 train 5000, loss 1.473e+00, top1 65.17, top5 85.36
2021-11-06 19:14:26 train 5000, loss 1.473e+00, top1 65.33, top5 85.34
2021-11-06 19:14:27 train 5000, loss 1.466e+00, top1 65.38, top5 85.49
2021-11-06 19:14:56 valid 0000, loss 6.958e-01, top1 84.71, top5 90.59
2021-11-06 19:14:56 valid 0000, loss 6.958e-01, top1 84.71, top5 90.59
2021-11-06 19:14:56 valid 0000, loss 6.958e-01, top1 84.71, top5 90.59
2021-11-06 19:19:27 (JOBID 31649) epoch 49: train time 4157.13, inference time 280.49s, valid_top1 68.70 (best_top1 69.66), valid_top5 88.94
2021-11-06 19:19:28 (JOBID 31649) epoch 49: train time 4157.84, inference time 281.87s, valid_top1 68.70 (best_top1 69.66), valid_top5 88.94
2021-11-06 19:19:28 (JOBID 31649) epoch 49: train time 4155.75, inference time 282.07s, valid_top1 68.70 (best_top1 69.66), valid_top5 88.94
2021-11-06 19:19:42 train 0000, loss 1.460e+00, top1 69.41, top5 82.35
2021-11-06 19:19:42 train 0000, loss 1.551e+00, top1 64.71, top5 85.88
2021-11-06 19:19:42 train 0000, loss 1.427e+00, top1 68.24, top5 90.59
2021-11-06 19:33:26 train 1000, loss 1.453e+00, top1 65.79, top5 85.57
2021-11-06 19:33:26 train 1000, loss 1.449e+00, top1 65.73, top5 85.75
2021-11-06 19:33:26 train 1000, loss 1.454e+00, top1 65.86, top5 85.57
2021-11-06 19:47:07 train 2000, loss 1.458e+00, top1 65.56, top5 85.52
2021-11-06 19:47:07 train 2000, loss 1.457e+00, top1 65.56, top5 85.66
2021-11-06 19:47:08 train 2000, loss 1.459e+00, top1 65.67, top5 85.54
2021-11-06 20:00:51 train 3000, loss 1.464e+00, top1 65.47, top5 85.54
2021-11-06 20:00:51 train 3000, loss 1.465e+00, top1 65.42, top5 85.42
2021-11-06 20:00:51 train 3000, loss 1.461e+00, top1 65.58, top5 85.51
2021-11-06 20:14:37 train 4000, loss 1.467e+00, top1 65.33, top5 85.39
2021-11-06 20:14:37 train 4000, loss 1.466e+00, top1 65.45, top5 85.48
2021-11-06 20:14:37 train 4000, loss 1.464e+00, top1 65.52, top5 85.46
2021-11-06 20:28:22 train 5000, loss 1.472e+00, top1 65.24, top5 85.33
2021-11-06 20:28:22 train 5000, loss 1.468e+00, top1 65.37, top5 85.46
2021-11-06 20:28:22 train 5000, loss 1.468e+00, top1 65.43, top5 85.40
2021-11-06 20:28:52 valid 0000, loss 5.639e-01, top1 89.41, top5 94.12
2021-11-06 20:28:52 valid 0000, loss 5.639e-01, top1 89.41, top5 94.12
2021-11-06 20:28:52 valid 0000, loss 5.639e-01, top1 89.41, top5 94.12
2021-11-06 20:33:12 (JOBID 31649) epoch 50: train time 4154.57, inference time 270.37s, valid_top1 68.84 (best_top1 69.66), valid_top5 89.19
2021-11-06 20:33:26 (JOBID 31649) epoch 50: train time 4153.23, inference time 284.62s, valid_top1 68.84 (best_top1 69.66), valid_top5 89.19
2021-11-06 20:33:27 (JOBID 31649) epoch 50: train time 4153.43, inference time 285.68s, valid_top1 68.84 (best_top1 69.66), valid_top5 89.19
2021-11-06 20:33:29 train 0000, loss 1.406e+00, top1 71.76, top5 83.53
2021-11-06 20:33:44 train 0000, loss 1.101e+00, top1 68.24, top5 88.24
2021-11-06 20:33:44 train 0000, loss 1.433e+00, top1 70.59, top5 84.71
2021-11-06 20:49:14 train 1000, loss 1.453e+00, top1 65.63, top5 85.62
2021-11-06 20:49:14 train 1000, loss 1.455e+00, top1 65.68, top5 85.56
2021-11-06 20:49:15 train 1000, loss 1.438e+00, top1 66.09, top5 85.75
2021-11-06 21:03:06 train 2000, loss 1.459e+00, top1 65.59, top5 85.49
2021-11-06 21:03:06 train 2000, loss 1.457e+00, top1 65.53, top5 85.58
2021-11-06 21:03:06 train 2000, loss 1.450e+00, top1 65.74, top5 85.65
2021-11-06 21:16:54 train 3000, loss 1.458e+00, top1 65.54, top5 85.58
2021-11-06 21:16:54 train 3000, loss 1.463e+00, top1 65.56, top5 85.44
2021-11-06 21:16:54 train 3000, loss 1.458e+00, top1 65.54, top5 85.59
2021-11-06 21:30:39 train 4000, loss 1.463e+00, top1 65.47, top5 85.52
2021-11-06 21:30:39 train 4000, loss 1.469e+00, top1 65.39, top5 85.36
2021-11-06 21:30:39 train 4000, loss 1.464e+00, top1 65.40, top5 85.52
