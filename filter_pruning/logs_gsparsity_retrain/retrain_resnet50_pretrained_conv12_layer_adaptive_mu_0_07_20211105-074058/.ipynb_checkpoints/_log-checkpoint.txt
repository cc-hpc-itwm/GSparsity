2021-11-05 07:41:03 CARME Slurm ID: 31681
2021-11-05 07:41:03 CARME Slurm ID: 31681
2021-11-05 07:41:03 CARME Slurm ID: 31681
2021-11-05 07:41:03 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_07', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.37:23456', distributed=True, epochs=90, evaluate=False, gpu=1, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_07_20211105-074058', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_07_20211105-074058', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-05 07:41:03 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_07', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.37:23456', distributed=True, epochs=90, evaluate=False, gpu=0, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_07_20211105-074058', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_07_20211105-074058', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-05 07:41:03 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_07', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.37:23456', distributed=True, epochs=90, evaluate=False, gpu=2, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_07_20211105-074058', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_07_20211105-074058', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-05 07:41:05 => loading baseline model 'conv12_lr_0.001_momentum_0.9_wd_0.07_normalization_div_pretrained_True_20211102-101803/small_model_conv12_1e-06.pth.tar'
2021-11-05 07:41:05 => loading baseline model 'conv12_lr_0.001_momentum_0.9_wd_0.07_normalization_div_pretrained_True_20211102-101803/small_model_conv12_1e-06.pth.tar'
2021-11-05 07:41:05 => loading baseline model 'conv12_lr_0.001_momentum_0.9_wd_0.07_normalization_div_pretrained_True_20211102-101803/small_model_conv12_1e-06.pth.tar'
2021-11-05 07:41:05 => loaded baseline model 'conv12_lr_0.001_momentum_0.9_wd_0.07_normalization_div_pretrained_True_20211102-101803/small_model_conv12_1e-06.pth.tar'
2021-11-05 07:41:05 => loaded baseline model 'conv12_lr_0.001_momentum_0.9_wd_0.07_normalization_div_pretrained_True_20211102-101803/small_model_conv12_1e-06.pth.tar'
2021-11-05 07:41:05 => loaded baseline model 'conv12_lr_0.001_momentum_0.9_wd_0.07_normalization_div_pretrained_True_20211102-101803/small_model_conv12_1e-06.pth.tar'
2021-11-05 07:41:14 Computational complexity:       1.92 GMac
2021-11-05 07:41:14 Computational complexity:       1.92 GMac
2021-11-05 07:41:14 Computational complexity:       1.92 GMac
2021-11-05 07:41:14 Number of parameters:           13.22 M 
2021-11-05 07:41:14 Number of parameters:           13.22 M 
2021-11-05 07:41:14 Number of parameters:           13.22 M 
2021-11-05 07:41:32 valid 0000, loss 5.936e-01, top1 89.41, top5 94.12
2021-11-05 07:41:32 valid 0000, loss 5.936e-01, top1 89.41, top5 94.12
2021-11-05 07:41:32 valid 0000, loss 5.936e-01, top1 89.41, top5 94.12
2021-11-05 07:46:18 (JOBID 31681) epoch -1: valid_top1 73.01, valid_top5 90.84, inference time 299.26
2021-11-05 07:46:20 (JOBID 31681) epoch -1: valid_top1 73.01, valid_top5 90.84, inference time 301.41
2021-11-05 07:46:20 (JOBID 31681) epoch -1: valid_top1 73.01, valid_top5 90.84, inference time 301.43
2021-11-05 07:46:38 train 0000, loss 6.261e-01, top1 87.06, top5 96.47
2021-11-05 07:46:38 train 0000, loss 7.031e-01, top1 78.82, top5 94.12
2021-11-05 07:46:38 train 0000, loss 8.546e-01, top1 82.35, top5 90.59
2021-11-05 07:55:18 train 1000, loss 1.512e+00, top1 64.66, top5 84.43
2021-11-05 07:55:18 train 1000, loss 1.511e+00, top1 64.63, top5 84.38
2021-11-05 07:55:18 train 1000, loss 1.502e+00, top1 64.77, top5 84.57
2021-11-05 08:03:51 train 2000, loss 1.449e+00, top1 66.05, top5 85.27
2021-11-05 08:03:51 train 2000, loss 1.445e+00, top1 65.91, top5 85.30
2021-11-05 08:03:51 train 2000, loss 1.439e+00, top1 66.05, top5 85.43
2021-11-05 08:12:27 train 3000, loss 1.420e+00, top1 66.41, top5 85.65
2021-11-05 08:12:27 train 3000, loss 1.421e+00, top1 66.58, top5 85.67
2021-11-05 08:12:27 train 3000, loss 1.418e+00, top1 66.58, top5 85.74
2021-11-05 08:20:58 train 4000, loss 1.405e+00, top1 66.84, top5 85.92
2021-11-05 08:20:58 train 4000, loss 1.408e+00, top1 66.86, top5 85.82
2021-11-05 08:20:59 train 4000, loss 1.409e+00, top1 66.67, top5 85.84
2021-11-05 08:29:32 train 5000, loss 1.405e+00, top1 66.95, top5 85.93
2021-11-05 08:29:32 train 5000, loss 1.405e+00, top1 66.81, top5 85.89
2021-11-05 08:29:32 train 5000, loss 1.401e+00, top1 66.93, top5 85.98
2021-11-05 08:30:00 valid 0000, loss 1.165e+00, top1 77.65, top5 87.06
2021-11-05 08:30:00 valid 0000, loss 1.165e+00, top1 77.65, top5 87.06
2021-11-05 08:30:00 valid 0000, loss 1.165e+00, top1 77.65, top5 87.06
2021-11-05 08:34:43 (JOBID 31681) epoch 0: train time 2607.28, inference time 294.48s, valid_top1 60.50 (best_top1 60.50), valid_top5 82.77
2021-11-05 08:34:45 (JOBID 31681) epoch 0: train time 2607.44, inference time 297.75s, valid_top1 60.50 (best_top1 60.50), valid_top5 82.77
2021-11-05 08:34:47 (JOBID 31681) epoch 0: train time 2609.55, inference time 299.58s, valid_top1 60.50 (best_top1 60.50), valid_top5 82.77
2021-11-05 08:34:58 train 0000, loss 1.246e+00, top1 74.12, top5 90.59
2021-11-05 08:35:00 train 0000, loss 1.407e+00, top1 64.71, top5 81.18
2021-11-05 08:35:01 train 0000, loss 1.152e+00, top1 71.76, top5 90.59
2021-11-05 08:43:29 train 1000, loss 1.396e+00, top1 67.06, top5 86.21
2021-11-05 08:43:29 train 1000, loss 1.389e+00, top1 67.38, top5 86.45
2021-11-05 08:43:29 train 1000, loss 1.388e+00, top1 67.48, top5 86.40
2021-11-05 08:51:56 train 2000, loss 1.405e+00, top1 67.02, top5 86.23
2021-11-05 08:51:56 train 2000, loss 1.410e+00, top1 66.84, top5 86.02
2021-11-05 08:51:56 train 2000, loss 1.403e+00, top1 67.14, top5 86.20
2021-11-05 09:00:23 train 3000, loss 1.430e+00, top1 66.42, top5 85.80
2021-11-05 09:00:23 train 3000, loss 1.420e+00, top1 66.73, top5 86.01
2021-11-05 09:00:23 train 3000, loss 1.419e+00, top1 66.66, top5 85.99
2021-11-05 09:08:50 train 4000, loss 1.445e+00, top1 66.11, top5 85.65
2021-11-05 09:08:50 train 4000, loss 1.440e+00, top1 66.25, top5 85.74
2021-11-05 09:08:50 train 4000, loss 1.435e+00, top1 66.39, top5 85.82
2021-11-05 09:17:19 train 5000, loss 1.459e+00, top1 65.88, top5 85.52
2021-11-05 09:17:19 train 5000, loss 1.455e+00, top1 65.96, top5 85.59
2021-11-05 09:17:20 train 5000, loss 1.463e+00, top1 65.77, top5 85.45
2021-11-05 09:17:42 valid 0000, loss 7.266e-01, top1 88.24, top5 94.12
2021-11-05 09:17:42 valid 0000, loss 7.266e-01, top1 88.24, top5 94.12
2021-11-05 09:17:42 valid 0000, loss 7.266e-01, top1 88.24, top5 94.12
2021-11-05 09:22:29 (JOBID 31681) epoch 1: train time 2566.87, inference time 296.39s, valid_top1 61.87 (best_top1 61.87), valid_top5 84.35
2021-11-05 09:22:29 (JOBID 31681) epoch 1: train time 2569.07, inference time 296.24s, valid_top1 61.87 (best_top1 61.87), valid_top5 84.35
2021-11-05 09:22:29 (JOBID 31681) epoch 1: train time 2564.98, inference time 297.20s, valid_top1 61.87 (best_top1 61.87), valid_top5 84.35
2021-11-05 09:22:43 train 0000, loss 1.571e+00, top1 58.82, top5 82.35
2021-11-05 09:22:43 train 0000, loss 1.418e+00, top1 68.24, top5 88.24
2021-11-05 09:22:44 train 0000, loss 1.625e+00, top1 57.65, top5 81.18
2021-11-05 09:31:23 train 1000, loss 1.541e+00, top1 64.21, top5 84.55
2021-11-05 09:31:23 train 1000, loss 1.524e+00, top1 64.47, top5 84.83
2021-11-05 09:31:23 train 1000, loss 1.542e+00, top1 64.13, top5 84.40
2021-11-05 09:39:58 train 2000, loss 1.558e+00, top1 63.93, top5 84.36
2021-11-05 09:39:58 train 2000, loss 1.551e+00, top1 63.95, top5 84.48
2021-11-05 09:39:58 train 2000, loss 1.556e+00, top1 63.91, top5 84.25
2021-11-05 09:48:36 train 3000, loss 1.580e+00, top1 63.44, top5 84.03
2021-11-05 09:48:36 train 3000, loss 1.574e+00, top1 63.48, top5 84.16
2021-11-05 09:48:36 train 3000, loss 1.576e+00, top1 63.45, top5 84.04
2021-11-05 09:57:11 train 4000, loss 1.604e+00, top1 63.03, top5 83.72
2021-11-05 09:57:11 train 4000, loss 1.599e+00, top1 62.96, top5 83.80
2021-11-05 09:57:11 train 4000, loss 1.597e+00, top1 63.00, top5 83.78
2021-11-05 10:05:50 train 5000, loss 1.623e+00, top1 62.62, top5 83.45
2021-11-05 10:05:50 train 5000, loss 1.616e+00, top1 62.58, top5 83.57
2021-11-05 10:05:50 train 5000, loss 1.616e+00, top1 62.64, top5 83.51
2021-11-05 10:06:13 valid 0000, loss 1.299e+00, top1 76.47, top5 87.06
2021-11-05 10:06:13 valid 0000, loss 1.299e+00, top1 76.47, top5 87.06
2021-11-05 10:06:13 valid 0000, loss 1.299e+00, top1 76.47, top5 87.06
2021-11-05 10:11:01 (JOBID 31681) epoch 2: train time 2613.57, inference time 297.77s, valid_top1 58.92 (best_top1 61.87), valid_top5 82.27
2021-11-05 10:11:01 (JOBID 31681) epoch 2: train time 2613.68, inference time 297.70s, valid_top1 58.92 (best_top1 61.87), valid_top5 82.27
2021-11-05 10:11:06 (JOBID 31681) epoch 2: train time 2614.36, inference time 302.89s, valid_top1 58.92 (best_top1 61.87), valid_top5 82.27
2021-11-05 10:11:15 train 0000, loss 1.947e+00, top1 51.76, top5 76.47
2021-11-05 10:11:15 train 0000, loss 1.317e+00, top1 70.59, top5 88.24
2021-11-05 10:11:20 train 0000, loss 1.796e+00, top1 62.35, top5 76.47
2021-11-05 10:19:59 train 1000, loss 1.695e+00, top1 60.91, top5 82.65
2021-11-05 10:19:59 train 1000, loss 1.701e+00, top1 60.92, top5 82.40
2021-11-05 10:19:59 train 1000, loss 1.707e+00, top1 60.83, top5 82.30
2021-11-05 10:28:28 train 2000, loss 1.723e+00, top1 60.31, top5 82.18
2021-11-05 10:28:28 train 2000, loss 1.724e+00, top1 60.39, top5 82.09
2021-11-05 10:28:28 train 2000, loss 1.725e+00, top1 60.44, top5 82.09
2021-11-05 10:36:54 train 3000, loss 1.750e+00, top1 59.84, top5 81.72
2021-11-05 10:36:54 train 3000, loss 1.750e+00, top1 59.91, top5 81.77
2021-11-05 10:36:54 train 3000, loss 1.745e+00, top1 59.88, top5 81.87
2021-11-05 10:45:21 train 4000, loss 1.770e+00, top1 59.39, top5 81.42
2021-11-05 10:45:22 train 4000, loss 1.768e+00, top1 59.52, top5 81.50
2021-11-05 10:45:22 train 4000, loss 1.763e+00, top1 59.54, top5 81.60
2021-11-05 10:53:50 train 5000, loss 1.783e+00, top1 59.11, top5 81.29
2021-11-05 10:53:50 train 5000, loss 1.790e+00, top1 58.97, top5 81.15
2021-11-05 10:53:50 train 5000, loss 1.789e+00, top1 59.10, top5 81.22
2021-11-05 10:54:14 valid 0000, loss 1.224e+00, top1 75.29, top5 85.88
2021-11-05 10:54:14 valid 0000, loss 1.224e+00, top1 75.29, top5 85.88
2021-11-05 10:54:14 valid 0000, loss 1.224e+00, top1 75.29, top5 85.88
2021-11-05 10:58:35 (JOBID 31681) epoch 3: train time 2581.56, inference time 272.46s, valid_top1 58.07 (best_top1 61.87), valid_top5 81.61
2021-11-05 10:58:50 (JOBID 31681) epoch 3: train time 2576.50, inference time 287.96s, valid_top1 58.07 (best_top1 61.87), valid_top5 81.61
2021-11-05 10:58:51 (JOBID 31681) epoch 3: train time 2581.35, inference time 288.37s, valid_top1 58.07 (best_top1 61.87), valid_top5 81.61
2021-11-05 10:59:05 train 0000, loss 1.921e+00, top1 54.12, top5 75.29
2021-11-05 10:58:50 train 0000, loss 2.120e+00, top1 52.94, top5 74.12
2021-11-05 10:59:05 train 0000, loss 2.199e+00, top1 48.24, top5 72.94
2021-11-05 11:07:40 train 1000, loss 1.861e+00, top1 57.39, top5 80.31
2021-11-05 11:07:40 train 1000, loss 1.851e+00, top1 57.59, top5 80.35
2021-11-05 11:07:41 train 1000, loss 1.874e+00, top1 57.24, top5 80.16
2021-11-05 11:16:14 train 2000, loss 1.887e+00, top1 56.85, top5 79.87
2021-11-05 11:16:14 train 2000, loss 1.877e+00, top1 57.11, top5 79.87
2021-11-05 11:16:14 train 2000, loss 1.884e+00, top1 56.93, top5 79.89
2021-11-05 11:24:38 train 3000, loss 1.901e+00, top1 56.68, top5 79.53
2021-11-05 11:24:38 train 3000, loss 1.905e+00, top1 56.58, top5 79.58
2021-11-05 11:24:38 train 3000, loss 1.909e+00, top1 56.47, top5 79.50
2021-11-05 11:33:02 train 4000, loss 1.920e+00, top1 56.29, top5 79.24
2021-11-05 11:33:02 train 4000, loss 1.924e+00, top1 56.19, top5 79.27
2021-11-05 11:33:02 train 4000, loss 1.923e+00, top1 56.23, top5 79.29
2021-11-05 11:41:27 train 5000, loss 1.939e+00, top1 55.92, top5 79.05
2021-11-05 11:41:27 train 5000, loss 1.936e+00, top1 55.97, top5 78.98
2021-11-05 11:41:27 train 5000, loss 1.941e+00, top1 55.90, top5 79.00
2021-11-05 11:41:50 valid 0000, loss 7.178e-01, top1 84.71, top5 94.12
2021-11-05 11:41:50 valid 0000, loss 7.178e-01, top1 84.71, top5 94.12
2021-11-05 11:41:50 valid 0000, loss 7.178e-01, top1 84.71, top5 94.12
2021-11-05 11:46:19 (JOBID 31681) epoch 4: train time 2585.12, inference time 279.37s, valid_top1 57.75 (best_top1 61.87), valid_top5 81.68
2021-11-05 11:46:22 (JOBID 31681) epoch 4: train time 2569.59, inference time 281.91s, valid_top1 57.75 (best_top1 61.87), valid_top5 81.68
2021-11-05 11:46:22 (JOBID 31681) epoch 4: train time 2568.83, inference time 281.54s, valid_top1 57.75 (best_top1 61.87), valid_top5 81.68
2021-11-05 11:46:36 train 0000, loss 2.173e+00, top1 51.76, top5 69.41
2021-11-05 11:46:34 train 0000, loss 2.116e+00, top1 52.94, top5 77.65
2021-11-05 11:46:36 train 0000, loss 2.115e+00, top1 52.94, top5 74.12
2021-11-05 11:55:23 train 1000, loss 1.997e+00, top1 54.79, top5 78.02
2021-11-05 11:55:23 train 1000, loss 1.984e+00, top1 54.93, top5 78.31
2021-11-05 11:55:23 train 1000, loss 1.994e+00, top1 54.81, top5 78.14
2021-11-05 12:04:06 train 2000, loss 2.015e+00, top1 54.35, top5 77.80
2021-11-05 12:04:06 train 2000, loss 2.007e+00, top1 54.48, top5 77.92
2021-11-05 12:04:06 train 2000, loss 2.012e+00, top1 54.38, top5 77.89
2021-11-05 12:12:36 train 3000, loss 2.027e+00, top1 54.15, top5 77.68
2021-11-05 12:12:37 train 3000, loss 2.029e+00, top1 54.10, top5 77.67
2021-11-05 12:12:37 train 3000, loss 2.024e+00, top1 54.18, top5 77.70
2021-11-05 12:21:14 train 4000, loss 2.047e+00, top1 53.77, top5 77.39
2021-11-05 12:21:14 train 4000, loss 2.043e+00, top1 53.84, top5 77.42
2021-11-05 12:21:14 train 4000, loss 2.038e+00, top1 53.86, top5 77.46
2021-11-05 12:29:42 train 5000, loss 2.058e+00, top1 53.54, top5 77.20
2021-11-05 12:29:42 train 5000, loss 2.050e+00, top1 53.63, top5 77.28
2021-11-05 12:29:42 train 5000, loss 2.056e+00, top1 53.58, top5 77.21
2021-11-05 12:30:06 valid 0000, loss 1.208e+00, top1 75.29, top5 88.24
2021-11-05 12:30:06 valid 0000, loss 1.208e+00, top1 75.29, top5 88.24
2021-11-05 12:30:06 valid 0000, loss 1.208e+00, top1 75.29, top5 88.24
2021-11-05 12:34:52 (JOBID 31681) epoch 5: train time 2615.57, inference time 296.74s, valid_top1 50.70 (best_top1 61.87), valid_top5 76.19
2021-11-05 12:34:53 (JOBID 31681) epoch 5: train time 2612.92, inference time 297.74s, valid_top1 50.70 (best_top1 61.87), valid_top5 76.19
2021-11-05 12:34:53 (JOBID 31681) epoch 5: train time 2612.95, inference time 298.26s, valid_top1 50.70 (best_top1 61.87), valid_top5 76.19
2021-11-05 12:35:07 train 0000, loss 2.388e+00, top1 52.94, top5 76.47
2021-11-05 12:35:07 train 0000, loss 1.976e+00, top1 57.65, top5 78.82
2021-11-05 12:35:07 train 0000, loss 2.520e+00, top1 47.06, top5 69.41
2021-11-05 12:43:43 train 1000, loss 2.079e+00, top1 53.08, top5 76.93
2021-11-05 12:43:43 train 1000, loss 2.088e+00, top1 53.12, top5 76.78
2021-11-05 12:43:43 train 1000, loss 2.080e+00, top1 53.07, top5 76.94
2021-11-05 12:52:21 train 2000, loss 2.105e+00, top1 52.69, top5 76.52
2021-11-05 12:52:21 train 2000, loss 2.095e+00, top1 52.78, top5 76.63
2021-11-05 12:52:21 train 2000, loss 2.087e+00, top1 52.87, top5 76.80
2021-11-05 13:00:52 train 3000, loss 2.108e+00, top1 52.53, top5 76.45
2021-11-05 13:00:52 train 3000, loss 2.110e+00, top1 52.57, top5 76.43
2021-11-05 13:00:52 train 3000, loss 2.104e+00, top1 52.56, top5 76.55
2021-11-05 13:09:19 train 4000, loss 2.119e+00, top1 52.34, top5 76.28
2021-11-05 13:09:19 train 4000, loss 2.118e+00, top1 52.36, top5 76.29
2021-11-05 13:09:19 train 4000, loss 2.111e+00, top1 52.39, top5 76.41
2021-11-05 13:17:47 train 5000, loss 2.127e+00, top1 52.18, top5 76.15
2021-11-05 13:17:46 train 5000, loss 2.128e+00, top1 52.15, top5 76.15
2021-11-05 13:17:47 train 5000, loss 2.122e+00, top1 52.19, top5 76.23
2021-11-05 13:18:09 valid 0000, loss 8.205e-01, top1 83.53, top5 92.94
2021-11-05 13:18:09 valid 0000, loss 8.205e-01, top1 83.53, top5 92.94
2021-11-05 13:18:09 valid 0000, loss 8.205e-01, top1 83.53, top5 92.94
2021-11-05 13:22:37 (JOBID 31681) epoch 6: train time 2586.04, inference time 277.66s, valid_top1 51.44 (best_top1 61.87), valid_top5 76.79
2021-11-05 13:22:37 (JOBID 31681) epoch 6: train time 2586.21, inference time 277.14s, valid_top1 51.44 (best_top1 61.87), valid_top5 76.79
2021-11-05 13:22:41 (JOBID 31681) epoch 6: train time 2587.43, inference time 281.75s, valid_top1 51.44 (best_top1 61.87), valid_top5 76.79
2021-11-05 13:22:51 train 0000, loss 2.170e+00, top1 48.24, top5 75.29
2021-11-05 13:22:51 train 0000, loss 2.489e+00, top1 48.24, top5 70.59
2021-11-05 13:22:55 train 0000, loss 2.172e+00, top1 48.24, top5 76.47
2021-11-05 13:32:03 train 1000, loss 2.120e+00, top1 52.34, top5 76.17
2021-11-05 13:32:03 train 1000, loss 2.124e+00, top1 52.13, top5 76.15
2021-11-05 13:32:03 train 1000, loss 2.136e+00, top1 52.11, top5 75.85
2021-11-05 13:41:11 train 2000, loss 2.141e+00, top1 51.97, top5 75.88
2021-11-05 13:41:11 train 2000, loss 2.131e+00, top1 52.01, top5 76.07
2021-11-05 13:41:12 train 2000, loss 2.137e+00, top1 52.04, top5 75.89
2021-11-05 13:50:15 train 3000, loss 2.144e+00, top1 51.75, top5 75.86
2021-11-05 13:50:15 train 3000, loss 2.148e+00, top1 51.75, top5 75.80
2021-11-05 13:50:15 train 3000, loss 2.144e+00, top1 51.82, top5 75.85
2021-11-05 13:59:18 train 4000, loss 2.151e+00, top1 51.64, top5 75.75
2021-11-05 13:59:18 train 4000, loss 2.153e+00, top1 51.60, top5 75.70
2021-11-05 13:59:18 train 4000, loss 2.153e+00, top1 51.67, top5 75.74
2021-11-05 14:08:27 train 5000, loss 2.159e+00, top1 51.54, top5 75.64
2021-11-05 14:08:27 train 5000, loss 2.159e+00, top1 51.51, top5 75.64
2021-11-05 14:08:27 train 5000, loss 2.158e+00, top1 51.48, top5 75.65
2021-11-05 14:08:51 valid 0000, loss 8.266e-01, top1 82.35, top5 91.76
2021-11-05 14:08:51 valid 0000, loss 8.266e-01, top1 82.35, top5 91.76
2021-11-05 14:08:51 valid 0000, loss 8.266e-01, top1 82.35, top5 91.76
2021-11-05 14:13:22 (JOBID 31681) epoch 7: train time 2759.85, inference time 281.05s, valid_top1 53.54 (best_top1 61.87), valid_top5 78.92
2021-11-05 14:13:22 (JOBID 31681) epoch 7: train time 2763.88, inference time 281.15s, valid_top1 53.54 (best_top1 61.87), valid_top5 78.92
2021-11-05 14:13:23 (JOBID 31681) epoch 7: train time 2763.73, inference time 282.21s, valid_top1 53.54 (best_top1 61.87), valid_top5 78.92
2021-11-05 14:13:36 train 0000, loss 2.459e+00, top1 43.53, top5 65.88
2021-11-05 14:13:36 train 0000, loss 2.063e+00, top1 49.41, top5 76.47
2021-11-05 14:13:38 train 0000, loss 2.447e+00, top1 47.06, top5 67.06
2021-11-05 14:22:37 train 1000, loss 2.154e+00, top1 51.48, top5 75.75
2021-11-05 14:22:37 train 1000, loss 2.149e+00, top1 51.61, top5 75.78
2021-11-05 14:22:37 train 1000, loss 2.161e+00, top1 51.41, top5 75.67
2021-11-05 14:31:43 train 2000, loss 2.162e+00, top1 51.23, top5 75.58
2021-11-05 14:31:43 train 2000, loss 2.155e+00, top1 51.54, top5 75.66
2021-11-05 14:31:44 train 2000, loss 2.173e+00, top1 51.23, top5 75.43
2021-11-05 14:40:48 train 3000, loss 2.164e+00, top1 51.39, top5 75.51
2021-11-05 14:40:48 train 3000, loss 2.166e+00, top1 51.24, top5 75.50
2021-11-05 14:40:48 train 3000, loss 2.176e+00, top1 51.15, top5 75.34
2021-11-05 14:49:51 train 4000, loss 2.172e+00, top1 51.25, top5 75.36
2021-11-05 14:49:51 train 4000, loss 2.172e+00, top1 51.17, top5 75.38
2021-11-05 14:49:51 train 4000, loss 2.179e+00, top1 51.13, top5 75.29
2021-11-05 14:58:54 train 5000, loss 2.182e+00, top1 51.08, top5 75.19
2021-11-05 14:58:54 train 5000, loss 2.183e+00, top1 51.04, top5 75.26
2021-11-05 14:58:54 train 5000, loss 2.175e+00, top1 51.17, top5 75.35
2021-11-05 14:59:18 valid 0000, loss 1.057e+00, top1 77.65, top5 88.24
2021-11-05 14:59:18 valid 0000, loss 1.057e+00, top1 77.65, top5 88.24
2021-11-05 14:59:18 valid 0000, loss 1.057e+00, top1 77.65, top5 88.24
2021-11-05 15:03:33 (JOBID 31681) epoch 8: train time 2744.05, inference time 265.19s, valid_top1 53.04 (best_top1 61.87), valid_top5 78.48
2021-11-05 15:04:03 (JOBID 31681) epoch 8: train time 2745.60, inference time 295.22s, valid_top1 53.04 (best_top1 61.87), valid_top5 78.48
2021-11-05 15:04:03 (JOBID 31681) epoch 8: train time 2745.54, inference time 295.74s, valid_top1 53.04 (best_top1 61.87), valid_top5 78.48
2021-11-05 15:03:47 train 0000, loss 2.132e+00, top1 55.29, top5 76.47
2021-11-05 15:04:17 train 0000, loss 1.910e+00, top1 60.00, top5 75.29
2021-11-05 15:04:17 train 0000, loss 2.072e+00, top1 51.76, top5 81.18
2021-11-05 15:13:18 train 1000, loss 2.163e+00, top1 51.37, top5 75.44
2021-11-05 15:13:18 train 1000, loss 2.176e+00, top1 51.41, top5 75.22
2021-11-05 15:13:18 train 1000, loss 2.166e+00, top1 51.15, top5 75.50
2021-11-05 15:22:28 train 2000, loss 2.175e+00, top1 51.14, top5 75.29
2021-11-05 15:22:28 train 2000, loss 2.175e+00, top1 51.35, top5 75.37
2021-11-05 15:22:28 train 2000, loss 2.176e+00, top1 51.10, top5 75.32
2021-11-05 15:31:35 train 3000, loss 2.179e+00, top1 51.11, top5 75.30
2021-11-05 15:31:35 train 3000, loss 2.183e+00, top1 51.03, top5 75.20
2021-11-05 15:31:35 train 3000, loss 2.186e+00, top1 51.01, top5 75.14
2021-11-05 15:40:44 train 4000, loss 2.186e+00, top1 51.03, top5 75.20
2021-11-05 15:40:44 train 4000, loss 2.191e+00, top1 50.85, top5 75.01
2021-11-05 15:40:44 train 4000, loss 2.186e+00, top1 50.94, top5 75.14
2021-11-05 15:49:50 train 5000, loss 2.190e+00, top1 50.87, top5 75.08
2021-11-05 15:49:50 train 5000, loss 2.191e+00, top1 50.89, top5 75.01
2021-11-05 15:49:50 train 5000, loss 2.189e+00, top1 50.98, top5 75.16
2021-11-05 15:50:14 valid 0000, loss 1.026e+00, top1 77.65, top5 89.41
2021-11-05 15:50:14 valid 0000, loss 1.026e+00, top1 77.65, top5 89.41
2021-11-05 15:50:14 valid 0000, loss 1.026e+00, top1 77.65, top5 89.41
2021-11-05 15:54:40 (JOBID 31681) epoch 9: train time 2791.18, inference time 275.53s, valid_top1 50.12 (best_top1 61.87), valid_top5 76.44
2021-11-05 15:54:41 (JOBID 31681) epoch 9: train time 2760.74, inference time 277.01s, valid_top1 50.12 (best_top1 61.87), valid_top5 76.44
2021-11-05 15:54:42 (JOBID 31681) epoch 9: train time 2761.35, inference time 278.30s, valid_top1 50.12 (best_top1 61.87), valid_top5 76.44
2021-11-05 15:54:55 train 0000, loss 2.221e+00, top1 47.06, top5 76.47
2021-11-05 15:54:55 train 0000, loss 2.196e+00, top1 51.76, top5 71.76
2021-11-05 15:54:57 train 0000, loss 2.035e+00, top1 49.41, top5 77.65
2021-11-05 16:04:10 train 1000, loss 2.182e+00, top1 51.24, top5 74.93
2021-11-05 16:04:10 train 1000, loss 2.176e+00, top1 51.19, top5 75.28
2021-11-05 16:04:10 train 1000, loss 2.173e+00, top1 51.14, top5 75.38
2021-11-05 16:13:31 train 2000, loss 2.181e+00, top1 51.06, top5 75.23
2021-11-05 16:13:31 train 2000, loss 2.180e+00, top1 51.14, top5 75.21
2021-11-05 16:13:31 train 2000, loss 2.188e+00, top1 51.05, top5 75.01
2021-11-05 16:22:59 train 3000, loss 2.185e+00, top1 50.99, top5 75.25
2021-11-05 16:22:59 train 3000, loss 2.188e+00, top1 50.98, top5 75.08
2021-11-05 16:22:59 train 3000, loss 2.193e+00, top1 50.95, top5 74.99
2021-11-05 16:33:55 train 4000, loss 2.191e+00, top1 50.86, top5 75.13
2021-11-05 16:33:55 train 4000, loss 2.192e+00, top1 50.88, top5 75.05
2021-11-05 16:33:55 train 4000, loss 2.195e+00, top1 50.83, top5 74.98
2021-11-05 16:42:57 train 5000, loss 2.196e+00, top1 50.79, top5 75.01
2021-11-05 16:42:57 train 5000, loss 2.195e+00, top1 50.82, top5 75.08
2021-11-05 16:42:57 train 5000, loss 2.195e+00, top1 50.81, top5 74.96
2021-11-05 16:43:20 valid 0000, loss 1.157e+00, top1 78.82, top5 90.59
2021-11-05 16:43:20 valid 0000, loss 1.157e+00, top1 78.82, top5 90.59
2021-11-05 16:43:20 valid 0000, loss 1.157e+00, top1 78.82, top5 90.59
2021-11-05 16:47:41 (JOBID 31681) epoch 10: train time 2909.35, inference time 270.65s, valid_top1 53.12 (best_top1 61.87), valid_top5 78.45
2021-11-05 16:48:02 (JOBID 31681) epoch 10: train time 2910.34, inference time 291.06s, valid_top1 53.12 (best_top1 61.87), valid_top5 78.45
2021-11-05 16:48:02 (JOBID 31681) epoch 10: train time 2907.98, inference time 291.81s, valid_top1 53.12 (best_top1 61.87), valid_top5 78.45
2021-11-05 16:47:55 train 0000, loss 2.124e+00, top1 48.24, top5 70.59
2021-11-05 16:48:15 train 0000, loss 2.478e+00, top1 49.41, top5 67.06
2021-11-05 16:48:15 train 0000, loss 2.500e+00, top1 44.71, top5 70.59
2021-11-05 16:57:11 train 1000, loss 2.154e+00, top1 51.45, top5 75.59
2021-11-05 16:57:11 train 1000, loss 2.180e+00, top1 51.26, top5 75.28
2021-11-05 16:57:11 train 1000, loss 2.184e+00, top1 51.07, top5 75.35
2021-11-05 17:06:10 train 2000, loss 2.164e+00, top1 51.35, top5 75.52
2021-11-05 17:06:10 train 2000, loss 2.190e+00, top1 50.99, top5 75.18
2021-11-05 17:06:10 train 2000, loss 2.186e+00, top1 50.94, top5 75.28
2021-11-05 17:15:05 train 3000, loss 2.196e+00, top1 50.89, top5 75.06
2021-11-05 17:15:05 train 3000, loss 2.174e+00, top1 51.15, top5 75.35
2021-11-05 17:15:05 train 3000, loss 2.194e+00, top1 50.76, top5 75.08
2021-11-05 17:24:51 train 4000, loss 2.202e+00, top1 50.70, top5 75.01
2021-11-05 17:24:51 train 4000, loss 2.185e+00, top1 50.98, top5 75.19
2021-11-05 17:24:51 train 4000, loss 2.198e+00, top1 50.70, top5 75.06
2021-11-05 17:33:48 train 5000, loss 2.194e+00, top1 50.86, top5 75.06
2021-11-05 17:33:48 train 5000, loss 2.204e+00, top1 50.64, top5 74.94
2021-11-05 17:33:48 train 5000, loss 2.198e+00, top1 50.70, top5 75.06
2021-11-05 17:34:12 valid 0000, loss 1.144e+00, top1 71.76, top5 92.94
2021-11-05 17:34:12 valid 0000, loss 1.144e+00, top1 71.76, top5 92.94
2021-11-05 17:34:12 valid 0000, loss 1.144e+00, top1 71.76, top5 92.94
2021-11-05 17:38:43 (JOBID 31681) epoch 11: train time 2780.24, inference time 281.66s, valid_top1 48.22 (best_top1 61.87), valid_top5 74.49
2021-11-05 17:38:43 (JOBID 31681) epoch 11: train time 2759.70, inference time 281.35s, valid_top1 48.22 (best_top1 61.87), valid_top5 74.49
2021-11-05 17:38:47 (JOBID 31681) epoch 11: train time 2759.12, inference time 286.19s, valid_top1 48.22 (best_top1 61.87), valid_top5 74.49
2021-11-05 17:38:58 train 0000, loss 2.550e+00, top1 43.53, top5 68.24
2021-11-05 17:38:58 train 0000, loss 2.157e+00, top1 47.06, top5 75.29
2021-11-05 17:39:01 train 0000, loss 1.954e+00, top1 57.65, top5 77.65
2021-11-05 17:48:08 train 1000, loss 2.174e+00, top1 51.36, top5 75.27
2021-11-05 17:48:08 train 1000, loss 2.179e+00, top1 51.11, top5 75.35
2021-11-05 17:48:08 train 1000, loss 2.167e+00, top1 51.18, top5 75.60
2021-11-05 17:57:12 train 2000, loss 2.186e+00, top1 50.85, top5 75.20
2021-11-05 17:57:12 train 2000, loss 2.180e+00, top1 51.01, top5 75.22
2021-11-05 17:57:12 train 2000, loss 2.185e+00, top1 51.02, top5 75.19
2021-11-05 18:07:09 train 3000, loss 2.184e+00, top1 50.93, top5 75.21
2021-11-05 18:07:09 train 3000, loss 2.192e+00, top1 50.76, top5 75.08
2021-11-05 18:07:09 train 3000, loss 2.193e+00, top1 50.92, top5 75.06
2021-11-05 18:16:12 train 4000, loss 2.196e+00, top1 50.74, top5 75.04
2021-11-05 18:16:12 train 4000, loss 2.191e+00, top1 50.77, top5 75.12
2021-11-05 18:16:12 train 4000, loss 2.198e+00, top1 50.78, top5 74.99
2021-11-05 18:25:16 train 5000, loss 2.203e+00, top1 50.69, top5 74.91
2021-11-05 18:25:16 train 5000, loss 2.198e+00, top1 50.64, top5 74.99
2021-11-05 18:25:16 train 5000, loss 2.201e+00, top1 50.67, top5 74.98
2021-11-05 18:25:39 valid 0000, loss 8.068e-01, top1 82.35, top5 89.41
2021-11-05 18:25:39 valid 0000, loss 8.068e-01, top1 82.35, top5 89.41
2021-11-05 18:25:39 valid 0000, loss 8.068e-01, top1 82.35, top5 89.41
2021-11-05 18:29:59 (JOBID 31681) epoch 12: train time 2806.53, inference time 270.00s, valid_top1 51.26 (best_top1 61.87), valid_top5 77.21
2021-11-05 18:30:08 (JOBID 31681) epoch 12: train time 2801.99, inference time 278.23s, valid_top1 51.26 (best_top1 61.87), valid_top5 77.21
2021-11-05 18:30:09 (JOBID 31681) epoch 12: train time 2806.39, inference time 279.09s, valid_top1 51.26 (best_top1 61.87), valid_top5 77.21
2021-11-05 18:30:13 train 0000, loss 1.935e+00, top1 52.94, top5 77.65
2021-11-05 18:30:22 train 0000, loss 2.001e+00, top1 51.76, top5 74.12
2021-11-05 18:30:22 train 0000, loss 2.061e+00, top1 50.59, top5 71.76
2021-11-05 18:39:20 train 1000, loss 2.188e+00, top1 50.88, top5 75.02
2021-11-05 18:39:20 train 1000, loss 2.179e+00, top1 51.04, top5 75.26
2021-11-05 18:39:20 train 1000, loss 2.166e+00, top1 51.33, top5 75.48
2021-11-05 18:48:20 train 2000, loss 2.182e+00, top1 50.98, top5 75.28
2021-11-05 18:48:20 train 2000, loss 2.186e+00, top1 50.92, top5 75.16
2021-11-05 18:48:20 train 2000, loss 2.189e+00, top1 50.89, top5 75.05
2021-11-05 18:57:18 train 3000, loss 2.195e+00, top1 50.77, top5 75.01
2021-11-05 18:57:18 train 3000, loss 2.189e+00, top1 50.87, top5 75.13
2021-11-05 18:57:18 train 3000, loss 2.192e+00, top1 50.88, top5 75.07
2021-11-05 19:06:14 train 4000, loss 2.200e+00, top1 50.70, top5 74.93
2021-11-05 19:06:14 train 4000, loss 2.195e+00, top1 50.76, top5 75.03
2021-11-05 19:06:14 train 4000, loss 2.198e+00, top1 50.74, top5 74.93
2021-11-05 19:15:11 train 5000, loss 2.199e+00, top1 50.71, top5 74.94
2021-11-05 19:15:11 train 5000, loss 2.203e+00, top1 50.60, top5 74.90
2021-11-05 19:15:11 train 5000, loss 2.201e+00, top1 50.69, top5 74.91
2021-11-05 19:15:35 valid 0000, loss 1.195e+00, top1 70.59, top5 90.59
2021-11-05 19:15:35 valid 0000, loss 1.195e+00, top1 70.59, top5 90.59
2021-11-05 19:15:35 valid 0000, loss 1.195e+00, top1 70.59, top5 90.59
2021-11-05 19:20:18 (JOBID 31681) epoch 13: train time 2717.00, inference time 293.74s, valid_top1 52.89 (best_top1 61.87), valid_top5 78.76
2021-11-05 19:20:18 (JOBID 31681) epoch 13: train time 2715.81, inference time 293.40s, valid_top1 52.89 (best_top1 61.87), valid_top5 78.76
2021-11-05 19:20:19 (JOBID 31681) epoch 13: train time 2725.19, inference time 294.28s, valid_top1 52.89 (best_top1 61.87), valid_top5 78.76
2021-11-05 19:20:32 train 0000, loss 1.988e+00, top1 51.76, top5 78.82
2021-11-05 19:20:32 train 0000, loss 2.483e+00, top1 48.24, top5 68.24
2021-11-05 19:20:33 train 0000, loss 2.089e+00, top1 50.59, top5 76.47
2021-11-05 19:29:33 train 1000, loss 2.187e+00, top1 51.04, top5 75.16
2021-11-05 19:29:33 train 1000, loss 2.177e+00, top1 51.01, top5 75.29
2021-11-05 19:29:33 train 1000, loss 2.181e+00, top1 51.02, top5 75.32
2021-11-05 19:38:36 train 2000, loss 2.194e+00, top1 50.72, top5 75.02
2021-11-05 19:38:36 train 2000, loss 2.194e+00, top1 50.91, top5 75.08
2021-11-05 19:38:36 train 2000, loss 2.192e+00, top1 50.76, top5 75.12
2021-11-05 19:47:40 train 3000, loss 2.198e+00, top1 50.67, top5 75.00
2021-11-05 19:47:40 train 3000, loss 2.196e+00, top1 50.82, top5 75.05
2021-11-05 19:47:40 train 3000, loss 2.194e+00, top1 50.67, top5 75.08
2021-11-05 19:56:42 train 4000, loss 2.201e+00, top1 50.73, top5 74.97
2021-11-05 19:56:42 train 4000, loss 2.201e+00, top1 50.62, top5 74.94
2021-11-05 19:56:43 train 4000, loss 2.197e+00, top1 50.62, top5 75.02
2021-11-05 20:05:46 train 5000, loss 2.204e+00, top1 50.56, top5 74.88
2021-11-05 20:05:45 train 5000, loss 2.204e+00, top1 50.66, top5 74.92
2021-11-05 20:05:46 train 5000, loss 2.202e+00, top1 50.57, top5 74.95
2021-11-05 20:06:09 valid 0000, loss 1.149e+00, top1 74.12, top5 83.53
2021-11-05 20:06:09 valid 0000, loss 1.149e+00, top1 74.12, top5 83.53
2021-11-05 20:06:09 valid 0000, loss 1.149e+00, top1 74.12, top5 83.53
2021-11-05 20:10:35 (JOBID 31681) epoch 14: train time 2740.37, inference time 276.18s, valid_top1 52.69 (best_top1 61.87), valid_top5 78.26
2021-11-05 20:10:39 (JOBID 31681) epoch 14: train time 2740.86, inference time 279.45s, valid_top1 52.69 (best_top1 61.87), valid_top5 78.26
2021-11-05 20:10:42 (JOBID 31681) epoch 14: train time 2740.85, inference time 281.97s, valid_top1 52.69 (best_top1 61.87), valid_top5 78.26
2021-11-05 20:10:50 train 0000, loss 2.107e+00, top1 55.29, top5 68.24
2021-11-05 20:10:53 train 0000, loss 2.166e+00, top1 54.12, top5 71.76
2021-11-05 20:10:55 train 0000, loss 1.948e+00, top1 49.41, top5 77.65
2021-11-05 20:19:58 train 1000, loss 2.187e+00, top1 51.01, top5 74.89
2021-11-05 20:19:58 train 1000, loss 2.172e+00, top1 51.20, top5 75.33
2021-11-05 20:19:58 train 1000, loss 2.185e+00, top1 50.90, top5 75.20
2021-11-05 20:28:58 train 2000, loss 2.189e+00, top1 50.87, top5 75.06
2021-11-05 20:28:58 train 2000, loss 2.191e+00, top1 50.70, top5 75.09
2021-11-05 20:28:58 train 2000, loss 2.195e+00, top1 50.83, top5 74.89
2021-11-05 20:37:57 train 3000, loss 2.196e+00, top1 50.65, top5 75.00
2021-11-05 20:37:57 train 3000, loss 2.195e+00, top1 50.77, top5 74.95
2021-11-05 20:37:57 train 3000, loss 2.200e+00, top1 50.80, top5 74.89
2021-11-05 20:46:56 train 4000, loss 2.204e+00, top1 50.49, top5 74.89
2021-11-05 20:46:56 train 4000, loss 2.202e+00, top1 50.66, top5 74.92
2021-11-05 20:46:56 train 4000, loss 2.200e+00, top1 50.74, top5 74.93
2021-11-05 20:55:55 train 5000, loss 2.206e+00, top1 50.47, top5 74.87
2021-11-05 20:55:55 train 5000, loss 2.206e+00, top1 50.59, top5 74.86
2021-11-05 20:55:55 train 5000, loss 2.204e+00, top1 50.65, top5 74.85
2021-11-05 20:56:19 valid 0000, loss 1.065e+00, top1 83.53, top5 87.06
2021-11-05 20:56:19 valid 0000, loss 1.065e+00, top1 83.53, top5 87.06
2021-11-05 20:56:19 valid 0000, loss 1.065e+00, top1 83.53, top5 87.06
2021-11-05 21:00:37 (JOBID 31681) epoch 15: train time 2729.56, inference time 268.80s, valid_top1 49.44 (best_top1 61.87), valid_top5 75.51
2021-11-05 21:00:44 (JOBID 31681) epoch 15: train time 2726.63, inference time 275.25s, valid_top1 49.44 (best_top1 61.87), valid_top5 75.51
2021-11-05 21:00:45 (JOBID 31681) epoch 15: train time 2732.93, inference time 276.96s, valid_top1 49.44 (best_top1 61.87), valid_top5 75.51
2021-11-05 21:00:58 train 0000, loss 2.006e+00, top1 57.65, top5 75.29
2021-11-05 21:00:51 train 0000, loss 2.140e+00, top1 54.12, top5 70.59
2021-11-05 21:00:59 train 0000, loss 2.214e+00, top1 52.94, top5 81.18
2021-11-05 21:10:09 train 1000, loss 2.180e+00, top1 51.21, top5 75.28
2021-11-05 21:10:09 train 1000, loss 2.184e+00, top1 50.81, top5 75.25
2021-11-05 21:10:09 train 1000, loss 2.180e+00, top1 50.98, top5 75.30
2021-11-05 21:19:12 train 2000, loss 2.191e+00, top1 50.88, top5 75.09
2021-11-05 21:19:12 train 2000, loss 2.195e+00, top1 50.83, top5 75.06
2021-11-05 21:19:12 train 2000, loss 2.187e+00, top1 50.96, top5 75.21
2021-11-05 21:28:16 train 3000, loss 2.194e+00, top1 50.87, top5 75.04
2021-11-05 21:28:16 train 3000, loss 2.199e+00, top1 50.74, top5 75.02
2021-11-05 21:28:16 train 3000, loss 2.197e+00, top1 50.77, top5 74.96
2021-11-05 21:37:23 train 4000, loss 2.198e+00, top1 50.80, top5 74.98
2021-11-05 21:37:23 train 4000, loss 2.202e+00, top1 50.66, top5 74.96
2021-11-05 21:37:23 train 4000, loss 2.203e+00, top1 50.69, top5 74.86
2021-11-05 21:47:13 train 5000, loss 2.206e+00, top1 50.64, top5 74.86
2021-11-05 21:47:13 train 5000, loss 2.203e+00, top1 50.66, top5 74.94
2021-11-05 21:47:13 train 5000, loss 2.201e+00, top1 50.78, top5 74.93
2021-11-05 21:47:37 valid 0000, loss 8.138e-01, top1 82.35, top5 94.12
2021-11-05 21:47:37 valid 0000, loss 8.138e-01, top1 82.35, top5 94.12
2021-11-05 21:47:37 valid 0000, loss 8.138e-01, top1 82.35, top5 94.12
2021-11-05 21:52:16 (JOBID 31681) epoch 16: train time 2801.99, inference time 289.03s, valid_top1 53.60 (best_top1 61.87), valid_top5 78.86
2021-11-05 21:52:17 (JOBID 31681) epoch 16: train time 2803.52, inference time 289.03s, valid_top1 53.60 (best_top1 61.87), valid_top5 78.86
2021-11-05 21:52:17 (JOBID 31681) epoch 16: train time 2810.26, inference time 289.53s, valid_top1 53.60 (best_top1 61.87), valid_top5 78.86
2021-11-05 21:52:38 train 0000, loss 1.953e+00, top1 58.82, top5 81.18
2021-11-05 21:52:38 train 0000, loss 2.597e+00, top1 50.59, top5 65.88
2021-11-05 21:52:38 train 0000, loss 1.783e+00, top1 63.53, top5 80.00
2021-11-05 22:03:28 train 1000, loss 2.192e+00, top1 50.58, top5 74.99
2021-11-05 22:03:28 train 1000, loss 2.182e+00, top1 50.71, top5 75.25
2021-11-05 22:03:28 train 1000, loss 2.182e+00, top1 51.06, top5 75.12
2021-11-05 22:12:33 train 2000, loss 2.190e+00, top1 50.66, top5 75.15
2021-11-05 22:12:33 train 2000, loss 2.193e+00, top1 50.78, top5 75.04
2021-11-05 22:12:33 train 2000, loss 2.203e+00, top1 50.53, top5 74.87
2021-11-05 22:21:34 train 3000, loss 2.201e+00, top1 50.58, top5 74.87
2021-11-05 22:21:34 train 3000, loss 2.193e+00, top1 50.76, top5 75.05
2021-11-05 22:21:34 train 3000, loss 2.198e+00, top1 50.73, top5 74.99
2021-11-05 22:30:32 train 4000, loss 2.201e+00, top1 50.69, top5 74.94
2021-11-05 22:30:32 train 4000, loss 2.194e+00, top1 50.74, top5 75.06
2021-11-05 22:30:32 train 4000, loss 2.204e+00, top1 50.52, top5 74.83
2021-11-05 22:39:33 train 5000, loss 2.208e+00, top1 50.48, top5 74.78
2021-11-05 22:39:33 train 5000, loss 2.197e+00, top1 50.71, top5 75.02
2021-11-05 22:39:34 train 5000, loss 2.205e+00, top1 50.65, top5 74.87
2021-11-05 22:39:58 valid 0000, loss 1.134e+00, top1 74.12, top5 89.41
2021-11-05 22:39:58 valid 0000, loss 1.134e+00, top1 74.12, top5 89.41
2021-11-05 22:39:58 valid 0000, loss 1.134e+00, top1 74.12, top5 89.41
2021-11-05 22:44:27 (JOBID 31681) epoch 17: train time 2850.53, inference time 279.30s, valid_top1 51.33 (best_top1 61.87), valid_top5 76.79
2021-11-05 22:44:27 (JOBID 31681) epoch 17: train time 2850.32, inference time 279.85s, valid_top1 51.33 (best_top1 61.87), valid_top5 76.79
2021-11-05 22:44:29 (JOBID 31681) epoch 17: train time 2850.77, inference time 281.89s, valid_top1 51.33 (best_top1 61.87), valid_top5 76.79
2021-11-05 22:44:41 train 0000, loss 1.837e+00, top1 62.35, top5 78.82
2021-11-05 22:44:41 train 0000, loss 2.467e+00, top1 44.71, top5 68.24
2021-11-05 22:44:44 train 0000, loss 2.363e+00, top1 51.76, top5 71.76
2021-11-05 22:53:55 train 1000, loss 2.187e+00, top1 50.85, top5 75.06
2021-11-05 22:53:55 train 1000, loss 2.193e+00, top1 50.83, top5 75.03
2021-11-05 22:53:55 train 1000, loss 2.188e+00, top1 50.72, top5 75.18
2021-11-05 23:03:01 train 2000, loss 2.194e+00, top1 50.69, top5 75.06
2021-11-05 23:03:01 train 2000, loss 2.193e+00, top1 50.82, top5 75.00
2021-11-05 23:03:02 train 2000, loss 2.190e+00, top1 50.73, top5 75.07
2021-11-05 23:12:04 train 3000, loss 2.194e+00, top1 50.78, top5 74.98
2021-11-05 23:12:04 train 3000, loss 2.196e+00, top1 50.68, top5 75.03
2021-11-05 23:12:05 train 3000, loss 2.192e+00, top1 50.77, top5 75.04
2021-11-05 23:21:10 train 4000, loss 2.202e+00, top1 50.67, top5 74.91
2021-11-05 23:21:10 train 4000, loss 2.200e+00, top1 50.59, top5 74.98
2021-11-05 23:21:10 train 4000, loss 2.203e+00, top1 50.61, top5 74.85
2021-11-05 23:30:13 train 5000, loss 2.204e+00, top1 50.58, top5 74.82
2021-11-05 23:30:13 train 5000, loss 2.204e+00, top1 50.56, top5 74.91
2021-11-05 23:30:14 train 5000, loss 2.202e+00, top1 50.65, top5 74.91
2021-11-05 23:30:37 valid 0000, loss 1.271e+00, top1 75.29, top5 88.24
2021-11-05 23:30:37 valid 0000, loss 1.271e+00, top1 75.29, top5 88.24
2021-11-05 23:30:37 valid 0000, loss 1.271e+00, top1 75.29, top5 88.24
2021-11-05 23:34:54 (JOBID 31681) epoch 18: train time 2757.83, inference time 267.20s, valid_top1 51.18 (best_top1 61.87), valid_top5 76.75
2021-11-05 23:35:06 (JOBID 31681) epoch 18: train time 2760.37, inference time 278.47s, valid_top1 51.18 (best_top1 61.87), valid_top5 76.75
2021-11-05 23:35:08 (JOBID 31681) epoch 18: train time 2759.82, inference time 281.02s, valid_top1 51.18 (best_top1 61.87), valid_top5 76.75
2021-11-05 23:35:20 train 0000, loss 2.285e+00, top1 48.24, top5 76.47
2021-11-05 23:35:09 train 0000, loss 1.948e+00, top1 52.94, top5 77.65
2021-11-05 23:35:22 train 0000, loss 2.400e+00, top1 43.53, top5 71.76
2021-11-05 23:44:27 train 1000, loss 2.169e+00, top1 51.15, top5 75.50
2021-11-05 23:44:26 train 1000, loss 2.180e+00, top1 51.16, top5 75.23
2021-11-05 23:44:27 train 1000, loss 2.183e+00, top1 51.02, top5 75.36
2021-11-05 23:53:29 train 2000, loss 2.188e+00, top1 50.86, top5 75.20
2021-11-05 23:53:29 train 2000, loss 2.194e+00, top1 50.84, top5 74.96
2021-11-05 23:53:29 train 2000, loss 2.186e+00, top1 50.93, top5 75.16
2021-11-06 00:02:33 train 3000, loss 2.198e+00, top1 50.77, top5 74.91
2021-11-06 00:02:33 train 3000, loss 2.200e+00, top1 50.68, top5 75.02
2021-11-06 00:02:33 train 3000, loss 2.190e+00, top1 50.82, top5 75.12
2021-11-06 00:11:33 train 4000, loss 2.202e+00, top1 50.61, top5 74.95
2021-11-06 00:11:33 train 4000, loss 2.206e+00, top1 50.56, top5 74.80
2021-11-06 00:11:33 train 4000, loss 2.196e+00, top1 50.75, top5 74.99
2021-11-06 00:20:31 train 5000, loss 2.204e+00, top1 50.61, top5 74.88
2021-11-06 00:20:31 train 5000, loss 2.209e+00, top1 50.51, top5 74.78
2021-11-06 00:20:31 train 5000, loss 2.201e+00, top1 50.65, top5 74.93
2021-11-06 00:20:55 valid 0000, loss 1.625e+00, top1 47.06, top5 87.06
2021-11-06 00:20:55 valid 0000, loss 1.625e+00, top1 47.06, top5 87.06
2021-11-06 00:20:55 valid 0000, loss 1.625e+00, top1 47.06, top5 87.06
2021-11-06 00:25:40 (JOBID 31681) epoch 19: train time 2736.83, inference time 294.93s, valid_top1 52.95 (best_top1 61.87), valid_top5 78.44
2021-11-06 00:25:40 (JOBID 31681) epoch 19: train time 2750.67, inference time 294.91s, valid_top1 52.95 (best_top1 61.87), valid_top5 78.44
2021-11-06 00:25:40 (JOBID 31681) epoch 19: train time 2739.03, inference time 294.80s, valid_top1 52.95 (best_top1 61.87), valid_top5 78.44
2021-11-06 00:25:54 train 0000, loss 2.291e+00, top1 50.59, top5 70.59
2021-11-06 00:25:54 train 0000, loss 2.122e+00, top1 55.29, top5 80.00
2021-11-06 00:25:54 train 0000, loss 2.320e+00, top1 49.41, top5 72.94
2021-11-06 00:34:59 train 1000, loss 2.189e+00, top1 50.98, top5 75.08
2021-11-06 00:34:59 train 1000, loss 2.196e+00, top1 50.69, top5 75.22
2021-11-06 00:34:59 train 1000, loss 2.182e+00, top1 51.10, top5 75.27
2021-11-06 00:44:08 train 2000, loss 2.201e+00, top1 50.81, top5 75.00
2021-11-06 00:44:08 train 2000, loss 2.186e+00, top1 50.98, top5 75.10
2021-11-06 00:44:08 train 2000, loss 2.202e+00, top1 50.61, top5 75.05
2021-11-06 00:53:14 train 3000, loss 2.209e+00, top1 50.62, top5 74.84
2021-11-06 00:53:14 train 3000, loss 2.189e+00, top1 50.91, top5 75.07
2021-11-06 00:53:14 train 3000, loss 2.203e+00, top1 50.59, top5 74.96
2021-11-06 01:02:13 train 4000, loss 2.193e+00, top1 50.82, top5 75.03
2021-11-06 01:02:13 train 4000, loss 2.207e+00, top1 50.63, top5 74.85
2021-11-06 01:02:13 train 4000, loss 2.207e+00, top1 50.58, top5 74.88
2021-11-06 01:11:10 train 5000, loss 2.197e+00, top1 50.77, top5 74.97
2021-11-06 01:11:10 train 5000, loss 2.211e+00, top1 50.55, top5 74.78
2021-11-06 01:11:10 train 5000, loss 2.210e+00, top1 50.50, top5 74.84
2021-11-06 01:11:33 valid 0000, loss 1.154e+00, top1 77.65, top5 87.06
2021-11-06 01:11:33 valid 0000, loss 1.154e+00, top1 77.65, top5 87.06
2021-11-06 01:11:33 valid 0000, loss 1.154e+00, top1 77.65, top5 87.06
2021-11-06 01:15:58 (JOBID 31681) epoch 20: train time 2743.08, inference time 274.70s, valid_top1 53.60 (best_top1 61.87), valid_top5 78.83
2021-11-06 01:16:05 (JOBID 31681) epoch 20: train time 2743.34, inference time 281.59s, valid_top1 53.60 (best_top1 61.87), valid_top5 78.83
2021-11-06 01:16:07 (JOBID 31681) epoch 20: train time 2743.37, inference time 284.20s, valid_top1 53.60 (best_top1 61.87), valid_top5 78.83
2021-11-06 01:16:19 train 0000, loss 1.950e+00, top1 52.94, top5 77.65
2021-11-06 01:16:12 train 0000, loss 2.589e+00, top1 43.53, top5 67.06
2021-11-06 01:16:21 train 0000, loss 2.101e+00, top1 57.65, top5 78.82
2021-11-06 01:25:31 train 1000, loss 2.182e+00, top1 51.01, top5 75.06
2021-11-06 01:25:31 train 1000, loss 2.178e+00, top1 50.93, top5 75.28
2021-11-06 01:25:31 train 1000, loss 2.186e+00, top1 51.04, top5 75.09
2021-11-06 01:34:38 train 2000, loss 2.190e+00, top1 50.88, top5 75.16
2021-11-06 01:34:38 train 2000, loss 2.189e+00, top1 50.82, top5 75.04
2021-11-06 01:34:38 train 2000, loss 2.192e+00, top1 50.80, top5 75.07
2021-11-06 01:43:43 train 3000, loss 2.195e+00, top1 50.65, top5 74.94
2021-11-06 01:43:43 train 3000, loss 2.195e+00, top1 50.81, top5 75.04
2021-11-06 01:43:43 train 3000, loss 2.194e+00, top1 50.79, top5 75.02
2021-11-06 01:52:47 train 4000, loss 2.197e+00, top1 50.75, top5 75.01
2021-11-06 01:52:47 train 4000, loss 2.199e+00, top1 50.70, top5 74.99
2021-11-06 01:52:47 train 4000, loss 2.199e+00, top1 50.65, top5 74.88
2021-11-06 02:01:48 train 5000, loss 2.203e+00, top1 50.60, top5 74.84
2021-11-06 02:01:48 train 5000, loss 2.208e+00, top1 50.58, top5 74.88
2021-11-06 02:01:48 train 5000, loss 2.202e+00, top1 50.64, top5 74.92
2021-11-06 02:02:11 valid 0000, loss 1.528e+00, top1 62.35, top5 88.24
2021-11-06 02:02:11 valid 0000, loss 1.528e+00, top1 62.35, top5 88.24
2021-11-06 02:02:11 valid 0000, loss 1.528e+00, top1 62.35, top5 88.24
2021-11-06 02:06:36 (JOBID 31681) epoch 21: train time 2756.68, inference time 275.04s, valid_top1 52.50 (best_top1 61.87), valid_top5 78.11
2021-11-06 02:06:40 (JOBID 31681) epoch 21: train time 2754.04, inference time 278.48s, valid_top1 52.50 (best_top1 61.87), valid_top5 78.11
2021-11-06 02:06:40 (JOBID 31681) epoch 21: train time 2763.55, inference time 278.67s, valid_top1 52.50 (best_top1 61.87), valid_top5 78.11
2021-11-06 02:06:54 train 0000, loss 2.344e+00, top1 54.12, top5 67.06
2021-11-06 02:06:51 train 0000, loss 1.900e+00, top1 56.47, top5 77.65
2021-11-06 02:06:54 train 0000, loss 1.924e+00, top1 60.00, top5 77.65
2021-11-06 02:16:04 train 1000, loss 2.181e+00, top1 51.00, top5 75.32
2021-11-06 02:16:04 train 1000, loss 2.182e+00, top1 50.95, top5 75.22
2021-11-06 02:16:04 train 1000, loss 2.187e+00, top1 51.06, top5 75.05
2021-11-06 02:25:10 train 2000, loss 2.190e+00, top1 50.87, top5 75.06
2021-11-06 02:25:10 train 2000, loss 2.194e+00, top1 50.76, top5 75.05
2021-11-06 02:25:10 train 2000, loss 2.195e+00, top1 50.88, top5 74.99
2021-11-06 02:34:14 train 3000, loss 2.197e+00, top1 50.73, top5 74.98
2021-11-06 02:34:14 train 3000, loss 2.194e+00, top1 50.72, top5 75.11
2021-11-06 02:34:14 train 3000, loss 2.198e+00, top1 50.74, top5 74.97
2021-11-06 02:43:16 train 4000, loss 2.199e+00, top1 50.65, top5 75.05
2021-11-06 02:43:16 train 4000, loss 2.200e+00, top1 50.63, top5 74.93
2021-11-06 02:43:16 train 4000, loss 2.201e+00, top1 50.70, top5 74.94
2021-11-06 02:52:14 train 5000, loss 2.205e+00, top1 50.50, top5 74.95
2021-11-06 02:52:14 train 5000, loss 2.205e+00, top1 50.60, top5 74.89
2021-11-06 02:52:14 train 5000, loss 2.203e+00, top1 50.62, top5 74.88
2021-11-06 02:52:37 valid 0000, loss 1.327e+00, top1 67.06, top5 87.06
2021-11-06 02:52:37 valid 0000, loss 1.327e+00, top1 67.06, top5 87.06
2021-11-06 02:52:37 valid 0000, loss 1.327e+00, top1 67.06, top5 87.06
2021-11-06 02:56:55 (JOBID 31681) epoch 22: train time 2747.38, inference time 267.86s, valid_top1 52.28 (best_top1 61.87), valid_top5 77.79
2021-11-06 02:57:05 (JOBID 31681) epoch 22: train time 2750.87, inference time 277.45s, valid_top1 52.28 (best_top1 61.87), valid_top5 77.79
2021-11-06 02:57:09 (JOBID 31681) epoch 22: train time 2746.96, inference time 280.94s, valid_top1 52.28 (best_top1 61.87), valid_top5 77.79
2021-11-06 02:57:19 train 0000, loss 1.633e+00, top1 54.12, top5 84.71
2021-11-06 02:57:09 train 0000, loss 1.958e+00, top1 54.12, top5 78.82
2021-11-06 02:57:23 train 0000, loss 2.313e+00, top1 44.71, top5 72.94
2021-11-06 03:06:31 train 1000, loss 2.196e+00, top1 50.81, top5 75.01
2021-11-06 03:06:31 train 1000, loss 2.178e+00, top1 50.95, top5 75.28
2021-11-06 03:06:32 train 1000, loss 2.192e+00, top1 50.87, top5 75.03
2021-11-06 03:15:34 train 2000, loss 2.184e+00, top1 50.97, top5 75.18
2021-11-06 03:15:34 train 2000, loss 2.201e+00, top1 50.67, top5 74.94
2021-11-06 03:15:34 train 2000, loss 2.193e+00, top1 50.81, top5 75.12
2021-11-06 03:24:36 train 3000, loss 2.190e+00, top1 50.91, top5 75.11
2021-11-06 03:24:36 train 3000, loss 2.201e+00, top1 50.65, top5 74.95
2021-11-06 03:24:36 train 3000, loss 2.197e+00, top1 50.69, top5 75.06
2021-11-06 03:33:35 train 4000, loss 2.196e+00, top1 50.79, top5 75.01
2021-11-06 03:33:35 train 4000, loss 2.204e+00, top1 50.55, top5 74.89
2021-11-06 03:33:35 train 4000, loss 2.202e+00, top1 50.64, top5 74.96
2021-11-06 03:42:32 train 5000, loss 2.203e+00, top1 50.69, top5 74.90
2021-11-06 03:42:31 train 5000, loss 2.205e+00, top1 50.52, top5 74.86
2021-11-06 03:42:32 train 5000, loss 2.204e+00, top1 50.60, top5 74.89
2021-11-06 03:42:55 valid 0000, loss 1.418e+00, top1 72.94, top5 88.24
2021-11-06 03:42:55 valid 0000, loss 1.418e+00, top1 72.94, top5 88.24
2021-11-06 03:42:55 valid 0000, loss 1.418e+00, top1 72.94, top5 88.24
2021-11-06 03:47:26 (JOBID 31681) epoch 23: train time 2749.84, inference time 281.54s, valid_top1 54.25 (best_top1 61.87), valid_top5 79.29
2021-11-06 03:47:26 (JOBID 31681) epoch 23: train time 2740.21, inference time 281.56s, valid_top1 54.25 (best_top1 61.87), valid_top5 79.29
2021-11-06 03:47:27 (JOBID 31681) epoch 23: train time 2736.19, inference time 281.87s, valid_top1 54.25 (best_top1 61.87), valid_top5 79.29
2021-11-06 03:47:40 train 0000, loss 2.519e+00, top1 45.88, top5 70.59
2021-11-06 03:47:40 train 0000, loss 1.974e+00, top1 54.12, top5 78.82
2021-11-06 03:47:41 train 0000, loss 2.194e+00, top1 50.59, top5 72.94
2021-11-06 03:56:18 train 1000, loss 2.186e+00, top1 50.91, top5 75.04
2021-11-06 03:56:18 train 1000, loss 2.177e+00, top1 50.96, top5 75.36
2021-11-06 03:56:18 train 1000, loss 2.172e+00, top1 51.25, top5 75.24
2021-11-06 04:04:50 train 2000, loss 2.189e+00, top1 50.85, top5 75.07
2021-11-06 04:04:50 train 2000, loss 2.184e+00, top1 50.89, top5 75.13
2021-11-06 04:04:50 train 2000, loss 2.190e+00, top1 50.83, top5 75.00
2021-11-06 04:13:24 train 3000, loss 2.197e+00, top1 50.74, top5 74.98
2021-11-06 04:13:24 train 3000, loss 2.194e+00, top1 50.73, top5 75.00
2021-11-06 04:13:24 train 3000, loss 2.196e+00, top1 50.72, top5 74.94
2021-11-06 04:21:57 train 4000, loss 2.202e+00, top1 50.68, top5 74.94
2021-11-06 04:21:57 train 4000, loss 2.200e+00, top1 50.67, top5 74.94
2021-11-06 04:21:57 train 4000, loss 2.202e+00, top1 50.62, top5 74.88
2021-11-06 04:30:24 train 5000, loss 2.202e+00, top1 50.64, top5 74.89
2021-11-06 04:30:24 train 5000, loss 2.204e+00, top1 50.59, top5 74.85
2021-11-06 04:30:24 train 5000, loss 2.205e+00, top1 50.64, top5 74.88
2021-11-06 04:30:48 valid 0000, loss 7.565e-01, top1 82.35, top5 94.12
2021-11-06 04:30:48 valid 0000, loss 7.565e-01, top1 82.35, top5 94.12
2021-11-06 04:30:48 valid 0000, loss 7.565e-01, top1 82.35, top5 94.12
2021-11-06 04:35:03 (JOBID 31681) epoch 24: train time 2590.62, inference time 266.31s, valid_top1 53.50 (best_top1 61.87), valid_top5 79.25
2021-11-06 04:35:18 (JOBID 31681) epoch 24: train time 2589.95, inference time 280.96s, valid_top1 53.50 (best_top1 61.87), valid_top5 79.25
2021-11-06 04:35:23 (JOBID 31681) epoch 24: train time 2590.61, inference time 285.98s, valid_top1 53.50 (best_top1 61.87), valid_top5 79.25
2021-11-06 04:35:31 train 0000, loss 2.181e+00, top1 48.24, top5 77.65
2021-11-06 04:35:17 train 0000, loss 2.545e+00, top1 47.06, top5 70.59
2021-11-06 04:35:37 train 0000, loss 2.155e+00, top1 47.06, top5 78.82
2021-11-06 04:44:13 train 1000, loss 2.181e+00, top1 51.03, top5 75.22
2021-11-06 04:44:13 train 1000, loss 2.178e+00, top1 51.22, top5 75.26
2021-11-06 04:44:13 train 1000, loss 2.196e+00, top1 50.52, top5 75.16
2021-11-06 04:52:50 train 2000, loss 2.193e+00, top1 50.85, top5 75.00
2021-11-06 04:52:50 train 2000, loss 2.193e+00, top1 50.83, top5 75.04
2021-11-06 04:52:50 train 2000, loss 2.198e+00, top1 50.66, top5 75.07
2021-11-06 05:01:22 train 3000, loss 2.195e+00, top1 50.69, top5 74.92
2021-11-06 05:01:22 train 3000, loss 2.195e+00, top1 50.78, top5 74.97
2021-11-06 05:01:22 train 3000, loss 2.199e+00, top1 50.71, top5 75.04
2021-11-06 05:09:51 train 4000, loss 2.198e+00, top1 50.65, top5 74.92
2021-11-06 05:09:51 train 4000, loss 2.200e+00, top1 50.74, top5 74.90
2021-11-06 05:09:51 train 4000, loss 2.203e+00, top1 50.63, top5 74.96
2021-11-06 05:18:21 train 5000, loss 2.203e+00, top1 50.55, top5 74.89
2021-11-06 05:18:21 train 5000, loss 2.205e+00, top1 50.64, top5 74.82
2021-11-06 05:18:21 train 5000, loss 2.205e+00, top1 50.61, top5 74.91
2021-11-06 05:18:46 valid 0000, loss 1.079e+00, top1 78.82, top5 88.24
2021-11-06 05:18:46 valid 0000, loss 1.079e+00, top1 78.82, top5 88.24
2021-11-06 05:18:46 valid 0000, loss 1.079e+00, top1 78.82, top5 88.24
2021-11-06 05:23:04 (JOBID 31681) epoch 25: train time 2595.22, inference time 270.72s, valid_top1 54.22 (best_top1 61.87), valid_top5 79.48
2021-11-06 05:23:18 (JOBID 31681) epoch 25: train time 2610.05, inference time 284.84s, valid_top1 54.22 (best_top1 61.87), valid_top5 79.48
2021-11-06 05:23:21 (JOBID 31681) epoch 25: train time 2590.36, inference time 287.60s, valid_top1 54.22 (best_top1 61.87), valid_top5 79.48
2021-11-06 05:23:33 train 0000, loss 2.172e+00, top1 54.12, top5 77.65
2021-11-06 05:23:18 train 0000, loss 2.020e+00, top1 52.94, top5 74.12
2021-11-06 05:23:35 train 0000, loss 2.282e+00, top1 45.88, top5 72.94
2021-11-06 05:32:05 train 1000, loss 2.175e+00, top1 51.08, top5 75.32
2021-11-06 05:32:05 train 1000, loss 2.178e+00, top1 50.91, top5 75.38
2021-11-06 05:32:05 train 1000, loss 2.175e+00, top1 51.00, top5 75.44
2021-11-06 05:40:43 train 2000, loss 2.189e+00, top1 50.82, top5 75.05
2021-11-06 05:40:43 train 2000, loss 2.187e+00, top1 50.72, top5 75.17
2021-11-06 05:40:43 train 2000, loss 2.186e+00, top1 50.89, top5 75.13
2021-11-06 05:49:09 train 3000, loss 2.198e+00, top1 50.63, top5 74.98
2021-11-06 05:49:09 train 3000, loss 2.195e+00, top1 50.72, top5 74.97
2021-11-06 05:49:09 train 3000, loss 2.196e+00, top1 50.76, top5 75.00
2021-11-06 05:57:34 train 4000, loss 2.200e+00, top1 50.62, top5 74.92
2021-11-06 05:57:34 train 4000, loss 2.194e+00, top1 50.74, top5 75.04
2021-11-06 05:57:34 train 4000, loss 2.201e+00, top1 50.68, top5 74.92
2021-11-06 06:05:55 train 5000, loss 2.204e+00, top1 50.58, top5 74.87
2021-11-06 06:05:55 train 5000, loss 2.197e+00, top1 50.72, top5 75.02
2021-11-06 06:05:55 train 5000, loss 2.205e+00, top1 50.52, top5 74.84
2021-11-06 06:06:20 valid 0000, loss 8.634e-01, top1 81.18, top5 92.94
2021-11-06 06:06:20 valid 0000, loss 8.634e-01, top1 81.18, top5 92.94
2021-11-06 06:06:20 valid 0000, loss 8.634e-01, top1 81.18, top5 92.94
2021-11-06 06:10:32 (JOBID 31681) epoch 26: train time 2566.77, inference time 264.36s, valid_top1 50.47 (best_top1 61.87), valid_top5 76.03
2021-11-06 06:10:54 (JOBID 31681) epoch 26: train time 2569.54, inference time 286.13s, valid_top1 50.47 (best_top1 61.87), valid_top5 76.03
2021-11-06 06:10:55 (JOBID 31681) epoch 26: train time 2583.21, inference time 287.07s, valid_top1 50.47 (best_top1 61.87), valid_top5 76.03
2021-11-06 06:11:08 train 0000, loss 2.258e+00, top1 50.59, top5 70.59
2021-11-06 06:10:45 train 0000, loss 2.457e+00, top1 49.41, top5 70.59
2021-11-06 06:11:08 train 0000, loss 2.276e+00, top1 49.41, top5 76.47
2021-11-06 06:19:45 train 1000, loss 2.182e+00, top1 50.87, top5 75.29
2021-11-06 06:19:45 train 1000, loss 2.179e+00, top1 50.98, top5 75.08
2021-11-06 06:19:45 train 1000, loss 2.182e+00, top1 50.97, top5 75.42
2021-11-06 06:28:25 train 2000, loss 2.191e+00, top1 50.87, top5 75.10
2021-11-06 06:28:25 train 2000, loss 2.186e+00, top1 50.95, top5 75.06
2021-11-06 06:28:25 train 2000, loss 2.189e+00, top1 50.78, top5 75.16
2021-11-06 06:36:55 train 3000, loss 2.196e+00, top1 50.76, top5 75.03
2021-11-06 06:36:55 train 3000, loss 2.190e+00, top1 50.89, top5 75.10
2021-11-06 06:36:55 train 3000, loss 2.194e+00, top1 50.70, top5 75.07
2021-11-06 06:45:24 train 4000, loss 2.196e+00, top1 50.80, top5 75.03
2021-11-06 06:45:24 train 4000, loss 2.206e+00, top1 50.64, top5 74.89
2021-11-06 06:45:24 train 4000, loss 2.200e+00, top1 50.66, top5 74.97
2021-11-06 06:53:56 train 5000, loss 2.207e+00, top1 50.61, top5 74.85
2021-11-06 06:53:56 train 5000, loss 2.200e+00, top1 50.73, top5 74.95
2021-11-06 06:53:56 train 5000, loss 2.205e+00, top1 50.59, top5 74.87
2021-11-06 06:54:19 valid 0000, loss 8.134e-01, top1 84.71, top5 92.94
2021-11-06 06:54:19 valid 0000, loss 8.134e-01, top1 84.71, top5 92.94
2021-11-06 06:54:19 valid 0000, loss 8.134e-01, top1 84.71, top5 92.94
2021-11-06 06:59:05 (JOBID 31681) epoch 27: train time 2593.61, inference time 296.47s, valid_top1 52.12 (best_top1 61.87), valid_top5 77.74
2021-11-06 06:59:07 (JOBID 31681) epoch 27: train time 2616.54, inference time 298.66s, valid_top1 52.12 (best_top1 61.87), valid_top5 77.74
2021-11-06 06:59:08 (JOBID 31681) epoch 27: train time 2594.79, inference time 299.09s, valid_top1 52.12 (best_top1 61.87), valid_top5 77.74
2021-11-06 06:59:20 train 0000, loss 2.176e+00, top1 51.76, top5 77.65
2021-11-06 06:59:22 train 0000, loss 2.587e+00, top1 44.71, top5 70.59
2021-11-06 06:59:22 train 0000, loss 2.129e+00, top1 48.24, top5 78.82
2021-11-06 07:08:18 train 1000, loss 2.187e+00, top1 51.03, top5 75.11
2021-11-06 07:08:18 train 1000, loss 2.175e+00, top1 51.13, top5 75.45
2021-11-06 07:08:18 train 1000, loss 2.199e+00, top1 50.77, top5 74.92
2021-11-06 07:17:18 train 2000, loss 2.188e+00, top1 50.87, top5 75.23
2021-11-06 07:17:18 train 2000, loss 2.189e+00, top1 50.97, top5 75.08
2021-11-06 07:17:19 train 2000, loss 2.189e+00, top1 50.92, top5 75.13
2021-11-06 07:26:14 train 3000, loss 2.195e+00, top1 50.74, top5 75.08
2021-11-06 07:26:14 train 3000, loss 2.190e+00, top1 50.90, top5 75.03
2021-11-06 07:26:14 train 3000, loss 2.199e+00, top1 50.76, top5 74.95
2021-11-06 07:35:03 train 4000, loss 2.199e+00, top1 50.69, top5 74.99
2021-11-06 07:35:03 train 4000, loss 2.204e+00, top1 50.73, top5 74.88
2021-11-06 07:35:03 train 4000, loss 2.201e+00, top1 50.66, top5 74.86
2021-11-06 07:43:50 train 5000, loss 2.204e+00, top1 50.63, top5 74.92
2021-11-06 07:43:50 train 5000, loss 2.205e+00, top1 50.60, top5 74.81
2021-11-06 07:43:50 train 5000, loss 2.202e+00, top1 50.70, top5 74.88
2021-11-06 07:44:13 valid 0000, loss 1.647e+00, top1 63.53, top5 81.18
2021-11-06 07:44:13 valid 0000, loss 1.647e+00, top1 63.53, top5 81.18
2021-11-06 07:44:13 valid 0000, loss 1.647e+00, top1 63.53, top5 81.18
2021-11-06 07:48:49 (JOBID 31681) epoch 28: train time 2695.82, inference time 285.54s, valid_top1 52.73 (best_top1 61.87), valid_top5 78.29
2021-11-06 07:48:49 (JOBID 31681) epoch 28: train time 2695.40, inference time 285.54s, valid_top1 52.73 (best_top1 61.87), valid_top5 78.29
2021-11-06 07:48:49 (JOBID 31681) epoch 28: train time 2697.70, inference time 285.54s, valid_top1 52.73 (best_top1 61.87), valid_top5 78.29
2021-11-06 07:49:03 train 0000, loss 1.975e+00, top1 51.76, top5 77.65
2021-11-06 07:49:03 train 0000, loss 1.872e+00, top1 51.76, top5 77.65
2021-11-06 07:49:03 train 0000, loss 2.238e+00, top1 44.71, top5 76.47
2021-11-06 07:57:40 train 1000, loss 2.186e+00, top1 50.95, top5 75.12
2021-11-06 07:57:40 train 1000, loss 2.169e+00, top1 51.22, top5 75.42
2021-11-06 07:57:40 train 1000, loss 2.189e+00, top1 50.68, top5 75.07
2021-11-06 08:06:27 train 2000, loss 2.181e+00, top1 50.96, top5 75.22
2021-11-06 08:06:27 train 2000, loss 2.193e+00, top1 50.77, top5 75.02
2021-11-06 08:06:27 train 2000, loss 2.196e+00, top1 50.70, top5 75.03
2021-11-06 08:15:05 train 3000, loss 2.197e+00, top1 50.69, top5 74.99
2021-11-06 08:15:05 train 3000, loss 2.193e+00, top1 50.73, top5 75.05
2021-11-06 08:15:05 train 3000, loss 2.199e+00, top1 50.65, top5 74.98
2021-11-06 08:23:37 train 4000, loss 2.201e+00, top1 50.62, top5 74.94
2021-11-06 08:23:37 train 4000, loss 2.197e+00, top1 50.62, top5 74.97
2021-11-06 08:23:38 train 4000, loss 2.201e+00, top1 50.64, top5 74.92
2021-11-06 08:32:06 train 5000, loss 2.206e+00, top1 50.51, top5 74.84
2021-11-06 08:32:06 train 5000, loss 2.200e+00, top1 50.60, top5 74.92
2021-11-06 08:32:06 train 5000, loss 2.202e+00, top1 50.60, top5 74.89
2021-11-06 08:32:29 valid 0000, loss 1.043e+00, top1 80.00, top5 87.06
2021-11-06 08:32:29 valid 0000, loss 1.043e+00, top1 80.00, top5 87.06
2021-11-06 08:32:29 valid 0000, loss 1.043e+00, top1 80.00, top5 87.06
2021-11-06 08:37:16 (JOBID 31681) epoch 29: train time 2610.09, inference time 296.26s, valid_top1 53.69 (best_top1 61.87), valid_top5 78.76
2021-11-06 08:37:16 (JOBID 31681) epoch 29: train time 2610.28, inference time 296.98s, valid_top1 53.69 (best_top1 61.87), valid_top5 78.76
2021-11-06 08:37:19 (JOBID 31681) epoch 29: train time 2610.29, inference time 299.88s, valid_top1 53.69 (best_top1 61.87), valid_top5 78.76
2021-11-06 08:37:30 train 0000, loss 2.284e+00, top1 47.06, top5 72.94
2021-11-06 08:37:30 train 0000, loss 1.909e+00, top1 58.82, top5 81.18
2021-11-06 08:37:33 train 0000, loss 2.058e+00, top1 56.47, top5 75.29
2021-11-06 08:46:26 train 1000, loss 1.795e+00, top1 58.96, top5 80.90
2021-11-06 08:46:26 train 1000, loss 1.813e+00, top1 58.85, top5 80.49
2021-11-06 08:46:26 train 1000, loss 1.805e+00, top1 58.81, top5 80.74
2021-11-06 08:55:29 train 2000, loss 1.749e+00, top1 59.96, top5 81.54
2021-11-06 08:55:29 train 2000, loss 1.762e+00, top1 59.85, top5 81.20
2021-11-06 08:55:29 train 2000, loss 1.749e+00, top1 60.01, top5 81.47
2021-11-06 09:04:19 train 3000, loss 1.732e+00, top1 60.44, top5 81.71
2021-11-06 09:04:19 train 3000, loss 1.719e+00, top1 60.57, top5 81.93
2021-11-06 09:04:19 train 3000, loss 1.722e+00, top1 60.49, top5 81.91
2021-11-06 09:13:05 train 4000, loss 1.702e+00, top1 60.87, top5 82.20
2021-11-06 09:13:05 train 4000, loss 1.711e+00, top1 60.83, top5 82.02
2021-11-06 09:13:05 train 4000, loss 1.702e+00, top1 60.88, top5 82.18
2021-11-06 09:21:53 train 5000, loss 1.686e+00, top1 61.17, top5 82.42
2021-11-06 09:21:53 train 5000, loss 1.695e+00, top1 61.13, top5 82.26
2021-11-06 09:21:53 train 5000, loss 1.687e+00, top1 61.17, top5 82.38
2021-11-06 09:22:16 valid 0000, loss 7.024e-01, top1 83.53, top5 92.94
2021-11-06 09:22:16 valid 0000, loss 7.024e-01, top1 83.53, top5 92.94
2021-11-06 09:22:16 valid 0000, loss 7.024e-01, top1 83.53, top5 92.94
2021-11-06 09:27:21 (JOBID 31681) epoch 30: train time 2690.23, inference time 315.29s, valid_top1 67.60 (best_top1 67.60), valid_top5 88.20
2021-11-06 09:27:22 (JOBID 31681) epoch 30: train time 2687.31, inference time 315.88s, valid_top1 67.60 (best_top1 67.60), valid_top5 88.20
2021-11-06 09:27:22 (JOBID 31681) epoch 30: train time 2690.65, inference time 315.28s, valid_top1 67.60 (best_top1 67.60), valid_top5 88.20
2021-11-06 09:27:36 train 0000, loss 1.633e+00, top1 62.35, top5 80.00
2021-11-06 09:27:36 train 0000, loss 1.395e+00, top1 68.24, top5 81.18
2021-11-06 09:27:37 train 0000, loss 1.230e+00, top1 71.76, top5 87.06
2021-11-06 09:36:43 train 1000, loss 1.604e+00, top1 62.89, top5 83.51
2021-11-06 09:36:43 train 1000, loss 1.596e+00, top1 63.01, top5 83.62
2021-11-06 09:36:43 train 1000, loss 1.587e+00, top1 63.22, top5 83.85
2021-11-06 09:45:53 train 2000, loss 1.591e+00, top1 63.00, top5 83.69
2021-11-06 09:45:53 train 2000, loss 1.597e+00, top1 63.05, top5 83.60
2021-11-06 09:45:53 train 2000, loss 1.588e+00, top1 63.14, top5 83.82
2021-11-06 09:55:02 train 3000, loss 1.587e+00, top1 63.15, top5 83.77
2021-11-06 09:55:02 train 3000, loss 1.591e+00, top1 63.07, top5 83.68
2021-11-06 09:55:02 train 3000, loss 1.584e+00, top1 63.20, top5 83.82
2021-11-06 10:04:08 train 4000, loss 1.584e+00, top1 63.25, top5 83.80
2021-11-06 10:04:08 train 4000, loss 1.583e+00, top1 63.25, top5 83.81
2021-11-06 10:04:08 train 4000, loss 1.584e+00, top1 63.24, top5 83.85
2021-11-06 10:13:10 train 5000, loss 1.581e+00, top1 63.31, top5 83.85
2021-11-06 10:13:10 train 5000, loss 1.578e+00, top1 63.37, top5 83.88
2021-11-06 10:13:10 train 5000, loss 1.581e+00, top1 63.30, top5 83.88
2021-11-06 10:13:34 valid 0000, loss 5.841e-01, top1 89.41, top5 95.29
2021-11-06 10:13:34 valid 0000, loss 5.841e-01, top1 89.41, top5 95.29
2021-11-06 10:13:34 valid 0000, loss 5.841e-01, top1 89.41, top5 95.29
2021-11-06 10:18:14 (JOBID 31681) epoch 31: train time 2761.79, inference time 289.83s, valid_top1 68.34 (best_top1 68.34), valid_top5 88.61
2021-11-06 10:18:20 (JOBID 31681) epoch 31: train time 2761.84, inference time 295.50s, valid_top1 68.34 (best_top1 68.34), valid_top5 88.61
2021-11-06 10:18:25 (JOBID 31681) epoch 31: train time 2762.37, inference time 301.20s, valid_top1 68.34 (best_top1 68.34), valid_top5 88.61
2021-11-06 10:18:33 train 0000, loss 1.463e+00, top1 61.18, top5 83.53
2021-11-06 10:18:27 train 0000, loss 1.725e+00, top1 64.71, top5 82.35
2021-11-06 10:18:39 train 0000, loss 1.494e+00, top1 65.88, top5 87.06
2021-11-06 10:27:56 train 1000, loss 1.530e+00, top1 64.30, top5 84.57
2021-11-06 10:27:56 train 1000, loss 1.530e+00, top1 64.31, top5 84.60
2021-11-06 10:27:56 train 1000, loss 1.534e+00, top1 64.29, top5 84.59
2021-11-06 10:37:10 train 2000, loss 1.535e+00, top1 64.23, top5 84.46
2021-11-06 10:37:10 train 2000, loss 1.538e+00, top1 64.26, top5 84.55
2021-11-06 10:37:10 train 2000, loss 1.535e+00, top1 64.29, top5 84.50
2021-11-06 10:46:17 train 3000, loss 1.537e+00, top1 64.19, top5 84.45
2021-11-06 10:46:17 train 3000, loss 1.532e+00, top1 64.41, top5 84.55
2021-11-06 10:46:17 train 3000, loss 1.538e+00, top1 64.23, top5 84.52
2021-11-06 10:55:20 train 4000, loss 1.537e+00, top1 64.21, top5 84.54
2021-11-06 10:55:19 train 4000, loss 1.537e+00, top1 64.24, top5 84.44
2021-11-06 10:55:20 train 4000, loss 1.534e+00, top1 64.36, top5 84.53
2021-11-06 11:04:21 train 5000, loss 1.537e+00, top1 64.22, top5 84.46
2021-11-06 11:04:21 train 5000, loss 1.535e+00, top1 64.32, top5 84.48
2021-11-06 11:04:21 train 5000, loss 1.535e+00, top1 64.20, top5 84.57
2021-11-06 11:04:45 valid 0000, loss 5.872e-01, top1 85.88, top5 94.12
2021-11-06 11:04:45 valid 0000, loss 5.872e-01, top1 85.88, top5 94.12
2021-11-06 11:04:45 valid 0000, loss 5.872e-01, top1 85.88, top5 94.12
2021-11-06 11:09:07 (JOBID 31681) epoch 32: train time 2774.97, inference time 271.88s, valid_top1 68.58 (best_top1 68.58), valid_top5 88.82
2021-11-06 11:09:17 (JOBID 31681) epoch 32: train time 2781.35, inference time 281.54s, valid_top1 68.58 (best_top1 68.58), valid_top5 88.82
2021-11-06 11:09:18 (JOBID 31681) epoch 32: train time 2769.80, inference time 283.15s, valid_top1 68.58 (best_top1 68.58), valid_top5 88.82
2021-11-06 11:09:31 train 0000, loss 1.573e+00, top1 68.24, top5 83.53
2021-11-06 11:09:21 train 0000, loss 1.849e+00, top1 55.29, top5 77.65
2021-11-06 11:09:32 train 0000, loss 1.650e+00, top1 61.18, top5 83.53
2021-11-06 11:18:38 train 1000, loss 1.504e+00, top1 64.72, top5 84.98
2021-11-06 11:18:38 train 1000, loss 1.517e+00, top1 64.66, top5 84.76
2021-11-06 11:18:38 train 1000, loss 1.504e+00, top1 65.11, top5 85.02
2021-11-06 11:27:45 train 2000, loss 1.511e+00, top1 64.68, top5 84.85
2021-11-06 11:27:46 train 2000, loss 1.510e+00, top1 64.90, top5 84.88
2021-11-06 11:27:46 train 2000, loss 1.517e+00, top1 64.61, top5 84.80
2021-11-06 11:36:54 train 3000, loss 1.512e+00, top1 64.68, top5 84.85
2021-11-06 11:36:54 train 3000, loss 1.513e+00, top1 64.83, top5 84.80
2021-11-06 11:36:54 train 3000, loss 1.518e+00, top1 64.63, top5 84.78
2021-11-06 11:46:09 train 4000, loss 1.515e+00, top1 64.75, top5 84.77
2021-11-06 11:46:09 train 4000, loss 1.512e+00, top1 64.67, top5 84.85
2021-11-06 11:46:09 train 4000, loss 1.518e+00, top1 64.66, top5 84.76
2021-11-06 11:55:24 train 5000, loss 1.512e+00, top1 64.68, top5 84.87
2021-11-06 11:55:24 train 5000, loss 1.513e+00, top1 64.79, top5 84.79
2021-11-06 11:55:24 train 5000, loss 1.515e+00, top1 64.71, top5 84.77
2021-11-06 11:55:48 valid 0000, loss 6.165e-01, top1 83.53, top5 95.29
2021-11-06 11:55:48 valid 0000, loss 6.165e-01, top1 83.53, top5 95.29
2021-11-06 11:55:48 valid 0000, loss 6.165e-01, top1 83.53, top5 95.29
2021-11-06 12:00:13 (JOBID 31681) epoch 33: train time 2781.06, inference time 274.98s, valid_top1 69.13 (best_top1 69.13), valid_top5 89.20
2021-11-06 12:00:15 (JOBID 31681) epoch 33: train time 2779.63, inference time 276.95s, valid_top1 69.13 (best_top1 69.13), valid_top5 89.20
2021-11-06 12:00:15 (JOBID 31681) epoch 33: train time 2790.35, inference time 276.43s, valid_top1 69.13 (best_top1 69.13), valid_top5 89.20
2021-11-06 12:00:29 train 0000, loss 1.503e+00, top1 63.53, top5 87.06
2021-11-06 12:00:27 train 0000, loss 1.330e+00, top1 68.24, top5 88.24
2021-11-06 12:00:29 train 0000, loss 1.817e+00, top1 55.29, top5 81.18
2021-11-06 12:09:42 train 1000, loss 1.482e+00, top1 65.38, top5 85.27
2021-11-06 12:09:42 train 1000, loss 1.483e+00, top1 65.29, top5 85.15
2021-11-06 12:09:42 train 1000, loss 1.481e+00, top1 65.53, top5 85.15
2021-11-06 12:18:44 train 2000, loss 1.497e+00, top1 65.04, top5 84.98
2021-11-06 12:18:44 train 2000, loss 1.490e+00, top1 65.22, top5 85.15
2021-11-06 12:18:45 train 2000, loss 1.490e+00, top1 65.13, top5 85.04
2021-11-06 12:27:48 train 3000, loss 1.497e+00, top1 65.05, top5 85.00
2021-11-06 12:27:48 train 3000, loss 1.496e+00, top1 65.05, top5 84.99
2021-11-06 12:27:48 train 3000, loss 1.496e+00, top1 65.03, top5 84.96
2021-11-06 12:36:52 train 4000, loss 1.500e+00, top1 65.00, top5 84.94
2021-11-06 12:36:52 train 4000, loss 1.499e+00, top1 64.97, top5 84.94
2021-11-06 12:36:52 train 4000, loss 1.496e+00, top1 64.98, top5 84.98
2021-11-06 12:45:55 train 5000, loss 1.499e+00, top1 64.95, top5 84.92
2021-11-06 12:45:55 train 5000, loss 1.502e+00, top1 64.96, top5 84.91
2021-11-06 12:45:55 train 5000, loss 1.497e+00, top1 64.97, top5 84.98
2021-11-06 12:46:19 valid 0000, loss 6.473e-01, top1 84.71, top5 95.29
2021-11-06 12:46:19 valid 0000, loss 6.473e-01, top1 84.71, top5 95.29
2021-11-06 12:46:19 valid 0000, loss 6.473e-01, top1 84.71, top5 95.29
2021-11-06 12:50:44 (JOBID 31681) epoch 34: train time 2754.26, inference time 275.21s, valid_top1 69.28 (best_top1 69.28), valid_top5 89.25
2021-11-06 12:50:45 (JOBID 31681) epoch 34: train time 2754.32, inference time 275.70s, valid_top1 69.28 (best_top1 69.28), valid_top5 89.25
2021-11-06 12:50:49 (JOBID 31681) epoch 34: train time 2756.22, inference time 280.13s, valid_top1 69.28 (best_top1 69.28), valid_top5 89.25
2021-11-06 12:50:59 train 0000, loss 1.676e+00, top1 63.53, top5 83.53
2021-11-06 12:50:59 train 0000, loss 1.421e+00, top1 65.88, top5 88.24
2021-11-06 12:51:03 train 0000, loss 1.268e+00, top1 68.24, top5 87.06
2021-11-06 13:00:22 train 1000, loss 1.481e+00, top1 65.46, top5 85.21
2021-11-06 13:00:22 train 1000, loss 1.474e+00, top1 65.66, top5 85.48
2021-11-06 13:00:23 train 1000, loss 1.476e+00, top1 65.49, top5 85.40
2021-11-06 13:09:46 train 2000, loss 1.476e+00, top1 65.56, top5 85.41
2021-11-06 13:09:46 train 2000, loss 1.484e+00, top1 65.33, top5 85.22
2021-11-06 13:09:46 train 2000, loss 1.483e+00, top1 65.29, top5 85.28
2021-11-06 13:18:49 train 3000, loss 1.480e+00, top1 65.36, top5 85.34
2021-11-06 13:18:49 train 3000, loss 1.485e+00, top1 65.32, top5 85.22
2021-11-06 13:18:49 train 3000, loss 1.488e+00, top1 65.17, top5 85.17
2021-11-06 13:27:49 train 4000, loss 1.486e+00, top1 65.23, top5 85.24
2021-11-06 13:27:49 train 4000, loss 1.487e+00, top1 65.24, top5 85.20
2021-11-06 13:27:49 train 4000, loss 1.488e+00, top1 65.18, top5 85.17
2021-11-06 13:36:49 train 5000, loss 1.487e+00, top1 65.20, top5 85.23
2021-11-06 13:36:49 train 5000, loss 1.491e+00, top1 65.15, top5 85.14
2021-11-06 13:36:49 train 5000, loss 1.489e+00, top1 65.15, top5 85.16
2021-11-06 13:37:13 valid 0000, loss 6.268e-01, top1 84.71, top5 96.47
2021-11-06 13:37:13 valid 0000, loss 6.268e-01, top1 84.71, top5 96.47
2021-11-06 13:37:13 valid 0000, loss 6.268e-01, top1 84.71, top5 96.47
2021-11-06 13:42:00 (JOBID 31681) epoch 35: train time 2773.75, inference time 297.16s, valid_top1 69.30 (best_top1 69.30), valid_top5 89.21
2021-11-06 13:42:00 (JOBID 31681) epoch 35: train time 2778.66, inference time 297.63s, valid_top1 69.30 (best_top1 69.30), valid_top5 89.21
2021-11-06 13:42:01 (JOBID 31681) epoch 35: train time 2777.62, inference time 297.53s, valid_top1 69.30 (best_top1 69.30), valid_top5 89.21
2021-11-06 13:42:14 train 0000, loss 1.503e+00, top1 62.35, top5 83.53
2021-11-06 13:42:14 train 0000, loss 1.730e+00, top1 61.18, top5 77.65
2021-11-06 13:42:14 train 0000, loss 1.313e+00, top1 69.41, top5 87.06
2021-11-06 13:51:36 train 1000, loss 1.465e+00, top1 65.59, top5 85.56
2021-11-06 13:51:36 train 1000, loss 1.468e+00, top1 65.58, top5 85.42
2021-11-06 13:51:36 train 1000, loss 1.473e+00, top1 65.53, top5 85.39
2021-11-06 14:00:44 train 2000, loss 1.478e+00, top1 65.51, top5 85.30
2021-11-06 14:00:44 train 2000, loss 1.474e+00, top1 65.45, top5 85.36
2021-11-06 14:00:44 train 2000, loss 1.477e+00, top1 65.35, top5 85.35
2021-11-06 14:09:52 train 3000, loss 1.484e+00, top1 65.22, top5 85.22
2021-11-06 14:09:52 train 3000, loss 1.478e+00, top1 65.39, top5 85.31
2021-11-06 14:09:52 train 3000, loss 1.473e+00, top1 65.42, top5 85.38
2021-11-06 14:19:03 train 4000, loss 1.482e+00, top1 65.30, top5 85.25
2021-11-06 14:19:03 train 4000, loss 1.486e+00, top1 65.18, top5 85.18
2021-11-06 14:19:04 train 4000, loss 1.478e+00, top1 65.36, top5 85.33
2021-11-06 14:28:15 train 5000, loss 1.488e+00, top1 65.16, top5 85.17
2021-11-06 14:28:14 train 5000, loss 1.483e+00, top1 65.26, top5 85.24
2021-11-06 14:28:15 train 5000, loss 1.482e+00, top1 65.27, top5 85.28
2021-11-06 14:28:38 valid 0000, loss 5.856e-01, top1 84.71, top5 91.76
2021-11-06 14:28:38 valid 0000, loss 5.856e-01, top1 84.71, top5 91.76
2021-11-06 14:28:38 valid 0000, loss 5.856e-01, top1 84.71, top5 91.76
2021-11-06 14:32:43 (JOBID 31681) epoch 36: train time 2788.14, inference time 255.24s, valid_top1 69.06 (best_top1 69.30), valid_top5 89.08
2021-11-06 14:33:20 (JOBID 31681) epoch 36: train time 2787.67, inference time 291.62s, valid_top1 69.06 (best_top1 69.30), valid_top5 89.08
2021-11-06 14:33:23 (JOBID 31681) epoch 36: train time 2787.17, inference time 295.13s, valid_top1 69.06 (best_top1 69.30), valid_top5 89.08
2021-11-06 14:32:56 train 0000, loss 1.167e+00, top1 71.76, top5 88.24
2021-11-06 14:33:34 train 0000, loss 1.484e+00, top1 56.47, top5 87.06
2021-11-06 14:33:38 train 0000, loss 1.621e+00, top1 67.06, top5 84.71
2021-11-06 14:42:59 train 1000, loss 1.469e+00, top1 65.54, top5 85.48
2021-11-06 14:42:59 train 1000, loss 1.456e+00, top1 65.66, top5 85.71
2021-11-06 14:42:59 train 1000, loss 1.467e+00, top1 65.71, top5 85.53
2021-11-06 14:52:16 train 2000, loss 1.471e+00, top1 65.43, top5 85.46
2021-11-06 14:52:16 train 2000, loss 1.472e+00, top1 65.44, top5 85.42
2021-11-06 14:52:16 train 2000, loss 1.471e+00, top1 65.59, top5 85.43
2021-11-06 15:01:29 train 3000, loss 1.475e+00, top1 65.34, top5 85.34
2021-11-06 15:01:29 train 3000, loss 1.477e+00, top1 65.28, top5 85.38
2021-11-06 15:01:30 train 3000, loss 1.476e+00, top1 65.43, top5 85.33
2021-11-06 15:10:48 train 4000, loss 1.478e+00, top1 65.33, top5 85.29
2021-11-06 15:10:48 train 4000, loss 1.480e+00, top1 65.21, top5 85.33
2021-11-06 15:10:48 train 4000, loss 1.478e+00, top1 65.43, top5 85.32
2021-11-06 15:19:55 train 5000, loss 1.482e+00, top1 65.26, top5 85.21
2021-11-06 15:19:55 train 5000, loss 1.480e+00, top1 65.39, top5 85.28
2021-11-06 15:19:55 train 5000, loss 1.483e+00, top1 65.17, top5 85.29
2021-11-06 15:20:19 valid 0000, loss 7.412e-01, top1 81.18, top5 92.94
2021-11-06 15:20:19 valid 0000, loss 7.412e-01, top1 81.18, top5 92.94
2021-11-06 15:20:19 valid 0000, loss 7.412e-01, top1 81.18, top5 92.94
2021-11-06 15:24:32 (JOBID 31681) epoch 37: train time 2845.79, inference time 262.98s, valid_top1 68.66 (best_top1 69.30), valid_top5 88.94
2021-11-06 15:24:50 (JOBID 31681) epoch 37: train time 2809.41, inference time 280.98s, valid_top1 68.66 (best_top1 69.30), valid_top5 88.94
2021-11-06 15:24:51 (JOBID 31681) epoch 37: train time 2805.58, inference time 281.42s, valid_top1 68.66 (best_top1 69.30), valid_top5 88.94
2021-11-06 15:24:45 train 0000, loss 1.917e+00, top1 67.06, top5 78.82
2021-11-06 15:25:04 train 0000, loss 1.417e+00, top1 60.00, top5 87.06
2021-11-06 15:25:04 train 0000, loss 1.466e+00, top1 70.59, top5 87.06
2021-11-06 15:34:17 train 1000, loss 1.460e+00, top1 65.65, top5 85.58
2021-11-06 15:34:17 train 1000, loss 1.464e+00, top1 65.72, top5 85.56
2021-11-06 15:34:17 train 1000, loss 1.481e+00, top1 65.23, top5 85.35
2021-11-06 15:43:33 train 2000, loss 1.469e+00, top1 65.66, top5 85.46
2021-11-06 15:43:33 train 2000, loss 1.467e+00, top1 65.53, top5 85.53
2021-11-06 15:43:33 train 2000, loss 1.476e+00, top1 65.43, top5 85.36
2021-11-06 15:52:42 train 3000, loss 1.480e+00, top1 65.35, top5 85.27
2021-11-06 15:52:42 train 3000, loss 1.470e+00, top1 65.41, top5 85.44
2021-11-06 15:52:42 train 3000, loss 1.474e+00, top1 65.52, top5 85.36
2021-11-06 16:01:44 train 4000, loss 1.475e+00, top1 65.34, top5 85.38
2021-11-06 16:01:44 train 4000, loss 1.484e+00, top1 65.28, top5 85.21
2021-11-06 16:01:45 train 4000, loss 1.480e+00, top1 65.37, top5 85.28
2021-11-06 16:10:36 train 5000, loss 1.478e+00, top1 65.31, top5 85.31
2021-11-06 16:10:37 train 5000, loss 1.480e+00, top1 65.40, top5 85.29
2021-11-06 16:10:37 train 5000, loss 1.485e+00, top1 65.22, top5 85.21
2021-11-06 16:11:00 valid 0000, loss 5.965e-01, top1 84.71, top5 92.94
2021-11-06 16:11:00 valid 0000, loss 5.965e-01, top1 84.71, top5 92.94
2021-11-06 16:11:00 valid 0000, loss 5.965e-01, top1 84.71, top5 92.94
2021-11-06 16:15:25 (JOBID 31681) epoch 38: train time 2777.93, inference time 275.48s, valid_top1 68.79 (best_top1 69.30), valid_top5 89.01
2021-11-06 16:15:28 (JOBID 31681) epoch 38: train time 2759.28, inference time 277.89s, valid_top1 68.79 (best_top1 69.30), valid_top5 89.01
2021-11-06 16:15:31 (JOBID 31681) epoch 38: train time 2759.98, inference time 280.91s, valid_top1 68.79 (best_top1 69.30), valid_top5 89.01
2021-11-06 16:15:43 train 0000, loss 1.260e+00, top1 67.06, top5 84.71
2021-11-06 16:15:40 train 0000, loss 1.471e+00, top1 63.53, top5 88.24
2021-11-06 16:15:46 train 0000, loss 1.347e+00, top1 69.41, top5 89.41
2021-11-06 16:24:48 train 1000, loss 1.464e+00, top1 65.88, top5 85.48
2021-11-06 16:24:48 train 1000, loss 1.470e+00, top1 65.57, top5 85.44
2021-11-06 16:24:48 train 1000, loss 1.461e+00, top1 65.78, top5 85.49
2021-11-06 16:33:50 train 2000, loss 1.474e+00, top1 65.48, top5 85.39
2021-11-06 16:33:50 train 2000, loss 1.469e+00, top1 65.53, top5 85.42
2021-11-06 16:33:50 train 2000, loss 1.464e+00, top1 65.83, top5 85.49
2021-11-06 16:42:49 train 3000, loss 1.471e+00, top1 65.45, top5 85.37
2021-11-06 16:42:49 train 3000, loss 1.476e+00, top1 65.43, top5 85.34
2021-11-06 16:42:49 train 3000, loss 1.471e+00, top1 65.61, top5 85.41
2021-11-06 16:51:56 train 4000, loss 1.479e+00, top1 65.39, top5 85.30
2021-11-06 16:51:55 train 4000, loss 1.477e+00, top1 65.35, top5 85.33
2021-11-06 16:51:56 train 4000, loss 1.473e+00, top1 65.54, top5 85.40
2021-11-06 17:00:52 train 5000, loss 1.479e+00, top1 65.31, top5 85.30
2021-11-06 17:00:52 train 5000, loss 1.482e+00, top1 65.29, top5 85.27
2021-11-06 17:00:52 train 5000, loss 1.480e+00, top1 65.44, top5 85.29
2021-11-06 17:01:16 valid 0000, loss 6.272e-01, top1 83.53, top5 94.12
2021-11-06 17:01:16 valid 0000, loss 6.272e-01, top1 83.53, top5 94.12
2021-11-06 17:01:16 valid 0000, loss 6.272e-01, top1 83.53, top5 94.12
2021-11-06 17:05:34 (JOBID 31681) epoch 39: train time 2740.10, inference time 268.73s, valid_top1 69.01 (best_top1 69.30), valid_top5 89.30
2021-11-06 17:05:40 (JOBID 31681) epoch 39: train time 2734.61, inference time 274.77s, valid_top1 69.01 (best_top1 69.30), valid_top5 89.30
2021-11-06 17:05:43 (JOBID 31681) epoch 39: train time 2737.41, inference time 276.76s, valid_top1 69.01 (best_top1 69.30), valid_top5 89.30
2021-11-06 17:05:55 train 0000, loss 1.479e+00, top1 65.88, top5 87.06
2021-11-06 17:05:49 train 0000, loss 1.727e+00, top1 61.18, top5 82.35
2021-11-06 17:05:57 train 0000, loss 1.626e+00, top1 64.71, top5 84.71
2021-11-06 17:14:59 train 1000, loss 1.471e+00, top1 65.56, top5 85.36
2021-11-06 17:14:59 train 1000, loss 1.461e+00, top1 65.64, top5 85.58
2021-11-06 17:14:59 train 1000, loss 1.456e+00, top1 65.68, top5 85.72
2021-11-06 17:24:05 train 2000, loss 1.461e+00, top1 65.62, top5 85.62
2021-11-06 17:24:05 train 2000, loss 1.471e+00, top1 65.38, top5 85.42
2021-11-06 17:24:05 train 2000, loss 1.471e+00, top1 65.54, top5 85.41
2021-11-06 17:33:08 train 3000, loss 1.478e+00, top1 65.38, top5 85.31
2021-11-06 17:33:08 train 3000, loss 1.475e+00, top1 65.32, top5 85.38
2021-11-06 17:33:08 train 3000, loss 1.468e+00, top1 65.51, top5 85.52
2021-11-06 17:42:12 train 4000, loss 1.472e+00, top1 65.43, top5 85.44
2021-11-06 17:42:12 train 4000, loss 1.479e+00, top1 65.31, top5 85.34
2021-11-06 17:42:12 train 4000, loss 1.479e+00, top1 65.38, top5 85.29
2021-11-06 17:51:14 train 5000, loss 1.483e+00, top1 65.22, top5 85.28
2021-11-06 17:51:14 train 5000, loss 1.478e+00, top1 65.32, top5 85.36
2021-11-06 17:51:14 train 5000, loss 1.482e+00, top1 65.28, top5 85.25
2021-11-06 17:51:37 valid 0000, loss 7.923e-01, top1 84.71, top5 91.76
2021-11-06 17:51:37 valid 0000, loss 7.923e-01, top1 84.71, top5 91.76
2021-11-06 17:51:37 valid 0000, loss 7.923e-01, top1 84.71, top5 91.76
2021-11-06 17:56:02 (JOBID 31681) epoch 40: train time 2744.57, inference time 274.64s, valid_top1 68.99 (best_top1 69.30), valid_top5 89.11
2021-11-06 17:56:07 (JOBID 31681) epoch 40: train time 2746.97, inference time 280.22s, valid_top1 68.99 (best_top1 69.30), valid_top5 89.11
2021-11-06 17:56:08 (JOBID 31681) epoch 40: train time 2752.95, inference time 280.39s, valid_top1 68.99 (best_top1 69.30), valid_top5 89.11
2021-11-06 17:56:16 train 0000, loss 9.601e-01, top1 74.12, top5 92.94
2021-11-06 17:56:21 train 0000, loss 1.255e+00, top1 71.76, top5 89.41
2021-11-06 17:56:21 train 0000, loss 1.675e+00, top1 62.35, top5 82.35
2021-11-06 18:05:24 train 1000, loss 1.464e+00, top1 65.58, top5 85.43
2021-11-06 18:05:24 train 1000, loss 1.469e+00, top1 65.55, top5 85.35
2021-11-06 18:05:24 train 1000, loss 1.468e+00, top1 65.49, top5 85.33
2021-11-06 18:14:28 train 2000, loss 1.468e+00, top1 65.53, top5 85.37
2021-11-06 18:14:28 train 2000, loss 1.470e+00, top1 65.51, top5 85.36
2021-11-06 18:14:28 train 2000, loss 1.479e+00, top1 65.45, top5 85.24
2021-11-06 18:23:30 train 3000, loss 1.483e+00, top1 65.28, top5 85.18
2021-11-06 18:23:30 train 3000, loss 1.470e+00, top1 65.55, top5 85.37
2021-11-06 18:23:30 train 3000, loss 1.473e+00, top1 65.42, top5 85.34
2021-11-06 18:32:33 train 4000, loss 1.475e+00, top1 65.38, top5 85.31
2021-11-06 18:32:33 train 4000, loss 1.476e+00, top1 65.36, top5 85.29
2021-11-06 18:32:33 train 4000, loss 1.488e+00, top1 65.15, top5 85.11
2021-11-06 18:41:35 train 5000, loss 1.480e+00, top1 65.24, top5 85.27
2021-11-06 18:41:35 train 5000, loss 1.489e+00, top1 65.11, top5 85.13
2021-11-06 18:41:35 train 5000, loss 1.480e+00, top1 65.29, top5 85.27
2021-11-06 18:41:58 valid 0000, loss 7.048e-01, top1 82.35, top5 91.76
2021-11-06 18:41:58 valid 0000, loss 7.048e-01, top1 82.35, top5 91.76
2021-11-06 18:41:58 valid 0000, loss 7.048e-01, top1 82.35, top5 91.76
2021-11-06 18:46:07 (JOBID 31681) epoch 41: train time 2746.25, inference time 258.56s, valid_top1 68.73 (best_top1 69.30), valid_top5 88.89
2021-11-06 18:46:44 (JOBID 31681) epoch 41: train time 2740.80, inference time 296.05s, valid_top1 68.73 (best_top1 69.30), valid_top5 88.89
2021-11-06 18:46:45 (JOBID 31681) epoch 41: train time 2740.69, inference time 297.14s, valid_top1 68.73 (best_top1 69.30), valid_top5 88.89
2021-11-06 18:46:21 train 0000, loss 1.711e+00, top1 58.82, top5 85.88
2021-11-06 18:46:58 train 0000, loss 1.251e+00, top1 65.88, top5 89.41
2021-11-06 18:46:58 train 0000, loss 1.586e+00, top1 70.59, top5 82.35
2021-11-06 18:56:05 train 1000, loss 1.472e+00, top1 65.45, top5 85.32
2021-11-06 18:56:05 train 1000, loss 1.460e+00, top1 65.68, top5 85.50
2021-11-06 18:56:05 train 1000, loss 1.473e+00, top1 65.34, top5 85.44
2021-11-06 19:05:10 train 2000, loss 1.469e+00, top1 65.46, top5 85.40
2021-11-06 19:05:10 train 2000, loss 1.477e+00, top1 65.40, top5 85.30
2021-11-06 19:05:11 train 2000, loss 1.480e+00, top1 65.34, top5 85.28
2021-11-06 19:14:16 train 3000, loss 1.470e+00, top1 65.45, top5 85.40
2021-11-06 19:14:16 train 3000, loss 1.481e+00, top1 65.31, top5 85.27
2021-11-06 19:14:16 train 3000, loss 1.483e+00, top1 65.23, top5 85.24
2021-11-06 19:23:23 train 4000, loss 1.487e+00, top1 65.17, top5 85.21
2021-11-06 19:23:23 train 4000, loss 1.478e+00, top1 65.28, top5 85.30
2021-11-06 19:23:23 train 4000, loss 1.484e+00, top1 65.22, top5 85.20
2021-11-06 19:32:26 train 5000, loss 1.481e+00, top1 65.25, top5 85.24
2021-11-06 19:32:26 train 5000, loss 1.488e+00, top1 65.12, top5 85.20
2021-11-06 19:32:26 train 5000, loss 1.488e+00, top1 65.15, top5 85.16
2021-11-06 19:32:49 valid 0000, loss 6.054e-01, top1 88.24, top5 92.94
2021-11-06 19:32:49 valid 0000, loss 6.054e-01, top1 88.24, top5 92.94
2021-11-06 19:32:49 valid 0000, loss 6.054e-01, top1 88.24, top5 92.94
2021-11-06 19:37:13 (JOBID 31681) epoch 42: train time 2792.26, inference time 272.94s, valid_top1 68.25 (best_top1 69.30), valid_top5 88.68
2021-11-06 19:37:24 (JOBID 31681) epoch 42: train time 2753.97, inference time 284.69s, valid_top1 68.25 (best_top1 69.30), valid_top5 88.68
2021-11-06 19:37:25 (JOBID 31681) epoch 42: train time 2754.94, inference time 285.69s, valid_top1 68.25 (best_top1 69.30), valid_top5 88.68
2021-11-06 19:37:26 train 0000, loss 1.409e+00, top1 65.88, top5 83.53
2021-11-06 19:37:38 train 0000, loss 1.422e+00, top1 65.88, top5 83.53
2021-11-06 19:37:38 train 0000, loss 1.363e+00, top1 64.71, top5 87.06
2021-11-06 19:46:42 train 1000, loss 1.468e+00, top1 65.65, top5 85.26
2021-11-06 19:46:42 train 1000, loss 1.464e+00, top1 65.53, top5 85.48
2021-11-06 19:46:42 train 1000, loss 1.460e+00, top1 65.72, top5 85.61
2021-11-06 19:55:47 train 2000, loss 1.473e+00, top1 65.55, top5 85.26
2021-11-06 19:55:47 train 2000, loss 1.477e+00, top1 65.31, top5 85.32
2021-11-06 19:55:47 train 2000, loss 1.474e+00, top1 65.44, top5 85.42
2021-11-06 20:04:52 train 3000, loss 1.480e+00, top1 65.28, top5 85.31
2021-11-06 20:04:52 train 3000, loss 1.479e+00, top1 65.29, top5 85.35
2021-11-06 20:04:52 train 3000, loss 1.476e+00, top1 65.45, top5 85.25
2021-11-06 20:13:58 train 4000, loss 1.485e+00, top1 65.19, top5 85.24
2021-11-06 20:13:58 train 4000, loss 1.478e+00, top1 65.41, top5 85.21
2021-11-06 20:13:58 train 4000, loss 1.482e+00, top1 65.23, top5 85.32
2021-11-06 20:22:57 train 5000, loss 1.487e+00, top1 65.16, top5 85.22
2021-11-06 20:22:57 train 5000, loss 1.481e+00, top1 65.28, top5 85.19
2021-11-06 20:22:57 train 5000, loss 1.487e+00, top1 65.15, top5 85.26
2021-11-06 20:23:22 valid 0000, loss 6.090e-01, top1 87.06, top5 94.12
2021-11-06 20:23:22 valid 0000, loss 6.090e-01, top1 87.06, top5 94.12
2021-11-06 20:23:22 valid 0000, loss 6.090e-01, top1 87.06, top5 94.12
2021-11-06 20:27:54 (JOBID 31681) epoch 43: train time 2745.56, inference time 283.70s, valid_top1 68.53 (best_top1 69.30), valid_top5 89.00
2021-11-06 20:27:54 (JOBID 31681) epoch 43: train time 2757.97, inference time 283.63s, valid_top1 68.53 (best_top1 69.30), valid_top5 89.00
2021-11-06 20:27:55 (JOBID 31681) epoch 43: train time 2746.35, inference time 285.02s, valid_top1 68.53 (best_top1 69.30), valid_top5 89.00
2021-11-06 20:28:11 train 0000, loss 1.215e+00, top1 68.24, top5 89.41
2021-11-06 20:28:11 train 0000, loss 1.432e+00, top1 58.82, top5 85.88
2021-11-06 20:28:11 train 0000, loss 1.342e+00, top1 67.06, top5 88.24
2021-11-06 20:38:22 train 1000, loss 1.463e+00, top1 65.57, top5 85.58
2021-11-06 20:38:22 train 1000, loss 1.467e+00, top1 65.40, top5 85.49
2021-11-06 20:38:23 train 1000, loss 1.470e+00, top1 65.34, top5 85.44
2021-11-06 20:47:49 train 2000, loss 1.476e+00, top1 65.36, top5 85.34
2021-11-06 20:47:49 train 2000, loss 1.480e+00, top1 65.19, top5 85.32
2021-11-06 20:47:49 train 2000, loss 1.476e+00, top1 65.43, top5 85.38
2021-11-06 20:56:46 train 3000, loss 1.483e+00, top1 65.10, top5 85.30
2021-11-06 20:56:46 train 3000, loss 1.479e+00, top1 65.30, top5 85.27
2021-11-06 20:56:47 train 3000, loss 1.480e+00, top1 65.31, top5 85.31
2021-11-06 21:05:36 train 4000, loss 1.485e+00, top1 65.06, top5 85.24
2021-11-06 21:05:36 train 4000, loss 1.479e+00, top1 65.31, top5 85.31
2021-11-06 21:05:37 train 4000, loss 1.484e+00, top1 65.21, top5 85.24
2021-11-06 21:14:26 train 5000, loss 1.488e+00, top1 65.03, top5 85.21
2021-11-06 21:14:26 train 5000, loss 1.484e+00, top1 65.20, top5 85.24
2021-11-06 21:14:26 train 5000, loss 1.488e+00, top1 65.12, top5 85.17
2021-11-06 21:14:51 valid 0000, loss 5.997e-01, top1 82.35, top5 94.12
2021-11-06 21:14:51 valid 0000, loss 5.997e-01, top1 82.35, top5 94.12
2021-11-06 21:14:51 valid 0000, loss 5.997e-01, top1 82.35, top5 94.12
2021-11-06 21:19:06 (JOBID 31681) epoch 44: train time 2804.39, inference time 266.87s, valid_top1 68.20 (best_top1 69.30), valid_top5 88.77
2021-11-06 21:19:24 (JOBID 31681) epoch 44: train time 2804.58, inference time 285.44s, valid_top1 68.20 (best_top1 69.30), valid_top5 88.77
2021-11-06 21:19:25 (JOBID 31681) epoch 44: train time 2803.39, inference time 286.38s, valid_top1 68.20 (best_top1 69.30), valid_top5 88.77
2021-11-06 21:19:21 train 0000, loss 1.407e+00, top1 67.06, top5 84.71
2021-11-06 21:19:38 train 0000, loss 1.457e+00, top1 67.06, top5 84.71
2021-11-06 21:19:38 train 0000, loss 1.345e+00, top1 67.06, top5 83.53
2021-11-06 21:28:33 train 1000, loss 1.469e+00, top1 65.53, top5 85.38
2021-11-06 21:28:33 train 1000, loss 1.476e+00, top1 65.46, top5 85.27
2021-11-06 21:28:33 train 1000, loss 1.459e+00, top1 65.64, top5 85.61
2021-11-06 21:37:30 train 2000, loss 1.477e+00, top1 65.32, top5 85.36
2021-11-06 21:37:30 train 2000, loss 1.475e+00, top1 65.40, top5 85.28
2021-11-06 21:37:30 train 2000, loss 1.475e+00, top1 65.34, top5 85.38
2021-11-06 21:46:23 train 3000, loss 1.483e+00, top1 65.25, top5 85.27
2021-11-06 21:46:23 train 3000, loss 1.480e+00, top1 65.23, top5 85.25
2021-11-06 21:46:23 train 3000, loss 1.476e+00, top1 65.35, top5 85.34
2021-11-06 21:55:20 train 4000, loss 1.485e+00, top1 65.13, top5 85.21
2021-11-06 21:55:20 train 4000, loss 1.486e+00, top1 65.16, top5 85.24
2021-11-06 21:55:20 train 4000, loss 1.483e+00, top1 65.24, top5 85.28
2021-11-06 22:04:12 train 5000, loss 1.490e+00, top1 65.09, top5 85.17
2021-11-06 22:04:12 train 5000, loss 1.491e+00, top1 65.05, top5 85.12
2021-11-06 22:04:12 train 5000, loss 1.486e+00, top1 65.18, top5 85.22
2021-11-06 22:04:36 valid 0000, loss 6.097e-01, top1 85.88, top5 92.94
2021-11-06 22:04:36 valid 0000, loss 6.097e-01, top1 85.88, top5 92.94
2021-11-06 22:04:36 valid 0000, loss 6.097e-01, top1 85.88, top5 92.94
2021-11-06 22:09:07 (JOBID 31681) epoch 45: train time 2700.25, inference time 281.98s, valid_top1 68.63 (best_top1 69.30), valid_top5 88.78
2021-11-06 22:09:07 (JOBID 31681) epoch 45: train time 2701.18, inference time 281.99s, valid_top1 68.63 (best_top1 69.30), valid_top5 88.78
2021-11-06 22:09:08 (JOBID 31681) epoch 45: train time 2719.44, inference time 281.96s, valid_top1 68.63 (best_top1 69.30), valid_top5 88.78
2021-11-06 22:09:22 train 0000, loss 1.275e+00, top1 65.88, top5 87.06
2021-11-06 22:09:22 train 0000, loss 1.248e+00, top1 67.06, top5 90.59
2021-11-06 22:09:23 train 0000, loss 1.449e+00, top1 67.06, top5 84.71
2021-11-06 22:18:37 train 1000, loss 1.457e+00, top1 65.84, top5 85.56
2021-11-06 22:18:37 train 1000, loss 1.466e+00, top1 65.65, top5 85.53
2021-11-06 22:18:37 train 1000, loss 1.483e+00, top1 65.48, top5 85.23
2021-11-06 22:27:42 train 2000, loss 1.489e+00, top1 65.30, top5 85.21
2021-11-06 22:27:42 train 2000, loss 1.474e+00, top1 65.47, top5 85.40
2021-11-06 22:27:42 train 2000, loss 1.478e+00, top1 65.39, top5 85.23
2021-11-06 22:36:46 train 3000, loss 1.482e+00, top1 65.27, top5 85.19
2021-11-06 22:36:46 train 3000, loss 1.481e+00, top1 65.28, top5 85.31
2021-11-06 22:36:46 train 3000, loss 1.490e+00, top1 65.20, top5 85.20
2021-11-06 22:45:49 train 4000, loss 1.486e+00, top1 65.15, top5 85.25
2021-11-06 22:45:50 train 4000, loss 1.491e+00, top1 65.17, top5 85.15
2021-11-06 22:45:50 train 4000, loss 1.483e+00, top1 65.23, top5 85.22
2021-11-06 22:54:51 train 5000, loss 1.493e+00, top1 65.14, top5 85.12
2021-11-06 22:54:51 train 5000, loss 1.489e+00, top1 65.07, top5 85.21
2021-11-06 22:54:51 train 5000, loss 1.487e+00, top1 65.11, top5 85.17
2021-11-06 22:55:14 valid 0000, loss 7.744e-01, top1 84.71, top5 92.94
2021-11-06 22:55:14 valid 0000, loss 7.744e-01, top1 84.71, top5 92.94
2021-11-06 22:55:14 valid 0000, loss 7.744e-01, top1 84.71, top5 92.94
2021-11-06 22:59:37 (JOBID 31681) epoch 46: train time 2756.78, inference time 272.52s, valid_top1 68.89 (best_top1 69.30), valid_top5 88.82
2021-11-06 22:59:38 (JOBID 31681) epoch 46: train time 2756.71, inference time 273.32s, valid_top1 68.89 (best_top1 69.30), valid_top5 88.82
2021-11-06 22:59:41 (JOBID 31681) epoch 46: train time 2756.32, inference time 276.54s, valid_top1 68.89 (best_top1 69.30), valid_top5 88.82
2021-11-06 22:59:52 train 0000, loss 1.702e+00, top1 60.00, top5 82.35
2021-11-06 22:59:52 train 0000, loss 1.148e+00, top1 68.24, top5 91.76
2021-11-06 22:59:55 train 0000, loss 1.477e+00, top1 69.41, top5 84.71
2021-11-06 23:08:55 train 1000, loss 1.459e+00, top1 65.54, top5 85.60
2021-11-06 23:08:55 train 1000, loss 1.474e+00, top1 65.52, top5 85.52
2021-11-06 23:08:55 train 1000, loss 1.477e+00, top1 65.46, top5 85.37
2021-11-06 23:17:55 train 2000, loss 1.467e+00, top1 65.46, top5 85.46
2021-11-06 23:17:55 train 2000, loss 1.481e+00, top1 65.30, top5 85.36
2021-11-06 23:17:55 train 2000, loss 1.480e+00, top1 65.31, top5 85.39
2021-11-06 23:26:57 train 3000, loss 1.489e+00, top1 65.13, top5 85.23
2021-11-06 23:26:57 train 3000, loss 1.475e+00, top1 65.33, top5 85.31
2021-11-06 23:26:57 train 3000, loss 1.484e+00, top1 65.23, top5 85.33
2021-11-06 23:35:58 train 4000, loss 1.489e+00, top1 65.07, top5 85.25
2021-11-06 23:35:58 train 4000, loss 1.481e+00, top1 65.23, top5 85.25
2021-11-06 23:35:58 train 4000, loss 1.488e+00, top1 65.15, top5 85.23
2021-11-06 23:44:58 train 5000, loss 1.491e+00, top1 65.02, top5 85.22
2021-11-06 23:44:58 train 5000, loss 1.485e+00, top1 65.15, top5 85.22
2021-11-06 23:44:58 train 5000, loss 1.492e+00, top1 65.09, top5 85.17
2021-11-06 23:45:22 valid 0000, loss 6.596e-01, top1 84.71, top5 91.76
2021-11-06 23:45:22 valid 0000, loss 6.596e-01, top1 84.71, top5 91.76
2021-11-06 23:45:22 valid 0000, loss 6.596e-01, top1 84.71, top5 91.76
2021-11-06 23:49:46 (JOBID 31681) epoch 47: train time 2730.92, inference time 274.00s, valid_top1 68.77 (best_top1 69.30), valid_top5 88.91
2021-11-06 23:49:54 (JOBID 31681) epoch 47: train time 2735.08, inference time 281.98s, valid_top1 68.77 (best_top1 69.30), valid_top5 88.91
2021-11-06 23:49:59 (JOBID 31681) epoch 47: train time 2734.32, inference time 287.02s, valid_top1 68.77 (best_top1 69.30), valid_top5 88.91
2021-11-06 23:50:07 train 0000, loss 1.358e+00, top1 62.35, top5 87.06
2021-11-06 23:50:00 train 0000, loss 1.755e+00, top1 62.35, top5 81.18
2021-11-06 23:50:13 train 0000, loss 1.635e+00, top1 64.71, top5 83.53
2021-11-06 23:59:05 train 1000, loss 1.466e+00, top1 65.59, top5 85.45
2021-11-06 23:59:05 train 1000, loss 1.474e+00, top1 65.53, top5 85.37
2021-11-06 23:59:06 train 1000, loss 1.460e+00, top1 65.48, top5 85.52
2021-11-07 00:07:59 train 2000, loss 1.482e+00, top1 65.29, top5 85.27
2021-11-07 00:07:59 train 2000, loss 1.481e+00, top1 65.28, top5 85.24
2021-11-07 00:07:59 train 2000, loss 1.474e+00, top1 65.36, top5 85.36
2021-11-07 00:16:52 train 3000, loss 1.482e+00, top1 65.24, top5 85.26
2021-11-07 00:16:52 train 3000, loss 1.486e+00, top1 65.15, top5 85.19
2021-11-07 00:16:53 train 3000, loss 1.481e+00, top1 65.15, top5 85.30
2021-11-07 00:25:46 train 4000, loss 1.485e+00, top1 65.16, top5 85.22
2021-11-07 00:25:46 train 4000, loss 1.489e+00, top1 65.10, top5 85.13
2021-11-07 00:25:46 train 4000, loss 1.484e+00, top1 65.09, top5 85.28
2021-11-07 00:34:41 train 5000, loss 1.492e+00, top1 65.03, top5 85.12
2021-11-07 00:34:41 train 5000, loss 1.490e+00, top1 65.07, top5 85.11
2021-11-07 00:34:41 train 5000, loss 1.486e+00, top1 65.10, top5 85.27
2021-11-07 00:35:04 valid 0000, loss 6.848e-01, top1 85.88, top5 88.24
2021-11-07 00:35:04 valid 0000, loss 6.848e-01, top1 85.88, top5 88.24
2021-11-07 00:35:04 valid 0000, loss 6.848e-01, top1 85.88, top5 88.24
2021-11-07 00:39:19 (JOBID 31681) epoch 48: train time 2707.83, inference time 264.80s, valid_top1 67.99 (best_top1 69.30), valid_top5 88.68
2021-11-07 00:39:40 (JOBID 31681) epoch 48: train time 2700.09, inference time 286.05s, valid_top1 67.99 (best_top1 69.30), valid_top5 88.68
2021-11-07 00:39:40 (JOBID 31681) epoch 48: train time 2695.09, inference time 286.22s, valid_top1 67.99 (best_top1 69.30), valid_top5 88.68
2021-11-07 00:39:32 train 0000, loss 1.594e+00, top1 63.53, top5 81.18
2021-11-07 00:39:53 train 0000, loss 1.402e+00, top1 64.71, top5 83.53
2021-11-07 00:39:53 train 0000, loss 1.125e+00, top1 70.59, top5 89.41
2021-11-07 00:48:55 train 1000, loss 1.459e+00, top1 65.66, top5 85.70
2021-11-07 00:48:55 train 1000, loss 1.472e+00, top1 65.32, top5 85.51
2021-11-07 00:48:55 train 1000, loss 1.468e+00, top1 65.56, top5 85.43
2021-11-07 00:57:56 train 2000, loss 1.473e+00, top1 65.44, top5 85.41
2021-11-07 00:57:56 train 2000, loss 1.481e+00, top1 65.23, top5 85.36
2021-11-07 00:57:56 train 2000, loss 1.474e+00, top1 65.44, top5 85.43
2021-11-07 01:06:55 train 3000, loss 1.487e+00, top1 65.10, top5 85.25
2021-11-07 01:06:56 train 3000, loss 1.479e+00, top1 65.25, top5 85.35
2021-11-07 01:06:56 train 3000, loss 1.483e+00, top1 65.27, top5 85.23
2021-11-07 01:15:54 train 4000, loss 1.489e+00, top1 65.16, top5 85.17
2021-11-07 01:15:54 train 4000, loss 1.490e+00, top1 65.04, top5 85.18
2021-11-07 01:15:54 train 4000, loss 1.485e+00, top1 65.17, top5 85.22
2021-11-07 01:24:53 train 5000, loss 1.492e+00, top1 65.06, top5 85.15
2021-11-07 01:24:53 train 5000, loss 1.491e+00, top1 65.01, top5 85.17
2021-11-07 01:24:53 train 5000, loss 1.486e+00, top1 65.11, top5 85.22
2021-11-07 01:25:17 valid 0000, loss 5.841e-01, top1 87.06, top5 94.12
2021-11-07 01:25:17 valid 0000, loss 5.841e-01, top1 87.06, top5 94.12
2021-11-07 01:25:17 valid 0000, loss 5.841e-01, top1 87.06, top5 94.12
2021-11-07 01:29:45 (JOBID 31681) epoch 49: train time 2726.14, inference time 278.18s, valid_top1 67.74 (best_top1 69.30), valid_top5 88.48
2021-11-07 01:29:46 (JOBID 31681) epoch 49: train time 2747.15, inference time 279.06s, valid_top1 67.74 (best_top1 69.30), valid_top5 88.48
2021-11-07 01:29:47 (JOBID 31681) epoch 49: train time 2726.30, inference time 280.88s, valid_top1 67.74 (best_top1 69.30), valid_top5 88.48
2021-11-07 01:29:59 train 0000, loss 1.637e+00, top1 62.35, top5 80.00
2021-11-07 01:29:59 train 0000, loss 1.354e+00, top1 68.24, top5 85.88
2021-11-07 01:30:02 train 0000, loss 1.584e+00, top1 62.35, top5 84.71
2021-11-07 01:39:04 train 1000, loss 1.472e+00, top1 65.36, top5 85.51
2021-11-07 01:39:05 train 1000, loss 1.462e+00, top1 65.73, top5 85.54
2021-11-07 01:39:05 train 1000, loss 1.479e+00, top1 65.26, top5 85.38
2021-11-07 01:48:08 train 2000, loss 1.474e+00, top1 65.31, top5 85.36
2021-11-07 01:48:08 train 2000, loss 1.474e+00, top1 65.36, top5 85.35
2021-11-07 01:48:08 train 2000, loss 1.483e+00, top1 65.17, top5 85.38
2021-11-07 01:57:12 train 3000, loss 1.484e+00, top1 65.16, top5 85.18
2021-11-07 01:57:13 train 3000, loss 1.480e+00, top1 65.25, top5 85.30
2021-11-07 01:57:13 train 3000, loss 1.485e+00, top1 65.20, top5 85.30
2021-11-07 02:06:16 train 4000, loss 1.484e+00, top1 65.18, top5 85.20
2021-11-07 02:06:16 train 4000, loss 1.482e+00, top1 65.22, top5 85.27
2021-11-07 02:06:16 train 4000, loss 1.486e+00, top1 65.18, top5 85.24
2021-11-07 02:15:21 train 5000, loss 1.491e+00, top1 65.03, top5 85.17
2021-11-07 02:15:20 train 5000, loss 1.484e+00, top1 65.13, top5 85.19
2021-11-07 02:15:21 train 5000, loss 1.485e+00, top1 65.15, top5 85.26
2021-11-07 02:15:44 valid 0000, loss 6.424e-01, top1 83.53, top5 95.29
2021-11-07 02:15:44 valid 0000, loss 6.424e-01, top1 83.53, top5 95.29
2021-11-07 02:15:44 valid 0000, loss 6.424e-01, top1 83.53, top5 95.29
2021-11-07 02:20:15 (JOBID 31681) epoch 50: train time 2746.97, inference time 280.36s, valid_top1 67.85 (best_top1 69.30), valid_top5 88.67
2021-11-07 02:20:15 (JOBID 31681) epoch 50: train time 2748.52, inference time 280.36s, valid_top1 67.85 (best_top1 69.30), valid_top5 88.67
2021-11-07 02:20:15 (JOBID 31681) epoch 50: train time 2749.68, inference time 280.83s, valid_top1 67.85 (best_top1 69.30), valid_top5 88.67
2021-11-07 02:20:29 train 0000, loss 1.647e+00, top1 61.18, top5 81.18
2021-11-07 02:20:29 train 0000, loss 1.583e+00, top1 62.35, top5 84.71
2021-11-07 02:20:29 train 0000, loss 1.502e+00, top1 67.06, top5 81.18
2021-11-07 02:29:23 train 1000, loss 1.472e+00, top1 65.32, top5 85.49
2021-11-07 02:29:23 train 1000, loss 1.452e+00, top1 65.71, top5 85.71
2021-11-07 02:29:24 train 1000, loss 1.475e+00, top1 65.17, top5 85.44
2021-11-07 02:38:15 train 2000, loss 1.467e+00, top1 65.41, top5 85.45
2021-11-07 02:38:15 train 2000, loss 1.474e+00, top1 65.37, top5 85.47
2021-11-07 02:38:15 train 2000, loss 1.479e+00, top1 65.29, top5 85.37
2021-11-07 02:47:05 train 3000, loss 1.479e+00, top1 65.30, top5 85.33
2021-11-07 02:47:05 train 3000, loss 1.473e+00, top1 65.33, top5 85.39
2021-11-07 02:47:05 train 3000, loss 1.478e+00, top1 65.29, top5 85.36
2021-11-07 02:55:57 train 4000, loss 1.484e+00, top1 65.19, top5 85.29
2021-11-07 02:55:57 train 4000, loss 1.479e+00, top1 65.22, top5 85.32
2021-11-07 02:55:58 train 4000, loss 1.483e+00, top1 65.17, top5 85.27
2021-11-07 03:04:53 train 5000, loss 1.485e+00, top1 65.17, top5 85.25
2021-11-07 03:04:53 train 5000, loss 1.482e+00, top1 65.15, top5 85.27
2021-11-07 03:04:53 train 5000, loss 1.486e+00, top1 65.10, top5 85.23
2021-11-07 03:05:17 valid 0000, loss 6.076e-01, top1 83.53, top5 94.12
2021-11-07 03:05:17 valid 0000, loss 6.076e-01, top1 83.53, top5 94.12
2021-11-07 03:05:17 valid 0000, loss 6.076e-01, top1 83.53, top5 94.12
2021-11-07 03:09:45 (JOBID 31681) epoch 51: train time 2691.71, inference time 278.02s, valid_top1 68.84 (best_top1 69.30), valid_top5 89.05
2021-11-07 03:09:45 (JOBID 31681) epoch 51: train time 2692.17, inference time 278.57s, valid_top1 68.84 (best_top1 69.30), valid_top5 89.05
2021-11-07 03:09:46 (JOBID 31681) epoch 51: train time 2691.95, inference time 278.63s, valid_top1 68.84 (best_top1 69.30), valid_top5 89.05
2021-11-07 03:10:00 train 0000, loss 1.422e+00, top1 72.94, top5 88.24
2021-11-07 03:10:00 train 0000, loss 1.637e+00, top1 57.65, top5 82.35
2021-11-07 03:10:00 train 0000, loss 1.291e+00, top1 70.59, top5 88.24
2021-11-07 03:19:02 train 1000, loss 1.466e+00, top1 65.51, top5 85.46
2021-11-07 03:19:02 train 1000, loss 1.454e+00, top1 65.68, top5 85.69
2021-11-07 03:19:02 train 1000, loss 1.462e+00, top1 65.68, top5 85.54
2021-11-07 03:27:57 train 2000, loss 1.469e+00, top1 65.34, top5 85.44
2021-11-07 03:27:57 train 2000, loss 1.469e+00, top1 65.45, top5 85.40
2021-11-07 03:27:58 train 2000, loss 1.471e+00, top1 65.42, top5 85.48
2021-11-07 03:36:52 train 3000, loss 1.474e+00, top1 65.28, top5 85.39
2021-11-07 03:36:52 train 3000, loss 1.478e+00, top1 65.29, top5 85.29
2021-11-07 03:36:53 train 3000, loss 1.475e+00, top1 65.31, top5 85.43
2021-11-07 03:45:48 train 4000, loss 1.479e+00, top1 65.16, top5 85.33
2021-11-07 03:45:48 train 4000, loss 1.483e+00, top1 65.14, top5 85.25
2021-11-07 03:45:49 train 4000, loss 1.480e+00, top1 65.25, top5 85.33
2021-11-07 03:54:46 train 5000, loss 1.481e+00, top1 65.15, top5 85.29
2021-11-07 03:54:46 train 5000, loss 1.486e+00, top1 65.08, top5 85.19
2021-11-07 03:54:46 train 5000, loss 1.485e+00, top1 65.16, top5 85.24
2021-11-07 03:55:09 valid 0000, loss 6.453e-01, top1 87.06, top5 92.94
2021-11-07 03:55:09 valid 0000, loss 6.453e-01, top1 87.06, top5 92.94
2021-11-07 03:55:09 valid 0000, loss 6.453e-01, top1 87.06, top5 92.94
2021-11-07 03:59:37 (JOBID 31681) epoch 52: train time 2714.24, inference time 277.31s, valid_top1 68.54 (best_top1 69.30), valid_top5 88.89
2021-11-07 03:59:37 (JOBID 31681) epoch 52: train time 2713.96, inference time 277.23s, valid_top1 68.54 (best_top1 69.30), valid_top5 88.89
2021-11-07 03:59:38 (JOBID 31681) epoch 52: train time 2714.77, inference time 278.61s, valid_top1 68.54 (best_top1 69.30), valid_top5 88.89
2021-11-07 03:59:51 train 0000, loss 1.464e+00, top1 70.59, top5 85.88
2021-11-07 03:59:51 train 0000, loss 1.374e+00, top1 74.12, top5 84.71
2021-11-07 03:59:53 train 0000, loss 1.985e+00, top1 58.82, top5 76.47
2021-11-07 04:08:59 train 1000, loss 1.466e+00, top1 65.64, top5 85.46
2021-11-07 04:08:59 train 1000, loss 1.470e+00, top1 65.34, top5 85.59
2021-11-07 04:08:59 train 1000, loss 1.461e+00, top1 65.63, top5 85.55
2021-11-07 04:18:05 train 2000, loss 1.466e+00, top1 65.59, top5 85.50
2021-11-07 04:18:05 train 2000, loss 1.477e+00, top1 65.38, top5 85.38
2021-11-07 04:18:05 train 2000, loss 1.473e+00, top1 65.31, top5 85.43
2021-11-07 04:27:10 train 3000, loss 1.474e+00, top1 65.40, top5 85.36
2021-11-07 04:27:10 train 3000, loss 1.481e+00, top1 65.25, top5 85.31
2021-11-07 04:27:10 train 3000, loss 1.478e+00, top1 65.21, top5 85.38
2021-11-07 04:36:11 train 4000, loss 1.481e+00, top1 65.16, top5 85.32
2021-11-07 04:36:12 train 4000, loss 1.477e+00, top1 65.32, top5 85.32
2021-11-07 04:36:12 train 4000, loss 1.486e+00, top1 65.12, top5 85.26
2021-11-07 04:45:14 train 5000, loss 1.486e+00, top1 65.10, top5 85.25
2021-11-07 04:45:14 train 5000, loss 1.481e+00, top1 65.29, top5 85.28
2021-11-07 04:45:14 train 5000, loss 1.490e+00, top1 65.08, top5 85.17
2021-11-07 04:45:39 valid 0000, loss 7.886e-01, top1 83.53, top5 90.59
2021-11-07 04:45:39 valid 0000, loss 7.886e-01, top1 83.53, top5 90.59
2021-11-07 04:45:39 valid 0000, loss 7.886e-01, top1 83.53, top5 90.59
2021-11-07 04:49:58 (JOBID 31681) epoch 53: train time 2750.04, inference time 269.65s, valid_top1 68.53 (best_top1 69.30), valid_top5 89.11
2021-11-07 04:50:08 (JOBID 31681) epoch 53: train time 2751.09, inference time 279.81s, valid_top1 68.53 (best_top1 69.30), valid_top5 89.11
2021-11-07 04:50:09 (JOBID 31681) epoch 53: train time 2751.25, inference time 280.97s, valid_top1 68.53 (best_top1 69.30), valid_top5 89.11
2021-11-07 04:50:12 train 0000, loss 1.094e+00, top1 74.12, top5 91.76
2021-11-07 04:50:22 train 0000, loss 1.138e+00, top1 69.41, top5 91.76
2021-11-07 04:50:22 train 0000, loss 1.475e+00, top1 64.71, top5 85.88
2021-11-07 04:59:24 train 1000, loss 1.456e+00, top1 65.74, top5 85.58
2021-11-07 04:59:24 train 1000, loss 1.465e+00, top1 65.52, top5 85.58
2021-11-07 04:59:24 train 1000, loss 1.451e+00, top1 65.84, top5 85.68
2021-11-07 05:08:22 train 2000, loss 1.463e+00, top1 65.64, top5 85.58
2021-11-07 05:08:22 train 2000, loss 1.467e+00, top1 65.53, top5 85.43
2021-11-07 05:08:22 train 2000, loss 1.472e+00, top1 65.28, top5 85.41
2021-11-07 05:17:16 train 3000, loss 1.474e+00, top1 65.41, top5 85.41
2021-11-07 05:17:16 train 3000, loss 1.478e+00, top1 65.33, top5 85.29
2021-11-07 05:17:16 train 3000, loss 1.479e+00, top1 65.19, top5 85.33
2021-11-07 05:26:12 train 4000, loss 1.478e+00, top1 65.31, top5 85.31
2021-11-07 05:26:12 train 4000, loss 1.483e+00, top1 65.21, top5 85.24
2021-11-07 05:26:12 train 4000, loss 1.483e+00, top1 65.12, top5 85.28
2021-11-07 05:35:10 train 5000, loss 1.487e+00, top1 65.12, top5 85.19
2021-11-07 05:35:10 train 5000, loss 1.482e+00, top1 65.26, top5 85.28
2021-11-07 05:35:10 train 5000, loss 1.484e+00, top1 65.10, top5 85.23
2021-11-07 05:35:33 valid 0000, loss 8.736e-01, top1 84.71, top5 89.41
2021-11-07 05:35:33 valid 0000, loss 8.736e-01, top1 84.71, top5 89.41
2021-11-07 05:35:33 valid 0000, loss 8.736e-01, top1 84.71, top5 89.41
2021-11-07 05:39:53 (JOBID 31681) epoch 54: train time 2715.32, inference time 269.53s, valid_top1 68.32 (best_top1 69.30), valid_top5 88.90
2021-11-07 05:40:08 (JOBID 31681) epoch 54: train time 2725.62, inference time 284.21s, valid_top1 68.32 (best_top1 69.30), valid_top5 88.90
2021-11-07 05:40:10 (JOBID 31681) epoch 54: train time 2714.39, inference time 286.12s, valid_top1 68.32 (best_top1 69.30), valid_top5 88.90
2021-11-07 05:40:22 train 0000, loss 1.409e+00, top1 62.35, top5 87.06
2021-11-07 05:40:07 train 0000, loss 1.603e+00, top1 60.00, top5 87.06
2021-11-07 05:40:24 train 0000, loss 1.347e+00, top1 65.88, top5 84.71
2021-11-07 05:49:31 train 1000, loss 1.464e+00, top1 65.53, top5 85.50
2021-11-07 05:49:31 train 1000, loss 1.459e+00, top1 65.78, top5 85.62
2021-11-07 05:49:31 train 1000, loss 1.473e+00, top1 65.54, top5 85.44
2021-11-07 05:58:37 train 2000, loss 1.473e+00, top1 65.37, top5 85.44
2021-11-07 05:58:37 train 2000, loss 1.467e+00, top1 65.47, top5 85.52
2021-11-07 05:58:37 train 2000, loss 1.475e+00, top1 65.54, top5 85.32
2021-11-07 06:07:42 train 3000, loss 1.472e+00, top1 65.40, top5 85.44
2021-11-07 06:07:42 train 3000, loss 1.482e+00, top1 65.38, top5 85.19
2021-11-07 06:07:42 train 3000, loss 1.479e+00, top1 65.22, top5 85.36
2021-11-07 06:16:46 train 4000, loss 1.476e+00, top1 65.32, top5 85.38
2021-11-07 06:16:46 train 4000, loss 1.481e+00, top1 65.30, top5 85.25
2021-11-07 06:16:46 train 4000, loss 1.479e+00, top1 65.22, top5 85.39
2021-11-07 06:25:51 train 5000, loss 1.483e+00, top1 65.15, top5 85.28
2021-11-07 06:25:51 train 5000, loss 1.481e+00, top1 65.21, top5 85.31
2021-11-07 06:25:51 train 5000, loss 1.485e+00, top1 65.20, top5 85.21
2021-11-07 06:26:15 valid 0000, loss 6.727e-01, top1 85.88, top5 92.94
2021-11-07 06:26:15 valid 0000, loss 6.727e-01, top1 85.88, top5 92.94
2021-11-07 06:26:15 valid 0000, loss 6.727e-01, top1 85.88, top5 92.94
2021-11-07 06:30:34 (JOBID 31681) epoch 55: train time 2755.08, inference time 268.89s, valid_top1 66.26 (best_top1 69.30), valid_top5 87.39
2021-11-07 06:30:44 (JOBID 31681) epoch 55: train time 2757.00, inference time 279.35s, valid_top1 66.26 (best_top1 69.30), valid_top5 87.39
2021-11-07 06:30:45 (JOBID 31681) epoch 55: train time 2771.45, inference time 279.82s, valid_top1 66.26 (best_top1 69.30), valid_top5 87.39
2021-11-07 06:30:47 train 0000, loss 1.959e+00, top1 58.82, top5 76.47
2021-11-07 06:30:59 train 0000, loss 1.362e+00, top1 70.59, top5 84.71
2021-11-07 06:30:59 train 0000, loss 1.563e+00, top1 61.18, top5 81.18
2021-11-07 06:40:01 train 1000, loss 1.469e+00, top1 65.43, top5 85.46
2021-11-07 06:40:02 train 1000, loss 1.453e+00, top1 65.70, top5 85.63
2021-11-07 06:40:02 train 1000, loss 1.462e+00, top1 65.87, top5 85.48
2021-11-07 06:49:11 train 2000, loss 1.463e+00, top1 65.68, top5 85.50
2021-11-07 06:49:11 train 2000, loss 1.472e+00, top1 65.41, top5 85.44
2021-11-07 06:49:11 train 2000, loss 1.456e+00, top1 65.67, top5 85.63
2021-11-07 06:58:14 train 3000, loss 1.469e+00, top1 65.50, top5 85.40
2021-11-07 06:58:14 train 3000, loss 1.476e+00, top1 65.30, top5 85.38
2021-11-07 06:58:15 train 3000, loss 1.466e+00, top1 65.51, top5 85.52
2021-11-07 07:07:17 train 4000, loss 1.475e+00, top1 65.34, top5 85.36
2021-11-07 07:07:17 train 4000, loss 1.479e+00, top1 65.24, top5 85.32
2021-11-07 07:07:18 train 4000, loss 1.472e+00, top1 65.45, top5 85.42
2021-11-07 07:16:22 train 5000, loss 1.484e+00, top1 65.12, top5 85.23
2021-11-07 07:16:22 train 5000, loss 1.476e+00, top1 65.36, top5 85.38
2021-11-07 07:16:22 train 5000, loss 1.480e+00, top1 65.22, top5 85.28
2021-11-07 07:16:46 valid 0000, loss 5.651e-01, top1 89.41, top5 96.47
2021-11-07 07:16:46 valid 0000, loss 5.651e-01, top1 89.41, top5 96.47
2021-11-07 07:16:46 valid 0000, loss 5.651e-01, top1 89.41, top5 96.47
2021-11-07 07:21:30 (JOBID 31681) epoch 56: train time 2762.16, inference time 294.55s, valid_top1 68.35 (best_top1 69.30), valid_top5 88.77
2021-11-07 07:21:31 (JOBID 31681) epoch 56: train time 2751.06, inference time 294.49s, valid_top1 68.35 (best_top1 69.30), valid_top5 88.77
2021-11-07 07:21:31 (JOBID 31681) epoch 56: train time 2751.69, inference time 295.23s, valid_top1 68.35 (best_top1 69.30), valid_top5 88.77
2021-11-07 07:21:45 train 0000, loss 1.622e+00, top1 64.71, top5 88.24
2021-11-07 07:21:45 train 0000, loss 1.454e+00, top1 63.53, top5 84.71
2021-11-07 07:21:45 train 0000, loss 1.411e+00, top1 72.94, top5 84.71
2021-11-07 07:30:35 train 1000, loss 1.453e+00, top1 65.89, top5 85.57
2021-11-07 07:30:35 train 1000, loss 1.457e+00, top1 65.62, top5 85.66
2021-11-07 07:30:35 train 1000, loss 1.449e+00, top1 65.80, top5 85.66
2021-11-07 07:39:27 train 2000, loss 1.467e+00, top1 65.55, top5 85.39
2021-11-07 07:39:27 train 2000, loss 1.466e+00, top1 65.45, top5 85.55
2021-11-07 07:39:28 train 2000, loss 1.457e+00, top1 65.67, top5 85.54
2021-11-07 07:48:19 train 3000, loss 1.470e+00, top1 65.50, top5 85.35
2021-11-07 07:48:19 train 3000, loss 1.466e+00, top1 65.49, top5 85.53
2021-11-07 07:48:19 train 3000, loss 1.468e+00, top1 65.51, top5 85.41
2021-11-07 07:57:09 train 4000, loss 1.473e+00, top1 65.39, top5 85.36
2021-11-07 07:57:09 train 4000, loss 1.472e+00, top1 65.34, top5 85.44
2021-11-07 07:57:09 train 4000, loss 1.477e+00, top1 65.38, top5 85.33
2021-11-07 08:06:15 train 5000, loss 1.475e+00, top1 65.25, top5 85.38
2021-11-07 08:06:15 train 5000, loss 1.480e+00, top1 65.20, top5 85.30
2021-11-07 08:06:16 train 5000, loss 1.479e+00, top1 65.32, top5 85.31
2021-11-07 08:06:39 valid 0000, loss 8.801e-01, top1 82.35, top5 88.24
2021-11-07 08:06:39 valid 0000, loss 8.801e-01, top1 82.35, top5 88.24
2021-11-07 08:06:39 valid 0000, loss 8.801e-01, top1 82.35, top5 88.24
2021-11-07 08:11:26 (JOBID 31681) epoch 57: train time 2697.96, inference time 297.05s, valid_top1 68.49 (best_top1 69.30), valid_top5 88.75
2021-11-07 08:11:27 (JOBID 31681) epoch 57: train time 2698.31, inference time 297.80s, valid_top1 68.49 (best_top1 69.30), valid_top5 88.75
2021-11-07 08:11:27 (JOBID 31681) epoch 57: train time 2698.63, inference time 298.24s, valid_top1 68.49 (best_top1 69.30), valid_top5 88.75
2021-11-07 08:11:41 train 0000, loss 1.594e+00, top1 70.59, top5 82.35
2021-11-07 08:11:41 train 0000, loss 1.568e+00, top1 64.71, top5 83.53
2021-11-07 08:11:41 train 0000, loss 1.339e+00, top1 67.06, top5 89.41
2021-11-07 08:20:42 train 1000, loss 1.453e+00, top1 65.87, top5 85.74
2021-11-07 08:20:42 train 1000, loss 1.457e+00, top1 65.73, top5 85.68
2021-11-07 08:20:43 train 1000, loss 1.456e+00, top1 65.64, top5 85.49
2021-11-07 08:29:43 train 2000, loss 1.457e+00, top1 65.74, top5 85.59
2021-11-07 08:29:43 train 2000, loss 1.471e+00, top1 65.54, top5 85.46
2021-11-07 08:29:44 train 2000, loss 1.463e+00, top1 65.55, top5 85.44
2021-11-07 08:38:50 train 3000, loss 1.472e+00, top1 65.45, top5 85.44
2021-11-07 08:38:50 train 3000, loss 1.463e+00, top1 65.59, top5 85.54
2021-11-07 08:38:50 train 3000, loss 1.471e+00, top1 65.34, top5 85.40
2021-11-07 08:47:55 train 4000, loss 1.468e+00, top1 65.48, top5 85.46
2021-11-07 08:47:55 train 4000, loss 1.473e+00, top1 65.41, top5 85.43
2021-11-07 08:47:55 train 4000, loss 1.475e+00, top1 65.28, top5 85.34
2021-11-07 08:57:01 train 5000, loss 1.475e+00, top1 65.32, top5 85.37
2021-11-07 08:57:01 train 5000, loss 1.477e+00, top1 65.29, top5 85.37
2021-11-07 08:57:01 train 5000, loss 1.477e+00, top1 65.23, top5 85.30
2021-11-07 08:57:25 valid 0000, loss 7.902e-01, top1 82.35, top5 91.76
2021-11-07 08:57:25 valid 0000, loss 7.902e-01, top1 82.35, top5 91.76
2021-11-07 08:57:25 valid 0000, loss 7.902e-01, top1 82.35, top5 91.76
2021-11-07 09:02:09 (JOBID 31681) epoch 58: train time 2748.65, inference time 294.06s, valid_top1 68.92 (best_top1 69.30), valid_top5 89.04
2021-11-07 09:02:09 (JOBID 31681) epoch 58: train time 2747.71, inference time 293.92s, valid_top1 68.92 (best_top1 69.30), valid_top5 89.04
2021-11-07 09:02:13 (JOBID 31681) epoch 58: train time 2747.60, inference time 297.75s, valid_top1 68.92 (best_top1 69.30), valid_top5 89.04
2021-11-07 09:02:23 train 0000, loss 1.596e+00, top1 68.24, top5 82.35
2021-11-07 09:02:23 train 0000, loss 1.536e+00, top1 71.76, top5 81.18
2021-11-07 09:02:26 train 0000, loss 1.377e+00, top1 67.06, top5 83.53
2021-11-07 09:11:37 train 1000, loss 1.462e+00, top1 65.40, top5 85.61
2021-11-07 09:11:37 train 1000, loss 1.454e+00, top1 65.78, top5 85.61
2021-11-07 09:11:37 train 1000, loss 1.459e+00, top1 65.59, top5 85.62
2021-11-07 09:20:48 train 2000, loss 1.470e+00, top1 65.42, top5 85.49
2021-11-07 09:20:48 train 2000, loss 1.470e+00, top1 65.52, top5 85.34
2021-11-07 09:20:48 train 2000, loss 1.465e+00, top1 65.42, top5 85.55
2021-11-07 09:30:04 train 3000, loss 1.473e+00, top1 65.39, top5 85.45
2021-11-07 09:30:04 train 3000, loss 1.470e+00, top1 65.50, top5 85.36
2021-11-07 09:30:04 train 3000, loss 1.472e+00, top1 65.28, top5 85.46
2021-11-07 09:39:17 train 4000, loss 1.474e+00, top1 65.41, top5 85.33
2021-11-07 09:39:18 train 4000, loss 1.477e+00, top1 65.27, top5 85.37
2021-11-07 09:39:18 train 4000, loss 1.476e+00, top1 65.22, top5 85.40
2021-11-07 09:48:33 train 5000, loss 1.477e+00, top1 65.35, top5 85.30
2021-11-07 09:48:34 train 5000, loss 1.476e+00, top1 65.23, top5 85.36
2021-11-07 09:48:34 train 5000, loss 1.479e+00, top1 65.25, top5 85.32
2021-11-07 09:48:57 valid 0000, loss 9.461e-01, top1 78.82, top5 90.59
2021-11-07 09:48:57 valid 0000, loss 9.461e-01, top1 78.82, top5 90.59
2021-11-07 09:48:57 valid 0000, loss 9.461e-01, top1 78.82, top5 90.59
2021-11-07 09:53:48 (JOBID 31681) epoch 59: train time 2798.63, inference time 300.66s, valid_top1 68.44 (best_top1 69.30), valid_top5 88.68
2021-11-07 09:53:48 (JOBID 31681) epoch 59: train time 2798.43, inference time 300.46s, valid_top1 68.44 (best_top1 69.30), valid_top5 88.68
2021-11-07 09:53:50 (JOBID 31681) epoch 59: train time 2794.84, inference time 302.21s, valid_top1 68.44 (best_top1 69.30), valid_top5 88.68
2021-11-07 09:54:03 train 0000, loss 1.491e+00, top1 69.41, top5 85.88
2021-11-07 09:54:03 train 0000, loss 1.547e+00, top1 67.06, top5 85.88
2021-11-07 09:54:05 train 0000, loss 1.193e+00, top1 70.59, top5 89.41
2021-11-07 10:03:20 train 1000, loss 1.342e+00, top1 68.40, top5 87.13
2021-11-07 10:03:20 train 1000, loss 1.337e+00, top1 68.58, top5 87.09
2021-11-07 10:03:21 train 1000, loss 1.329e+00, top1 68.77, top5 87.30
2021-11-07 10:12:32 train 2000, loss 1.318e+00, top1 68.92, top5 87.45
2021-11-07 10:12:32 train 2000, loss 1.315e+00, top1 69.04, top5 87.43
2021-11-07 10:12:33 train 2000, loss 1.312e+00, top1 69.10, top5 87.44
2021-11-07 10:21:51 train 3000, loss 1.301e+00, top1 69.28, top5 87.61
2021-11-07 10:21:51 train 3000, loss 1.300e+00, top1 69.36, top5 87.67
2021-11-07 10:21:52 train 3000, loss 1.299e+00, top1 69.33, top5 87.66
2021-11-07 10:31:19 train 4000, loss 1.292e+00, top1 69.46, top5 87.74
2021-11-07 10:31:19 train 4000, loss 1.290e+00, top1 69.57, top5 87.76
2021-11-07 10:31:19 train 4000, loss 1.289e+00, top1 69.52, top5 87.77
2021-11-07 10:40:24 train 5000, loss 1.283e+00, top1 69.74, top5 87.85
2021-11-07 10:40:24 train 5000, loss 1.286e+00, top1 69.62, top5 87.82
2021-11-07 10:40:24 train 5000, loss 1.283e+00, top1 69.59, top5 87.86
2021-11-07 10:40:51 valid 0000, loss 6.337e-01, top1 87.06, top5 92.94
2021-11-07 10:40:51 valid 0000, loss 6.337e-01, top1 87.06, top5 92.94
2021-11-07 10:40:51 valid 0000, loss 6.337e-01, top1 87.06, top5 92.94
2021-11-07 10:45:21 (JOBID 31681) epoch 60: train time 2809.41, inference time 283.52s, valid_top1 72.78 (best_top1 72.78), valid_top5 91.18
2021-11-07 10:45:22 (JOBID 31681) epoch 60: train time 2807.83, inference time 284.24s, valid_top1 72.78 (best_top1 72.78), valid_top5 91.18
2021-11-07 10:45:23 (JOBID 31681) epoch 60: train time 2809.24, inference time 284.00s, valid_top1 72.78 (best_top1 72.78), valid_top5 91.18
2021-11-07 10:45:39 train 0000, loss 1.647e+00, top1 65.88, top5 83.53
2021-11-07 10:45:39 train 0000, loss 1.075e+00, top1 72.94, top5 90.59
2021-11-07 10:45:40 train 0000, loss 1.563e+00, top1 61.18, top5 81.18
2021-11-07 10:54:52 train 1000, loss 1.253e+00, top1 70.33, top5 88.24
2021-11-07 10:54:52 train 1000, loss 1.245e+00, top1 70.57, top5 88.31
2021-11-07 10:54:52 train 1000, loss 1.245e+00, top1 70.46, top5 88.35
2021-11-07 11:03:50 train 2000, loss 1.247e+00, top1 70.42, top5 88.24
2021-11-07 11:03:50 train 2000, loss 1.248e+00, top1 70.34, top5 88.24
2021-11-07 11:03:50 train 2000, loss 1.245e+00, top1 70.47, top5 88.32
2021-11-07 11:12:53 train 3000, loss 1.240e+00, top1 70.57, top5 88.33
2021-11-07 11:12:53 train 3000, loss 1.248e+00, top1 70.34, top5 88.21
2021-11-07 11:12:53 train 3000, loss 1.239e+00, top1 70.66, top5 88.38
2021-11-07 11:21:54 train 4000, loss 1.246e+00, top1 70.40, top5 88.26
2021-11-07 11:21:53 train 4000, loss 1.236e+00, top1 70.62, top5 88.43
2021-11-07 11:21:54 train 4000, loss 1.239e+00, top1 70.64, top5 88.36
2021-11-07 11:30:52 train 5000, loss 1.244e+00, top1 70.47, top5 88.29
2021-11-07 11:30:52 train 5000, loss 1.235e+00, top1 70.67, top5 88.44
2021-11-07 11:30:53 train 5000, loss 1.238e+00, top1 70.65, top5 88.40
2021-11-07 11:31:35 valid 0000, loss 5.961e-01, top1 87.06, top5 91.76
2021-11-07 11:31:35 valid 0000, loss 5.961e-01, top1 87.06, top5 91.76
2021-11-07 11:31:35 valid 0000, loss 5.961e-01, top1 87.06, top5 91.76
2021-11-07 11:36:03 (JOBID 31681) epoch 61: train time 2744.59, inference time 296.61s, valid_top1 73.14 (best_top1 73.14), valid_top5 91.35
2021-11-07 11:36:06 (JOBID 31681) epoch 61: train time 2745.19, inference time 299.57s, valid_top1 73.14 (best_top1 73.14), valid_top5 91.35
2021-11-07 11:36:06 (JOBID 31681) epoch 61: train time 2743.05, inference time 298.99s, valid_top1 73.14 (best_top1 73.14), valid_top5 91.35
2021-11-07 11:36:24 train 0000, loss 1.412e+00, top1 64.71, top5 85.88
2021-11-07 11:36:24 train 0000, loss 1.432e+00, top1 72.94, top5 84.71
2021-11-07 11:36:24 train 0000, loss 1.190e+00, top1 67.06, top5 89.41
2021-11-07 11:45:30 train 1000, loss 1.231e+00, top1 70.76, top5 88.45
2021-11-07 11:45:30 train 1000, loss 1.212e+00, top1 71.24, top5 88.75
2021-11-07 11:45:30 train 1000, loss 1.220e+00, top1 71.26, top5 88.65
2021-11-07 11:54:34 train 2000, loss 1.219e+00, top1 71.06, top5 88.62
2021-11-07 11:54:34 train 2000, loss 1.225e+00, top1 70.87, top5 88.48
2021-11-07 11:54:34 train 2000, loss 1.221e+00, top1 71.09, top5 88.66
2021-11-07 12:03:37 train 3000, loss 1.224e+00, top1 70.90, top5 88.50
2021-11-07 12:03:37 train 3000, loss 1.218e+00, top1 71.09, top5 88.62
2021-11-07 12:03:37 train 3000, loss 1.222e+00, top1 71.01, top5 88.60
2021-11-07 12:12:48 train 4000, loss 1.220e+00, top1 70.95, top5 88.57
2021-11-07 12:12:48 train 4000, loss 1.218e+00, top1 71.08, top5 88.67
2021-11-07 12:12:48 train 4000, loss 1.221e+00, top1 70.97, top5 88.63
2021-11-07 12:21:50 train 5000, loss 1.221e+00, top1 70.95, top5 88.57
2021-11-07 12:21:50 train 5000, loss 1.218e+00, top1 71.09, top5 88.65
2021-11-07 12:21:50 train 5000, loss 1.222e+00, top1 70.96, top5 88.61
2021-11-07 12:22:14 valid 0000, loss 6.200e-01, top1 87.06, top5 91.76
2021-11-07 12:22:14 valid 0000, loss 6.200e-01, top1 87.06, top5 91.76
2021-11-07 12:22:14 valid 0000, loss 6.200e-01, top1 87.06, top5 91.76
2021-11-07 12:26:35 (JOBID 31681) epoch 62: train time 2760.84, inference time 271.07s, valid_top1 73.42 (best_top1 73.42), valid_top5 91.43
2021-11-07 12:26:46 (JOBID 31681) epoch 62: train time 2757.95, inference time 282.64s, valid_top1 73.42 (best_top1 73.42), valid_top5 91.43
2021-11-07 12:26:47 (JOBID 31681) epoch 62: train time 2757.66, inference time 282.62s, valid_top1 73.42 (best_top1 73.42), valid_top5 91.43
2021-11-07 12:26:49 train 0000, loss 9.348e-01, top1 72.94, top5 95.29
2021-11-07 12:27:01 train 0000, loss 1.078e+00, top1 68.24, top5 94.12
2021-11-07 12:27:01 train 0000, loss 1.355e+00, top1 68.24, top5 88.24
2021-11-07 12:36:15 train 1000, loss 1.191e+00, top1 71.52, top5 89.07
2021-11-07 12:36:15 train 1000, loss 1.207e+00, top1 71.33, top5 88.91
2021-11-07 12:36:15 train 1000, loss 1.213e+00, top1 71.13, top5 88.72
2021-11-07 12:45:25 train 2000, loss 1.205e+00, top1 71.32, top5 88.88
2021-11-07 12:45:25 train 2000, loss 1.195e+00, top1 71.52, top5 88.97
2021-11-07 12:45:25 train 2000, loss 1.214e+00, top1 71.10, top5 88.73
2021-11-07 12:54:34 train 3000, loss 1.200e+00, top1 71.36, top5 88.95
2021-11-07 12:54:33 train 3000, loss 1.208e+00, top1 71.31, top5 88.82
2021-11-07 12:54:34 train 3000, loss 1.213e+00, top1 71.17, top5 88.71
2021-11-07 13:03:51 train 4000, loss 1.208e+00, top1 71.22, top5 88.79
2021-11-07 13:03:51 train 4000, loss 1.203e+00, top1 71.30, top5 88.84
2021-11-07 13:03:51 train 4000, loss 1.210e+00, top1 71.26, top5 88.74
2021-11-07 13:12:57 train 5000, loss 1.206e+00, top1 71.28, top5 88.81
2021-11-07 13:12:57 train 5000, loss 1.203e+00, top1 71.34, top5 88.85
2021-11-07 13:12:57 train 5000, loss 1.211e+00, top1 71.22, top5 88.74
2021-11-07 13:13:21 valid 0000, loss 5.855e-01, top1 88.24, top5 94.12
2021-11-07 13:13:21 valid 0000, loss 5.855e-01, top1 88.24, top5 94.12
2021-11-07 13:13:21 valid 0000, loss 5.855e-01, top1 88.24, top5 94.12
2021-11-07 13:17:50 (JOBID 31681) epoch 63: train time 2795.80, inference time 279.43s, valid_top1 73.39 (best_top1 73.42), valid_top5 91.45
2021-11-07 13:17:51 (JOBID 31681) epoch 63: train time 2783.50, inference time 280.21s, valid_top1 73.39 (best_top1 73.42), valid_top5 91.45
2021-11-07 13:17:56 (JOBID 31681) epoch 63: train time 2784.18, inference time 285.56s, valid_top1 73.39 (best_top1 73.42), valid_top5 91.45
2021-11-07 13:18:05 train 0000, loss 1.230e+00, top1 67.06, top5 95.29
2021-11-07 13:18:05 train 0000, loss 1.278e+00, top1 67.06, top5 88.24
2021-11-07 13:18:11 train 0000, loss 1.273e+00, top1 72.94, top5 87.06
2021-11-07 13:27:30 train 1000, loss 1.195e+00, top1 71.57, top5 89.01
2021-11-07 13:27:30 train 1000, loss 1.190e+00, top1 71.65, top5 89.05
2021-11-07 13:27:30 train 1000, loss 1.192e+00, top1 71.67, top5 88.97
2021-11-07 13:36:50 train 2000, loss 1.195e+00, top1 71.56, top5 88.97
2021-11-07 13:36:51 train 2000, loss 1.196e+00, top1 71.57, top5 88.94
2021-11-07 13:36:51 train 2000, loss 1.193e+00, top1 71.56, top5 88.94
2021-11-07 13:46:08 train 3000, loss 1.200e+00, top1 71.47, top5 88.91
2021-11-07 13:46:09 train 3000, loss 1.193e+00, top1 71.59, top5 88.94
2021-11-07 13:46:09 train 3000, loss 1.195e+00, top1 71.54, top5 88.95
2021-11-07 13:55:28 train 4000, loss 1.200e+00, top1 71.44, top5 88.88
2021-11-07 13:55:28 train 4000, loss 1.197e+00, top1 71.51, top5 88.93
2021-11-07 13:55:29 train 4000, loss 1.192e+00, top1 71.58, top5 88.93
2021-11-07 14:04:43 train 5000, loss 1.197e+00, top1 71.49, top5 88.94
2021-11-07 14:04:43 train 5000, loss 1.199e+00, top1 71.48, top5 88.90
2021-11-07 14:04:43 train 5000, loss 1.193e+00, top1 71.55, top5 88.92
2021-11-07 14:05:07 valid 0000, loss 6.024e-01, top1 89.41, top5 94.12
2021-11-07 14:05:07 valid 0000, loss 6.024e-01, top1 89.41, top5 94.12
2021-11-07 14:05:07 valid 0000, loss 6.024e-01, top1 89.41, top5 94.12
2021-11-07 14:09:36 (JOBID 31681) epoch 64: train time 2827.11, inference time 278.49s, valid_top1 73.43 (best_top1 73.43), valid_top5 91.54
2021-11-07 14:09:36 (JOBID 31681) epoch 64: train time 2825.97, inference time 278.23s, valid_top1 73.43 (best_top1 73.43), valid_top5 91.54
2021-11-07 14:09:36 (JOBID 31681) epoch 64: train time 2820.86, inference time 278.94s, valid_top1 73.43 (best_top1 73.43), valid_top5 91.54
2021-11-07 14:09:50 train 0000, loss 1.020e+00, top1 78.82, top5 90.59
2021-11-07 14:09:50 train 0000, loss 7.441e-01, top1 82.35, top5 96.47
2021-11-07 14:09:50 train 0000, loss 1.134e+00, top1 75.29, top5 91.76
2021-11-07 14:19:22 train 1000, loss 1.185e+00, top1 71.80, top5 89.03
2021-11-07 14:19:22 train 1000, loss 1.192e+00, top1 71.72, top5 89.03
2021-11-07 14:19:22 train 1000, loss 1.190e+00, top1 71.69, top5 89.00
2021-11-07 14:28:41 train 2000, loss 1.189e+00, top1 71.61, top5 89.04
2021-11-07 14:28:42 train 2000, loss 1.183e+00, top1 71.82, top5 89.06
2021-11-07 14:28:42 train 2000, loss 1.193e+00, top1 71.66, top5 88.96
2021-11-07 14:38:00 train 3000, loss 1.191e+00, top1 71.68, top5 89.01
2021-11-07 14:38:00 train 3000, loss 1.187e+00, top1 71.72, top5 89.00
2021-11-07 14:38:00 train 3000, loss 1.191e+00, top1 71.56, top5 88.99
2021-11-07 14:47:19 train 4000, loss 1.187e+00, top1 71.77, top5 89.02
2021-11-07 14:47:19 train 4000, loss 1.189e+00, top1 71.68, top5 88.97
2021-11-07 14:47:19 train 4000, loss 1.192e+00, top1 71.55, top5 88.95
2021-11-07 14:56:33 train 5000, loss 1.189e+00, top1 71.70, top5 88.97
2021-11-07 14:56:33 train 5000, loss 1.191e+00, top1 71.59, top5 88.95
2021-11-07 14:56:33 train 5000, loss 1.188e+00, top1 71.73, top5 89.01
2021-11-07 14:56:57 valid 0000, loss 6.161e-01, top1 85.88, top5 94.12
2021-11-07 14:56:57 valid 0000, loss 6.161e-01, top1 85.88, top5 94.12
2021-11-07 14:56:57 valid 0000, loss 6.161e-01, top1 85.88, top5 94.12
2021-11-07 15:01:35 (JOBID 31681) epoch 65: train time 2830.91, inference time 288.71s, valid_top1 73.53 (best_top1 73.53), valid_top5 91.64
2021-11-07 15:01:36 (JOBID 31681) epoch 65: train time 2830.63, inference time 289.16s, valid_top1 73.53 (best_top1 73.53), valid_top5 91.64
2021-11-07 15:01:36 (JOBID 31681) epoch 65: train time 2830.74, inference time 289.13s, valid_top1 73.53 (best_top1 73.53), valid_top5 91.64
2021-11-07 15:01:50 train 0000, loss 1.736e+00, top1 64.71, top5 85.88
2021-11-07 15:01:50 train 0000, loss 1.230e+00, top1 72.94, top5 89.41
2021-11-07 15:01:50 train 0000, loss 1.026e+00, top1 71.76, top5 90.59
2021-11-07 15:11:11 train 1000, loss 1.181e+00, top1 71.79, top5 89.22
2021-11-07 15:11:11 train 1000, loss 1.175e+00, top1 72.17, top5 89.11
2021-11-07 15:11:11 train 1000, loss 1.182e+00, top1 71.94, top5 89.11
2021-11-07 15:20:27 train 2000, loss 1.183e+00, top1 71.70, top5 89.16
2021-11-07 15:20:27 train 2000, loss 1.180e+00, top1 71.98, top5 89.13
2021-11-07 15:20:27 train 2000, loss 1.181e+00, top1 71.87, top5 89.08
2021-11-07 15:29:44 train 3000, loss 1.182e+00, top1 71.92, top5 89.09
2021-11-07 15:29:44 train 3000, loss 1.182e+00, top1 71.85, top5 89.09
2021-11-07 15:29:44 train 3000, loss 1.186e+00, top1 71.67, top5 89.15
2021-11-07 15:39:07 train 4000, loss 1.185e+00, top1 71.70, top5 89.12
2021-11-07 15:39:07 train 4000, loss 1.184e+00, top1 71.92, top5 89.10
2021-11-07 15:39:08 train 4000, loss 1.182e+00, top1 71.86, top5 89.08
2021-11-07 15:48:10 train 5000, loss 1.183e+00, top1 71.91, top5 89.10
2021-11-07 15:48:10 train 5000, loss 1.184e+00, top1 71.70, top5 89.13
2021-11-07 15:48:11 train 5000, loss 1.183e+00, top1 71.84, top5 89.08
2021-11-07 15:48:35 valid 0000, loss 6.676e-01, top1 84.71, top5 91.76
2021-11-07 15:48:35 valid 0000, loss 6.676e-01, top1 84.71, top5 91.76
2021-11-07 15:48:35 valid 0000, loss 6.676e-01, top1 84.71, top5 91.76
2021-11-07 15:53:01 (JOBID 31681) epoch 66: train time 2808.73, inference time 277.13s, valid_top1 73.57 (best_top1 73.57), valid_top5 91.60
2021-11-07 15:53:01 (JOBID 31681) epoch 66: train time 2808.32, inference time 277.16s, valid_top1 73.57 (best_top1 73.57), valid_top5 91.60
2021-11-07 15:53:02 (JOBID 31681) epoch 66: train time 2807.74, inference time 277.18s, valid_top1 73.57 (best_top1 73.57), valid_top5 91.60
2021-11-07 15:53:15 train 0000, loss 1.416e+00, top1 64.71, top5 87.06
2021-11-07 15:53:15 train 0000, loss 1.238e+00, top1 67.06, top5 88.24
2021-11-07 15:53:16 train 0000, loss 1.336e+00, top1 67.06, top5 88.24
2021-11-07 16:02:22 train 1000, loss 1.161e+00, top1 72.25, top5 89.28
2021-11-07 16:02:23 train 1000, loss 1.172e+00, top1 71.92, top5 89.06
2021-11-07 16:02:23 train 1000, loss 1.176e+00, top1 71.89, top5 89.16
2021-11-07 16:11:34 train 2000, loss 1.174e+00, top1 72.00, top5 89.11
2021-11-07 16:11:34 train 2000, loss 1.171e+00, top1 72.09, top5 89.16
2021-11-07 16:11:34 train 2000, loss 1.175e+00, top1 71.85, top5 89.12
2021-11-07 16:20:45 train 3000, loss 1.169e+00, top1 72.14, top5 89.21
2021-11-07 16:20:45 train 3000, loss 1.178e+00, top1 71.89, top5 89.11
2021-11-07 16:20:45 train 3000, loss 1.175e+00, top1 71.91, top5 89.17
2021-11-07 16:29:54 train 4000, loss 1.173e+00, top1 72.01, top5 89.16
2021-11-07 16:29:54 train 4000, loss 1.180e+00, top1 71.86, top5 89.08
2021-11-07 16:29:55 train 4000, loss 1.177e+00, top1 71.93, top5 89.12
2021-11-07 16:39:07 train 5000, loss 1.177e+00, top1 71.93, top5 89.12
2021-11-07 16:39:07 train 5000, loss 1.176e+00, top1 71.97, top5 89.12
2021-11-07 16:39:07 train 5000, loss 1.182e+00, top1 71.80, top5 89.06
2021-11-07 16:39:31 valid 0000, loss 5.892e-01, top1 88.24, top5 95.29
2021-11-07 16:39:31 valid 0000, loss 5.892e-01, top1 88.24, top5 95.29
2021-11-07 16:39:31 valid 0000, loss 5.892e-01, top1 88.24, top5 95.29
2021-11-07 16:44:10 (JOBID 31681) epoch 67: train time 2779.08, inference time 289.92s, valid_top1 73.77 (best_top1 73.77), valid_top5 91.60
2021-11-07 16:44:11 (JOBID 31681) epoch 67: train time 2779.29, inference time 290.38s, valid_top1 73.77 (best_top1 73.77), valid_top5 91.60
2021-11-07 16:44:11 (JOBID 31681) epoch 67: train time 2778.61, inference time 290.48s, valid_top1 73.77 (best_top1 73.77), valid_top5 91.60
2021-11-07 16:44:25 train 0000, loss 1.154e+00, top1 67.06, top5 90.59
2021-11-07 16:44:25 train 0000, loss 1.202e+00, top1 67.06, top5 87.06
2021-11-07 16:44:25 train 0000, loss 9.866e-01, top1 77.65, top5 88.24
2021-11-07 16:53:40 train 1000, loss 1.170e+00, top1 72.33, top5 89.13
2021-11-07 16:53:40 train 1000, loss 1.164e+00, top1 72.29, top5 89.38
2021-11-07 16:53:40 train 1000, loss 1.174e+00, top1 72.20, top5 89.23
2021-11-07 17:02:50 train 2000, loss 1.170e+00, top1 72.23, top5 89.23
2021-11-07 17:02:50 train 2000, loss 1.170e+00, top1 72.25, top5 89.22
2021-11-07 17:02:50 train 2000, loss 1.169e+00, top1 72.10, top5 89.35
2021-11-07 17:12:01 train 3000, loss 1.171e+00, top1 72.05, top5 89.29
2021-11-07 17:12:01 train 3000, loss 1.173e+00, top1 72.15, top5 89.21
2021-11-07 17:12:01 train 3000, loss 1.171e+00, top1 72.16, top5 89.24
2021-11-07 17:21:08 train 4000, loss 1.174e+00, top1 72.06, top5 89.20
2021-11-07 17:21:08 train 4000, loss 1.172e+00, top1 72.11, top5 89.24
2021-11-07 17:21:08 train 4000, loss 1.173e+00, top1 72.02, top5 89.25
2021-11-07 17:30:15 train 5000, loss 1.175e+00, top1 72.03, top5 89.21
2021-11-07 17:30:15 train 5000, loss 1.173e+00, top1 72.09, top5 89.23
2021-11-07 17:30:15 train 5000, loss 1.174e+00, top1 71.99, top5 89.22
2021-11-07 17:30:38 valid 0000, loss 6.046e-01, top1 87.06, top5 95.29
2021-11-07 17:30:38 valid 0000, loss 6.046e-01, top1 87.06, top5 95.29
2021-11-07 17:30:38 valid 0000, loss 6.046e-01, top1 87.06, top5 95.29
2021-11-07 17:35:00 (JOBID 31681) epoch 68: train time 2777.09, inference time 271.12s, valid_top1 73.77 (best_top1 73.77), valid_top5 91.69
2021-11-07 17:35:09 (JOBID 31681) epoch 68: train time 2777.85, inference time 280.54s, valid_top1 73.77 (best_top1 73.77), valid_top5 91.69
2021-11-07 17:35:09 (JOBID 31681) epoch 68: train time 2778.30, inference time 280.96s, valid_top1 73.77 (best_top1 73.77), valid_top5 91.69
2021-11-07 17:35:23 train 0000, loss 1.026e+00, top1 75.29, top5 91.76
2021-11-07 17:35:13 train 0000, loss 1.147e+00, top1 70.59, top5 90.59
2021-11-07 17:35:23 train 0000, loss 1.190e+00, top1 71.76, top5 83.53
2021-11-07 17:44:35 train 1000, loss 1.162e+00, top1 72.41, top5 89.30
2021-11-07 17:44:35 train 1000, loss 1.164e+00, top1 72.08, top5 89.42
2021-11-07 17:44:35 train 1000, loss 1.172e+00, top1 71.95, top5 89.22
2021-11-07 17:53:46 train 2000, loss 1.167e+00, top1 72.07, top5 89.35
2021-11-07 17:53:46 train 2000, loss 1.167e+00, top1 72.10, top5 89.27
2021-11-07 17:53:46 train 2000, loss 1.163e+00, top1 72.41, top5 89.28
2021-11-07 18:02:57 train 3000, loss 1.165e+00, top1 72.27, top5 89.28
2021-11-07 18:02:56 train 3000, loss 1.165e+00, top1 72.13, top5 89.34
2021-11-07 18:02:57 train 3000, loss 1.166e+00, top1 72.14, top5 89.29
2021-11-07 18:12:08 train 4000, loss 1.165e+00, top1 72.19, top5 89.30
2021-11-07 18:12:08 train 4000, loss 1.163e+00, top1 72.24, top5 89.31
2021-11-07 18:12:08 train 4000, loss 1.166e+00, top1 72.11, top5 89.30
2021-11-07 18:21:14 train 5000, loss 1.167e+00, top1 72.16, top5 89.27
2021-11-07 18:21:14 train 5000, loss 1.168e+00, top1 72.13, top5 89.26
2021-11-07 18:21:14 train 5000, loss 1.166e+00, top1 72.11, top5 89.31
2021-11-07 18:21:37 valid 0000, loss 5.623e-01, top1 85.88, top5 92.94
2021-11-07 18:21:37 valid 0000, loss 5.623e-01, top1 85.88, top5 92.94
2021-11-07 18:21:37 valid 0000, loss 5.623e-01, top1 85.88, top5 92.94
2021-11-07 18:26:13 (JOBID 31681) epoch 69: train time 2778.33, inference time 285.19s, valid_top1 73.75 (best_top1 73.77), valid_top5 91.65
2021-11-07 18:26:13 (JOBID 31681) epoch 69: train time 2777.93, inference time 286.02s, valid_top1 73.75 (best_top1 73.77), valid_top5 91.65
2021-11-07 18:26:14 (JOBID 31681) epoch 69: train time 2787.58, inference time 286.37s, valid_top1 73.75 (best_top1 73.77), valid_top5 91.65
2021-11-07 18:26:27 train 0000, loss 9.900e-01, top1 78.82, top5 95.29
2021-11-07 18:26:27 train 0000, loss 1.133e+00, top1 76.47, top5 89.41
2021-11-07 18:26:28 train 0000, loss 9.865e-01, top1 71.76, top5 94.12
2021-11-07 18:35:41 train 1000, loss 1.152e+00, top1 72.55, top5 89.43
2021-11-07 18:35:41 train 1000, loss 1.163e+00, top1 72.20, top5 89.34
2021-11-07 18:35:41 train 1000, loss 1.159e+00, top1 72.38, top5 89.38
2021-11-07 18:44:54 train 2000, loss 1.158e+00, top1 72.25, top5 89.41
2021-11-07 18:44:54 train 2000, loss 1.158e+00, top1 72.30, top5 89.42
2021-11-07 18:44:54 train 2000, loss 1.160e+00, top1 72.34, top5 89.36
2021-11-07 18:54:04 train 3000, loss 1.158e+00, top1 72.34, top5 89.39
2021-11-07 18:54:04 train 3000, loss 1.154e+00, top1 72.37, top5 89.48
2021-11-07 18:54:04 train 3000, loss 1.158e+00, top1 72.34, top5 89.37
2021-11-07 19:03:12 train 4000, loss 1.159e+00, top1 72.36, top5 89.36
2021-11-07 19:03:12 train 4000, loss 1.160e+00, top1 72.31, top5 89.34
2021-11-07 19:03:12 train 4000, loss 1.157e+00, top1 72.30, top5 89.42
2021-11-07 19:56:54 CARME Slurm ID: 31715
2021-11-07 19:56:54 CARME Slurm ID: 31715
2021-11-07 19:56:54 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_07', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.41:23456', distributed=True, epochs=90, evaluate=False, gpu=0, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_07_20211105-074058', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_07_20211105-074058', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_07_20211105-074058', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=2)
2021-11-07 19:56:54 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_07', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.41:23456', distributed=True, epochs=90, evaluate=False, gpu=1, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_07_20211105-074058', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_07_20211105-074058', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_07_20211105-074058', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=2)
2021-11-07 19:57:49 CARME Slurm ID: 31717
2021-11-07 19:57:49 CARME Slurm ID: 31717
2021-11-07 19:57:49 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_07', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.44:23456', distributed=True, epochs=90, evaluate=False, gpu=2, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_07_20211105-074058', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_07_20211105-074058', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_07_20211105-074058', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-07 19:57:49 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_07', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.44:23456', distributed=True, epochs=90, evaluate=False, gpu=0, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_07_20211105-074058', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_07_20211105-074058', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_07_20211105-074058', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-07 19:57:49 CARME Slurm ID: 31717
2021-11-07 19:57:49 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_07', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.44:23456', distributed=True, epochs=90, evaluate=False, gpu=1, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_07_20211105-074058', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_07_20211105-074058', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_07_20211105-074058', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-07 19:57:59 Computational complexity:       1.92 GMac
2021-11-07 19:57:59 Computational complexity:       1.92 GMac
2021-11-07 19:57:59 Number of parameters:           13.22 M 
2021-11-07 19:57:59 Number of parameters:           13.22 M 
2021-11-07 19:57:59 Computational complexity:       1.92 GMac
2021-11-07 19:57:59 Number of parameters:           13.22 M 
2021-11-07 19:57:59 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_07_20211105-074058'
2021-11-07 19:57:59 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_07_20211105-074058'
2021-11-07 19:57:59 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_07_20211105-074058'
2021-11-07 19:57:59 => loaded checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_07_20211105-074058' (epoch 70)
2021-11-07 19:57:59 => loaded checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_07_20211105-074058' (epoch 70)
2021-11-07 19:57:59 => loaded checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_07_20211105-074058' (epoch 70)
