2021-11-03 10:16:39 CARME Slurm ID: 31582
2021-11-03 10:16:39 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_1', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.46:23456', distributed=True, epochs=90, evaluate=False, gpu=0, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-03 10:16:39 CARME Slurm ID: 31582
2021-11-03 10:16:39 CARME Slurm ID: 31582
2021-11-03 10:16:39 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_1', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.46:23456', distributed=True, epochs=90, evaluate=False, gpu=1, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-03 10:16:39 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_1', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.46:23456', distributed=True, epochs=90, evaluate=False, gpu=2, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-03 10:16:40 => loading baseline model 'conv12_lr_0.001_momentum_0.9_wd_0.1_normalization_div_pretrained_True_20211031-110931/small_model_conv12_1e-06.pth.tar'
2021-11-03 10:16:40 => loading baseline model 'conv12_lr_0.001_momentum_0.9_wd_0.1_normalization_div_pretrained_True_20211031-110931/small_model_conv12_1e-06.pth.tar'
2021-11-03 10:16:40 => loading baseline model 'conv12_lr_0.001_momentum_0.9_wd_0.1_normalization_div_pretrained_True_20211031-110931/small_model_conv12_1e-06.pth.tar'
2021-11-03 10:16:41 => loaded baseline model 'conv12_lr_0.001_momentum_0.9_wd_0.1_normalization_div_pretrained_True_20211031-110931/small_model_conv12_1e-06.pth.tar'
2021-11-03 10:16:41 => loaded baseline model 'conv12_lr_0.001_momentum_0.9_wd_0.1_normalization_div_pretrained_True_20211031-110931/small_model_conv12_1e-06.pth.tar'
2021-11-03 10:16:41 => loaded baseline model 'conv12_lr_0.001_momentum_0.9_wd_0.1_normalization_div_pretrained_True_20211031-110931/small_model_conv12_1e-06.pth.tar'
2021-11-03 10:16:49 Computational complexity:       1.74 GMac
2021-11-03 10:16:49 Number of parameters:           12.36 M 
2021-11-03 10:16:49 Computational complexity:       1.74 GMac
2021-11-03 10:16:49 Number of parameters:           12.36 M 
2021-11-03 10:16:49 Computational complexity:       1.74 GMac
2021-11-03 10:16:49 Number of parameters:           12.36 M 
2021-11-03 10:17:07 valid 0000, loss 6.018e-01, top1 89.41, top5 95.29
2021-11-03 10:17:07 valid 0000, loss 6.018e-01, top1 89.41, top5 95.29
2021-11-03 10:17:07 valid 0000, loss 6.018e-01, top1 89.41, top5 95.29
2021-11-03 10:21:28 (JOBID 31582) epoch -1: valid_top1 72.45, valid_top5 90.55, inference time 274.33
2021-11-03 10:21:29 (JOBID 31582) epoch -1: valid_top1 72.45, valid_top5 90.55, inference time 275.29
2021-11-03 10:21:30 (JOBID 31582) epoch -1: valid_top1 72.45, valid_top5 90.55, inference time 275.89
2021-11-03 10:21:48 train 0000, loss 5.493e-01, top1 84.71, top5 96.47
2021-11-03 10:21:48 train 0000, loss 5.472e-01, top1 85.88, top5 96.47
2021-11-03 10:21:48 train 0000, loss 8.010e-01, top1 81.18, top5 92.94
2021-11-03 10:30:46 train 1000, loss 1.585e+00, top1 63.42, top5 83.28
2021-11-03 10:30:46 train 1000, loss 1.572e+00, top1 63.38, top5 83.49
2021-11-03 10:30:46 train 1000, loss 1.575e+00, top1 63.42, top5 83.52
2021-11-03 10:39:30 train 2000, loss 1.504e+00, top1 64.97, top5 84.41
2021-11-03 10:39:30 train 2000, loss 1.496e+00, top1 64.92, top5 84.62
2021-11-03 10:39:30 train 2000, loss 1.503e+00, top1 64.89, top5 84.54
2021-11-03 10:48:12 train 3000, loss 1.473e+00, top1 65.56, top5 84.92
2021-11-03 10:48:12 train 3000, loss 1.468e+00, top1 65.51, top5 85.08
2021-11-03 10:48:12 train 3000, loss 1.472e+00, top1 65.49, top5 84.98
2021-11-03 10:56:56 train 4000, loss 1.452e+00, top1 65.92, top5 85.30
2021-11-03 10:56:56 train 4000, loss 1.457e+00, top1 65.98, top5 85.18
2021-11-03 10:56:56 train 4000, loss 1.457e+00, top1 65.82, top5 85.22
2021-11-03 11:05:41 train 5000, loss 1.451e+00, top1 66.09, top5 85.30
2021-11-03 11:05:41 train 5000, loss 1.444e+00, top1 66.07, top5 85.43
2021-11-03 11:05:41 train 5000, loss 1.452e+00, top1 65.96, top5 85.29
2021-11-03 11:06:07 valid 0000, loss 1.043e+00, top1 83.53, top5 91.76
2021-11-03 11:06:07 valid 0000, loss 1.043e+00, top1 83.53, top5 91.76
2021-11-03 11:06:07 valid 0000, loss 1.043e+00, top1 83.53, top5 91.76
2021-11-03 11:10:30 (JOBID 31582) epoch 0: train time 2667.11, inference time 272.64s, valid_top1 63.94 (best_top1 63.94), valid_top5 85.29
2021-11-03 11:10:43 (JOBID 31582) epoch 0: train time 2668.65, inference time 284.50s, valid_top1 63.94 (best_top1 63.94), valid_top5 85.29
2021-11-03 11:10:45 (JOBID 31582) epoch 0: train time 2667.85, inference time 288.25s, valid_top1 63.94 (best_top1 63.94), valid_top5 85.29
2021-11-03 11:10:57 train 0000, loss 1.276e+00, top1 65.88, top5 89.41
2021-11-03 11:10:43 train 0000, loss 1.477e+00, top1 67.06, top5 84.71
2021-11-03 11:11:00 train 0000, loss 1.225e+00, top1 72.94, top5 89.41
2021-11-03 11:19:57 train 1000, loss 1.423e+00, top1 66.79, top5 85.77
2021-11-03 11:19:57 train 1000, loss 1.430e+00, top1 66.41, top5 85.83
2021-11-03 11:19:57 train 1000, loss 1.418e+00, top1 66.69, top5 85.98
2021-11-03 11:28:39 train 2000, loss 1.436e+00, top1 66.48, top5 85.65
2021-11-03 11:28:39 train 2000, loss 1.434e+00, top1 66.35, top5 85.85
2021-11-03 11:28:39 train 2000, loss 1.431e+00, top1 66.45, top5 85.87
2021-11-03 11:37:28 train 3000, loss 1.454e+00, top1 65.97, top5 85.58
2021-11-03 11:37:29 train 3000, loss 1.456e+00, top1 66.02, top5 85.47
2021-11-03 11:37:29 train 3000, loss 1.450e+00, top1 66.07, top5 85.65
2021-11-03 11:46:29 train 4000, loss 1.471e+00, top1 65.63, top5 85.37
2021-11-03 11:46:29 train 4000, loss 1.466e+00, top1 65.77, top5 85.43
2021-11-03 11:46:29 train 4000, loss 1.473e+00, top1 65.72, top5 85.25
2021-11-03 11:55:26 train 5000, loss 1.490e+00, top1 65.38, top5 85.04
2021-11-03 11:55:26 train 5000, loss 1.490e+00, top1 65.26, top5 85.13
2021-11-03 11:55:26 train 5000, loss 1.486e+00, top1 65.37, top5 85.19
2021-11-03 11:55:50 valid 0000, loss 8.180e-01, top1 85.88, top5 94.12
2021-11-03 11:55:50 valid 0000, loss 8.180e-01, top1 85.88, top5 94.12
2021-11-03 11:55:50 valid 0000, loss 8.180e-01, top1 85.88, top5 94.12
2021-11-03 12:00:20 (JOBID 31582) epoch 1: train time 2709.57, inference time 280.73s, valid_top1 61.66 (best_top1 63.94), valid_top5 83.88
2021-11-03 12:00:22 (JOBID 31582) epoch 1: train time 2693.93, inference time 282.27s, valid_top1 61.66 (best_top1 63.94), valid_top5 83.88
2021-11-03 12:00:23 (JOBID 31582) epoch 1: train time 2696.60, inference time 283.12s, valid_top1 61.66 (best_top1 63.94), valid_top5 83.88
2021-11-03 12:00:36 train 0000, loss 1.381e+00, top1 70.59, top5 87.06
2021-11-03 12:00:35 train 0000, loss 1.498e+00, top1 58.82, top5 92.94
2021-11-03 12:00:36 train 0000, loss 1.501e+00, top1 65.88, top5 83.53
2021-11-03 12:09:32 train 1000, loss 1.564e+00, top1 63.85, top5 84.14
2021-11-03 12:09:32 train 1000, loss 1.581e+00, top1 63.58, top5 83.99
2021-11-03 12:09:32 train 1000, loss 1.566e+00, top1 63.82, top5 84.27
2021-11-03 12:18:17 train 2000, loss 1.591e+00, top1 63.31, top5 83.88
2021-11-03 12:18:17 train 2000, loss 1.584e+00, top1 63.45, top5 83.94
2021-11-03 12:18:17 train 2000, loss 1.587e+00, top1 63.42, top5 83.95
2021-11-03 12:27:07 train 3000, loss 1.609e+00, top1 62.90, top5 83.69
2021-11-03 12:27:07 train 3000, loss 1.604e+00, top1 63.02, top5 83.74
2021-11-03 12:27:07 train 3000, loss 1.610e+00, top1 62.96, top5 83.68
2021-11-03 12:35:59 train 4000, loss 1.632e+00, top1 62.54, top5 83.37
2021-11-03 12:35:59 train 4000, loss 1.627e+00, top1 62.54, top5 83.47
2021-11-03 12:35:59 train 4000, loss 1.631e+00, top1 62.41, top5 83.36
2021-11-03 12:44:48 train 5000, loss 1.652e+00, top1 61.97, top5 83.07
2021-11-03 12:44:48 train 5000, loss 1.648e+00, top1 62.13, top5 83.17
2021-11-03 12:44:48 train 5000, loss 1.651e+00, top1 62.11, top5 83.12
2021-11-03 12:45:12 valid 0000, loss 1.119e+00, top1 80.00, top5 87.06
2021-11-03 12:45:12 valid 0000, loss 1.119e+00, top1 80.00, top5 87.06
2021-11-03 12:45:12 valid 0000, loss 1.119e+00, top1 80.00, top5 87.06
2021-11-03 12:50:02 (JOBID 31582) epoch 2: train time 2679.95, inference time 300.35s, valid_top1 60.07 (best_top1 63.94), valid_top5 83.14
2021-11-03 12:50:03 (JOBID 31582) epoch 2: train time 2678.82, inference time 301.13s, valid_top1 60.07 (best_top1 63.94), valid_top5 83.14
2021-11-03 12:50:03 (JOBID 31582) epoch 2: train time 2681.46, inference time 301.35s, valid_top1 60.07 (best_top1 63.94), valid_top5 83.14
2021-11-03 12:50:17 train 0000, loss 1.621e+00, top1 62.35, top5 82.35
2021-11-03 12:50:17 train 0000, loss 1.778e+00, top1 57.65, top5 80.00
2021-11-03 12:50:17 train 0000, loss 1.623e+00, top1 61.18, top5 82.35
2021-11-03 12:59:01 train 1000, loss 1.735e+00, top1 60.14, top5 81.92
2021-11-03 12:59:01 train 1000, loss 1.727e+00, top1 60.40, top5 82.09
2021-11-03 12:59:01 train 1000, loss 1.735e+00, top1 60.21, top5 81.95
2021-11-03 13:07:44 train 2000, loss 1.751e+00, top1 59.79, top5 81.67
2021-11-03 13:07:44 train 2000, loss 1.756e+00, top1 59.81, top5 81.62
2021-11-03 13:07:44 train 2000, loss 1.752e+00, top1 59.89, top5 81.81
2021-11-03 13:16:29 train 3000, loss 1.774e+00, top1 59.41, top5 81.36
2021-11-03 13:16:29 train 3000, loss 1.777e+00, top1 59.31, top5 81.31
2021-11-03 13:16:29 train 3000, loss 1.779e+00, top1 59.35, top5 81.43
2021-11-03 13:25:19 train 4000, loss 1.798e+00, top1 58.87, top5 81.02
2021-11-03 13:25:19 train 4000, loss 1.793e+00, top1 59.08, top5 81.14
2021-11-03 13:25:19 train 4000, loss 1.800e+00, top1 58.95, top5 81.11
2021-11-03 13:34:02 train 5000, loss 1.816e+00, top1 58.46, top5 80.76
2021-11-03 13:34:02 train 5000, loss 1.811e+00, top1 58.68, top5 80.84
2021-11-03 13:34:02 train 5000, loss 1.818e+00, top1 58.58, top5 80.83
2021-11-03 13:34:25 valid 0000, loss 1.371e+00, top1 65.88, top5 85.88
2021-11-03 13:34:25 valid 0000, loss 1.371e+00, top1 65.88, top5 85.88
2021-11-03 13:34:25 valid 0000, loss 1.371e+00, top1 65.88, top5 85.88
2021-11-03 13:38:50 (JOBID 31582) epoch 3: train time 2651.95, inference time 275.30s, valid_top1 55.62 (best_top1 63.94), valid_top5 80.35
2021-11-03 13:38:51 (JOBID 31582) epoch 3: train time 2651.85, inference time 275.86s, valid_top1 55.62 (best_top1 63.94), valid_top5 80.35
2021-11-03 13:39:00 (JOBID 31582) epoch 3: train time 2652.91, inference time 285.46s, valid_top1 55.62 (best_top1 63.94), valid_top5 80.35
2021-11-03 13:39:04 train 0000, loss 1.886e+00, top1 52.94, top5 74.12
2021-11-03 13:39:04 train 0000, loss 2.038e+00, top1 50.59, top5 76.47
2021-11-03 13:39:14 train 0000, loss 2.212e+00, top1 45.88, top5 70.59
2021-11-03 13:47:49 train 1000, loss 1.892e+00, top1 56.84, top5 79.88
2021-11-03 13:47:49 train 1000, loss 1.893e+00, top1 56.85, top5 79.70
2021-11-03 13:47:49 train 1000, loss 1.894e+00, top1 56.85, top5 79.86
2021-11-03 13:56:30 train 2000, loss 1.906e+00, top1 56.57, top5 79.47
2021-11-03 13:56:30 train 2000, loss 1.916e+00, top1 56.37, top5 79.48
2021-11-03 13:56:30 train 2000, loss 1.908e+00, top1 56.55, top5 79.57
2021-11-03 14:05:15 train 3000, loss 1.926e+00, top1 56.20, top5 79.30
2021-11-03 14:05:15 train 3000, loss 1.932e+00, top1 56.07, top5 79.18
2021-11-03 14:05:15 train 3000, loss 1.927e+00, top1 56.22, top5 79.19
2021-11-03 14:14:06 train 4000, loss 1.946e+00, top1 55.80, top5 78.92
2021-11-03 14:14:06 train 4000, loss 1.944e+00, top1 55.88, top5 78.92
2021-11-03 14:14:06 train 4000, loss 1.946e+00, top1 55.83, top5 78.99
2021-11-03 14:23:00 train 5000, loss 1.965e+00, top1 55.48, top5 78.61
2021-11-03 14:23:00 train 5000, loss 1.959e+00, top1 55.56, top5 78.69
2021-11-03 14:23:00 train 5000, loss 1.963e+00, top1 55.51, top5 78.71
2021-11-03 14:23:24 valid 0000, loss 9.258e-01, top1 81.18, top5 94.12
2021-11-03 14:23:24 valid 0000, loss 9.258e-01, top1 81.18, top5 94.12
2021-11-03 14:23:24 valid 0000, loss 9.258e-01, top1 81.18, top5 94.12
2021-11-03 14:27:56 (JOBID 31582) epoch 4: train time 2663.11, inference time 281.50s, valid_top1 52.95 (best_top1 63.94), valid_top5 78.00
2021-11-03 14:27:58 (JOBID 31582) epoch 4: train time 2653.58, inference time 283.88s, valid_top1 52.95 (best_top1 63.94), valid_top5 78.00
2021-11-03 14:27:58 (JOBID 31582) epoch 4: train time 2663.72, inference time 283.94s, valid_top1 52.95 (best_top1 63.94), valid_top5 78.00
2021-11-03 14:28:12 train 0000, loss 2.397e+00, top1 43.53, top5 69.41
2021-11-03 14:28:11 train 0000, loss 2.224e+00, top1 52.94, top5 70.59
2021-11-03 14:28:12 train 0000, loss 1.899e+00, top1 52.94, top5 77.65
2021-11-03 14:36:32 train 1000, loss 2.008e+00, top1 54.60, top5 78.02
2021-11-03 14:36:32 train 1000, loss 2.013e+00, top1 54.32, top5 78.02
2021-11-03 14:36:32 train 1000, loss 2.011e+00, top1 54.46, top5 77.87
2021-11-03 14:44:53 train 2000, loss 2.031e+00, top1 54.13, top5 77.67
2021-11-03 14:44:53 train 2000, loss 2.040e+00, top1 53.86, top5 77.50
2021-11-03 14:44:53 train 2000, loss 2.029e+00, top1 54.03, top5 77.62
2021-11-03 14:53:16 train 3000, loss 2.047e+00, top1 53.79, top5 77.32
2021-11-03 14:53:16 train 3000, loss 2.051e+00, top1 53.68, top5 77.36
2021-11-03 14:53:16 train 3000, loss 2.049e+00, top1 53.79, top5 77.36
2021-11-03 15:01:43 train 4000, loss 2.067e+00, top1 53.39, top5 77.02
2021-11-03 15:01:43 train 4000, loss 2.067e+00, top1 53.39, top5 77.06
2021-11-03 15:01:43 train 4000, loss 2.065e+00, top1 53.52, top5 77.06
2021-11-03 15:09:55 train 5000, loss 2.077e+00, top1 53.26, top5 76.87
2021-11-03 15:09:55 train 5000, loss 2.077e+00, top1 53.20, top5 76.86
2021-11-03 15:09:55 train 5000, loss 2.081e+00, top1 53.11, top5 76.86
2021-11-03 15:10:17 valid 0000, loss 9.769e-01, top1 82.35, top5 90.59
2021-11-03 15:10:17 valid 0000, loss 9.769e-01, top1 82.35, top5 90.59
2021-11-03 15:10:17 valid 0000, loss 9.769e-01, top1 82.35, top5 90.59
2021-11-03 15:14:42 (JOBID 31582) epoch 5: train time 2529.39, inference time 275.16s, valid_top1 52.71 (best_top1 63.94), valid_top5 78.20
2021-11-03 15:14:53 (JOBID 31582) epoch 5: train time 2529.53, inference time 285.29s, valid_top1 52.71 (best_top1 63.94), valid_top5 78.20
2021-11-03 15:14:53 (JOBID 31582) epoch 5: train time 2531.45, inference time 285.28s, valid_top1 52.71 (best_top1 63.94), valid_top5 78.20
2021-11-03 15:14:57 train 0000, loss 2.668e+00, top1 43.53, top5 72.94
2021-11-03 15:15:06 train 0000, loss 2.162e+00, top1 52.94, top5 78.82
2021-11-03 15:15:06 train 0000, loss 2.192e+00, top1 50.59, top5 72.94
2021-11-03 15:25:40 train 1000, loss 2.105e+00, top1 52.58, top5 76.45
2021-11-03 15:25:40 train 1000, loss 2.098e+00, top1 52.67, top5 76.69
2021-11-03 15:25:40 train 1000, loss 2.097e+00, top1 52.84, top5 76.59
2021-11-03 15:33:55 train 2000, loss 2.119e+00, top1 52.18, top5 76.26
2021-11-03 15:33:55 train 2000, loss 2.117e+00, top1 52.25, top5 76.36
2021-11-03 15:33:55 train 2000, loss 2.107e+00, top1 52.50, top5 76.45
2021-11-03 15:42:06 train 3000, loss 2.128e+00, top1 52.01, top5 76.19
2021-11-03 15:42:06 train 3000, loss 2.129e+00, top1 52.08, top5 76.08
2021-11-03 15:42:06 train 3000, loss 2.123e+00, top1 52.21, top5 76.22
2021-11-03 15:50:25 train 4000, loss 2.132e+00, top1 52.03, top5 76.07
2021-11-03 15:50:25 train 4000, loss 2.138e+00, top1 51.92, top5 75.91
2021-11-03 15:50:25 train 4000, loss 2.139e+00, top1 51.87, top5 75.96
2021-11-03 15:58:43 train 5000, loss 2.149e+00, top1 51.71, top5 75.76
2021-11-03 15:58:43 train 5000, loss 2.147e+00, top1 51.74, top5 75.79
2021-11-03 15:58:43 train 5000, loss 2.142e+00, top1 51.86, top5 75.91
2021-11-03 15:59:05 valid 0000, loss 8.205e-01, top1 84.71, top5 95.29
2021-11-03 15:59:05 valid 0000, loss 8.205e-01, top1 84.71, top5 95.29
2021-11-03 15:59:05 valid 0000, loss 8.205e-01, top1 84.71, top5 95.29
2021-11-03 16:03:23 (JOBID 31582) epoch 6: train time 2652.86, inference time 267.63s, valid_top1 53.78 (best_top1 63.94), valid_top5 78.92
2021-11-03 16:03:42 (JOBID 31582) epoch 6: train time 2642.50, inference time 286.96s, valid_top1 53.78 (best_top1 63.94), valid_top5 78.92
2021-11-03 16:03:45 (JOBID 31582) epoch 6: train time 2642.64, inference time 289.77s, valid_top1 53.78 (best_top1 63.94), valid_top5 78.92
2021-11-03 16:03:57 train 0000, loss 2.138e+00, top1 54.12, top5 75.29
2021-11-03 16:03:37 train 0000, loss 2.391e+00, top1 44.71, top5 74.12
2021-11-03 16:03:59 train 0000, loss 2.225e+00, top1 49.41, top5 75.29
2021-11-03 16:12:19 train 1000, loss 2.158e+00, top1 51.59, top5 75.58
2021-11-03 16:12:20 train 1000, loss 2.149e+00, top1 51.75, top5 75.82
2021-11-03 16:12:20 train 1000, loss 2.156e+00, top1 51.50, top5 75.74
2021-11-03 16:20:34 train 2000, loss 2.166e+00, top1 51.46, top5 75.50
2021-11-03 16:20:34 train 2000, loss 2.168e+00, top1 51.31, top5 75.50
2021-11-03 16:20:34 train 2000, loss 2.159e+00, top1 51.59, top5 75.65
2021-11-03 16:28:56 train 3000, loss 2.175e+00, top1 51.17, top5 75.37
2021-11-03 16:28:56 train 3000, loss 2.174e+00, top1 51.27, top5 75.36
2021-11-03 16:28:56 train 3000, loss 2.167e+00, top1 51.40, top5 75.54
2021-11-03 16:37:23 train 4000, loss 2.181e+00, top1 51.08, top5 75.31
2021-11-03 16:37:23 train 4000, loss 2.180e+00, top1 51.17, top5 75.27
2021-11-03 16:37:23 train 4000, loss 2.173e+00, top1 51.29, top5 75.44
2021-11-03 16:45:48 train 5000, loss 2.186e+00, top1 50.99, top5 75.22
2021-11-03 16:45:48 train 5000, loss 2.185e+00, top1 51.08, top5 75.20
2021-11-03 16:45:48 train 5000, loss 2.182e+00, top1 51.12, top5 75.29
2021-11-03 16:46:11 valid 0000, loss 1.090e+00, top1 77.65, top5 88.24
2021-11-03 16:46:11 valid 0000, loss 1.090e+00, top1 77.65, top5 88.24
2021-11-03 16:46:11 valid 0000, loss 1.090e+00, top1 77.65, top5 88.24
2021-11-03 16:50:51 (JOBID 31582) epoch 7: train time 2538.41, inference time 289.92s, valid_top1 52.79 (best_top1 63.94), valid_top5 77.96
2021-11-03 16:50:52 (JOBID 31582) epoch 7: train time 2558.12, inference time 290.60s, valid_top1 52.79 (best_top1 63.94), valid_top5 77.96
2021-11-03 16:50:52 (JOBID 31582) epoch 7: train time 2535.78, inference time 290.94s, valid_top1 52.79 (best_top1 63.94), valid_top5 77.96
2021-11-03 16:51:06 train 0000, loss 2.329e+00, top1 47.06, top5 69.41
2021-11-03 16:51:06 train 0000, loss 1.800e+00, top1 58.82, top5 82.35
2021-11-03 16:51:06 train 0000, loss 2.418e+00, top1 42.35, top5 69.41
2021-11-03 16:59:26 train 1000, loss 2.168e+00, top1 51.34, top5 75.33
2021-11-03 16:59:26 train 1000, loss 2.182e+00, top1 51.22, top5 75.28
2021-11-03 16:59:26 train 1000, loss 2.184e+00, top1 51.07, top5 75.26
2021-11-03 17:07:39 train 2000, loss 2.178e+00, top1 51.21, top5 75.21
2021-11-03 17:07:39 train 2000, loss 2.192e+00, top1 50.92, top5 75.13
2021-11-03 17:07:39 train 2000, loss 2.187e+00, top1 51.04, top5 75.22
2021-11-03 17:16:00 train 3000, loss 2.187e+00, top1 51.01, top5 75.16
2021-11-03 17:16:00 train 3000, loss 2.198e+00, top1 50.75, top5 75.04
2021-11-03 17:16:00 train 3000, loss 2.189e+00, top1 50.96, top5 75.20
2021-11-03 17:24:19 train 4000, loss 2.195e+00, top1 50.83, top5 75.04
2021-11-03 17:24:19 train 4000, loss 2.200e+00, top1 50.68, top5 75.00
2021-11-03 17:24:19 train 4000, loss 2.196e+00, top1 50.86, top5 75.07
2021-11-03 17:32:44 train 5000, loss 2.202e+00, top1 50.70, top5 74.93
2021-11-03 17:32:44 train 5000, loss 2.205e+00, top1 50.64, top5 74.90
2021-11-03 17:32:44 train 5000, loss 2.198e+00, top1 50.82, top5 75.03
2021-11-03 17:33:06 valid 0000, loss 1.419e+00, top1 68.24, top5 84.71
2021-11-03 17:33:06 valid 0000, loss 1.419e+00, top1 68.24, top5 84.71
2021-11-03 17:33:06 valid 0000, loss 1.419e+00, top1 68.24, top5 84.71
2021-11-03 17:37:38 (JOBID 31582) epoch 8: train time 2524.66, inference time 281.46s, valid_top1 53.26 (best_top1 63.94), valid_top5 78.54
2021-11-03 17:37:42 (JOBID 31582) epoch 8: train time 2524.86, inference time 285.88s, valid_top1 53.26 (best_top1 63.94), valid_top5 78.54
2021-11-03 17:37:44 (JOBID 31582) epoch 8: train time 2525.42, inference time 287.59s, valid_top1 53.26 (best_top1 63.94), valid_top5 78.54
2021-11-03 17:37:57 train 0000, loss 2.223e+00, top1 38.82, top5 77.65
2021-11-03 17:37:52 train 0000, loss 2.072e+00, top1 54.12, top5 71.76
2021-11-03 17:37:57 train 0000, loss 2.201e+00, top1 57.65, top5 74.12
2021-11-03 17:46:26 train 1000, loss 2.191e+00, top1 51.07, top5 75.01
2021-11-03 17:46:26 train 1000, loss 2.195e+00, top1 50.63, top5 75.07
2021-11-03 17:46:26 train 1000, loss 2.185e+00, top1 51.09, top5 75.11
2021-11-03 17:54:46 train 2000, loss 2.199e+00, top1 50.77, top5 74.90
2021-11-03 17:54:46 train 2000, loss 2.205e+00, top1 50.61, top5 74.91
2021-11-03 17:54:46 train 2000, loss 2.197e+00, top1 50.77, top5 74.97
2021-11-03 18:03:17 train 3000, loss 2.209e+00, top1 50.61, top5 74.83
2021-11-03 18:03:17 train 3000, loss 2.203e+00, top1 50.67, top5 74.86
2021-11-03 18:03:17 train 3000, loss 2.206e+00, top1 50.64, top5 74.81
2021-11-03 18:11:39 train 4000, loss 2.208e+00, top1 50.57, top5 74.75
2021-11-03 18:11:39 train 4000, loss 2.210e+00, top1 50.55, top5 74.82
2021-11-03 18:11:39 train 4000, loss 2.211e+00, top1 50.52, top5 74.71
2021-11-03 18:20:04 train 5000, loss 2.211e+00, top1 50.54, top5 74.75
2021-11-03 18:20:04 train 5000, loss 2.214e+00, top1 50.46, top5 74.77
2021-11-03 18:20:04 train 5000, loss 2.212e+00, top1 50.48, top5 74.69
2021-11-03 18:20:27 valid 0000, loss 1.257e+00, top1 74.12, top5 85.88
2021-11-03 18:20:27 valid 0000, loss 1.257e+00, top1 74.12, top5 85.88
2021-11-03 18:20:27 valid 0000, loss 1.257e+00, top1 74.12, top5 85.88
2021-11-03 18:24:51 (JOBID 31582) epoch 9: train time 2554.21, inference time 274.48s, valid_top1 54.10 (best_top1 63.94), valid_top5 79.45
2021-11-03 18:25:05 (JOBID 31582) epoch 9: train time 2552.35, inference time 288.08s, valid_top1 54.10 (best_top1 63.94), valid_top5 79.45
2021-11-03 18:25:10 (JOBID 31582) epoch 9: train time 2558.64, inference time 293.21s, valid_top1 54.10 (best_top1 63.94), valid_top5 79.45
2021-11-03 18:25:06 train 0000, loss 2.365e+00, top1 47.06, top5 74.12
2021-11-03 18:25:20 train 0000, loss 2.229e+00, top1 54.12, top5 70.59
2021-11-03 18:25:24 train 0000, loss 1.881e+00, top1 57.65, top5 84.71
2021-11-03 18:33:52 train 1000, loss 2.198e+00, top1 50.91, top5 75.19
2021-11-03 18:33:52 train 1000, loss 2.206e+00, top1 50.76, top5 74.78
2021-11-03 18:33:52 train 1000, loss 2.194e+00, top1 50.84, top5 75.04
2021-11-03 18:42:17 train 2000, loss 2.195e+00, top1 50.83, top5 75.20
2021-11-03 18:42:17 train 2000, loss 2.205e+00, top1 50.72, top5 74.78
2021-11-03 18:42:17 train 2000, loss 2.204e+00, top1 50.66, top5 74.85
2021-11-03 18:50:50 train 3000, loss 2.214e+00, top1 50.56, top5 74.66
2021-11-03 18:50:50 train 3000, loss 2.206e+00, top1 50.58, top5 74.95
2021-11-03 18:50:50 train 3000, loss 2.210e+00, top1 50.57, top5 74.76
2021-11-03 18:59:12 train 4000, loss 2.211e+00, top1 50.51, top5 74.85
2021-11-03 18:59:12 train 4000, loss 2.214e+00, top1 50.51, top5 74.66
2021-11-03 18:59:12 train 4000, loss 2.214e+00, top1 50.50, top5 74.69
2021-11-03 19:07:34 train 5000, loss 2.215e+00, top1 50.47, top5 74.79
2021-11-03 19:07:34 train 5000, loss 2.216e+00, top1 50.49, top5 74.62
2021-11-03 19:07:34 train 5000, loss 2.218e+00, top1 50.46, top5 74.64
2021-11-03 19:07:57 valid 0000, loss 1.415e+00, top1 76.47, top5 87.06
2021-11-03 19:07:57 valid 0000, loss 1.415e+00, top1 76.47, top5 87.06
2021-11-03 19:07:57 valid 0000, loss 1.415e+00, top1 76.47, top5 87.06
2021-11-03 19:12:15 (JOBID 31582) epoch 10: train time 2556.97, inference time 268.71s, valid_top1 51.72 (best_top1 63.94), valid_top5 77.38
2021-11-03 19:12:31 (JOBID 31582) epoch 10: train time 2575.63, inference time 283.95s, valid_top1 51.72 (best_top1 63.94), valid_top5 77.38
2021-11-03 19:12:33 (JOBID 31582) epoch 10: train time 2561.82, inference time 286.57s, valid_top1 51.72 (best_top1 63.94), valid_top5 77.38
2021-11-03 19:12:45 train 0000, loss 2.093e+00, top1 58.82, top5 74.12
2021-11-03 19:12:29 train 0000, loss 2.398e+00, top1 43.53, top5 65.88
2021-11-03 19:12:47 train 0000, loss 2.470e+00, top1 42.35, top5 71.76
2021-11-03 19:21:24 train 1000, loss 2.207e+00, top1 50.52, top5 74.93
2021-11-03 19:21:24 train 1000, loss 2.205e+00, top1 50.58, top5 74.95
2021-11-03 19:21:24 train 1000, loss 2.183e+00, top1 51.12, top5 75.19
2021-11-03 19:29:51 train 2000, loss 2.210e+00, top1 50.43, top5 74.81
2021-11-03 19:29:51 train 2000, loss 2.211e+00, top1 50.47, top5 74.85
2021-11-03 19:29:52 train 2000, loss 2.195e+00, top1 50.82, top5 74.98
2021-11-03 19:38:22 train 3000, loss 2.218e+00, top1 50.36, top5 74.67
2021-11-03 19:38:22 train 3000, loss 2.216e+00, top1 50.36, top5 74.69
2021-11-03 19:38:22 train 3000, loss 2.204e+00, top1 50.68, top5 74.90
2021-11-03 19:46:50 train 4000, loss 2.222e+00, top1 50.26, top5 74.61
2021-11-03 19:46:50 train 4000, loss 2.219e+00, top1 50.39, top5 74.70
2021-11-03 19:46:50 train 4000, loss 2.212e+00, top1 50.53, top5 74.76
2021-11-03 19:55:24 train 5000, loss 2.222e+00, top1 50.33, top5 74.66
2021-11-03 19:55:24 train 5000, loss 2.217e+00, top1 50.43, top5 74.66
2021-11-03 19:55:24 train 5000, loss 2.223e+00, top1 50.24, top5 74.60
2021-11-03 19:55:47 valid 0000, loss 1.202e+00, top1 75.29, top5 85.88
2021-11-03 19:55:47 valid 0000, loss 1.202e+00, top1 75.29, top5 85.88
2021-11-03 19:55:47 valid 0000, loss 1.202e+00, top1 75.29, top5 85.88
2021-11-03 20:00:16 (JOBID 31582) epoch 11: train time 2582.86, inference time 279.83s, valid_top1 49.38 (best_top1 63.94), valid_top5 75.72
2021-11-03 20:00:28 (JOBID 31582) epoch 11: train time 2585.90, inference time 291.85s, valid_top1 49.38 (best_top1 63.94), valid_top5 75.72
2021-11-03 20:00:29 (JOBID 31582) epoch 11: train time 2600.94, inference time 292.36s, valid_top1 49.38 (best_top1 63.94), valid_top5 75.72
2021-11-03 20:00:31 train 0000, loss 2.623e+00, top1 43.53, top5 72.94
2021-11-03 20:00:42 train 0000, loss 2.049e+00, top1 51.76, top5 77.65
2021-11-03 20:00:42 train 0000, loss 2.459e+00, top1 45.88, top5 76.47
2021-11-03 20:09:20 train 1000, loss 2.197e+00, top1 50.69, top5 75.02
2021-11-03 20:09:20 train 1000, loss 2.202e+00, top1 50.71, top5 74.98
2021-11-03 20:09:20 train 1000, loss 2.203e+00, top1 50.76, top5 74.87
2021-11-03 20:17:55 train 2000, loss 2.209e+00, top1 50.59, top5 74.89
2021-11-03 20:17:55 train 2000, loss 2.211e+00, top1 50.45, top5 74.78
2021-11-03 20:17:56 train 2000, loss 2.211e+00, top1 50.49, top5 74.74
2021-11-03 20:26:25 train 3000, loss 2.214e+00, top1 50.45, top5 74.77
2021-11-03 20:26:25 train 3000, loss 2.217e+00, top1 50.41, top5 74.69
2021-11-03 20:26:25 train 3000, loss 2.217e+00, top1 50.37, top5 74.63
2021-11-03 20:34:50 train 4000, loss 2.217e+00, top1 50.37, top5 74.72
2021-11-03 20:34:50 train 4000, loss 2.220e+00, top1 50.34, top5 74.66
2021-11-03 20:34:50 train 4000, loss 2.221e+00, top1 50.28, top5 74.57
2021-11-03 20:43:13 train 5000, loss 2.222e+00, top1 50.24, top5 74.63
2021-11-03 20:43:13 train 5000, loss 2.225e+00, top1 50.23, top5 74.57
2021-11-03 20:43:13 train 5000, loss 2.227e+00, top1 50.18, top5 74.49
2021-11-03 20:43:36 valid 0000, loss 8.593e-01, top1 80.00, top5 92.94
2021-11-03 20:43:36 valid 0000, loss 8.593e-01, top1 80.00, top5 92.94
2021-11-03 20:43:36 valid 0000, loss 8.593e-01, top1 80.00, top5 92.94
2021-11-03 20:47:55 (JOBID 31582) epoch 12: train time 2577.12, inference time 269.58s, valid_top1 52.68 (best_top1 63.94), valid_top5 78.18
2021-11-03 20:48:08 (JOBID 31582) epoch 12: train time 2589.10, inference time 282.39s, valid_top1 52.68 (best_top1 63.94), valid_top5 78.18
2021-11-03 20:48:09 (JOBID 31582) epoch 12: train time 2576.75, inference time 283.58s, valid_top1 52.68 (best_top1 63.94), valid_top5 78.18
2021-11-03 20:48:09 train 0000, loss 2.314e+00, top1 47.06, top5 74.12
2021-11-03 20:48:22 train 0000, loss 2.145e+00, top1 55.29, top5 75.29
2021-11-03 20:48:22 train 0000, loss 1.897e+00, top1 55.29, top5 80.00
2021-11-03 20:56:59 train 1000, loss 2.199e+00, top1 50.81, top5 74.88
2021-11-03 20:56:59 train 1000, loss 2.205e+00, top1 50.74, top5 74.88
2021-11-03 20:56:59 train 1000, loss 2.213e+00, top1 50.37, top5 74.73
2021-11-03 21:05:33 train 2000, loss 2.211e+00, top1 50.56, top5 74.71
2021-11-03 21:05:33 train 2000, loss 2.217e+00, top1 50.36, top5 74.65
2021-11-03 21:05:33 train 2000, loss 2.213e+00, top1 50.39, top5 74.74
2021-11-03 21:13:56 train 3000, loss 2.221e+00, top1 50.31, top5 74.59
2021-11-03 21:13:56 train 3000, loss 2.214e+00, top1 50.46, top5 74.62
2021-11-03 21:13:56 train 3000, loss 2.215e+00, top1 50.34, top5 74.75
2021-11-03 21:22:15 train 4000, loss 2.226e+00, top1 50.23, top5 74.49
2021-11-03 21:22:15 train 4000, loss 2.222e+00, top1 50.22, top5 74.60
2021-11-03 21:22:15 train 4000, loss 2.222e+00, top1 50.29, top5 74.51
2021-11-03 21:30:35 train 5000, loss 2.223e+00, top1 50.31, top5 74.52
2021-11-03 21:30:35 train 5000, loss 2.225e+00, top1 50.18, top5 74.56
2021-11-03 21:30:35 train 5000, loss 2.229e+00, top1 50.18, top5 74.49
2021-11-03 21:30:57 valid 0000, loss 1.479e+00, top1 67.06, top5 84.71
2021-11-03 21:30:57 valid 0000, loss 1.479e+00, top1 67.06, top5 84.71
2021-11-03 21:30:57 valid 0000, loss 1.479e+00, top1 67.06, top5 84.71
2021-11-03 21:35:48 (JOBID 31582) epoch 13: train time 2559.00, inference time 300.54s, valid_top1 52.30 (best_top1 63.94), valid_top5 77.79
2021-11-03 21:35:48 (JOBID 31582) epoch 13: train time 2572.02, inference time 300.95s, valid_top1 52.30 (best_top1 63.94), valid_top5 77.79
2021-11-03 21:35:48 (JOBID 31582) epoch 13: train time 2558.12, inference time 301.37s, valid_top1 52.30 (best_top1 63.94), valid_top5 77.79
2021-11-03 21:36:03 train 0000, loss 2.095e+00, top1 49.41, top5 76.47
2021-11-03 21:36:03 train 0000, loss 1.769e+00, top1 54.12, top5 78.82
2021-11-03 21:36:03 train 0000, loss 2.403e+00, top1 47.06, top5 70.59
2021-11-03 21:44:51 train 1000, loss 2.203e+00, top1 50.73, top5 74.87
2021-11-03 21:44:51 train 1000, loss 2.203e+00, top1 50.47, top5 74.75
2021-11-03 21:44:52 train 1000, loss 2.215e+00, top1 50.44, top5 74.66
2021-11-03 21:53:20 train 2000, loss 2.211e+00, top1 50.51, top5 74.73
2021-11-03 21:53:20 train 2000, loss 2.216e+00, top1 50.26, top5 74.63
2021-11-03 21:53:20 train 2000, loss 2.217e+00, top1 50.39, top5 74.65
2021-11-03 22:02:01 train 3000, loss 2.215e+00, top1 50.45, top5 74.68
2021-11-03 22:02:01 train 3000, loss 2.221e+00, top1 50.19, top5 74.58
2021-11-03 22:02:01 train 3000, loss 2.220e+00, top1 50.35, top5 74.67
2021-11-03 22:10:42 train 4000, loss 2.221e+00, top1 50.34, top5 74.57
2021-11-03 22:10:42 train 4000, loss 2.224e+00, top1 50.13, top5 74.51
2021-11-03 22:10:42 train 4000, loss 2.221e+00, top1 50.29, top5 74.63
2021-11-03 22:19:21 train 5000, loss 2.223e+00, top1 50.28, top5 74.56
2021-11-03 22:19:21 train 5000, loss 2.228e+00, top1 50.08, top5 74.46
2021-11-03 22:19:21 train 5000, loss 2.225e+00, top1 50.22, top5 74.57
2021-11-03 22:19:43 valid 0000, loss 1.062e+00, top1 76.47, top5 88.24
2021-11-03 22:19:43 valid 0000, loss 1.062e+00, top1 76.47, top5 88.24
2021-11-03 22:19:44 valid 0000, loss 1.062e+00, top1 76.47, top5 88.24
2021-11-03 22:24:04 (JOBID 31582) epoch 14: train time 2624.97, inference time 270.87s, valid_top1 52.79 (best_top1 63.94), valid_top5 78.63
2021-11-03 22:24:15 (JOBID 31582) epoch 14: train time 2625.71, inference time 281.75s, valid_top1 52.79 (best_top1 63.94), valid_top5 78.63
2021-11-03 22:24:18 (JOBID 31582) epoch 14: train time 2625.61, inference time 284.44s, valid_top1 52.79 (best_top1 63.94), valid_top5 78.63
2021-11-03 22:24:30 train 0000, loss 1.798e+00, top1 52.94, top5 84.71
2021-11-03 22:24:18 train 0000, loss 2.318e+00, top1 43.53, top5 70.59
2021-11-03 22:24:32 train 0000, loss 1.992e+00, top1 51.76, top5 78.82
2021-11-03 22:33:30 train 1000, loss 2.189e+00, top1 50.64, top5 75.21
2021-11-03 22:33:30 train 1000, loss 2.200e+00, top1 50.50, top5 75.02
2021-11-03 22:33:31 train 1000, loss 2.201e+00, top1 50.53, top5 74.98
2021-11-03 22:42:14 train 2000, loss 2.206e+00, top1 50.43, top5 74.89
2021-11-03 22:42:14 train 2000, loss 2.207e+00, top1 50.41, top5 74.93
2021-11-03 22:42:14 train 2000, loss 2.214e+00, top1 50.36, top5 74.72
2021-11-03 22:50:50 train 3000, loss 2.213e+00, top1 50.27, top5 74.75
2021-11-03 22:50:50 train 3000, loss 2.214e+00, top1 50.30, top5 74.82
2021-11-03 22:50:50 train 3000, loss 2.219e+00, top1 50.25, top5 74.63
2021-11-03 22:59:27 train 4000, loss 2.220e+00, top1 50.16, top5 74.64
2021-11-03 22:59:27 train 4000, loss 2.220e+00, top1 50.22, top5 74.72
2021-11-03 22:59:27 train 4000, loss 2.220e+00, top1 50.26, top5 74.62
2021-11-03 23:08:08 train 5000, loss 2.225e+00, top1 50.12, top5 74.62
2021-11-03 23:08:08 train 5000, loss 2.223e+00, top1 50.15, top5 74.62
2021-11-03 23:08:08 train 5000, loss 2.223e+00, top1 50.23, top5 74.60
2021-11-03 23:08:31 valid 0000, loss 8.292e-01, top1 78.82, top5 92.94
2021-11-03 23:08:31 valid 0000, loss 8.292e-01, top1 78.82, top5 92.94
2021-11-03 23:08:31 valid 0000, loss 8.292e-01, top1 78.82, top5 92.94
2021-11-03 23:13:20 (JOBID 31582) epoch 15: train time 2645.07, inference time 299.59s, valid_top1 52.69 (best_top1 63.94), valid_top5 78.08
2021-11-03 23:13:21 (JOBID 31582) epoch 15: train time 2642.59, inference time 300.33s, valid_top1 52.69 (best_top1 63.94), valid_top5 78.08
2021-11-03 23:13:22 (JOBID 31582) epoch 15: train time 2656.28, inference time 300.98s, valid_top1 52.69 (best_top1 63.94), valid_top5 78.08
2021-11-03 23:13:36 train 0000, loss 1.948e+00, top1 54.12, top5 78.82
2021-11-03 23:13:36 train 0000, loss 2.235e+00, top1 50.59, top5 71.76
2021-11-03 23:13:36 train 0000, loss 2.304e+00, top1 44.71, top5 77.65
2021-11-03 23:22:09 train 1000, loss 2.207e+00, top1 50.52, top5 74.68
2021-11-03 23:22:09 train 1000, loss 2.199e+00, top1 50.61, top5 74.96
2021-11-03 23:22:09 train 1000, loss 2.200e+00, top1 50.33, top5 74.93
2021-11-03 23:30:44 train 2000, loss 2.215e+00, top1 50.42, top5 74.54
2021-11-03 23:30:44 train 2000, loss 2.207e+00, top1 50.54, top5 74.86
2021-11-03 23:30:44 train 2000, loss 2.214e+00, top1 50.15, top5 74.69
2021-11-03 23:39:09 train 3000, loss 2.222e+00, top1 50.27, top5 74.53
2021-11-03 23:39:09 train 3000, loss 2.215e+00, top1 50.41, top5 74.70
2021-11-03 23:39:09 train 3000, loss 2.219e+00, top1 50.17, top5 74.66
2021-11-03 23:47:35 train 4000, loss 2.224e+00, top1 50.22, top5 74.48
2021-11-03 23:47:35 train 4000, loss 2.219e+00, top1 50.35, top5 74.65
2021-11-03 23:47:35 train 4000, loss 2.226e+00, top1 50.12, top5 74.53
2021-11-03 23:56:08 train 5000, loss 2.219e+00, top1 50.31, top5 74.63
2021-11-03 23:56:08 train 5000, loss 2.226e+00, top1 50.21, top5 74.45
2021-11-03 23:56:08 train 5000, loss 2.226e+00, top1 50.12, top5 74.54
2021-11-03 23:56:31 valid 0000, loss 8.250e-01, top1 81.18, top5 91.76
2021-11-03 23:56:31 valid 0000, loss 8.250e-01, top1 81.18, top5 91.76
2021-11-03 23:56:31 valid 0000, loss 8.250e-01, top1 81.18, top5 91.76
2021-11-04 00:01:08 (JOBID 31582) epoch 16: train time 2579.92, inference time 287.39s, valid_top1 48.97 (best_top1 63.94), valid_top5 75.03
2021-11-04 00:01:10 (JOBID 31582) epoch 16: train time 2579.43, inference time 288.65s, valid_top1 48.97 (best_top1 63.94), valid_top5 75.03
2021-11-04 00:01:11 (JOBID 31582) epoch 16: train time 2580.44, inference time 289.50s, valid_top1 48.97 (best_top1 63.94), valid_top5 75.03
2021-11-04 00:01:23 train 0000, loss 1.932e+00, top1 60.00, top5 78.82
2021-11-04 00:01:24 train 0000, loss 2.359e+00, top1 56.47, top5 68.24
2021-11-04 00:01:24 train 0000, loss 2.137e+00, top1 55.29, top5 77.65
2021-11-04 00:09:57 train 1000, loss 2.200e+00, top1 50.45, top5 74.99
2021-11-04 00:09:57 train 1000, loss 2.203e+00, top1 50.44, top5 74.88
2021-11-04 00:09:57 train 1000, loss 2.208e+00, top1 50.61, top5 74.78
2021-11-04 00:18:32 train 2000, loss 2.212e+00, top1 50.34, top5 74.70
2021-11-04 00:18:32 train 2000, loss 2.216e+00, top1 50.31, top5 74.74
2021-11-04 00:18:32 train 2000, loss 2.217e+00, top1 50.53, top5 74.57
2021-11-04 00:26:56 train 3000, loss 2.217e+00, top1 50.36, top5 74.64
2021-11-04 00:26:56 train 3000, loss 2.220e+00, top1 50.25, top5 74.69
2021-11-04 00:26:56 train 3000, loss 2.218e+00, top1 50.42, top5 74.58
2021-11-04 00:35:22 train 4000, loss 2.216e+00, top1 50.39, top5 74.67
2021-11-04 00:35:22 train 4000, loss 2.222e+00, top1 50.23, top5 74.66
2021-11-04 00:35:22 train 4000, loss 2.222e+00, top1 50.34, top5 74.52
2021-11-04 00:43:57 train 5000, loss 2.227e+00, top1 50.14, top5 74.57
2021-11-04 00:43:57 train 5000, loss 2.217e+00, top1 50.39, top5 74.67
2021-11-04 00:43:57 train 5000, loss 2.228e+00, top1 50.24, top5 74.43
2021-11-04 00:44:19 valid 0000, loss 7.591e-01, top1 82.35, top5 91.76
2021-11-04 00:44:19 valid 0000, loss 7.591e-01, top1 82.35, top5 91.76
2021-11-04 00:44:19 valid 0000, loss 7.591e-01, top1 82.35, top5 91.76
2021-11-04 00:48:41 (JOBID 31582) epoch 17: train time 2579.35, inference time 272.00s, valid_top1 48.92 (best_top1 63.94), valid_top5 74.61
2021-11-04 00:48:53 (JOBID 31582) epoch 17: train time 2578.33, inference time 283.35s, valid_top1 48.92 (best_top1 63.94), valid_top5 74.61
2021-11-04 00:48:55 (JOBID 31582) epoch 17: train time 2580.77, inference time 286.18s, valid_top1 48.92 (best_top1 63.94), valid_top5 74.61
2021-11-04 00:49:07 train 0000, loss 1.885e+00, top1 56.47, top5 81.18
2021-11-04 00:48:55 train 0000, loss 2.268e+00, top1 47.06, top5 76.47
2021-11-04 00:49:10 train 0000, loss 2.366e+00, top1 43.53, top5 68.24
2021-11-04 00:57:39 train 1000, loss 2.205e+00, top1 50.63, top5 74.77
2021-11-04 00:57:39 train 1000, loss 2.213e+00, top1 50.32, top5 74.68
2021-11-04 00:57:39 train 1000, loss 2.212e+00, top1 50.31, top5 74.85
2021-11-04 01:06:12 train 2000, loss 2.214e+00, top1 50.46, top5 74.73
2021-11-04 01:06:12 train 2000, loss 2.216e+00, top1 50.33, top5 74.64
2021-11-04 01:06:12 train 2000, loss 2.216e+00, top1 50.33, top5 74.72
2021-11-04 01:14:35 train 3000, loss 2.217e+00, top1 50.37, top5 74.66
2021-11-04 01:14:35 train 3000, loss 2.216e+00, top1 50.44, top5 74.66
2021-11-04 01:14:35 train 3000, loss 2.219e+00, top1 50.31, top5 74.64
2021-11-04 01:22:56 train 4000, loss 2.225e+00, top1 50.23, top5 74.54
2021-11-04 01:22:56 train 4000, loss 2.223e+00, top1 50.29, top5 74.55
2021-11-04 01:22:56 train 4000, loss 2.225e+00, top1 50.17, top5 74.55
2021-11-04 01:31:28 train 5000, loss 2.226e+00, top1 50.23, top5 74.51
2021-11-04 01:31:28 train 5000, loss 2.224e+00, top1 50.28, top5 74.54
2021-11-04 01:31:28 train 5000, loss 2.228e+00, top1 50.15, top5 74.50
2021-11-04 01:31:50 valid 0000, loss 8.778e-01, top1 81.18, top5 90.59
2021-11-04 01:31:50 valid 0000, loss 8.778e-01, top1 81.18, top5 90.59
2021-11-04 01:31:50 valid 0000, loss 8.778e-01, top1 81.18, top5 90.59
2021-11-04 01:36:24 (JOBID 31582) epoch 18: train time 2564.89, inference time 283.49s, valid_top1 52.02 (best_top1 63.94), valid_top5 77.64
2021-11-04 01:36:24 (JOBID 31582) epoch 18: train time 2579.01, inference time 283.94s, valid_top1 52.02 (best_top1 63.94), valid_top5 77.64
2021-11-04 01:36:25 (JOBID 31582) epoch 18: train time 2567.38, inference time 284.95s, valid_top1 52.02 (best_top1 63.94), valid_top5 77.64
2021-11-04 01:36:38 train 0000, loss 2.179e+00, top1 47.06, top5 76.47
2021-11-04 01:36:38 train 0000, loss 2.556e+00, top1 41.18, top5 63.53
2021-11-04 01:36:40 train 0000, loss 2.199e+00, top1 55.29, top5 76.47
2021-11-04 01:45:07 train 1000, loss 2.203e+00, top1 50.68, top5 74.87
2021-11-04 01:45:06 train 1000, loss 2.188e+00, top1 50.83, top5 75.19
2021-11-04 01:45:07 train 1000, loss 2.219e+00, top1 50.28, top5 74.66
2021-11-04 01:53:34 train 2000, loss 2.215e+00, top1 50.31, top5 74.70
2021-11-04 01:53:34 train 2000, loss 2.204e+00, top1 50.65, top5 74.95
2021-11-04 01:53:34 train 2000, loss 2.217e+00, top1 50.26, top5 74.68
2021-11-04 02:01:49 train 3000, loss 2.221e+00, top1 50.23, top5 74.61
2021-11-04 02:01:49 train 3000, loss 2.207e+00, top1 50.58, top5 74.87
2021-11-04 02:01:49 train 3000, loss 2.221e+00, top1 50.26, top5 74.59
2021-11-04 02:10:06 train 4000, loss 2.213e+00, top1 50.47, top5 74.74
2021-11-04 02:10:06 train 4000, loss 2.222e+00, top1 50.21, top5 74.60
2021-11-04 02:10:06 train 4000, loss 2.226e+00, top1 50.11, top5 74.52
2021-11-04 02:18:22 train 5000, loss 2.223e+00, top1 50.21, top5 74.58
2021-11-04 02:18:22 train 5000, loss 2.218e+00, top1 50.38, top5 74.68
2021-11-04 02:18:22 train 5000, loss 2.229e+00, top1 50.10, top5 74.45
2021-11-04 02:18:45 valid 0000, loss 1.577e+00, top1 64.71, top5 85.88
2021-11-04 02:18:45 valid 0000, loss 1.577e+00, top1 64.71, top5 85.88
2021-11-04 02:18:45 valid 0000, loss 1.577e+00, top1 64.71, top5 85.88
2021-11-04 02:23:20 (JOBID 31582) epoch 19: train time 2531.01, inference time 285.06s, valid_top1 52.43 (best_top1 63.94), valid_top5 77.68
2021-11-04 02:23:20 (JOBID 31582) epoch 19: train time 2530.64, inference time 285.27s, valid_top1 52.43 (best_top1 63.94), valid_top5 77.68
2021-11-04 02:23:23 (JOBID 31582) epoch 19: train time 2529.30, inference time 287.89s, valid_top1 52.43 (best_top1 63.94), valid_top5 77.68
2021-11-04 02:23:34 train 0000, loss 2.246e+00, top1 51.76, top5 74.12
2021-11-04 02:23:34 train 0000, loss 2.287e+00, top1 45.88, top5 72.94
2021-11-04 02:23:37 train 0000, loss 1.952e+00, top1 55.29, top5 74.12
2021-11-04 02:31:52 train 1000, loss 2.215e+00, top1 50.38, top5 74.81
2021-11-04 02:31:52 train 1000, loss 2.199e+00, top1 50.80, top5 74.96
2021-11-04 02:31:52 train 1000, loss 2.213e+00, top1 50.42, top5 74.75
2021-11-04 02:40:18 train 2000, loss 2.205e+00, top1 50.47, top5 74.87
2021-11-04 02:40:18 train 2000, loss 2.220e+00, top1 50.31, top5 74.74
2021-11-04 02:40:18 train 2000, loss 2.215e+00, top1 50.35, top5 74.71
2021-11-04 02:48:33 train 3000, loss 2.223e+00, top1 50.25, top5 74.66
2021-11-04 02:48:33 train 3000, loss 2.206e+00, top1 50.54, top5 74.84
2021-11-04 02:48:33 train 3000, loss 2.224e+00, top1 50.14, top5 74.59
2021-11-04 02:56:53 train 4000, loss 2.211e+00, top1 50.45, top5 74.78
2021-11-04 02:56:52 train 4000, loss 2.226e+00, top1 50.22, top5 74.59
2021-11-04 02:56:53 train 4000, loss 2.227e+00, top1 50.16, top5 74.52
2021-11-04 03:05:14 train 5000, loss 2.230e+00, top1 50.12, top5 74.53
2021-11-04 03:05:14 train 5000, loss 2.232e+00, top1 50.11, top5 74.42
2021-11-04 03:05:14 train 5000, loss 2.214e+00, top1 50.41, top5 74.70
2021-11-04 03:05:37 valid 0000, loss 1.020e+00, top1 78.82, top5 89.41
2021-11-04 03:05:37 valid 0000, loss 1.020e+00, top1 78.82, top5 89.41
2021-11-04 03:05:37 valid 0000, loss 1.020e+00, top1 78.82, top5 89.41
2021-11-04 03:09:55 (JOBID 31582) epoch 20: train time 2526.56, inference time 268.70s, valid_top1 52.66 (best_top1 63.94), valid_top5 77.93
2021-11-04 03:10:12 (JOBID 31582) epoch 20: train time 2526.72, inference time 285.84s, valid_top1 52.66 (best_top1 63.94), valid_top5 77.93
2021-11-04 03:10:13 (JOBID 31582) epoch 20: train time 2523.63, inference time 286.38s, valid_top1 52.66 (best_top1 63.94), valid_top5 77.93
2021-11-04 03:10:26 train 0000, loss 2.366e+00, top1 48.24, top5 71.76
2021-11-04 03:10:09 train 0000, loss 2.072e+00, top1 51.76, top5 75.29
2021-11-04 03:10:26 train 0000, loss 1.781e+00, top1 55.29, top5 82.35
2021-11-04 03:18:44 train 1000, loss 2.200e+00, top1 50.80, top5 75.04
2021-11-04 03:18:44 train 1000, loss 2.213e+00, top1 50.37, top5 74.72
2021-11-04 03:18:44 train 1000, loss 2.195e+00, top1 50.76, top5 74.88
2021-11-04 03:27:08 train 2000, loss 2.208e+00, top1 50.44, top5 74.85
2021-11-04 03:27:08 train 2000, loss 2.217e+00, top1 50.27, top5 74.67
2021-11-04 03:27:08 train 2000, loss 2.200e+00, top1 50.64, top5 74.89
2021-11-04 03:35:25 train 3000, loss 2.214e+00, top1 50.30, top5 74.71
2021-11-04 03:35:25 train 3000, loss 2.221e+00, top1 50.19, top5 74.62
2021-11-04 03:35:25 train 3000, loss 2.209e+00, top1 50.51, top5 74.80
2021-11-04 03:43:45 train 4000, loss 2.218e+00, top1 50.27, top5 74.70
2021-11-04 03:43:45 train 4000, loss 2.225e+00, top1 50.19, top5 74.53
2021-11-04 03:43:45 train 4000, loss 2.216e+00, top1 50.37, top5 74.66
2021-11-04 03:52:01 train 5000, loss 2.221e+00, top1 50.29, top5 74.62
2021-11-04 03:52:01 train 5000, loss 2.225e+00, top1 50.19, top5 74.51
2021-11-04 03:52:01 train 5000, loss 2.224e+00, top1 50.14, top5 74.60
2021-11-04 03:52:24 valid 0000, loss 1.366e+00, top1 69.41, top5 88.24
2021-11-04 03:52:24 valid 0000, loss 1.366e+00, top1 69.41, top5 88.24
2021-11-04 03:52:24 valid 0000, loss 1.366e+00, top1 69.41, top5 88.24
2021-11-04 03:56:44 (JOBID 31582) epoch 21: train time 2520.37, inference time 270.62s, valid_top1 51.86 (best_top1 63.94), valid_top5 77.21
2021-11-04 03:56:58 (JOBID 31582) epoch 21: train time 2521.18, inference time 284.19s, valid_top1 51.86 (best_top1 63.94), valid_top5 77.21
2021-11-04 03:57:00 (JOBID 31582) epoch 21: train time 2538.25, inference time 286.11s, valid_top1 51.86 (best_top1 63.94), valid_top5 77.21
2021-11-04 03:57:12 train 0000, loss 2.080e+00, top1 54.12, top5 80.00
2021-11-04 03:56:58 train 0000, loss 1.689e+00, top1 60.00, top5 84.71
2021-11-04 03:57:13 train 0000, loss 2.207e+00, top1 50.59, top5 75.29
2021-11-04 04:05:45 train 1000, loss 2.201e+00, top1 50.54, top5 74.96
2021-11-04 04:05:45 train 1000, loss 2.199e+00, top1 50.58, top5 74.92
2021-11-04 04:05:45 train 1000, loss 2.203e+00, top1 50.50, top5 75.06
2021-11-04 04:14:23 train 2000, loss 2.211e+00, top1 50.45, top5 74.80
2021-11-04 04:14:24 train 2000, loss 2.211e+00, top1 50.37, top5 74.86
2021-11-04 04:14:24 train 2000, loss 2.212e+00, top1 50.43, top5 74.76
2021-11-04 04:23:04 train 3000, loss 2.216e+00, top1 50.38, top5 74.66
2021-11-04 04:23:04 train 3000, loss 2.216e+00, top1 50.39, top5 74.67
2021-11-04 04:23:04 train 3000, loss 2.215e+00, top1 50.30, top5 74.77
2021-11-04 04:31:48 train 4000, loss 2.222e+00, top1 50.28, top5 74.62
2021-11-04 04:31:48 train 4000, loss 2.220e+00, top1 50.31, top5 74.59
2021-11-04 04:31:48 train 4000, loss 2.219e+00, top1 50.28, top5 74.68
2021-11-04 04:40:36 train 5000, loss 2.225e+00, top1 50.20, top5 74.59
2021-11-04 04:40:36 train 5000, loss 2.226e+00, top1 50.19, top5 74.51
2021-11-04 04:40:37 train 5000, loss 2.224e+00, top1 50.24, top5 74.58
2021-11-04 04:41:00 valid 0000, loss 1.243e+00, top1 71.76, top5 89.41
2021-11-04 04:41:00 valid 0000, loss 1.243e+00, top1 71.76, top5 89.41
2021-11-04 04:41:00 valid 0000, loss 1.243e+00, top1 71.76, top5 89.41
2021-11-04 04:45:43 (JOBID 31582) epoch 22: train time 2630.22, inference time 292.75s, valid_top1 48.61 (best_top1 63.94), valid_top5 74.29
2021-11-04 04:45:43 (JOBID 31582) epoch 22: train time 2632.09, inference time 292.74s, valid_top1 48.61 (best_top1 63.94), valid_top5 74.29
2021-11-04 04:45:45 (JOBID 31582) epoch 22: train time 2645.68, inference time 294.58s, valid_top1 48.61 (best_top1 63.94), valid_top5 74.29
2021-11-04 04:45:56 train 0000, loss 2.067e+00, top1 44.71, top5 76.47
2021-11-04 04:45:56 train 0000, loss 2.165e+00, top1 52.94, top5 74.12
2021-11-04 04:45:59 train 0000, loss 2.402e+00, top1 45.88, top5 75.29
2021-11-04 04:54:49 train 1000, loss 2.216e+00, top1 50.39, top5 74.57
2021-11-04 04:54:49 train 1000, loss 2.194e+00, top1 50.76, top5 74.93
2021-11-04 04:54:49 train 1000, loss 2.201e+00, top1 50.56, top5 75.07
2021-11-04 05:03:47 train 2000, loss 2.206e+00, top1 50.62, top5 74.71
2021-11-04 05:03:47 train 2000, loss 2.225e+00, top1 50.33, top5 74.50
2021-11-04 05:03:47 train 2000, loss 2.206e+00, top1 50.51, top5 74.86
2021-11-04 05:12:37 train 3000, loss 2.224e+00, top1 50.30, top5 74.58
2021-11-04 05:12:37 train 3000, loss 2.215e+00, top1 50.45, top5 74.67
2021-11-04 05:12:37 train 3000, loss 2.213e+00, top1 50.35, top5 74.74
2021-11-04 05:21:26 train 4000, loss 2.222e+00, top1 50.30, top5 74.62
2021-11-04 05:21:26 train 4000, loss 2.222e+00, top1 50.32, top5 74.54
2021-11-04 05:21:26 train 4000, loss 2.221e+00, top1 50.22, top5 74.63
2021-11-04 05:30:13 train 5000, loss 2.223e+00, top1 50.27, top5 74.59
2021-11-04 05:30:13 train 5000, loss 2.226e+00, top1 50.25, top5 74.50
2021-11-04 05:30:13 train 5000, loss 2.224e+00, top1 50.19, top5 74.57
2021-11-04 05:30:36 valid 0000, loss 9.105e-01, top1 77.65, top5 90.59
2021-11-04 05:30:36 valid 0000, loss 9.105e-01, top1 77.65, top5 90.59
2021-11-04 05:30:36 valid 0000, loss 9.105e-01, top1 77.65, top5 90.59
2021-11-04 05:35:09 (JOBID 31582) epoch 23: train time 2683.54, inference time 283.14s, valid_top1 53.33 (best_top1 63.94), valid_top5 78.75
2021-11-04 05:35:19 (JOBID 31582) epoch 23: train time 2681.26, inference time 292.44s, valid_top1 53.33 (best_top1 63.94), valid_top5 78.75
2021-11-04 05:35:19 (JOBID 31582) epoch 23: train time 2683.53, inference time 292.71s, valid_top1 53.33 (best_top1 63.94), valid_top5 78.75
2021-11-04 05:35:23 train 0000, loss 2.678e+00, top1 45.88, top5 68.24
2021-11-04 05:35:33 train 0000, loss 2.371e+00, top1 43.53, top5 74.12
2021-11-04 05:35:33 train 0000, loss 2.199e+00, top1 45.88, top5 72.94
2021-11-04 05:44:07 train 1000, loss 2.201e+00, top1 50.82, top5 74.87
2021-11-04 05:44:07 train 1000, loss 2.201e+00, top1 50.47, top5 74.90
2021-11-04 05:44:07 train 1000, loss 2.207e+00, top1 50.52, top5 74.78
2021-11-04 05:52:47 train 2000, loss 2.205e+00, top1 50.48, top5 74.82
2021-11-04 05:52:47 train 2000, loss 2.214e+00, top1 50.42, top5 74.61
2021-11-04 05:52:47 train 2000, loss 2.207e+00, top1 50.57, top5 74.80
2021-11-04 06:01:31 train 3000, loss 2.213e+00, top1 50.38, top5 74.72
2021-11-04 06:01:31 train 3000, loss 2.220e+00, top1 50.29, top5 74.56
2021-11-04 06:01:31 train 3000, loss 2.219e+00, top1 50.39, top5 74.56
2021-11-04 06:10:14 train 4000, loss 2.220e+00, top1 50.30, top5 74.59
2021-11-04 06:10:14 train 4000, loss 2.222e+00, top1 50.26, top5 74.53
2021-11-04 06:10:14 train 4000, loss 2.223e+00, top1 50.34, top5 74.51
2021-11-04 06:19:05 train 5000, loss 2.222e+00, top1 50.25, top5 74.53
2021-11-04 06:19:05 train 5000, loss 2.224e+00, top1 50.21, top5 74.51
2021-11-04 06:19:05 train 5000, loss 2.225e+00, top1 50.32, top5 74.50
2021-11-04 06:19:28 valid 0000, loss 9.268e-01, top1 80.00, top5 92.94
2021-11-04 06:19:28 valid 0000, loss 9.268e-01, top1 80.00, top5 92.94
2021-11-04 06:19:28 valid 0000, loss 9.268e-01, top1 80.00, top5 92.94
2021-11-04 06:23:59 (JOBID 31582) epoch 24: train time 2639.48, inference time 281.25s, valid_top1 51.91 (best_top1 63.94), valid_top5 77.74
2021-11-04 06:24:00 (JOBID 31582) epoch 24: train time 2649.18, inference time 281.13s, valid_top1 51.91 (best_top1 63.94), valid_top5 77.74
2021-11-04 06:24:06 (JOBID 31582) epoch 24: train time 2639.54, inference time 287.25s, valid_top1 51.91 (best_top1 63.94), valid_top5 77.74
2021-11-04 06:24:14 train 0000, loss 2.295e+00, top1 51.76, top5 74.12
2021-11-04 06:24:14 train 0000, loss 2.011e+00, top1 52.94, top5 81.18
2021-11-04 06:24:20 train 0000, loss 1.975e+00, top1 52.94, top5 85.88
2021-11-04 06:32:45 train 1000, loss 2.212e+00, top1 50.46, top5 74.69
2021-11-04 06:32:45 train 1000, loss 2.201e+00, top1 50.55, top5 74.98
2021-11-04 06:32:45 train 1000, loss 2.200e+00, top1 50.81, top5 74.96
2021-11-04 06:41:23 train 2000, loss 2.217e+00, top1 50.39, top5 74.63
2021-11-04 06:41:23 train 2000, loss 2.213e+00, top1 50.50, top5 74.75
2021-11-04 06:41:24 train 2000, loss 2.211e+00, top1 50.54, top5 74.77
2021-11-04 06:49:52 train 3000, loss 2.220e+00, top1 50.30, top5 74.56
2021-11-04 06:49:52 train 3000, loss 2.215e+00, top1 50.47, top5 74.75
2021-11-04 06:49:52 train 3000, loss 2.219e+00, top1 50.33, top5 74.61
2021-11-04 06:58:30 train 4000, loss 2.219e+00, top1 50.36, top5 74.67
2021-11-04 06:58:30 train 4000, loss 2.226e+00, top1 50.23, top5 74.51
2021-11-04 06:58:30 train 4000, loss 2.222e+00, top1 50.23, top5 74.58
2021-11-04 07:06:58 train 5000, loss 2.223e+00, top1 50.26, top5 74.61
2021-11-04 07:06:58 train 5000, loss 2.228e+00, top1 50.18, top5 74.44
2021-11-04 07:06:58 train 5000, loss 2.226e+00, top1 50.14, top5 74.50
2021-11-04 07:07:21 valid 0000, loss 1.106e+00, top1 74.12, top5 85.88
2021-11-04 07:07:21 valid 0000, loss 1.106e+00, top1 74.12, top5 85.88
2021-11-04 07:07:21 valid 0000, loss 1.106e+00, top1 74.12, top5 85.88
2021-11-04 07:11:40 (JOBID 31582) epoch 25: train time 2584.98, inference time 268.96s, valid_top1 50.18 (best_top1 63.94), valid_top5 76.33
2021-11-04 07:11:56 (JOBID 31582) epoch 25: train time 2591.24, inference time 285.36s, valid_top1 50.18 (best_top1 63.94), valid_top5 76.33
2021-11-04 07:11:57 (JOBID 31582) epoch 25: train time 2591.28, inference time 285.73s, valid_top1 50.18 (best_top1 63.94), valid_top5 76.33
2021-11-04 07:11:53 train 0000, loss 2.124e+00, top1 51.76, top5 77.65
2021-11-04 07:12:10 train 0000, loss 2.491e+00, top1 45.88, top5 69.41
2021-11-04 07:12:10 train 0000, loss 2.458e+00, top1 50.59, top5 69.41
2021-11-04 07:20:46 train 1000, loss 2.203e+00, top1 50.49, top5 74.90
2021-11-04 07:20:46 train 1000, loss 2.187e+00, top1 50.78, top5 75.16
2021-11-04 07:20:46 train 1000, loss 2.205e+00, top1 50.91, top5 74.89
2021-11-04 07:29:27 train 2000, loss 2.207e+00, top1 50.49, top5 74.86
2021-11-04 07:29:27 train 2000, loss 2.216e+00, top1 50.31, top5 74.65
2021-11-04 07:29:27 train 2000, loss 2.213e+00, top1 50.59, top5 74.71
2021-11-04 07:38:03 train 3000, loss 2.220e+00, top1 50.29, top5 74.58
2021-11-04 07:38:03 train 3000, loss 2.216e+00, top1 50.34, top5 74.65
2021-11-04 07:38:03 train 3000, loss 2.219e+00, top1 50.37, top5 74.59
2021-11-04 07:46:45 train 4000, loss 2.217e+00, top1 50.32, top5 74.65
2021-11-04 07:46:45 train 4000, loss 2.226e+00, top1 50.23, top5 74.52
2021-11-04 07:46:45 train 4000, loss 2.221e+00, top1 50.32, top5 74.53
2021-11-04 07:55:19 train 5000, loss 2.219e+00, top1 50.29, top5 74.63
2021-11-04 07:55:19 train 5000, loss 2.226e+00, top1 50.19, top5 74.50
2021-11-04 07:55:19 train 5000, loss 2.224e+00, top1 50.29, top5 74.50
2021-11-04 07:55:42 valid 0000, loss 8.429e-01, top1 82.35, top5 91.76
2021-11-04 07:55:42 valid 0000, loss 8.429e-01, top1 82.35, top5 91.76
2021-11-04 07:55:42 valid 0000, loss 8.429e-01, top1 82.35, top5 91.76
2021-11-04 08:00:21 (JOBID 31582) epoch 26: train time 2615.25, inference time 289.47s, valid_top1 51.17 (best_top1 63.94), valid_top5 76.66
2021-11-04 08:00:22 (JOBID 31582) epoch 26: train time 2615.63, inference time 290.72s, valid_top1 51.17 (best_top1 63.94), valid_top5 76.66
2021-11-04 08:00:23 (JOBID 31582) epoch 26: train time 2631.85, inference time 290.88s, valid_top1 51.17 (best_top1 63.94), valid_top5 76.66
2021-11-04 08:00:36 train 0000, loss 2.214e+00, top1 50.59, top5 74.12
2021-11-04 08:00:36 train 0000, loss 2.109e+00, top1 54.12, top5 76.47
2021-11-04 08:00:37 train 0000, loss 2.249e+00, top1 50.59, top5 72.94
2021-11-04 08:09:40 train 1000, loss 2.197e+00, top1 50.53, top5 74.88
2021-11-04 08:09:40 train 1000, loss 2.195e+00, top1 50.74, top5 74.81
2021-11-04 08:09:40 train 1000, loss 2.197e+00, top1 50.63, top5 75.01
2021-11-04 08:18:28 train 2000, loss 2.205e+00, top1 50.58, top5 74.76
2021-11-04 08:18:28 train 2000, loss 2.210e+00, top1 50.40, top5 74.68
2021-11-04 08:18:28 train 2000, loss 2.207e+00, top1 50.60, top5 74.90
2021-11-04 08:27:23 train 3000, loss 2.216e+00, top1 50.29, top5 74.61
2021-11-04 08:27:23 train 3000, loss 2.211e+00, top1 50.42, top5 74.66
2021-11-04 08:27:23 train 3000, loss 2.213e+00, top1 50.48, top5 74.82
2021-11-04 20:00:27 CARME Slurm ID: 31682
2021-11-04 20:00:27 CARME Slurm ID: 31682
2021-11-04 20:00:27 CARME Slurm ID: 31682
2021-11-04 20:00:27 args = Namespace(adaptive_lr=True, arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_1', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.42:23456', distributed=True, epochs=90, evaluate=False, gpu=1, lr=0.1, momentum=0.9, multiprocessing_distributed=True, normalization=None, path_to_resume='', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', pretrained=True, print_freq=1000, pruning_threshold=1e-06, rank=0, resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 20:00:27 args = Namespace(adaptive_lr=True, arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_1', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.42:23456', distributed=True, epochs=90, evaluate=False, gpu=0, lr=0.1, momentum=0.9, multiprocessing_distributed=True, normalization=None, path_to_resume='', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', pretrained=True, print_freq=1000, pruning_threshold=1e-06, rank=0, resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 20:00:27 args = Namespace(adaptive_lr=True, arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_1', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.42:23456', distributed=True, epochs=90, evaluate=False, gpu=2, lr=0.1, momentum=0.9, multiprocessing_distributed=True, normalization=None, path_to_resume='', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', pretrained=True, print_freq=1000, pruning_threshold=1e-06, rank=0, resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 20:00:34 prunable/total params (ratio): 15.65M/25.56M (61.22%)
2021-11-04 20:00:34 prunable/total params (ratio): 15.65M/25.56M (61.22%)
2021-11-04 20:00:34 prunable/total params (ratio): 15.65M/25.56M (61.22%)
2021-11-04 20:00:34 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635'
2021-11-04 20:00:34 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635'
2021-11-04 20:00:34 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635'
2021-11-04 20:02:39 CARME Slurm ID: 31682
2021-11-04 20:02:39 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_1', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.42:23456', distributed=True, epochs=90, evaluate=False, gpu=0, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 20:02:39 CARME Slurm ID: 31682
2021-11-04 20:02:39 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_1', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.42:23456', distributed=True, epochs=90, evaluate=False, gpu=2, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 20:02:39 CARME Slurm ID: 31682
2021-11-04 20:02:39 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_1', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.42:23456', distributed=True, epochs=90, evaluate=False, gpu=1, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 20:02:48 Computational complexity:       1.74 GMac
2021-11-04 20:02:48 Computational complexity:       1.74 GMac
2021-11-04 20:02:48 Number of parameters:           12.36 M 
2021-11-04 20:02:48 Number of parameters:           12.36 M 
2021-11-04 20:02:48 Computational complexity:       1.74 GMac
2021-11-04 20:02:48 Number of parameters:           12.36 M 
2021-11-04 20:02:48 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635'
2021-11-04 20:02:48 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635'
2021-11-04 20:02:48 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635'
2021-11-04 20:02:49 => loaded checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635' (epoch 27)
2021-11-04 20:02:49 => loaded checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635' (epoch 27)
2021-11-04 20:02:49 => loaded checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635' (epoch 27)
2021-11-04 20:51:50 CARME Slurm ID: 31682
2021-11-04 20:51:50 CARME Slurm ID: 31682
2021-11-04 20:51:50 CARME Slurm ID: 31682
2021-11-04 20:51:50 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_1', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.42:23456', distributed=True, epochs=90, evaluate=False, gpu=0, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 20:51:50 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_1', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.42:23456', distributed=True, epochs=90, evaluate=False, gpu=1, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 20:51:50 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_1', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.42:23456', distributed=True, epochs=90, evaluate=False, gpu=2, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 20:52:02 Computational complexity:       1.74 GMac
2021-11-04 20:52:02 Computational complexity:       1.74 GMac
2021-11-04 20:52:02 Computational complexity:       1.74 GMac
2021-11-04 20:52:02 Number of parameters:           12.36 M 
2021-11-04 20:52:02 Number of parameters:           12.36 M 
2021-11-04 20:52:02 Number of parameters:           12.36 M 
2021-11-04 20:52:02 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635'
2021-11-04 20:52:02 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635'
2021-11-04 20:52:02 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635'
2021-11-04 20:52:02 => loaded checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635' (epoch 27)
2021-11-04 20:52:02 => loaded checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635' (epoch 27)
2021-11-04 20:52:02 => loaded checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635' (epoch 27)
2021-11-04 20:52:21 valid 0000, loss 8.429e-01, top1 82.35, top5 91.76
2021-11-04 20:52:21 valid 0000, loss 8.429e-01, top1 82.35, top5 91.76
2021-11-04 20:52:21 valid 0000, loss 8.429e-01, top1 82.35, top5 91.76
2021-11-04 20:56:39 (JOBID 31682) epoch -1: valid_top1 51.17, valid_top5 76.66, inference time 272.17
2021-11-04 20:56:40 (JOBID 31682) epoch -1: valid_top1 51.17, valid_top5 76.66, inference time 273.06
2021-11-04 20:56:41 (JOBID 31682) epoch -1: valid_top1 51.17, valid_top5 76.66, inference time 273.55
2021-11-04 20:56:59 train 0000, loss 2.415e+00, top1 43.53, top5 71.76
2021-11-04 20:56:59 train 0000, loss 2.241e+00, top1 47.06, top5 76.47
2021-11-04 20:56:59 train 0000, loss 2.175e+00, top1 50.59, top5 75.29
2021-11-04 21:06:19 train 1000, loss 2.199e+00, top1 50.67, top5 74.94
2021-11-04 21:06:19 train 1000, loss 2.198e+00, top1 50.74, top5 74.74
2021-11-04 21:06:20 train 1000, loss 2.197e+00, top1 50.61, top5 75.03
2021-11-04 21:15:44 train 2000, loss 2.203e+00, top1 50.71, top5 74.80
2021-11-04 21:15:44 train 2000, loss 2.209e+00, top1 50.46, top5 74.80
2021-11-04 21:15:44 train 2000, loss 2.208e+00, top1 50.43, top5 74.80
2021-11-04 21:25:11 train 3000, loss 2.214e+00, top1 50.45, top5 74.73
2021-11-04 21:25:11 train 3000, loss 2.209e+00, top1 50.55, top5 74.76
2021-11-04 21:25:11 train 3000, loss 2.213e+00, top1 50.38, top5 74.77
2021-11-04 21:34:47 train 4000, loss 2.219e+00, top1 50.38, top5 74.64
2021-11-04 21:34:47 train 4000, loss 2.214e+00, top1 50.46, top5 74.67
2021-11-04 21:34:47 train 4000, loss 2.218e+00, top1 50.29, top5 74.71
2021-11-04 21:44:20 train 5000, loss 2.224e+00, top1 50.23, top5 74.58
2021-11-04 21:44:20 train 5000, loss 2.217e+00, top1 50.37, top5 74.63
2021-11-04 21:44:20 train 5000, loss 2.220e+00, top1 50.24, top5 74.65
2021-11-04 21:44:48 valid 0000, loss 8.499e-01, top1 82.35, top5 95.29
2021-11-04 21:44:48 valid 0000, loss 8.499e-01, top1 82.35, top5 95.29
2021-11-04 21:44:48 valid 0000, loss 8.499e-01, top1 82.35, top5 95.29
2021-11-04 21:48:57 (JOBID 31682) epoch 27: train time 2878.47, inference time 259.56s, valid_top1 45.80 (best_top1 63.94), valid_top5 72.05
2021-11-04 21:49:22 (JOBID 31682) epoch 27: train time 2877.55, inference time 284.24s, valid_top1 45.80 (best_top1 63.94), valid_top5 72.05
2021-11-04 21:49:22 (JOBID 31682) epoch 27: train time 2877.07, inference time 284.27s, valid_top1 45.80 (best_top1 63.94), valid_top5 72.05
2021-11-04 21:49:12 train 0000, loss 2.214e+00, top1 52.94, top5 71.76
2021-11-04 21:49:35 train 0000, loss 2.822e+00, top1 44.71, top5 67.06
2021-11-04 21:49:35 train 0000, loss 2.061e+00, top1 56.47, top5 78.82
2021-11-04 21:59:00 train 1000, loss 2.206e+00, top1 50.65, top5 74.88
2021-11-04 21:59:00 train 1000, loss 2.218e+00, top1 50.50, top5 74.68
2021-11-04 21:59:00 train 1000, loss 2.199e+00, top1 50.54, top5 74.93
2021-11-04 22:08:25 train 2000, loss 2.210e+00, top1 50.50, top5 74.90
2021-11-04 22:08:25 train 2000, loss 2.219e+00, top1 50.43, top5 74.71
2021-11-04 22:08:26 train 2000, loss 2.214e+00, top1 50.26, top5 74.75
2021-11-04 22:17:51 train 3000, loss 2.225e+00, top1 50.32, top5 74.57
2021-11-04 22:17:51 train 3000, loss 2.209e+00, top1 50.48, top5 74.90
2021-11-04 22:17:51 train 3000, loss 2.220e+00, top1 50.15, top5 74.65
2021-11-04 22:27:25 train 4000, loss 2.226e+00, top1 50.29, top5 74.53
2021-11-04 22:27:25 train 4000, loss 2.216e+00, top1 50.36, top5 74.78
2021-11-04 22:27:25 train 4000, loss 2.223e+00, top1 50.14, top5 74.60
2021-11-04 22:36:54 train 5000, loss 2.226e+00, top1 50.25, top5 74.52
2021-11-04 22:36:54 train 5000, loss 2.221e+00, top1 50.28, top5 74.67
2021-11-04 22:36:54 train 5000, loss 2.227e+00, top1 50.09, top5 74.52
2021-11-04 22:37:18 valid 0000, loss 1.334e+00, top1 72.94, top5 84.71
2021-11-04 22:37:18 valid 0000, loss 1.334e+00, top1 72.94, top5 84.71
2021-11-04 22:37:18 valid 0000, loss 1.334e+00, top1 72.94, top5 84.71
2021-11-04 22:42:00 (JOBID 31682) epoch 28: train time 2866.17, inference time 291.45s, valid_top1 53.57 (best_top1 63.94), valid_top5 79.02
2021-11-04 22:42:00 (JOBID 31682) epoch 28: train time 2865.98, inference time 291.67s, valid_top1 53.57 (best_top1 63.94), valid_top5 79.02
2021-11-04 22:42:00 (JOBID 31682) epoch 28: train time 2890.43, inference time 291.67s, valid_top1 53.57 (best_top1 63.94), valid_top5 79.02
2021-11-04 22:42:14 train 0000, loss 2.345e+00, top1 47.06, top5 81.18
2021-11-04 22:42:14 train 0000, loss 2.144e+00, top1 50.59, top5 76.47
2021-11-04 22:42:14 train 0000, loss 2.040e+00, top1 50.59, top5 76.47
2021-11-04 22:51:50 train 1000, loss 2.207e+00, top1 50.75, top5 74.71
2021-11-04 22:51:50 train 1000, loss 2.197e+00, top1 50.49, top5 74.90
2021-11-04 22:51:50 train 1000, loss 2.207e+00, top1 50.45, top5 74.83
2021-11-04 23:01:23 train 2000, loss 2.210e+00, top1 50.59, top5 74.74
2021-11-04 23:01:23 train 2000, loss 2.207e+00, top1 50.48, top5 74.88
2021-11-04 23:01:23 train 2000, loss 2.211e+00, top1 50.44, top5 74.80
2021-11-04 23:10:59 train 3000, loss 2.213e+00, top1 50.52, top5 74.69
2021-11-04 23:10:59 train 3000, loss 2.217e+00, top1 50.35, top5 74.72
2021-11-04 23:10:59 train 3000, loss 2.217e+00, top1 50.32, top5 74.65
2021-11-04 23:20:38 train 4000, loss 2.217e+00, top1 50.37, top5 74.67
2021-11-04 23:20:38 train 4000, loss 2.219e+00, top1 50.31, top5 74.64
2021-11-04 23:20:38 train 4000, loss 2.218e+00, top1 50.29, top5 74.66
2021-11-04 23:30:07 train 5000, loss 2.221e+00, top1 50.29, top5 74.64
2021-11-04 23:30:07 train 5000, loss 2.224e+00, top1 50.21, top5 74.59
2021-11-04 23:30:08 train 5000, loss 2.222e+00, top1 50.21, top5 74.59
2021-11-04 23:30:32 valid 0000, loss 1.258e+00, top1 76.47, top5 85.88
2021-11-04 23:30:32 valid 0000, loss 1.258e+00, top1 76.47, top5 85.88
2021-11-04 23:30:32 valid 0000, loss 1.258e+00, top1 76.47, top5 85.88
2021-11-04 23:34:52 (JOBID 31682) epoch 29: train time 2902.38, inference time 270.16s, valid_top1 52.83 (best_top1 63.94), valid_top5 78.08
2021-11-04 23:34:55 (JOBID 31682) epoch 29: train time 2902.14, inference time 273.77s, valid_top1 52.83 (best_top1 63.94), valid_top5 78.08
2021-11-04 23:34:57 (JOBID 31682) epoch 29: train time 2901.90, inference time 275.10s, valid_top1 52.83 (best_top1 63.94), valid_top5 78.08
2021-11-04 23:35:10 train 0000, loss 2.016e+00, top1 52.94, top5 78.82
2021-11-04 23:35:06 train 0000, loss 2.102e+00, top1 55.29, top5 77.65
2021-11-04 23:35:12 train 0000, loss 2.055e+00, top1 55.29, top5 76.47
2021-11-04 23:44:40 train 1000, loss 1.838e+00, top1 58.22, top5 80.29
2021-11-04 23:44:40 train 1000, loss 1.824e+00, top1 58.43, top5 80.39
2021-11-04 23:44:40 train 1000, loss 1.818e+00, top1 58.72, top5 80.55
2021-11-04 23:54:08 train 2000, loss 1.771e+00, top1 59.58, top5 81.15
2021-11-04 23:54:08 train 2000, loss 1.786e+00, top1 59.25, top5 80.97
2021-11-04 23:54:08 train 2000, loss 1.770e+00, top1 59.72, top5 81.16
2021-11-05 00:03:52 train 3000, loss 1.752e+00, top1 59.90, top5 81.46
2021-11-05 00:03:52 train 3000, loss 1.745e+00, top1 60.16, top5 81.53
2021-11-05 00:03:52 train 3000, loss 1.744e+00, top1 60.21, top5 81.53
2021-11-05 00:13:22 train 4000, loss 1.724e+00, top1 60.58, top5 81.83
2021-11-05 00:13:22 train 4000, loss 1.732e+00, top1 60.29, top5 81.76
2021-11-05 00:13:22 train 4000, loss 1.725e+00, top1 60.51, top5 81.84
2021-11-05 00:22:49 train 5000, loss 1.711e+00, top1 60.80, top5 82.01
2021-11-05 00:22:49 train 5000, loss 1.714e+00, top1 60.63, top5 82.03
2021-11-05 00:22:49 train 5000, loss 1.710e+00, top1 60.78, top5 82.07
2021-11-05 00:23:13 valid 0000, loss 6.790e-01, top1 87.06, top5 94.12
2021-11-05 00:23:13 valid 0000, loss 6.790e-01, top1 87.06, top5 94.12
2021-11-05 00:23:13 valid 0000, loss 6.790e-01, top1 87.06, top5 94.12
2021-11-05 00:27:33 (JOBID 31682) epoch 30: train time 2886.83, inference time 271.13s, valid_top1 67.18 (best_top1 67.18), valid_top5 87.92
2021-11-05 00:27:35 (JOBID 31682) epoch 30: train time 2885.27, inference time 271.95s, valid_top1 67.18 (best_top1 67.18), valid_top5 87.92
2021-11-05 00:27:39 (JOBID 31682) epoch 30: train time 2890.39, inference time 276.63s, valid_top1 67.18 (best_top1 67.18), valid_top5 87.92
2021-11-05 00:27:49 train 0000, loss 1.474e+00, top1 69.41, top5 83.53
2021-11-05 00:27:47 train 0000, loss 1.747e+00, top1 63.53, top5 78.82
2021-11-05 00:27:53 train 0000, loss 1.283e+00, top1 74.12, top5 88.24
2021-11-05 00:37:12 train 1000, loss 1.624e+00, top1 62.42, top5 83.29
2021-11-05 00:37:12 train 1000, loss 1.609e+00, top1 62.69, top5 83.52
2021-11-05 00:37:12 train 1000, loss 1.606e+00, top1 62.90, top5 83.45
2021-11-05 00:46:36 train 2000, loss 1.619e+00, top1 62.50, top5 83.30
2021-11-05 00:46:36 train 2000, loss 1.612e+00, top1 62.62, top5 83.41
2021-11-05 00:46:36 train 2000, loss 1.613e+00, top1 62.78, top5 83.41
2021-11-05 00:56:11 train 3000, loss 1.607e+00, top1 62.78, top5 83.52
2021-11-05 00:56:11 train 3000, loss 1.615e+00, top1 62.58, top5 83.36
2021-11-05 00:56:12 train 3000, loss 1.611e+00, top1 62.79, top5 83.46
2021-11-05 01:05:41 train 4000, loss 1.605e+00, top1 62.85, top5 83.56
2021-11-05 01:05:41 train 4000, loss 1.609e+00, top1 62.75, top5 83.45
2021-11-05 01:05:41 train 4000, loss 1.606e+00, top1 62.85, top5 83.51
2021-11-05 01:15:08 train 5000, loss 1.604e+00, top1 62.85, top5 83.57
2021-11-05 01:15:08 train 5000, loss 1.605e+00, top1 62.87, top5 83.47
2021-11-05 01:15:09 train 5000, loss 1.603e+00, top1 62.92, top5 83.56
2021-11-05 01:15:32 valid 0000, loss 7.111e-01, top1 88.24, top5 91.76
2021-11-05 01:15:32 valid 0000, loss 7.111e-01, top1 88.24, top5 91.76
2021-11-05 01:15:32 valid 0000, loss 7.111e-01, top1 88.24, top5 91.76
2021-11-05 01:19:59 (JOBID 31682) epoch 31: train time 2863.43, inference time 276.84s, valid_top1 67.59 (best_top1 67.59), valid_top5 88.16
2021-11-05 01:19:59 (JOBID 31682) epoch 31: train time 2868.88, inference time 277.09s, valid_top1 67.59 (best_top1 67.59), valid_top5 88.16
2021-11-05 01:20:00 (JOBID 31682) epoch 31: train time 2867.41, inference time 277.16s, valid_top1 67.59 (best_top1 67.59), valid_top5 88.16
2021-11-05 01:20:14 train 0000, loss 1.290e+00, top1 71.76, top5 87.06
2021-11-05 01:20:14 train 0000, loss 1.483e+00, top1 64.71, top5 83.53
2021-11-05 01:20:14 train 0000, loss 1.274e+00, top1 71.76, top5 89.41
2021-11-05 01:29:54 train 1000, loss 1.563e+00, top1 63.67, top5 84.16
2021-11-05 01:29:54 train 1000, loss 1.560e+00, top1 63.88, top5 84.12
2021-11-05 01:29:54 train 1000, loss 1.562e+00, top1 63.57, top5 84.09
2021-11-05 01:39:34 train 2000, loss 1.568e+00, top1 63.70, top5 84.07
2021-11-05 01:39:34 train 2000, loss 1.561e+00, top1 63.84, top5 84.18
2021-11-05 01:39:34 train 2000, loss 1.565e+00, top1 63.59, top5 84.10
2021-11-05 01:49:19 train 3000, loss 1.568e+00, top1 63.69, top5 84.06
2021-11-05 01:49:19 train 3000, loss 1.563e+00, top1 63.76, top5 84.16
2021-11-05 01:49:20 train 3000, loss 1.561e+00, top1 63.74, top5 84.12
2021-11-05 01:58:53 train 4000, loss 1.567e+00, top1 63.67, top5 84.04
2021-11-05 01:58:53 train 4000, loss 1.565e+00, top1 63.73, top5 84.13
2021-11-05 01:58:53 train 4000, loss 1.561e+00, top1 63.72, top5 84.12
2021-11-05 02:08:33 train 5000, loss 1.566e+00, top1 63.69, top5 84.15
2021-11-05 02:08:33 train 5000, loss 1.565e+00, top1 63.68, top5 84.04
2021-11-05 02:08:34 train 5000, loss 1.562e+00, top1 63.70, top5 84.11
2021-11-05 02:08:59 valid 0000, loss 5.023e-01, top1 88.24, top5 96.47
2021-11-05 02:08:59 valid 0000, loss 5.023e-01, top1 88.24, top5 96.47
2021-11-05 02:08:59 valid 0000, loss 5.023e-01, top1 88.24, top5 96.47
2021-11-05 02:13:32 (JOBID 31682) epoch 32: train time 2928.53, inference time 283.82s, valid_top1 68.30 (best_top1 68.30), valid_top5 88.61
2021-11-05 02:13:32 (JOBID 31682) epoch 32: train time 2928.41, inference time 283.94s, valid_top1 68.30 (best_top1 68.30), valid_top5 88.61
2021-11-05 02:13:32 (JOBID 31682) epoch 32: train time 2927.77, inference time 283.94s, valid_top1 68.30 (best_top1 68.30), valid_top5 88.61
2021-11-05 02:13:47 train 0000, loss 1.862e+00, top1 61.18, top5 76.47
2021-11-05 02:13:47 train 0000, loss 1.522e+00, top1 65.88, top5 87.06
2021-11-05 02:13:47 train 0000, loss 1.714e+00, top1 61.18, top5 83.53
2021-11-05 02:23:13 train 1000, loss 1.533e+00, top1 64.20, top5 84.51
2021-11-05 02:23:13 train 1000, loss 1.536e+00, top1 64.30, top5 84.37
2021-11-05 02:23:13 train 1000, loss 1.551e+00, top1 63.92, top5 84.28
2021-11-05 02:32:51 train 2000, loss 1.537e+00, top1 64.13, top5 84.45
2021-11-05 02:32:51 train 2000, loss 1.532e+00, top1 64.45, top5 84.53
2021-11-05 02:32:51 train 2000, loss 1.555e+00, top1 63.80, top5 84.25
2021-11-05 02:42:27 train 3000, loss 1.535e+00, top1 64.34, top5 84.51
2021-11-05 02:42:27 train 3000, loss 1.537e+00, top1 64.17, top5 84.47
2021-11-05 02:42:28 train 3000, loss 1.547e+00, top1 63.91, top5 84.37
2021-11-05 02:51:57 train 4000, loss 1.537e+00, top1 64.27, top5 84.48
2021-11-05 02:51:57 train 4000, loss 1.539e+00, top1 64.15, top5 84.42
2021-11-05 02:51:58 train 4000, loss 1.546e+00, top1 63.93, top5 84.37
2021-11-05 03:01:24 train 5000, loss 1.537e+00, top1 64.25, top5 84.47
2021-11-05 03:01:24 train 5000, loss 1.537e+00, top1 64.17, top5 84.46
2021-11-05 03:01:24 train 5000, loss 1.544e+00, top1 63.96, top5 84.39
2021-11-05 03:01:49 valid 0000, loss 7.365e-01, top1 83.53, top5 90.59
2021-11-05 03:01:49 valid 0000, loss 7.365e-01, top1 83.53, top5 90.59
2021-11-05 03:01:49 valid 0000, loss 7.365e-01, top1 83.53, top5 90.59
2021-11-05 03:06:10 (JOBID 31682) epoch 33: train time 2886.57, inference time 271.99s, valid_top1 68.45 (best_top1 68.45), valid_top5 88.82
2021-11-05 03:06:11 (JOBID 31682) epoch 33: train time 2886.35, inference time 272.59s, valid_top1 68.45 (best_top1 68.45), valid_top5 88.82
2021-11-05 03:06:11 (JOBID 31682) epoch 33: train time 2885.76, inference time 272.10s, valid_top1 68.45 (best_top1 68.45), valid_top5 88.82
2021-11-05 03:06:26 train 0000, loss 1.769e+00, top1 63.53, top5 80.00
2021-11-05 03:06:26 train 0000, loss 1.470e+00, top1 62.35, top5 87.06
2021-11-05 03:06:26 train 0000, loss 1.507e+00, top1 63.53, top5 87.06
2021-11-05 03:16:07 train 1000, loss 1.516e+00, top1 64.76, top5 84.81
2021-11-05 03:16:07 train 1000, loss 1.512e+00, top1 64.82, top5 84.83
2021-11-05 03:16:07 train 1000, loss 1.519e+00, top1 64.62, top5 84.67
2021-11-05 03:25:54 train 2000, loss 1.521e+00, top1 64.61, top5 84.80
2021-11-05 03:25:54 train 2000, loss 1.522e+00, top1 64.54, top5 84.72
2021-11-05 03:25:54 train 2000, loss 1.526e+00, top1 64.55, top5 84.64
2021-11-05 03:35:36 train 3000, loss 1.526e+00, top1 64.47, top5 84.66
2021-11-05 03:35:36 train 3000, loss 1.524e+00, top1 64.45, top5 84.70
2021-11-05 03:35:36 train 3000, loss 1.525e+00, top1 64.60, top5 84.64
2021-11-05 03:45:17 train 4000, loss 1.524e+00, top1 64.48, top5 84.67
2021-11-05 03:45:17 train 4000, loss 1.526e+00, top1 64.45, top5 84.68
2021-11-05 03:45:18 train 4000, loss 1.525e+00, top1 64.53, top5 84.67
2021-11-05 03:55:00 train 5000, loss 1.525e+00, top1 64.47, top5 84.70
2021-11-05 03:55:00 train 5000, loss 1.527e+00, top1 64.43, top5 84.62
2021-11-05 03:55:00 train 5000, loss 1.525e+00, top1 64.51, top5 84.67
2021-11-05 03:55:26 valid 0000, loss 6.582e-01, top1 83.53, top5 94.12
2021-11-05 03:55:26 valid 0000, loss 6.582e-01, top1 83.53, top5 94.12
2021-11-05 03:55:26 valid 0000, loss 6.582e-01, top1 83.53, top5 94.12
2021-11-05 04:00:00 (JOBID 31682) epoch 34: train time 2944.63, inference time 285.46s, valid_top1 68.58 (best_top1 68.58), valid_top5 88.95
2021-11-05 04:00:01 (JOBID 31682) epoch 34: train time 2944.16, inference time 286.21s, valid_top1 68.58 (best_top1 68.58), valid_top5 88.95
2021-11-05 04:00:02 (JOBID 31682) epoch 34: train time 2943.97, inference time 286.85s, valid_top1 68.58 (best_top1 68.58), valid_top5 88.95
2021-11-05 04:00:16 train 0000, loss 1.327e+00, top1 67.06, top5 87.06
2021-11-05 04:00:16 train 0000, loss 1.518e+00, top1 64.71, top5 84.71
2021-11-05 04:00:16 train 0000, loss 1.490e+00, top1 62.35, top5 87.06
2021-11-05 04:10:03 train 1000, loss 1.506e+00, top1 64.77, top5 84.89
2021-11-05 04:10:03 train 1000, loss 1.499e+00, top1 65.13, top5 85.02
2021-11-05 04:10:03 train 1000, loss 1.504e+00, top1 64.79, top5 85.00
2021-11-05 04:19:50 train 2000, loss 1.508e+00, top1 64.77, top5 84.87
2021-11-05 04:19:50 train 2000, loss 1.507e+00, top1 64.87, top5 84.91
2021-11-05 04:19:50 train 2000, loss 1.505e+00, top1 64.86, top5 84.98
2021-11-05 04:29:32 train 3000, loss 1.509e+00, top1 64.77, top5 84.81
2021-11-05 04:29:32 train 3000, loss 1.510e+00, top1 64.78, top5 84.90
2021-11-05 04:29:32 train 3000, loss 1.510e+00, top1 64.74, top5 84.89
2021-11-05 04:39:14 train 4000, loss 1.512e+00, top1 64.74, top5 84.78
2021-11-05 04:39:14 train 4000, loss 1.513e+00, top1 64.66, top5 84.85
2021-11-05 04:39:14 train 4000, loss 1.516e+00, top1 64.64, top5 84.79
2021-11-05 04:48:58 train 5000, loss 1.513e+00, top1 64.70, top5 84.80
2021-11-05 04:48:58 train 5000, loss 1.516e+00, top1 64.61, top5 84.80
2021-11-05 04:48:58 train 5000, loss 1.516e+00, top1 64.59, top5 84.79
2021-11-05 04:49:24 valid 0000, loss 6.852e-01, top1 84.71, top5 92.94
2021-11-05 04:49:24 valid 0000, loss 6.852e-01, top1 84.71, top5 92.94
2021-11-05 04:49:24 valid 0000, loss 6.852e-01, top1 84.71, top5 92.94
2021-11-05 04:53:48 (JOBID 31682) epoch 35: train time 2952.14, inference time 275.14s, valid_top1 68.69 (best_top1 68.69), valid_top5 88.94
2021-11-05 04:53:48 (JOBID 31682) epoch 35: train time 2951.25, inference time 275.46s, valid_top1 68.69 (best_top1 68.69), valid_top5 88.94
2021-11-05 04:53:48 (JOBID 31682) epoch 35: train time 2949.87, inference time 275.46s, valid_top1 68.69 (best_top1 68.69), valid_top5 88.94
2021-11-05 04:54:02 train 0000, loss 1.722e+00, top1 57.65, top5 84.71
2021-11-05 04:54:02 train 0000, loss 1.583e+00, top1 65.88, top5 84.71
2021-11-05 04:54:02 train 0000, loss 1.763e+00, top1 55.29, top5 78.82
2021-11-05 05:03:53 train 1000, loss 1.500e+00, top1 64.89, top5 85.04
2021-11-05 05:03:53 train 1000, loss 1.510e+00, top1 64.72, top5 84.88
2021-11-05 05:03:54 train 1000, loss 1.497e+00, top1 64.98, top5 85.11
2021-11-05 05:13:40 train 2000, loss 1.504e+00, top1 64.82, top5 84.97
2021-11-05 05:13:40 train 2000, loss 1.510e+00, top1 64.74, top5 84.92
2021-11-05 05:13:40 train 2000, loss 1.505e+00, top1 64.85, top5 84.99
2021-11-05 05:23:30 train 3000, loss 1.506e+00, top1 64.76, top5 84.97
2021-11-05 05:23:30 train 3000, loss 1.508e+00, top1 64.76, top5 84.91
2021-11-05 05:23:31 train 3000, loss 1.513e+00, top1 64.65, top5 84.85
2021-11-05 05:33:22 train 4000, loss 1.508e+00, top1 64.79, top5 84.90
2021-11-05 05:33:22 train 4000, loss 1.511e+00, top1 64.71, top5 84.85
2021-11-05 05:33:23 train 4000, loss 1.516e+00, top1 64.59, top5 84.82
2021-11-05 05:43:11 train 5000, loss 1.514e+00, top1 64.63, top5 84.82
2021-11-05 05:43:11 train 5000, loss 1.512e+00, top1 64.73, top5 84.84
2021-11-05 05:43:11 train 5000, loss 1.517e+00, top1 64.58, top5 84.78
2021-11-05 05:43:36 valid 0000, loss 6.412e-01, top1 84.71, top5 95.29
2021-11-05 05:43:36 valid 0000, loss 6.412e-01, top1 84.71, top5 95.29
2021-11-05 05:43:36 valid 0000, loss 6.412e-01, top1 84.71, top5 95.29
2021-11-05 05:48:01 (JOBID 31682) epoch 36: train time 2977.70, inference time 275.15s, valid_top1 68.52 (best_top1 68.69), valid_top5 88.82
2021-11-05 05:48:10 (JOBID 31682) epoch 36: train time 2977.15, inference time 284.29s, valid_top1 68.52 (best_top1 68.69), valid_top5 88.82
2021-11-05 05:48:12 (JOBID 31682) epoch 36: train time 2977.92, inference time 285.95s, valid_top1 68.52 (best_top1 68.69), valid_top5 88.82
2021-11-05 05:48:25 train 0000, loss 1.576e+00, top1 56.47, top5 83.53
2021-11-05 05:48:16 train 0000, loss 1.490e+00, top1 63.53, top5 87.06
2021-11-05 05:48:26 train 0000, loss 1.316e+00, top1 68.24, top5 88.24
2021-11-05 05:58:04 train 1000, loss 1.493e+00, top1 65.01, top5 85.14
2021-11-05 05:58:04 train 1000, loss 1.499e+00, top1 64.89, top5 85.03
2021-11-05 05:58:04 train 1000, loss 1.498e+00, top1 65.03, top5 84.88
2021-11-05 06:07:34 train 2000, loss 1.500e+00, top1 64.85, top5 84.96
2021-11-05 06:07:34 train 2000, loss 1.501e+00, top1 64.86, top5 85.05
2021-11-05 06:07:34 train 2000, loss 1.500e+00, top1 64.85, top5 84.89
2021-11-05 06:17:04 train 3000, loss 1.503e+00, top1 64.83, top5 84.94
2021-11-05 06:17:04 train 3000, loss 1.508e+00, top1 64.81, top5 84.95
2021-11-05 06:17:04 train 3000, loss 1.504e+00, top1 64.79, top5 84.85
2021-11-05 06:26:32 train 4000, loss 1.510e+00, top1 64.78, top5 84.91
2021-11-05 06:26:32 train 4000, loss 1.506e+00, top1 64.78, top5 84.88
2021-11-05 06:26:32 train 4000, loss 1.507e+00, top1 64.77, top5 84.82
2021-11-05 06:36:10 train 5000, loss 1.510e+00, top1 64.67, top5 84.83
2021-11-05 06:36:10 train 5000, loss 1.512e+00, top1 64.72, top5 84.89
2021-11-05 06:36:10 train 5000, loss 1.508e+00, top1 64.75, top5 84.81
2021-11-05 06:36:34 valid 0000, loss 7.074e-01, top1 85.88, top5 94.12
2021-11-05 06:36:34 valid 0000, loss 7.074e-01, top1 85.88, top5 94.12
2021-11-05 06:36:34 valid 0000, loss 7.074e-01, top1 85.88, top5 94.12
2021-11-05 06:40:59 (JOBID 31682) epoch 37: train time 2892.30, inference time 274.92s, valid_top1 68.77 (best_top1 68.77), valid_top5 88.88
2021-11-05 06:40:59 (JOBID 31682) epoch 37: train time 2903.05, inference time 275.30s, valid_top1 68.77 (best_top1 68.77), valid_top5 88.88
2021-11-05 06:41:00 (JOBID 31682) epoch 37: train time 2893.69, inference time 275.26s, valid_top1 68.77 (best_top1 68.77), valid_top5 88.88
2021-11-05 06:41:14 train 0000, loss 1.336e+00, top1 74.12, top5 87.06
2021-11-05 06:41:14 train 0000, loss 1.806e+00, top1 60.00, top5 81.18
2021-11-05 06:41:14 train 0000, loss 1.684e+00, top1 60.00, top5 82.35
2021-11-05 06:51:00 train 1000, loss 1.489e+00, top1 65.11, top5 85.14
2021-11-05 06:51:00 train 1000, loss 1.489e+00, top1 65.12, top5 85.24
2021-11-05 06:51:00 train 1000, loss 1.502e+00, top1 64.87, top5 84.93
2021-11-05 07:00:36 train 2000, loss 1.498e+00, top1 64.99, top5 85.04
2021-11-05 07:00:36 train 2000, loss 1.493e+00, top1 64.95, top5 85.19
2021-11-05 07:00:37 train 2000, loss 1.501e+00, top1 64.94, top5 84.96
2021-11-05 07:10:12 train 3000, loss 1.504e+00, top1 64.85, top5 84.98
2021-11-05 07:10:12 train 3000, loss 1.497e+00, top1 64.84, top5 85.12
2021-11-05 07:10:12 train 3000, loss 1.507e+00, top1 64.81, top5 84.86
2021-11-05 07:19:48 train 4000, loss 1.503e+00, top1 64.77, top5 85.01
2021-11-05 07:19:48 train 4000, loss 1.506e+00, top1 64.72, top5 84.95
2021-11-05 07:19:48 train 4000, loss 1.511e+00, top1 64.73, top5 84.84
2021-11-05 07:29:22 train 5000, loss 1.507e+00, top1 64.70, top5 84.97
2021-11-05 07:29:22 train 5000, loss 1.505e+00, top1 64.77, top5 84.95
2021-11-05 07:29:22 train 5000, loss 1.511e+00, top1 64.71, top5 84.81
2021-11-05 07:29:49 valid 0000, loss 6.717e-01, top1 85.88, top5 92.94
2021-11-05 07:29:49 valid 0000, loss 6.717e-01, top1 85.88, top5 92.94
2021-11-05 07:29:49 valid 0000, loss 6.717e-01, top1 85.88, top5 92.94
2021-11-05 07:34:22 (JOBID 31682) epoch 38: train time 2917.38, inference time 285.13s, valid_top1 68.53 (best_top1 68.77), valid_top5 88.82
2021-11-05 07:34:22 (JOBID 31682) epoch 38: train time 2917.26, inference time 285.48s, valid_top1 68.53 (best_top1 68.77), valid_top5 88.82
2021-11-05 07:34:23 (JOBID 31682) epoch 38: train time 2916.59, inference time 286.32s, valid_top1 68.53 (best_top1 68.77), valid_top5 88.82
2021-11-05 07:34:38 train 0000, loss 1.543e+00, top1 69.41, top5 83.53
2021-11-05 07:34:38 train 0000, loss 1.484e+00, top1 65.88, top5 85.88
2021-11-05 07:34:38 train 0000, loss 1.457e+00, top1 68.24, top5 85.88
2021-11-05 07:44:17 train 1000, loss 1.490e+00, top1 65.03, top5 85.05
2021-11-05 07:44:17 train 1000, loss 1.486e+00, top1 65.01, top5 85.30
2021-11-05 07:44:17 train 1000, loss 1.491e+00, top1 65.12, top5 85.10
2021-11-05 07:53:38 train 2000, loss 1.492e+00, top1 65.07, top5 85.18
2021-11-05 07:53:38 train 2000, loss 1.493e+00, top1 64.92, top5 85.10
2021-11-05 07:53:38 train 2000, loss 1.506e+00, top1 64.87, top5 84.90
2021-11-05 08:02:55 train 3000, loss 1.500e+00, top1 64.98, top5 85.05
2021-11-05 08:02:55 train 3000, loss 1.497e+00, top1 64.91, top5 85.09
2021-11-05 08:02:56 train 3000, loss 1.506e+00, top1 64.86, top5 84.91
2021-11-05 08:12:12 train 4000, loss 1.504e+00, top1 64.88, top5 84.99
2021-11-05 08:12:12 train 4000, loss 1.503e+00, top1 64.80, top5 84.99
2021-11-05 08:12:13 train 4000, loss 1.508e+00, top1 64.77, top5 84.92
2021-11-05 08:21:26 train 5000, loss 1.510e+00, top1 64.74, top5 84.91
2021-11-05 08:21:26 train 5000, loss 1.506e+00, top1 64.74, top5 84.94
2021-11-05 08:21:26 train 5000, loss 1.511e+00, top1 64.71, top5 84.90
2021-11-05 08:21:50 valid 0000, loss 7.014e-01, top1 82.35, top5 92.94
2021-11-05 08:21:50 valid 0000, loss 7.014e-01, top1 82.35, top5 92.94
2021-11-05 08:21:50 valid 0000, loss 7.014e-01, top1 82.35, top5 92.94
2021-11-05 08:26:13 (JOBID 31682) epoch 39: train time 2838.13, inference time 273.24s, valid_top1 67.67 (best_top1 68.77), valid_top5 88.50
2021-11-05 08:26:13 (JOBID 31682) epoch 39: train time 2837.72, inference time 273.48s, valid_top1 67.67 (best_top1 68.77), valid_top5 88.50
2021-11-05 08:26:13 (JOBID 31682) epoch 39: train time 2836.40, inference time 273.39s, valid_top1 67.67 (best_top1 68.77), valid_top5 88.50
2021-11-05 08:26:27 train 0000, loss 1.606e+00, top1 60.00, top5 82.35
2021-11-05 08:26:27 train 0000, loss 1.749e+00, top1 60.00, top5 83.53
2021-11-05 08:26:27 train 0000, loss 1.748e+00, top1 64.71, top5 80.00
2021-11-05 08:35:41 train 1000, loss 1.497e+00, top1 64.81, top5 85.05
2021-11-05 08:35:41 train 1000, loss 1.499e+00, top1 64.95, top5 85.01
2021-11-05 08:35:41 train 1000, loss 1.496e+00, top1 65.06, top5 85.14
2021-11-05 08:44:52 train 2000, loss 1.500e+00, top1 64.96, top5 85.00
2021-11-05 08:44:52 train 2000, loss 1.500e+00, top1 64.83, top5 85.04
2021-11-05 08:44:52 train 2000, loss 1.497e+00, top1 65.03, top5 85.09
2021-11-05 08:54:01 train 3000, loss 1.503e+00, top1 64.78, top5 84.99
2021-11-05 08:54:01 train 3000, loss 1.503e+00, top1 64.86, top5 84.97
2021-11-05 08:54:01 train 3000, loss 1.506e+00, top1 64.85, top5 84.96
2021-11-05 09:03:15 train 4000, loss 1.506e+00, top1 64.80, top5 84.92
2021-11-05 09:03:15 train 4000, loss 1.508e+00, top1 64.74, top5 84.91
2021-11-05 09:03:15 train 4000, loss 1.507e+00, top1 64.82, top5 84.95
2021-11-05 09:12:25 train 5000, loss 1.513e+00, top1 64.63, top5 84.84
2021-11-05 09:12:25 train 5000, loss 1.511e+00, top1 64.69, top5 84.85
2021-11-05 09:12:25 train 5000, loss 1.512e+00, top1 64.72, top5 84.88
2021-11-05 09:12:50 valid 0000, loss 8.523e-01, top1 82.35, top5 89.41
2021-11-05 09:12:50 valid 0000, loss 8.523e-01, top1 82.35, top5 89.41
2021-11-05 09:12:50 valid 0000, loss 8.523e-01, top1 82.35, top5 89.41
2021-11-05 09:17:21 (JOBID 31682) epoch 40: train time 2786.07, inference time 280.99s, valid_top1 67.74 (best_top1 68.77), valid_top5 88.53
2021-11-05 09:17:21 (JOBID 31682) epoch 40: train time 2786.45, inference time 281.46s, valid_top1 67.74 (best_top1 68.77), valid_top5 88.53
2021-11-05 09:17:22 (JOBID 31682) epoch 40: train time 2786.26, inference time 282.97s, valid_top1 67.74 (best_top1 68.77), valid_top5 88.53
2021-11-05 09:17:35 train 0000, loss 1.764e+00, top1 65.88, top5 78.82
2021-11-05 09:17:35 train 0000, loss 1.116e+00, top1 65.88, top5 95.29
2021-11-05 09:17:37 train 0000, loss 1.664e+00, top1 63.53, top5 82.35
2021-11-05 09:26:51 train 1000, loss 1.499e+00, top1 64.98, top5 85.04
2021-11-05 09:26:51 train 1000, loss 1.497e+00, top1 64.84, top5 85.13
2021-11-05 09:26:52 train 1000, loss 1.504e+00, top1 64.85, top5 84.92
2021-11-05 09:36:07 train 2000, loss 1.503e+00, top1 64.95, top5 84.96
2021-11-05 09:36:07 train 2000, loss 1.501e+00, top1 64.89, top5 85.07
2021-11-05 09:36:07 train 2000, loss 1.504e+00, top1 64.83, top5 84.95
2021-11-05 09:45:20 train 3000, loss 1.508e+00, top1 64.81, top5 84.95
2021-11-05 09:45:20 train 3000, loss 1.506e+00, top1 64.85, top5 84.94
2021-11-05 09:45:20 train 3000, loss 1.502e+00, top1 64.87, top5 85.01
2021-11-05 09:54:33 train 4000, loss 1.507e+00, top1 64.84, top5 84.93
2021-11-05 09:54:33 train 4000, loss 1.513e+00, top1 64.67, top5 84.89
2021-11-05 09:54:33 train 4000, loss 1.506e+00, top1 64.76, top5 84.99
2021-11-05 10:03:52 train 5000, loss 1.515e+00, top1 64.60, top5 84.85
2021-11-05 10:03:52 train 5000, loss 1.511e+00, top1 64.72, top5 84.87
2021-11-05 10:03:52 train 5000, loss 1.511e+00, top1 64.65, top5 84.91
2021-11-05 10:04:16 valid 0000, loss 6.942e-01, top1 84.71, top5 94.12
2021-11-05 10:04:16 valid 0000, loss 6.942e-01, top1 84.71, top5 94.12
2021-11-05 10:04:16 valid 0000, loss 6.942e-01, top1 84.71, top5 94.12
2021-11-05 10:08:38 (JOBID 31682) epoch 41: train time 2804.30, inference time 273.08s, valid_top1 68.47 (best_top1 68.77), valid_top5 88.79
2021-11-05 10:08:38 (JOBID 31682) epoch 41: train time 2802.81, inference time 273.19s, valid_top1 68.47 (best_top1 68.77), valid_top5 88.79
2021-11-05 10:08:39 (JOBID 31682) epoch 41: train time 2804.61, inference time 273.23s, valid_top1 68.47 (best_top1 68.77), valid_top5 88.79
2021-11-05 10:08:54 train 0000, loss 1.331e+00, top1 74.12, top5 85.88
2021-11-05 10:08:54 train 0000, loss 1.808e+00, top1 56.47, top5 82.35
2021-11-05 10:08:54 train 0000, loss 1.322e+00, top1 67.06, top5 87.06
2021-11-05 10:18:18 train 1000, loss 1.501e+00, top1 64.78, top5 85.03
2021-11-05 10:18:18 train 1000, loss 1.486e+00, top1 65.04, top5 85.21
2021-11-05 10:18:18 train 1000, loss 1.498e+00, top1 64.99, top5 85.05
2021-11-05 10:27:36 train 2000, loss 1.496e+00, top1 64.87, top5 85.06
2021-11-05 10:27:36 train 2000, loss 1.504e+00, top1 64.76, top5 84.98
2021-11-05 10:27:36 train 2000, loss 1.502e+00, top1 64.76, top5 85.05
2021-11-05 10:36:54 train 3000, loss 1.507e+00, top1 64.71, top5 84.94
2021-11-05 10:36:54 train 3000, loss 1.499e+00, top1 64.80, top5 84.99
2021-11-05 10:36:54 train 3000, loss 1.508e+00, top1 64.68, top5 85.00
2021-11-05 10:46:16 train 4000, loss 1.511e+00, top1 64.62, top5 84.86
2021-11-05 10:46:16 train 4000, loss 1.506e+00, top1 64.70, top5 84.89
2021-11-05 10:46:16 train 4000, loss 1.513e+00, top1 64.61, top5 84.86
2021-11-05 10:55:35 train 5000, loss 1.514e+00, top1 64.60, top5 84.81
2021-11-05 10:55:35 train 5000, loss 1.512e+00, top1 64.61, top5 84.79
2021-11-05 10:55:35 train 5000, loss 1.517e+00, top1 64.52, top5 84.80
2021-11-05 10:56:00 valid 0000, loss 7.189e-01, top1 85.88, top5 92.94
2021-11-05 10:56:00 valid 0000, loss 7.189e-01, top1 85.88, top5 92.94
2021-11-05 10:56:00 valid 0000, loss 7.189e-01, top1 85.88, top5 92.94
2021-11-05 11:00:24 (JOBID 31682) epoch 42: train time 2831.08, inference time 274.65s, valid_top1 67.71 (best_top1 68.77), valid_top5 88.42
2021-11-05 11:00:24 (JOBID 31682) epoch 42: train time 2830.58, inference time 274.80s, valid_top1 67.71 (best_top1 68.77), valid_top5 88.42
2021-11-05 11:00:25 (JOBID 31682) epoch 42: train time 2830.93, inference time 276.21s, valid_top1 67.71 (best_top1 68.77), valid_top5 88.42
2021-11-05 11:00:38 train 0000, loss 1.208e+00, top1 67.06, top5 89.41
2021-11-05 11:00:38 train 0000, loss 1.262e+00, top1 69.41, top5 85.88
2021-11-05 11:00:41 train 0000, loss 1.543e+00, top1 61.18, top5 87.06
2021-11-05 11:10:00 train 1000, loss 1.496e+00, top1 64.92, top5 85.01
2021-11-05 11:10:00 train 1000, loss 1.500e+00, top1 64.72, top5 84.94
2021-11-05 11:10:01 train 1000, loss 1.494e+00, top1 65.05, top5 85.09
2021-11-05 11:19:19 train 2000, loss 1.511e+00, top1 64.68, top5 84.82
2021-11-05 11:19:19 train 2000, loss 1.510e+00, top1 64.55, top5 84.86
2021-11-05 11:19:19 train 2000, loss 1.500e+00, top1 64.92, top5 85.02
2021-11-05 11:28:36 train 3000, loss 1.514e+00, top1 64.62, top5 84.82
2021-11-05 11:28:36 train 3000, loss 1.512e+00, top1 64.56, top5 84.83
2021-11-05 11:28:37 train 3000, loss 1.508e+00, top1 64.80, top5 84.90
2021-11-05 11:37:57 train 4000, loss 1.515e+00, top1 64.56, top5 84.85
2021-11-05 11:37:58 train 4000, loss 1.516e+00, top1 64.49, top5 84.78
2021-11-05 11:37:58 train 4000, loss 1.508e+00, top1 64.81, top5 84.90
2021-11-05 11:47:22 train 5000, loss 1.518e+00, top1 64.46, top5 84.76
2021-11-05 11:47:22 train 5000, loss 1.519e+00, top1 64.50, top5 84.78
2021-11-05 11:47:22 train 5000, loss 1.512e+00, top1 64.74, top5 84.82
2021-11-05 11:47:46 valid 0000, loss 6.948e-01, top1 82.35, top5 94.12
2021-11-05 11:47:46 valid 0000, loss 6.948e-01, top1 82.35, top5 94.12
2021-11-05 11:47:46 valid 0000, loss 6.948e-01, top1 82.35, top5 94.12
2021-11-05 11:52:10 (JOBID 31682) epoch 43: train time 2831.04, inference time 273.83s, valid_top1 67.55 (best_top1 68.77), valid_top5 88.23
2021-11-05 11:52:23 (JOBID 31682) epoch 43: train time 2832.18, inference time 285.88s, valid_top1 67.55 (best_top1 68.77), valid_top5 88.23
2021-11-05 11:52:23 (JOBID 31682) epoch 43: train time 2832.57, inference time 286.58s, valid_top1 67.55 (best_top1 68.77), valid_top5 88.23
2021-11-05 11:52:26 train 0000, loss 1.288e+00, top1 65.88, top5 88.24
2021-11-05 11:52:36 train 0000, loss 1.467e+00, top1 63.53, top5 83.53
2021-11-05 11:52:36 train 0000, loss 1.573e+00, top1 56.47, top5 88.24
2021-11-05 12:02:11 train 1000, loss 1.504e+00, top1 64.78, top5 84.89
2021-11-05 12:02:11 train 1000, loss 1.498e+00, top1 64.86, top5 85.09
2021-11-05 12:02:12 train 1000, loss 1.499e+00, top1 64.81, top5 85.01
2021-11-05 12:11:34 train 2000, loss 1.503e+00, top1 64.90, top5 84.97
2021-11-05 12:11:34 train 2000, loss 1.505e+00, top1 64.71, top5 84.92
2021-11-05 12:11:34 train 2000, loss 1.507e+00, top1 64.67, top5 84.89
2021-11-05 12:21:03 train 3000, loss 1.505e+00, top1 64.82, top5 84.96
2021-11-05 12:21:03 train 3000, loss 1.507e+00, top1 64.69, top5 84.88
2021-11-05 12:21:03 train 3000, loss 1.510e+00, top1 64.56, top5 84.87
2021-11-05 12:30:25 train 4000, loss 1.511e+00, top1 64.67, top5 84.87
2021-11-05 12:30:25 train 4000, loss 1.511e+00, top1 64.57, top5 84.87
2021-11-05 12:30:25 train 4000, loss 1.512e+00, top1 64.50, top5 84.83
2021-11-05 12:39:46 train 5000, loss 1.518e+00, top1 64.56, top5 84.75
2021-11-05 12:39:46 train 5000, loss 1.516e+00, top1 64.50, top5 84.84
2021-11-05 12:39:47 train 5000, loss 1.514e+00, top1 64.45, top5 84.80
2021-11-05 12:40:10 valid 0000, loss 5.422e-01, top1 87.06, top5 95.29
2021-11-05 12:40:10 valid 0000, loss 5.422e-01, top1 87.06, top5 95.29
2021-11-05 12:40:10 valid 0000, loss 5.422e-01, top1 87.06, top5 95.29
2021-11-05 12:44:42 (JOBID 31682) epoch 44: train time 2857.09, inference time 281.66s, valid_top1 68.35 (best_top1 68.77), valid_top5 88.79
2021-11-05 12:44:43 (JOBID 31682) epoch 44: train time 2869.75, inference time 282.34s, valid_top1 68.35 (best_top1 68.77), valid_top5 88.79
2021-11-05 12:44:44 (JOBID 31682) epoch 44: train time 2857.51, inference time 283.22s, valid_top1 68.35 (best_top1 68.77), valid_top5 88.79
2021-11-05 12:44:56 train 0000, loss 1.502e+00, top1 63.53, top5 81.18
2021-11-05 12:44:56 train 0000, loss 1.590e+00, top1 57.65, top5 85.88
2021-11-05 12:44:58 train 0000, loss 1.635e+00, top1 62.35, top5 83.53
2021-11-05 12:54:18 train 1000, loss 1.493e+00, top1 65.00, top5 85.18
2021-11-05 12:54:18 train 1000, loss 1.499e+00, top1 64.83, top5 85.09
2021-11-05 12:54:18 train 1000, loss 1.499e+00, top1 64.81, top5 85.06
2021-11-05 13:03:36 train 2000, loss 1.493e+00, top1 64.97, top5 85.19
2021-11-05 13:03:36 train 2000, loss 1.508e+00, top1 64.66, top5 84.98
2021-11-05 13:03:36 train 2000, loss 1.508e+00, top1 64.68, top5 84.92
2021-11-05 13:12:53 train 3000, loss 1.509e+00, top1 64.70, top5 84.97
2021-11-05 13:12:53 train 3000, loss 1.504e+00, top1 64.78, top5 85.03
2021-11-05 13:12:53 train 3000, loss 1.512e+00, top1 64.58, top5 84.89
2021-11-05 13:22:17 train 4000, loss 1.513e+00, top1 64.62, top5 84.89
2021-11-05 13:22:17 train 4000, loss 1.511e+00, top1 64.66, top5 84.91
2021-11-05 13:22:17 train 4000, loss 1.514e+00, top1 64.55, top5 84.89
2021-11-05 13:31:35 train 5000, loss 1.517e+00, top1 64.51, top5 84.82
2021-11-05 13:31:35 train 5000, loss 1.517e+00, top1 64.56, top5 84.82
2021-11-05 13:31:35 train 5000, loss 1.519e+00, top1 64.49, top5 84.81
2021-11-05 13:31:59 valid 0000, loss 5.906e-01, top1 87.06, top5 94.12
2021-11-05 13:31:59 valid 0000, loss 5.906e-01, top1 87.06, top5 94.12
2021-11-05 13:31:59 valid 0000, loss 5.906e-01, top1 87.06, top5 94.12
2021-11-05 13:36:22 (JOBID 31682) epoch 45: train time 2824.82, inference time 272.86s, valid_top1 67.65 (best_top1 68.77), valid_top5 88.45
2021-11-05 13:36:22 (JOBID 31682) epoch 45: train time 2825.96, inference time 273.46s, valid_top1 67.65 (best_top1 68.77), valid_top5 88.45
2021-11-05 13:36:22 (JOBID 31682) epoch 45: train time 2826.64, inference time 273.78s, valid_top1 67.65 (best_top1 68.77), valid_top5 88.45
2021-11-05 13:36:36 train 0000, loss 1.212e+00, top1 72.94, top5 90.59
2021-11-05 13:36:36 train 0000, loss 1.396e+00, top1 72.94, top5 85.88
2021-11-05 13:36:36 train 0000, loss 1.303e+00, top1 72.94, top5 88.24
2021-11-05 13:45:59 train 1000, loss 1.504e+00, top1 64.86, top5 84.93
2021-11-05 13:46:00 train 1000, loss 1.484e+00, top1 65.31, top5 85.22
2021-11-05 13:46:00 train 1000, loss 1.507e+00, top1 64.90, top5 84.96
2021-11-05 13:55:20 train 2000, loss 1.510e+00, top1 64.72, top5 84.89
2021-11-05 13:55:20 train 2000, loss 1.505e+00, top1 64.84, top5 84.93
2021-11-05 13:55:20 train 2000, loss 1.520e+00, top1 64.51, top5 84.77
2021-11-05 14:04:48 train 3000, loss 1.506e+00, top1 64.81, top5 84.90
2021-11-05 14:04:48 train 3000, loss 1.514e+00, top1 64.67, top5 84.83
2021-11-05 14:04:48 train 3000, loss 1.523e+00, top1 64.43, top5 84.69
2021-11-05 14:14:12 train 4000, loss 1.517e+00, top1 64.55, top5 84.78
2021-11-05 14:14:12 train 4000, loss 1.510e+00, top1 64.65, top5 84.89
2021-11-05 14:14:12 train 4000, loss 1.524e+00, top1 64.42, top5 84.68
2021-11-05 14:23:29 train 5000, loss 1.516e+00, top1 64.51, top5 84.80
2021-11-05 14:23:29 train 5000, loss 1.522e+00, top1 64.49, top5 84.71
2021-11-05 14:23:29 train 5000, loss 1.526e+00, top1 64.37, top5 84.65
2021-11-05 14:23:53 valid 0000, loss 7.706e-01, top1 82.35, top5 88.24
2021-11-05 14:23:53 valid 0000, loss 7.706e-01, top1 82.35, top5 88.24
2021-11-05 14:23:53 valid 0000, loss 7.706e-01, top1 82.35, top5 88.24
2021-11-05 14:28:24 (JOBID 31682) epoch 46: train time 2841.00, inference time 280.84s, valid_top1 67.16 (best_top1 68.77), valid_top5 87.97
2021-11-05 14:28:24 (JOBID 31682) epoch 46: train time 2840.63, inference time 280.72s, valid_top1 67.16 (best_top1 68.77), valid_top5 87.97
2021-11-05 14:28:24 (JOBID 31682) epoch 46: train time 2841.31, inference time 280.83s, valid_top1 67.16 (best_top1 68.77), valid_top5 87.97
2021-11-05 14:28:38 train 0000, loss 1.388e+00, top1 68.24, top5 83.53
2021-11-05 14:28:38 train 0000, loss 1.920e+00, top1 54.12, top5 77.65
2021-11-05 14:28:38 train 0000, loss 1.156e+00, top1 78.82, top5 94.12
2021-11-05 14:38:04 train 1000, loss 1.488e+00, top1 64.88, top5 85.24
2021-11-05 14:38:04 train 1000, loss 1.503e+00, top1 64.78, top5 85.00
2021-11-05 14:38:04 train 1000, loss 1.493e+00, top1 64.76, top5 85.07
2021-11-05 14:47:29 train 2000, loss 1.496e+00, top1 64.76, top5 85.18
2021-11-05 14:47:29 train 2000, loss 1.507e+00, top1 64.75, top5 84.92
2021-11-05 14:47:29 train 2000, loss 1.501e+00, top1 64.69, top5 84.98
2021-11-05 14:56:51 train 3000, loss 1.515e+00, top1 64.58, top5 84.88
2021-11-05 14:56:51 train 3000, loss 1.505e+00, top1 64.64, top5 85.05
2021-11-05 14:56:51 train 3000, loss 1.509e+00, top1 64.54, top5 84.90
2021-11-05 15:06:22 train 4000, loss 1.510e+00, top1 64.60, top5 84.99
2021-11-05 15:06:22 train 4000, loss 1.520e+00, top1 64.41, top5 84.81
2021-11-05 15:06:22 train 4000, loss 1.511e+00, top1 64.54, top5 84.85
2021-11-05 15:15:46 train 5000, loss 1.516e+00, top1 64.49, top5 84.86
2021-11-05 15:15:46 train 5000, loss 1.521e+00, top1 64.41, top5 84.78
2021-11-05 15:15:47 train 5000, loss 1.516e+00, top1 64.45, top5 84.78
2021-11-05 15:16:11 valid 0000, loss 5.546e-01, top1 84.71, top5 95.29
2021-11-05 15:16:11 valid 0000, loss 5.546e-01, top1 84.71, top5 95.29
2021-11-05 15:16:11 valid 0000, loss 5.546e-01, top1 84.71, top5 95.29
2021-11-05 15:20:32 (JOBID 31682) epoch 47: train time 2857.05, inference time 271.08s, valid_top1 68.25 (best_top1 68.77), valid_top5 88.67
2021-11-05 15:20:35 (JOBID 31682) epoch 47: train time 2857.23, inference time 274.30s, valid_top1 68.25 (best_top1 68.77), valid_top5 88.67
2021-11-05 15:20:36 (JOBID 31682) epoch 47: train time 2856.84, inference time 274.92s, valid_top1 68.25 (best_top1 68.77), valid_top5 88.67
2021-11-05 15:20:47 train 0000, loss 1.547e+00, top1 61.18, top5 82.35
2021-11-05 15:20:49 train 0000, loss 1.248e+00, top1 75.29, top5 87.06
2021-11-05 15:20:49 train 0000, loss 1.915e+00, top1 54.12, top5 77.65
2021-11-05 15:30:02 train 1000, loss 1.500e+00, top1 64.81, top5 85.07
2021-11-05 15:30:02 train 1000, loss 1.490e+00, top1 65.10, top5 85.27
2021-11-05 15:30:02 train 1000, loss 1.498e+00, top1 64.96, top5 84.92
2021-11-05 15:39:17 train 2000, loss 1.502e+00, top1 64.84, top5 85.01
2021-11-05 15:39:17 train 2000, loss 1.512e+00, top1 64.55, top5 84.90
2021-11-05 15:39:17 train 2000, loss 1.511e+00, top1 64.69, top5 84.79
2021-11-05 15:48:30 train 3000, loss 1.518e+00, top1 64.40, top5 84.82
2021-11-05 15:48:30 train 3000, loss 1.512e+00, top1 64.64, top5 84.89
2021-11-05 15:48:30 train 3000, loss 1.513e+00, top1 64.63, top5 84.80
2021-11-05 15:57:50 train 4000, loss 1.518e+00, top1 64.40, top5 84.78
2021-11-05 15:57:50 train 4000, loss 1.515e+00, top1 64.59, top5 84.83
2021-11-05 15:57:51 train 4000, loss 1.516e+00, top1 64.62, top5 84.74
2021-11-05 16:07:02 train 5000, loss 1.518e+00, top1 64.54, top5 84.77
2021-11-05 16:07:02 train 5000, loss 1.519e+00, top1 64.40, top5 84.75
2021-11-05 16:07:02 train 5000, loss 1.521e+00, top1 64.51, top5 84.67
2021-11-05 16:07:27 valid 0000, loss 6.285e-01, top1 87.06, top5 94.12
2021-11-05 16:07:27 valid 0000, loss 6.285e-01, top1 87.06, top5 94.12
2021-11-05 16:07:27 valid 0000, loss 6.285e-01, top1 87.06, top5 94.12
2021-11-05 16:11:45 (JOBID 31682) epoch 48: train time 2803.31, inference time 269.40s, valid_top1 68.05 (best_top1 68.77), valid_top5 88.33
2021-11-05 16:11:59 (JOBID 31682) epoch 48: train time 2799.32, inference time 283.53s, valid_top1 68.05 (best_top1 68.77), valid_top5 88.33
2021-11-05 16:12:00 (JOBID 31682) epoch 48: train time 2800.15, inference time 284.58s, valid_top1 68.05 (best_top1 68.77), valid_top5 88.33
2021-11-05 16:11:59 train 0000, loss 1.425e+00, top1 67.06, top5 83.53
2021-11-05 16:12:13 train 0000, loss 1.501e+00, top1 63.53, top5 82.35
2021-11-05 16:12:13 train 0000, loss 1.553e+00, top1 65.88, top5 85.88
2021-11-05 16:22:04 train 1000, loss 1.504e+00, top1 64.98, top5 84.95
2021-11-05 16:22:04 train 1000, loss 1.502e+00, top1 64.80, top5 84.98
2021-11-05 16:22:04 train 1000, loss 1.491e+00, top1 65.01, top5 85.06
2021-11-05 16:33:11 train 2000, loss 1.510e+00, top1 64.79, top5 85.00
2021-11-05 16:33:11 train 2000, loss 1.508e+00, top1 64.67, top5 84.93
2021-11-05 16:33:11 train 2000, loss 1.506e+00, top1 64.73, top5 84.91
2021-11-05 16:42:40 train 3000, loss 1.514e+00, top1 64.63, top5 84.92
2021-11-05 16:42:40 train 3000, loss 1.510e+00, top1 64.56, top5 84.94
2021-11-05 16:42:40 train 3000, loss 1.511e+00, top1 64.60, top5 84.85
2021-11-05 16:52:03 train 4000, loss 1.513e+00, top1 64.51, top5 84.91
2021-11-05 16:52:03 train 4000, loss 1.516e+00, top1 64.56, top5 84.86
2021-11-05 16:52:04 train 4000, loss 1.518e+00, top1 64.49, top5 84.75
2021-11-05 17:01:26 train 5000, loss 1.518e+00, top1 64.50, top5 84.83
2021-11-05 17:01:26 train 5000, loss 1.516e+00, top1 64.45, top5 84.85
2021-11-05 17:01:26 train 5000, loss 1.520e+00, top1 64.41, top5 84.71
2021-11-05 17:01:49 valid 0000, loss 7.665e-01, top1 85.88, top5 92.94
2021-11-05 17:01:49 valid 0000, loss 7.665e-01, top1 85.88, top5 92.94
2021-11-05 17:01:49 valid 0000, loss 7.665e-01, top1 85.88, top5 92.94
2021-11-05 17:06:22 (JOBID 31682) epoch 49: train time 2994.47, inference time 282.53s, valid_top1 67.77 (best_top1 68.77), valid_top5 88.47
2021-11-05 17:06:22 (JOBID 31682) epoch 49: train time 2979.26, inference time 282.52s, valid_top1 67.77 (best_top1 68.77), valid_top5 88.47
2021-11-05 17:06:22 (JOBID 31682) epoch 49: train time 2980.25, inference time 282.54s, valid_top1 67.77 (best_top1 68.77), valid_top5 88.47
2021-11-05 17:06:38 train 0000, loss 1.297e+00, top1 68.24, top5 87.06
2021-11-05 17:06:38 train 0000, loss 1.701e+00, top1 61.18, top5 78.82
2021-11-05 17:06:38 train 0000, loss 1.384e+00, top1 65.88, top5 89.41
2021-11-05 17:15:54 train 1000, loss 1.500e+00, top1 65.11, top5 84.99
2021-11-05 17:15:54 train 1000, loss 1.497e+00, top1 65.06, top5 84.99
2021-11-05 17:15:54 train 1000, loss 1.495e+00, top1 64.82, top5 85.14
2021-11-05 17:26:02 train 2000, loss 1.502e+00, top1 64.87, top5 84.96
2021-11-05 17:26:02 train 2000, loss 1.500e+00, top1 64.94, top5 85.00
2021-11-05 17:26:02 train 2000, loss 1.505e+00, top1 64.75, top5 85.02
2021-11-05 17:35:24 train 3000, loss 1.506e+00, top1 64.73, top5 84.97
2021-11-05 17:35:24 train 3000, loss 1.510e+00, top1 64.70, top5 84.86
2021-11-05 17:35:24 train 3000, loss 1.511e+00, top1 64.65, top5 84.89
2021-11-05 17:44:43 train 4000, loss 1.513e+00, top1 64.65, top5 84.82
2021-11-05 17:44:43 train 4000, loss 1.510e+00, top1 64.71, top5 84.89
2021-11-05 17:44:43 train 4000, loss 1.515e+00, top1 64.56, top5 84.88
2021-11-05 17:54:01 train 5000, loss 1.516e+00, top1 64.55, top5 84.79
2021-11-05 17:54:01 train 5000, loss 1.514e+00, top1 64.60, top5 84.83
2021-11-05 17:54:01 train 5000, loss 1.519e+00, top1 64.47, top5 84.81
2021-11-05 17:54:26 valid 0000, loss 7.949e-01, top1 83.53, top5 90.59
2021-11-05 17:54:26 valid 0000, loss 7.949e-01, top1 83.53, top5 90.59
2021-11-05 17:54:26 valid 0000, loss 7.949e-01, top1 83.53, top5 90.59
2021-11-05 17:58:56 (JOBID 31682) epoch 50: train time 2873.34, inference time 280.36s, valid_top1 68.04 (best_top1 68.77), valid_top5 88.67
2021-11-05 17:58:57 (JOBID 31682) epoch 50: train time 2873.13, inference time 282.23s, valid_top1 68.04 (best_top1 68.77), valid_top5 88.67
2021-11-05 17:59:02 (JOBID 31682) epoch 50: train time 2872.53, inference time 286.91s, valid_top1 68.04 (best_top1 68.77), valid_top5 88.67
2021-11-05 17:59:13 train 0000, loss 1.390e+00, top1 63.53, top5 90.59
2021-11-05 17:59:13 train 0000, loss 1.628e+00, top1 67.06, top5 80.00
2021-11-05 17:59:21 train 0000, loss 1.599e+00, top1 64.71, top5 81.18
2021-11-05 18:09:07 train 1000, loss 1.490e+00, top1 65.19, top5 85.16
2021-11-05 18:09:07 train 1000, loss 1.499e+00, top1 64.91, top5 85.02
2021-11-05 18:09:07 train 1000, loss 1.506e+00, top1 64.70, top5 84.83
2021-11-05 18:18:19 train 2000, loss 1.501e+00, top1 64.91, top5 85.04
2021-11-05 18:18:19 train 2000, loss 1.504e+00, top1 64.84, top5 84.98
2021-11-05 18:18:20 train 2000, loss 1.507e+00, top1 64.72, top5 84.85
2021-11-05 18:27:36 train 3000, loss 1.506e+00, top1 64.77, top5 84.93
2021-11-05 18:27:36 train 3000, loss 1.508e+00, top1 64.70, top5 84.97
2021-11-05 18:27:36 train 3000, loss 1.511e+00, top1 64.63, top5 84.78
2021-11-05 18:36:52 train 4000, loss 1.514e+00, top1 64.56, top5 84.90
2021-11-05 18:36:52 train 4000, loss 1.509e+00, top1 64.72, top5 84.90
2021-11-05 18:36:52 train 4000, loss 1.519e+00, top1 64.50, top5 84.73
2021-11-05 18:46:04 train 5000, loss 1.514e+00, top1 64.60, top5 84.82
2021-11-05 18:46:04 train 5000, loss 1.517e+00, top1 64.49, top5 84.84
2021-11-05 18:46:04 train 5000, loss 1.522e+00, top1 64.45, top5 84.70
2021-11-05 18:46:28 valid 0000, loss 7.585e-01, top1 81.18, top5 91.76
2021-11-05 18:46:28 valid 0000, loss 7.585e-01, top1 81.18, top5 91.76
2021-11-05 18:46:28 valid 0000, loss 7.585e-01, top1 81.18, top5 91.76
2021-11-05 18:51:04 (JOBID 31682) epoch 51: train time 2842.50, inference time 286.21s, valid_top1 66.89 (best_top1 68.77), valid_top5 88.03
2021-11-05 18:51:05 (JOBID 31682) epoch 51: train time 2835.59, inference time 287.04s, valid_top1 66.89 (best_top1 68.77), valid_top5 88.03
2021-11-05 18:51:05 (JOBID 31682) epoch 51: train time 2840.66, inference time 287.53s, valid_top1 66.89 (best_top1 68.77), valid_top5 88.03
2021-11-05 18:51:19 train 0000, loss 1.258e+00, top1 70.59, top5 85.88
2021-11-05 18:51:19 train 0000, loss 1.800e+00, top1 64.71, top5 77.65
2021-11-05 18:51:19 train 0000, loss 1.542e+00, top1 62.35, top5 89.41
2021-11-05 19:00:39 train 1000, loss 1.504e+00, top1 64.77, top5 84.90
2021-11-05 19:00:39 train 1000, loss 1.488e+00, top1 65.16, top5 85.27
2021-11-05 19:00:39 train 1000, loss 1.497e+00, top1 64.98, top5 85.18
2021-11-05 19:10:01 train 2000, loss 1.505e+00, top1 64.78, top5 84.98
2021-11-05 19:10:01 train 2000, loss 1.495e+00, top1 64.96, top5 85.14
2021-11-05 19:10:02 train 2000, loss 1.497e+00, top1 64.95, top5 85.13
2021-11-05 19:19:27 train 3000, loss 1.505e+00, top1 64.74, top5 84.95
2021-11-05 19:19:27 train 3000, loss 1.513e+00, top1 64.63, top5 84.87
2021-11-05 19:19:28 train 3000, loss 1.502e+00, top1 64.80, top5 85.03
2021-11-05 19:28:53 train 4000, loss 1.517e+00, top1 64.53, top5 84.83
2021-11-05 19:28:53 train 4000, loss 1.512e+00, top1 64.65, top5 84.85
2021-11-05 19:28:53 train 4000, loss 1.507e+00, top1 64.70, top5 84.92
2021-11-05 19:38:20 train 5000, loss 1.515e+00, top1 64.59, top5 84.80
2021-11-05 19:38:20 train 5000, loss 1.519e+00, top1 64.49, top5 84.77
2021-11-05 19:38:20 train 5000, loss 1.512e+00, top1 64.61, top5 84.85
2021-11-05 19:38:44 valid 0000, loss 6.231e-01, top1 90.59, top5 94.12
2021-11-05 19:38:44 valid 0000, loss 6.231e-01, top1 90.59, top5 94.12
2021-11-05 19:38:44 valid 0000, loss 6.231e-01, top1 90.59, top5 94.12
2021-11-05 19:43:05 (JOBID 31682) epoch 52: train time 2848.91, inference time 270.89s, valid_top1 68.00 (best_top1 68.77), valid_top5 88.45
2021-11-05 19:43:18 (JOBID 31682) epoch 52: train time 2850.21, inference time 283.52s, valid_top1 68.00 (best_top1 68.77), valid_top5 88.45
2021-11-05 19:43:20 (JOBID 31682) epoch 52: train time 2849.13, inference time 285.00s, valid_top1 68.00 (best_top1 68.77), valid_top5 88.45
2021-11-05 19:43:32 train 0000, loss 1.371e+00, top1 68.24, top5 89.41
2021-11-05 19:43:20 train 0000, loss 1.931e+00, top1 58.82, top5 76.47
2021-11-05 19:43:32 train 0000, loss 1.239e+00, top1 68.24, top5 88.24
2021-11-05 19:52:49 train 1000, loss 1.501e+00, top1 64.94, top5 85.09
2021-11-05 19:52:49 train 1000, loss 1.492e+00, top1 64.88, top5 85.10
2021-11-05 19:52:49 train 1000, loss 1.499e+00, top1 64.88, top5 85.12
2021-11-05 20:02:07 train 2000, loss 1.499e+00, top1 64.77, top5 85.05
2021-11-05 20:02:07 train 2000, loss 1.508e+00, top1 64.82, top5 85.01
2021-11-05 20:02:07 train 2000, loss 1.505e+00, top1 64.69, top5 84.99
2021-11-05 20:11:27 train 3000, loss 1.513e+00, top1 64.72, top5 84.92
2021-11-05 20:11:27 train 3000, loss 1.506e+00, top1 64.67, top5 84.95
2021-11-05 20:11:27 train 3000, loss 1.508e+00, top1 64.59, top5 84.95
2021-11-05 20:20:44 train 4000, loss 1.514e+00, top1 64.65, top5 84.89
2021-11-05 20:20:44 train 4000, loss 1.509e+00, top1 64.60, top5 84.93
2021-11-05 20:20:44 train 4000, loss 1.512e+00, top1 64.54, top5 84.91
2021-11-05 20:30:04 train 5000, loss 1.512e+00, top1 64.54, top5 84.87
2021-11-05 20:30:04 train 5000, loss 1.518e+00, top1 64.52, top5 84.86
2021-11-05 20:30:04 train 5000, loss 1.515e+00, top1 64.49, top5 84.89
2021-11-05 20:30:27 valid 0000, loss 8.623e-01, top1 81.18, top5 92.94
2021-11-05 20:30:27 valid 0000, loss 8.623e-01, top1 81.18, top5 92.94
2021-11-05 20:30:27 valid 0000, loss 8.623e-01, top1 81.18, top5 92.94
2021-11-05 20:34:48 (JOBID 31682) epoch 53: train time 2832.17, inference time 271.01s, valid_top1 68.13 (best_top1 68.77), valid_top5 88.77
2021-11-05 20:34:49 (JOBID 31682) epoch 53: train time 2819.60, inference time 271.39s, valid_top1 68.13 (best_top1 68.77), valid_top5 88.77
2021-11-05 20:34:49 (JOBID 31682) epoch 53: train time 2817.83, inference time 271.55s, valid_top1 68.13 (best_top1 68.77), valid_top5 88.77
2021-11-05 20:35:03 train 0000, loss 1.821e+00, top1 52.94, top5 75.29
2021-11-05 20:35:03 train 0000, loss 1.199e+00, top1 71.76, top5 89.41
2021-11-05 20:35:03 train 0000, loss 1.256e+00, top1 67.06, top5 91.76
2021-11-05 20:44:16 train 1000, loss 1.494e+00, top1 64.86, top5 85.23
2021-11-05 20:44:16 train 1000, loss 1.500e+00, top1 64.89, top5 85.06
2021-11-05 20:44:16 train 1000, loss 1.479e+00, top1 65.43, top5 85.33
2021-11-05 20:53:35 train 2000, loss 1.501e+00, top1 64.84, top5 85.10
2021-11-05 20:53:35 train 2000, loss 1.510e+00, top1 64.69, top5 84.91
2021-11-05 20:53:35 train 2000, loss 1.498e+00, top1 65.00, top5 85.02
2021-11-05 21:02:55 train 3000, loss 1.511e+00, top1 64.66, top5 84.92
2021-11-05 21:02:55 train 3000, loss 1.506e+00, top1 64.75, top5 85.01
2021-11-05 21:02:55 train 3000, loss 1.506e+00, top1 64.78, top5 84.97
2021-11-05 21:12:13 train 4000, loss 1.510e+00, top1 64.63, top5 84.93
2021-11-05 21:12:13 train 4000, loss 1.512e+00, top1 64.61, top5 84.91
2021-11-05 21:12:13 train 4000, loss 1.509e+00, top1 64.73, top5 84.95
2021-11-05 21:21:33 train 5000, loss 1.514e+00, top1 64.59, top5 84.88
2021-11-05 21:21:33 train 5000, loss 1.514e+00, top1 64.56, top5 84.86
2021-11-05 21:21:33 train 5000, loss 1.513e+00, top1 64.63, top5 84.84
2021-11-05 21:21:56 valid 0000, loss 6.851e-01, top1 83.53, top5 97.65
2021-11-05 21:21:56 valid 0000, loss 6.851e-01, top1 83.53, top5 97.65
2021-11-05 21:21:56 valid 0000, loss 6.851e-01, top1 83.53, top5 97.65
2021-11-05 21:26:27 (JOBID 31682) epoch 54: train time 2817.44, inference time 280.58s, valid_top1 67.28 (best_top1 68.77), valid_top5 88.23
2021-11-05 21:26:27 (JOBID 31682) epoch 54: train time 2817.12, inference time 280.35s, valid_top1 67.28 (best_top1 68.77), valid_top5 88.23
2021-11-05 21:26:28 (JOBID 31682) epoch 54: train time 2817.93, inference time 281.53s, valid_top1 67.28 (best_top1 68.77), valid_top5 88.23
2021-11-05 21:26:41 train 0000, loss 1.687e+00, top1 65.88, top5 83.53
2021-11-05 21:26:41 train 0000, loss 1.498e+00, top1 63.53, top5 82.35
2021-11-05 21:26:43 train 0000, loss 1.675e+00, top1 58.82, top5 84.71
2021-11-05 21:36:06 train 1000, loss 1.496e+00, top1 64.64, top5 85.16
2021-11-05 21:36:06 train 1000, loss 1.496e+00, top1 64.85, top5 85.09
2021-11-05 21:36:06 train 1000, loss 1.493e+00, top1 64.94, top5 85.08
2021-11-05 21:46:15 train 2000, loss 1.497e+00, top1 64.72, top5 85.08
2021-11-05 21:46:15 train 2000, loss 1.502e+00, top1 64.73, top5 85.02
2021-11-05 21:46:15 train 2000, loss 1.496e+00, top1 64.77, top5 85.12
2021-11-05 21:58:25 train 3000, loss 1.506e+00, top1 64.56, top5 84.94
2021-11-05 21:58:25 train 3000, loss 1.505e+00, top1 64.70, top5 84.98
2021-11-05 21:58:26 train 3000, loss 1.502e+00, top1 64.69, top5 85.02
2021-11-05 22:07:45 train 4000, loss 1.508e+00, top1 64.66, top5 84.94
2021-11-05 22:07:45 train 4000, loss 1.510e+00, top1 64.54, top5 84.92
2021-11-05 22:07:45 train 4000, loss 1.507e+00, top1 64.61, top5 84.94
2021-11-05 22:17:06 train 5000, loss 1.510e+00, top1 64.63, top5 84.89
2021-11-05 22:17:06 train 5000, loss 1.514e+00, top1 64.47, top5 84.87
2021-11-05 22:17:06 train 5000, loss 1.510e+00, top1 64.56, top5 84.91
2021-11-05 22:17:30 valid 0000, loss 6.254e-01, top1 84.71, top5 94.12
2021-11-05 22:17:30 valid 0000, loss 6.254e-01, top1 84.71, top5 94.12
2021-11-05 22:17:30 valid 0000, loss 6.254e-01, top1 84.71, top5 94.12
2021-11-05 22:21:52 (JOBID 31682) epoch 55: train time 3051.87, inference time 271.79s, valid_top1 67.58 (best_top1 68.77), valid_top5 88.25
2021-11-05 22:21:52 (JOBID 31682) epoch 55: train time 3052.91, inference time 272.40s, valid_top1 67.58 (best_top1 68.77), valid_top5 88.25
2021-11-05 22:21:52 (JOBID 31682) epoch 55: train time 3052.72, inference time 272.34s, valid_top1 67.58 (best_top1 68.77), valid_top5 88.25
2021-11-05 22:22:06 train 0000, loss 1.568e+00, top1 67.06, top5 84.71
2021-11-05 22:22:06 train 0000, loss 1.784e+00, top1 60.00, top5 77.65
2021-11-05 22:22:06 train 0000, loss 1.654e+00, top1 62.35, top5 84.71
2021-11-05 22:31:23 train 1000, loss 1.510e+00, top1 64.76, top5 84.83
2021-11-05 22:31:23 train 1000, loss 1.485e+00, top1 65.05, top5 85.23
2021-11-05 22:31:23 train 1000, loss 1.496e+00, top1 64.64, top5 85.04
2021-11-05 22:40:41 train 2000, loss 1.508e+00, top1 64.67, top5 84.88
2021-11-05 22:40:41 train 2000, loss 1.491e+00, top1 64.84, top5 85.16
2021-11-05 22:40:42 train 2000, loss 1.499e+00, top1 64.78, top5 85.01
2021-11-05 22:50:04 train 3000, loss 1.509e+00, top1 64.63, top5 84.88
2021-11-05 22:50:04 train 3000, loss 1.500e+00, top1 64.79, top5 85.05
2021-11-05 22:50:04 train 3000, loss 1.505e+00, top1 64.69, top5 84.94
2021-11-05 22:59:27 train 4000, loss 1.512e+00, top1 64.58, top5 84.84
2021-11-05 22:59:27 train 4000, loss 1.504e+00, top1 64.75, top5 85.01
2021-11-05 22:59:27 train 4000, loss 1.508e+00, top1 64.63, top5 84.94
2021-11-05 23:08:44 train 5000, loss 1.510e+00, top1 64.63, top5 84.90
2021-11-05 23:08:44 train 5000, loss 1.516e+00, top1 64.50, top5 84.78
2021-11-05 23:08:44 train 5000, loss 1.512e+00, top1 64.56, top5 84.89
2021-11-05 23:09:07 valid 0000, loss 6.272e-01, top1 87.06, top5 92.94
2021-11-05 23:09:07 valid 0000, loss 6.272e-01, top1 87.06, top5 92.94
2021-11-05 23:09:07 valid 0000, loss 6.272e-01, top1 87.06, top5 92.94
2021-11-05 23:13:37 (JOBID 31682) epoch 56: train time 2825.76, inference time 279.87s, valid_top1 67.35 (best_top1 68.77), valid_top5 88.49
2021-11-05 23:13:37 (JOBID 31682) epoch 56: train time 2825.13, inference time 279.75s, valid_top1 67.35 (best_top1 68.77), valid_top5 88.49
2021-11-05 23:13:37 (JOBID 31682) epoch 56: train time 2824.92, inference time 279.87s, valid_top1 67.35 (best_top1 68.77), valid_top5 88.49
2021-11-05 23:13:51 train 0000, loss 1.263e+00, top1 71.76, top5 89.41
2021-11-05 23:13:51 train 0000, loss 1.634e+00, top1 64.71, top5 84.71
2021-11-05 23:13:51 train 0000, loss 1.640e+00, top1 62.35, top5 82.35
2021-11-05 23:22:21 train 1000, loss 1.497e+00, top1 64.92, top5 84.99
2021-11-05 23:22:21 train 1000, loss 1.483e+00, top1 65.26, top5 85.25
2021-11-05 23:22:21 train 1000, loss 1.481e+00, top1 65.17, top5 85.33
2021-11-05 23:30:53 train 2000, loss 1.488e+00, top1 65.14, top5 85.20
2021-11-05 23:30:53 train 2000, loss 1.503e+00, top1 64.72, top5 84.94
2021-11-05 23:30:53 train 2000, loss 1.494e+00, top1 64.92, top5 85.10
2021-11-05 23:39:23 train 3000, loss 1.495e+00, top1 64.93, top5 85.12
2021-11-05 23:39:23 train 3000, loss 1.504e+00, top1 64.77, top5 84.93
2021-11-05 23:39:23 train 3000, loss 1.499e+00, top1 64.91, top5 85.03
2021-11-05 23:47:52 train 4000, loss 1.501e+00, top1 64.82, top5 85.07
2021-11-05 23:47:52 train 4000, loss 1.507e+00, top1 64.71, top5 84.90
2021-11-05 23:47:52 train 4000, loss 1.503e+00, top1 64.80, top5 85.00
2021-11-05 23:56:22 train 5000, loss 1.504e+00, top1 64.77, top5 85.03
2021-11-05 23:56:22 train 5000, loss 1.512e+00, top1 64.63, top5 84.85
2021-11-05 23:56:22 train 5000, loss 1.508e+00, top1 64.67, top5 84.95
2021-11-05 23:56:45 valid 0000, loss 7.240e-01, top1 87.06, top5 92.94
2021-11-05 23:56:45 valid 0000, loss 7.240e-01, top1 87.06, top5 92.94
2021-11-05 23:56:45 valid 0000, loss 7.240e-01, top1 87.06, top5 92.94
2021-11-06 00:01:16 (JOBID 31682) epoch 57: train time 2578.00, inference time 281.31s, valid_top1 67.30 (best_top1 68.77), valid_top5 87.98
2021-11-06 00:01:20 (JOBID 31682) epoch 57: train time 2577.71, inference time 284.29s, valid_top1 67.30 (best_top1 68.77), valid_top5 87.98
2021-11-06 00:01:20 (JOBID 31682) epoch 57: train time 2577.95, inference time 285.30s, valid_top1 67.30 (best_top1 68.77), valid_top5 87.98
2021-11-06 00:01:34 train 0000, loss 1.384e+00, top1 68.24, top5 87.06
2021-11-06 00:01:32 train 0000, loss 1.202e+00, top1 65.88, top5 91.76
2021-11-06 00:01:34 train 0000, loss 1.778e+00, top1 57.65, top5 83.53
2021-11-06 00:10:49 train 1000, loss 1.489e+00, top1 65.11, top5 85.29
2021-11-06 00:10:49 train 1000, loss 1.491e+00, top1 65.20, top5 85.12
2021-11-06 00:10:49 train 1000, loss 1.482e+00, top1 65.06, top5 85.31
2021-11-06 00:20:11 train 2000, loss 1.493e+00, top1 64.90, top5 85.11
2021-11-06 00:20:11 train 2000, loss 1.497e+00, top1 64.98, top5 85.05
2021-11-06 00:20:11 train 2000, loss 1.491e+00, top1 65.02, top5 85.11
2021-11-06 00:29:36 train 3000, loss 1.497e+00, top1 64.88, top5 85.05
2021-11-06 00:29:36 train 3000, loss 1.503e+00, top1 64.81, top5 85.01
2021-11-06 00:29:36 train 3000, loss 1.498e+00, top1 64.87, top5 85.01
2021-11-06 00:39:04 train 4000, loss 1.509e+00, top1 64.70, top5 84.93
2021-11-06 00:39:04 train 4000, loss 1.500e+00, top1 64.76, top5 84.98
2021-11-06 00:39:04 train 4000, loss 1.503e+00, top1 64.75, top5 84.97
2021-11-06 00:48:30 train 5000, loss 1.505e+00, top1 64.67, top5 84.94
2021-11-06 00:48:31 train 5000, loss 1.508e+00, top1 64.66, top5 84.89
2021-11-06 00:48:31 train 5000, loss 1.513e+00, top1 64.61, top5 84.89
2021-11-06 00:48:55 valid 0000, loss 6.492e-01, top1 85.88, top5 97.65
2021-11-06 00:48:55 valid 0000, loss 6.492e-01, top1 85.88, top5 97.65
2021-11-06 00:48:55 valid 0000, loss 6.492e-01, top1 85.88, top5 97.65
2021-11-06 00:53:18 (JOBID 31682) epoch 58: train time 2844.15, inference time 273.37s, valid_top1 68.17 (best_top1 68.77), valid_top5 88.69
2021-11-06 00:53:23 (JOBID 31682) epoch 58: train time 2844.64, inference time 277.91s, valid_top1 68.17 (best_top1 68.77), valid_top5 88.69
2021-11-06 00:53:23 (JOBID 31682) epoch 58: train time 2847.93, inference time 278.85s, valid_top1 68.17 (best_top1 68.77), valid_top5 88.69
2021-11-06 00:53:32 train 0000, loss 1.356e+00, top1 63.53, top5 87.06
2021-11-06 00:53:37 train 0000, loss 1.567e+00, top1 58.82, top5 84.71
2021-11-06 00:53:37 train 0000, loss 1.499e+00, top1 69.41, top5 84.71
2021-11-06 01:02:10 train 1000, loss 1.491e+00, top1 64.93, top5 85.16
2021-11-06 01:02:10 train 1000, loss 1.487e+00, top1 65.02, top5 85.22
2021-11-06 01:02:10 train 1000, loss 1.504e+00, top1 64.59, top5 85.16
2021-11-06 01:10:42 train 2000, loss 1.501e+00, top1 64.78, top5 84.97
2021-11-06 01:10:42 train 2000, loss 1.500e+00, top1 64.73, top5 85.06
2021-11-06 01:10:42 train 2000, loss 1.507e+00, top1 64.67, top5 85.05
2021-11-06 01:19:19 train 3000, loss 1.502e+00, top1 64.78, top5 84.94
2021-11-06 01:19:19 train 3000, loss 1.505e+00, top1 64.67, top5 85.01
2021-11-06 01:19:19 train 3000, loss 1.505e+00, top1 64.75, top5 85.05
2021-11-06 01:27:56 train 4000, loss 1.509e+00, top1 64.56, top5 84.93
2021-11-06 01:27:56 train 4000, loss 1.507e+00, top1 64.67, top5 84.91
2021-11-06 01:27:56 train 4000, loss 1.512e+00, top1 64.56, top5 84.93
2021-11-06 01:36:34 train 5000, loss 1.508e+00, top1 64.57, top5 84.94
2021-11-06 01:36:34 train 5000, loss 1.509e+00, top1 64.62, top5 84.90
2021-11-06 01:36:34 train 5000, loss 1.513e+00, top1 64.55, top5 84.92
2021-11-06 01:36:57 valid 0000, loss 8.149e-01, top1 85.88, top5 91.76
2021-11-06 01:36:57 valid 0000, loss 8.149e-01, top1 85.88, top5 91.76
2021-11-06 01:36:57 valid 0000, loss 8.149e-01, top1 85.88, top5 91.76
2021-11-06 01:41:24 (JOBID 31682) epoch 59: train time 2603.76, inference time 277.30s, valid_top1 67.71 (best_top1 68.77), valid_top5 88.37
2021-11-06 01:41:30 (JOBID 31682) epoch 59: train time 2604.18, inference time 282.80s, valid_top1 67.71 (best_top1 68.77), valid_top5 88.37
2021-11-06 01:41:30 (JOBID 31682) epoch 59: train time 2609.10, inference time 283.06s, valid_top1 67.71 (best_top1 68.77), valid_top5 88.37
2021-11-06 01:41:38 train 0000, loss 1.516e+00, top1 64.71, top5 87.06
2021-11-06 01:41:44 train 0000, loss 1.321e+00, top1 67.06, top5 89.41
2021-11-06 01:41:44 train 0000, loss 1.485e+00, top1 64.71, top5 84.71
2021-11-06 01:50:11 train 1000, loss 1.365e+00, top1 67.83, top5 86.69
2021-11-06 01:50:11 train 1000, loss 1.354e+00, top1 68.19, top5 86.94
2021-11-06 01:50:11 train 1000, loss 1.372e+00, top1 67.74, top5 86.74
2021-11-06 01:58:38 train 2000, loss 1.350e+00, top1 68.29, top5 86.90
2021-11-06 01:58:38 train 2000, loss 1.341e+00, top1 68.55, top5 87.09
2021-11-06 01:58:38 train 2000, loss 1.353e+00, top1 68.23, top5 86.95
2021-11-06 02:07:07 train 3000, loss 1.335e+00, top1 68.61, top5 87.11
2021-11-06 02:07:07 train 3000, loss 1.329e+00, top1 68.75, top5 87.24
2021-11-06 02:07:07 train 3000, loss 1.339e+00, top1 68.48, top5 87.13
2021-11-06 02:15:36 train 4000, loss 1.320e+00, top1 68.95, top5 87.35
2021-11-06 02:15:36 train 4000, loss 1.323e+00, top1 68.84, top5 87.27
2021-11-06 02:15:37 train 4000, loss 1.327e+00, top1 68.70, top5 87.27
2021-11-06 02:24:05 train 5000, loss 1.312e+00, top1 69.07, top5 87.46
2021-11-06 02:24:05 train 5000, loss 1.317e+00, top1 68.96, top5 87.37
2021-11-06 02:24:05 train 5000, loss 1.320e+00, top1 68.87, top5 87.38
2021-11-06 02:24:28 valid 0000, loss 6.057e-01, top1 88.24, top5 96.47
2021-11-06 02:24:28 valid 0000, loss 6.057e-01, top1 88.24, top5 96.47
2021-11-06 02:24:28 valid 0000, loss 6.057e-01, top1 88.24, top5 96.47
2021-11-06 02:28:53 (JOBID 31682) epoch 60: train time 2568.09, inference time 274.72s, valid_top1 72.10 (best_top1 72.10), valid_top5 90.83
2021-11-06 02:28:55 (JOBID 31682) epoch 60: train time 2573.88, inference time 277.26s, valid_top1 72.10 (best_top1 72.10), valid_top5 90.83
2021-11-06 02:29:02 (JOBID 31682) epoch 60: train time 2568.18, inference time 282.83s, valid_top1 72.10 (best_top1 72.10), valid_top5 90.83
2021-11-06 02:29:09 train 0000, loss 1.533e+00, top1 67.06, top5 85.88
2021-11-06 02:29:07 train 0000, loss 1.185e+00, top1 69.41, top5 88.24
2021-11-06 02:29:16 train 0000, loss 1.648e+00, top1 67.06, top5 82.35
2021-11-06 02:37:48 train 1000, loss 1.276e+00, top1 69.90, top5 87.93
2021-11-06 02:37:48 train 1000, loss 1.291e+00, top1 69.67, top5 87.65
2021-11-06 02:37:48 train 1000, loss 1.278e+00, top1 69.75, top5 88.02
2021-11-06 02:46:21 train 2000, loss 1.287e+00, top1 69.74, top5 87.74
2021-11-06 02:46:21 train 2000, loss 1.274e+00, top1 69.83, top5 87.99
2021-11-06 02:46:21 train 2000, loss 1.276e+00, top1 69.84, top5 87.98
2021-11-06 02:54:58 train 3000, loss 1.276e+00, top1 69.83, top5 87.94
2021-11-06 02:54:58 train 3000, loss 1.273e+00, top1 69.89, top5 88.02
2021-11-06 02:54:59 train 3000, loss 1.279e+00, top1 69.92, top5 87.86
2021-11-06 03:03:45 train 4000, loss 1.275e+00, top1 69.99, top5 87.92
2021-11-06 03:03:44 train 4000, loss 1.271e+00, top1 69.93, top5 88.04
2021-11-06 03:03:45 train 4000, loss 1.275e+00, top1 69.82, top5 87.97
2021-11-06 03:12:36 train 5000, loss 1.274e+00, top1 69.84, top5 87.98
2021-11-06 03:12:36 train 5000, loss 1.271e+00, top1 69.97, top5 88.03
2021-11-06 03:12:36 train 5000, loss 1.274e+00, top1 69.96, top5 87.94
2021-11-06 03:12:59 valid 0000, loss 5.758e-01, top1 85.88, top5 95.29
2021-11-06 03:12:59 valid 0000, loss 5.758e-01, top1 85.88, top5 95.29
2021-11-06 03:12:59 valid 0000, loss 5.758e-01, top1 85.88, top5 95.29
2021-11-06 03:17:25 (JOBID 31682) epoch 61: train time 2626.57, inference time 275.53s, valid_top1 72.44 (best_top1 72.44), valid_top5 91.04
2021-11-06 03:17:31 (JOBID 31682) epoch 61: train time 2632.96, inference time 282.08s, valid_top1 72.44 (best_top1 72.44), valid_top5 91.04
2021-11-06 03:17:32 (JOBID 31682) epoch 61: train time 2635.52, inference time 283.28s, valid_top1 72.44 (best_top1 72.44), valid_top5 91.04
2021-11-06 03:17:45 train 0000, loss 1.363e+00, top1 67.06, top5 87.06
2021-11-06 03:17:39 train 0000, loss 1.204e+00, top1 74.12, top5 88.24
2021-11-06 03:17:45 train 0000, loss 1.141e+00, top1 71.76, top5 89.41
2021-11-06 03:26:30 train 1000, loss 1.242e+00, top1 70.55, top5 88.33
2021-11-06 03:26:30 train 1000, loss 1.257e+00, top1 70.34, top5 88.11
2021-11-06 03:26:30 train 1000, loss 1.249e+00, top1 70.48, top5 88.22
2021-11-06 03:35:11 train 2000, loss 1.258e+00, top1 70.26, top5 88.11
2021-11-06 03:35:11 train 2000, loss 1.249e+00, top1 70.36, top5 88.27
2021-11-06 03:35:11 train 2000, loss 1.251e+00, top1 70.44, top5 88.24
2021-11-06 03:43:53 train 3000, loss 1.260e+00, top1 70.24, top5 88.12
2021-11-06 03:43:53 train 3000, loss 1.249e+00, top1 70.37, top5 88.27
2021-11-06 03:43:53 train 3000, loss 1.256e+00, top1 70.31, top5 88.18
2021-11-06 03:52:42 train 4000, loss 1.256e+00, top1 70.28, top5 88.16
2021-11-06 03:52:42 train 4000, loss 1.252e+00, top1 70.34, top5 88.22
2021-11-06 03:52:42 train 4000, loss 1.255e+00, top1 70.28, top5 88.19
2021-11-06 04:01:29 train 5000, loss 1.252e+00, top1 70.37, top5 88.22
2021-11-06 04:01:29 train 5000, loss 1.257e+00, top1 70.26, top5 88.14
2021-11-06 04:01:29 train 5000, loss 1.255e+00, top1 70.27, top5 88.20
2021-11-06 04:01:52 valid 0000, loss 5.951e-01, top1 87.06, top5 95.29
2021-11-06 04:01:52 valid 0000, loss 5.951e-01, top1 87.06, top5 95.29
2021-11-06 04:01:52 valid 0000, loss 5.951e-01, top1 87.06, top5 95.29
2021-11-06 04:06:33 (JOBID 31682) epoch 62: train time 2651.73, inference time 290.52s, valid_top1 72.64 (best_top1 72.64), valid_top5 91.13
2021-11-06 04:06:33 (JOBID 31682) epoch 62: train time 2650.55, inference time 290.47s, valid_top1 72.64 (best_top1 72.64), valid_top5 91.13
2021-11-06 04:06:33 (JOBID 31682) epoch 62: train time 2657.44, inference time 290.52s, valid_top1 72.64 (best_top1 72.64), valid_top5 91.13
2021-11-06 04:06:47 train 0000, loss 1.424e+00, top1 68.24, top5 83.53
2021-11-06 04:06:47 train 0000, loss 1.065e+00, top1 75.29, top5 94.12
2021-11-06 04:06:47 train 0000, loss 9.174e-01, top1 76.47, top5 96.47
2021-11-06 04:15:20 train 1000, loss 1.252e+00, top1 70.43, top5 88.26
2021-11-06 04:15:20 train 1000, loss 1.248e+00, top1 70.25, top5 88.29
2021-11-06 04:15:20 train 1000, loss 1.248e+00, top1 70.47, top5 88.33
2021-11-06 04:23:55 train 2000, loss 1.247e+00, top1 70.57, top5 88.30
2021-11-06 04:23:55 train 2000, loss 1.243e+00, top1 70.44, top5 88.35
2021-11-06 04:23:55 train 2000, loss 1.241e+00, top1 70.53, top5 88.38
2021-11-06 04:32:30 train 3000, loss 1.242e+00, top1 70.48, top5 88.39
2021-11-06 04:32:30 train 3000, loss 1.247e+00, top1 70.53, top5 88.30
2021-11-06 04:32:30 train 3000, loss 1.240e+00, top1 70.57, top5 88.38
2021-11-06 04:41:08 train 4000, loss 1.242e+00, top1 70.54, top5 88.36
2021-11-06 04:41:07 train 4000, loss 1.244e+00, top1 70.51, top5 88.33
2021-11-06 04:41:08 train 4000, loss 1.242e+00, top1 70.54, top5 88.34
2021-11-06 04:49:47 train 5000, loss 1.244e+00, top1 70.50, top5 88.35
2021-11-06 04:49:47 train 5000, loss 1.243e+00, top1 70.51, top5 88.33
2021-11-06 04:49:47 train 5000, loss 1.242e+00, top1 70.50, top5 88.35
2021-11-06 04:50:10 valid 0000, loss 5.108e-01, top1 89.41, top5 97.65
2021-11-06 04:50:10 valid 0000, loss 5.108e-01, top1 89.41, top5 97.65
2021-11-06 04:50:10 valid 0000, loss 5.108e-01, top1 89.41, top5 97.65
2021-11-06 04:54:45 (JOBID 31682) epoch 63: train time 2607.04, inference time 284.75s, valid_top1 72.82 (best_top1 72.82), valid_top5 91.16
2021-11-06 04:54:45 (JOBID 31682) epoch 63: train time 2607.06, inference time 284.74s, valid_top1 72.82 (best_top1 72.82), valid_top5 91.16
2021-11-06 04:54:48 (JOBID 31682) epoch 63: train time 2606.41, inference time 286.94s, valid_top1 72.82 (best_top1 72.82), valid_top5 91.16
2021-11-06 04:55:00 train 0000, loss 1.202e+00, top1 69.41, top5 89.41
2021-11-06 04:55:00 train 0000, loss 1.206e+00, top1 70.59, top5 89.41
2021-11-06 04:55:02 train 0000, loss 1.311e+00, top1 68.24, top5 90.59
2021-11-06 05:03:39 train 1000, loss 1.232e+00, top1 70.75, top5 88.48
2021-11-06 05:03:38 train 1000, loss 1.234e+00, top1 70.80, top5 88.39
2021-11-06 05:03:39 train 1000, loss 1.238e+00, top1 70.79, top5 88.37
2021-11-06 05:12:13 train 2000, loss 1.235e+00, top1 70.67, top5 88.37
2021-11-06 05:12:13 train 2000, loss 1.236e+00, top1 70.75, top5 88.32
2021-11-06 05:12:13 train 2000, loss 1.235e+00, top1 70.66, top5 88.42
2021-11-06 05:20:52 train 3000, loss 1.241e+00, top1 70.70, top5 88.26
2021-11-06 05:20:52 train 3000, loss 1.234e+00, top1 70.70, top5 88.45
2021-11-06 05:20:52 train 3000, loss 1.232e+00, top1 70.72, top5 88.46
2021-11-06 05:29:35 train 4000, loss 1.235e+00, top1 70.71, top5 88.43
2021-11-06 05:29:35 train 4000, loss 1.239e+00, top1 70.70, top5 88.31
2021-11-06 05:29:35 train 4000, loss 1.234e+00, top1 70.63, top5 88.43
2021-11-06 05:38:21 train 5000, loss 1.232e+00, top1 70.66, top5 88.46
2021-11-06 05:38:21 train 5000, loss 1.234e+00, top1 70.74, top5 88.45
2021-11-06 05:38:21 train 5000, loss 1.239e+00, top1 70.70, top5 88.32
2021-11-06 05:38:44 valid 0000, loss 5.751e-01, top1 88.24, top5 96.47
2021-11-06 05:38:44 valid 0000, loss 5.751e-01, top1 88.24, top5 96.47
2021-11-06 05:38:44 valid 0000, loss 5.751e-01, top1 88.24, top5 96.47
2021-11-06 05:43:01 (JOBID 31682) epoch 64: train time 2629.14, inference time 267.53s, valid_top1 72.93 (best_top1 72.93), valid_top5 91.30
2021-11-06 05:43:13 (JOBID 31682) epoch 64: train time 2626.24, inference time 278.46s, valid_top1 72.93 (best_top1 72.93), valid_top5 91.30
2021-11-06 05:43:14 (JOBID 31682) epoch 64: train time 2629.04, inference time 279.80s, valid_top1 72.93 (best_top1 72.93), valid_top5 91.30
2021-11-06 05:43:27 train 0000, loss 1.094e+00, top1 76.47, top5 88.24
2021-11-06 05:43:18 train 0000, loss 1.046e+00, top1 72.94, top5 91.76
2021-11-06 05:43:27 train 0000, loss 1.280e+00, top1 67.06, top5 91.76
2021-11-06 05:51:54 train 1000, loss 1.217e+00, top1 71.02, top5 88.58
2021-11-06 05:51:55 train 1000, loss 1.222e+00, top1 70.85, top5 88.63
2021-11-06 05:51:55 train 1000, loss 1.219e+00, top1 71.11, top5 88.64
2021-11-06 06:00:22 train 2000, loss 1.226e+00, top1 70.78, top5 88.55
2021-11-06 06:00:22 train 2000, loss 1.223e+00, top1 70.89, top5 88.58
2021-11-06 06:00:22 train 2000, loss 1.225e+00, top1 70.86, top5 88.59
2021-11-06 06:08:50 train 3000, loss 1.225e+00, top1 70.88, top5 88.58
2021-11-06 06:08:50 train 3000, loss 1.225e+00, top1 70.87, top5 88.57
2021-11-06 06:08:50 train 3000, loss 1.227e+00, top1 70.81, top5 88.56
2021-11-06 06:17:20 train 4000, loss 1.224e+00, top1 70.96, top5 88.57
2021-11-06 06:17:20 train 4000, loss 1.225e+00, top1 70.88, top5 88.58
2021-11-06 06:17:20 train 4000, loss 1.228e+00, top1 70.82, top5 88.55
2021-11-06 06:25:55 train 5000, loss 1.226e+00, top1 70.89, top5 88.53
2021-11-06 06:25:55 train 5000, loss 1.224e+00, top1 70.91, top5 88.58
2021-11-06 06:25:55 train 5000, loss 1.227e+00, top1 70.85, top5 88.54
2021-11-06 06:26:20 valid 0000, loss 5.319e-01, top1 88.24, top5 97.65
2021-11-06 06:26:20 valid 0000, loss 5.319e-01, top1 88.24, top5 97.65
2021-11-06 06:26:20 valid 0000, loss 5.319e-01, top1 88.24, top5 97.65
2021-11-06 06:30:49 (JOBID 31682) epoch 65: train time 2575.42, inference time 279.57s, valid_top1 73.04 (best_top1 73.04), valid_top5 91.35
2021-11-06 06:30:49 (JOBID 31682) epoch 65: train time 2574.79, inference time 280.93s, valid_top1 73.04 (best_top1 73.04), valid_top5 91.35
2021-11-06 06:30:51 (JOBID 31682) epoch 65: train time 2586.99, inference time 283.06s, valid_top1 73.04 (best_top1 73.04), valid_top5 91.35
2021-11-06 06:31:04 train 0000, loss 7.708e-01, top1 78.82, top5 97.65
2021-11-06 06:31:04 train 0000, loss 1.497e+00, top1 64.71, top5 85.88
2021-11-06 06:31:07 train 0000, loss 1.120e+00, top1 69.41, top5 89.41
2021-11-06 06:39:54 train 1000, loss 1.220e+00, top1 71.02, top5 88.64
2021-11-06 06:39:54 train 1000, loss 1.225e+00, top1 70.85, top5 88.52
2021-11-06 06:39:54 train 1000, loss 1.215e+00, top1 71.02, top5 88.70
2021-11-06 06:48:41 train 2000, loss 1.215e+00, top1 71.18, top5 88.73
2021-11-06 06:48:41 train 2000, loss 1.220e+00, top1 71.02, top5 88.59
2021-11-06 06:48:41 train 2000, loss 1.216e+00, top1 71.10, top5 88.67
2021-11-06 06:57:33 train 3000, loss 1.219e+00, top1 71.03, top5 88.66
2021-11-06 06:57:33 train 3000, loss 1.217e+00, top1 71.10, top5 88.68
2021-11-06 06:57:33 train 3000, loss 1.217e+00, top1 71.02, top5 88.68
2021-11-06 07:06:22 train 4000, loss 1.219e+00, top1 71.08, top5 88.63
2021-11-06 07:06:22 train 4000, loss 1.218e+00, top1 71.10, top5 88.64
2021-11-06 07:06:22 train 4000, loss 1.217e+00, top1 71.07, top5 88.70
2021-11-06 07:15:11 train 5000, loss 1.219e+00, top1 71.05, top5 88.63
2021-11-06 07:15:11 train 5000, loss 1.216e+00, top1 71.14, top5 88.66
2021-11-06 07:15:11 train 5000, loss 1.219e+00, top1 71.04, top5 88.67
2021-11-06 07:15:35 valid 0000, loss 5.366e-01, top1 87.06, top5 98.82
2021-11-06 07:15:35 valid 0000, loss 5.366e-01, top1 87.06, top5 98.82
2021-11-06 07:15:35 valid 0000, loss 5.366e-01, top1 87.06, top5 98.82
2021-11-06 07:20:00 (JOBID 31682) epoch 66: train time 2673.09, inference time 275.42s, valid_top1 73.06 (best_top1 73.06), valid_top5 91.39
2021-11-06 07:20:11 (JOBID 31682) epoch 66: train time 2675.11, inference time 286.33s, valid_top1 73.06 (best_top1 73.06), valid_top5 91.39
2021-11-06 07:20:11 (JOBID 31682) epoch 66: train time 2675.74, inference time 285.81s, valid_top1 73.06 (best_top1 73.06), valid_top5 91.39
2021-11-06 07:20:15 train 0000, loss 8.703e-01, top1 71.76, top5 95.29
2021-11-06 07:20:24 train 0000, loss 1.478e+00, top1 68.24, top5 77.65
2021-11-06 07:20:24 train 0000, loss 1.388e+00, top1 70.59, top5 85.88
2021-11-06 07:28:57 train 1000, loss 1.195e+00, top1 71.62, top5 88.88
2021-11-06 07:28:57 train 1000, loss 1.212e+00, top1 71.17, top5 88.55
2021-11-06 07:28:57 train 1000, loss 1.201e+00, top1 71.37, top5 88.97
2021-11-06 07:37:29 train 2000, loss 1.206e+00, top1 71.26, top5 88.84
2021-11-06 07:37:29 train 2000, loss 1.211e+00, top1 71.17, top5 88.68
2021-11-06 07:37:29 train 2000, loss 1.204e+00, top1 71.39, top5 88.90
2021-11-06 07:46:05 train 3000, loss 1.215e+00, top1 71.10, top5 88.63
2021-11-06 07:46:05 train 3000, loss 1.206e+00, top1 71.29, top5 88.87
2021-11-06 07:46:05 train 3000, loss 1.206e+00, top1 71.28, top5 88.85
2021-11-06 07:54:43 train 4000, loss 1.208e+00, top1 71.19, top5 88.79
2021-11-06 07:54:43 train 4000, loss 1.216e+00, top1 71.12, top5 88.63
2021-11-06 07:54:43 train 4000, loss 1.209e+00, top1 71.22, top5 88.81
2021-11-06 08:03:22 train 5000, loss 1.210e+00, top1 71.19, top5 88.77
2021-11-06 08:03:22 train 5000, loss 1.216e+00, top1 71.10, top5 88.64
2021-11-06 08:03:22 train 5000, loss 1.210e+00, top1 71.20, top5 88.80
2021-11-06 08:03:45 valid 0000, loss 5.316e-01, top1 87.06, top5 96.47
2021-11-06 08:03:45 valid 0000, loss 5.316e-01, top1 87.06, top5 96.47
2021-11-06 08:03:45 valid 0000, loss 5.316e-01, top1 87.06, top5 96.47
2021-11-06 08:08:19 (JOBID 31682) epoch 67: train time 2604.14, inference time 283.47s, valid_top1 73.18 (best_top1 73.18), valid_top5 91.49
2021-11-06 08:08:34 (JOBID 31682) epoch 67: train time 2614.96, inference time 299.51s, valid_top1 73.18 (best_top1 73.18), valid_top5 91.49
2021-11-06 08:08:35 (JOBID 31682) epoch 67: train time 2604.22, inference time 300.04s, valid_top1 73.18 (best_top1 73.18), valid_top5 91.49
2021-11-06 08:08:48 train 0000, loss 1.063e+00, top1 71.76, top5 91.76
2021-11-06 08:08:33 train 0000, loss 1.184e+00, top1 67.06, top5 87.06
2021-11-06 08:08:48 train 0000, loss 8.528e-01, top1 81.18, top5 91.76
2021-11-06 08:17:23 train 1000, loss 1.202e+00, top1 71.35, top5 88.91
2021-11-06 08:17:23 train 1000, loss 1.205e+00, top1 71.45, top5 88.80
2021-11-06 08:17:23 train 1000, loss 1.205e+00, top1 71.36, top5 88.84
2021-11-06 08:25:57 train 2000, loss 1.203e+00, top1 71.39, top5 88.78
2021-11-06 08:25:57 train 2000, loss 1.200e+00, top1 71.42, top5 88.89
2021-11-06 08:25:57 train 2000, loss 1.207e+00, top1 71.22, top5 88.80
2021-11-06 08:34:31 train 3000, loss 1.206e+00, top1 71.25, top5 88.77
2021-11-06 08:34:31 train 3000, loss 1.203e+00, top1 71.38, top5 88.85
2021-11-06 08:34:31 train 3000, loss 1.205e+00, top1 71.34, top5 88.85
2021-11-06 08:43:07 train 4000, loss 1.206e+00, top1 71.24, top5 88.78
2021-11-06 08:43:07 train 4000, loss 1.204e+00, top1 71.35, top5 88.84
2021-11-06 08:43:07 train 4000, loss 1.207e+00, top1 71.28, top5 88.82
2021-11-06 08:51:51 train 5000, loss 1.208e+00, top1 71.28, top5 88.80
2021-11-06 08:51:51 train 5000, loss 1.206e+00, top1 71.27, top5 88.79
2021-11-06 08:51:51 train 5000, loss 1.207e+00, top1 71.24, top5 88.81
2021-11-06 08:52:13 valid 0000, loss 4.943e-01, top1 90.59, top5 97.65
2021-11-06 08:52:13 valid 0000, loss 4.943e-01, top1 90.59, top5 97.65
2021-11-06 08:52:13 valid 0000, loss 4.943e-01, top1 90.59, top5 97.65
2021-11-06 08:56:31 (JOBID 31682) epoch 68: train time 2624.58, inference time 267.36s, valid_top1 73.20 (best_top1 73.20), valid_top5 91.54
2021-11-06 08:56:42 (JOBID 31682) epoch 68: train time 2608.56, inference time 278.08s, valid_top1 73.20 (best_top1 73.20), valid_top5 91.54
2021-11-06 08:56:42 (JOBID 31682) epoch 68: train time 2609.05, inference time 278.64s, valid_top1 73.20 (best_top1 73.20), valid_top5 91.54
2021-11-06 08:56:45 train 0000, loss 1.279e+00, top1 72.94, top5 90.59
2021-11-06 08:56:55 train 0000, loss 1.045e+00, top1 71.76, top5 89.41
2021-11-06 08:56:55 train 0000, loss 9.880e-01, top1 72.94, top5 92.94
2021-11-06 09:05:25 train 1000, loss 1.197e+00, top1 71.49, top5 88.90
2021-11-06 09:05:25 train 1000, loss 1.208e+00, top1 71.21, top5 88.78
2021-11-06 09:05:25 train 1000, loss 1.205e+00, top1 71.42, top5 88.89
2021-11-06 09:13:51 train 2000, loss 1.197e+00, top1 71.58, top5 88.86
2021-11-06 09:13:51 train 2000, loss 1.204e+00, top1 71.30, top5 88.82
2021-11-06 09:13:51 train 2000, loss 1.207e+00, top1 71.33, top5 88.83
2021-11-06 09:22:21 train 3000, loss 1.202e+00, top1 71.33, top5 88.82
2021-11-06 09:22:21 train 3000, loss 1.202e+00, top1 71.37, top5 88.80
2021-11-06 09:22:21 train 3000, loss 1.203e+00, top1 71.47, top5 88.87
2021-11-06 09:30:53 train 4000, loss 1.201e+00, top1 71.38, top5 88.83
2021-11-06 09:30:53 train 4000, loss 1.202e+00, top1 71.42, top5 88.87
2021-11-06 09:30:53 train 4000, loss 1.200e+00, top1 71.40, top5 88.88
2021-11-06 09:39:22 train 5000, loss 1.202e+00, top1 71.34, top5 88.84
2021-11-06 09:39:22 train 5000, loss 1.202e+00, top1 71.38, top5 88.88
2021-11-06 09:39:22 train 5000, loss 1.203e+00, top1 71.39, top5 88.85
2021-11-06 09:39:44 valid 0000, loss 4.840e-01, top1 89.41, top5 98.82
2021-11-06 09:39:44 valid 0000, loss 4.840e-01, top1 89.41, top5 98.82
2021-11-06 09:39:44 valid 0000, loss 4.840e-01, top1 89.41, top5 98.82
2021-11-06 09:44:17 (JOBID 31682) epoch 69: train time 2572.41, inference time 282.92s, valid_top1 73.18 (best_top1 73.20), valid_top5 91.43
2021-11-06 09:44:19 (JOBID 31682) epoch 69: train time 2572.91, inference time 284.14s, valid_top1 73.18 (best_top1 73.20), valid_top5 91.43
2021-11-06 09:44:19 (JOBID 31682) epoch 69: train time 2583.17, inference time 283.94s, valid_top1 73.18 (best_top1 73.20), valid_top5 91.43
2021-11-06 09:44:32 train 0000, loss 9.848e-01, top1 74.12, top5 91.76
2021-11-06 09:44:32 train 0000, loss 1.245e+00, top1 70.59, top5 87.06
2021-11-06 09:44:32 train 0000, loss 1.096e+00, top1 72.94, top5 91.76
2021-11-06 09:53:10 train 1000, loss 1.193e+00, top1 71.71, top5 89.06
2021-11-06 09:53:10 train 1000, loss 1.196e+00, top1 71.41, top5 89.03
2021-11-06 09:53:10 train 1000, loss 1.195e+00, top1 71.73, top5 88.96
2021-11-06 10:01:45 train 2000, loss 1.193e+00, top1 71.47, top5 89.06
2021-11-06 10:01:45 train 2000, loss 1.194e+00, top1 71.62, top5 89.03
2021-11-06 10:01:45 train 2000, loss 1.199e+00, top1 71.66, top5 88.90
2021-11-06 10:10:18 train 3000, loss 1.194e+00, top1 71.63, top5 88.99
2021-11-06 10:10:18 train 3000, loss 1.193e+00, top1 71.52, top5 89.02
2021-11-06 10:10:18 train 3000, loss 1.196e+00, top1 71.68, top5 88.93
2021-11-06 10:18:56 train 4000, loss 1.192e+00, top1 71.61, top5 89.00
2021-11-06 10:18:56 train 4000, loss 1.194e+00, top1 71.56, top5 88.98
2021-11-06 10:18:56 train 4000, loss 1.198e+00, top1 71.62, top5 88.90
2021-11-06 10:27:38 train 5000, loss 1.196e+00, top1 71.48, top5 88.97
2021-11-06 10:27:38 train 5000, loss 1.196e+00, top1 71.54, top5 88.93
2021-11-06 10:27:38 train 5000, loss 1.199e+00, top1 71.56, top5 88.88
2021-11-06 10:28:01 valid 0000, loss 4.808e-01, top1 89.41, top5 97.65
2021-11-06 10:28:01 valid 0000, loss 4.808e-01, top1 89.41, top5 97.65
2021-11-06 10:28:01 valid 0000, loss 4.808e-01, top1 89.41, top5 97.65
2021-11-06 10:32:24 (JOBID 31682) epoch 70: train time 2613.26, inference time 273.05s, valid_top1 73.37 (best_top1 73.37), valid_top5 91.45
2021-11-06 10:32:31 (JOBID 31682) epoch 70: train time 2612.07, inference time 279.87s, valid_top1 73.37 (best_top1 73.37), valid_top5 91.45
2021-11-06 10:32:32 (JOBID 31682) epoch 70: train time 2612.12, inference time 281.48s, valid_top1 73.37 (best_top1 73.37), valid_top5 91.45
2021-11-06 10:32:38 train 0000, loss 9.820e-01, top1 76.47, top5 95.29
2021-11-06 10:32:45 train 0000, loss 1.019e+00, top1 81.18, top5 90.59
2021-11-06 10:32:45 train 0000, loss 1.046e+00, top1 72.94, top5 90.59
2021-11-06 10:41:22 train 1000, loss 1.186e+00, top1 71.67, top5 89.05
2021-11-06 10:41:22 train 1000, loss 1.199e+00, top1 71.42, top5 88.86
2021-11-06 10:41:23 train 1000, loss 1.188e+00, top1 71.84, top5 88.85
2021-11-06 10:49:59 train 2000, loss 1.185e+00, top1 71.78, top5 89.02
2021-11-06 10:49:58 train 2000, loss 1.195e+00, top1 71.51, top5 88.94
2021-11-06 10:49:59 train 2000, loss 1.190e+00, top1 71.66, top5 88.96
2021-11-06 10:58:36 train 3000, loss 1.198e+00, top1 71.44, top5 88.88
2021-11-06 10:58:36 train 3000, loss 1.190e+00, top1 71.72, top5 88.95
2021-11-06 10:58:36 train 3000, loss 1.189e+00, top1 71.68, top5 88.98
2021-11-06 11:07:15 train 4000, loss 1.189e+00, top1 71.73, top5 89.00
2021-11-06 11:07:15 train 4000, loss 1.196e+00, top1 71.47, top5 88.92
2021-11-06 11:07:15 train 4000, loss 1.191e+00, top1 71.66, top5 88.95
2021-11-06 11:15:55 train 5000, loss 1.191e+00, top1 71.68, top5 88.98
2021-11-06 11:15:55 train 5000, loss 1.197e+00, top1 71.50, top5 88.92
2021-11-06 11:15:55 train 5000, loss 1.191e+00, top1 71.68, top5 88.98
2021-11-06 11:16:18 valid 0000, loss 4.689e-01, top1 90.59, top5 97.65
2021-11-06 11:16:18 valid 0000, loss 4.689e-01, top1 90.59, top5 97.65
2021-11-06 11:16:18 valid 0000, loss 4.689e-01, top1 90.59, top5 97.65
2021-11-06 11:20:35 (JOBID 31682) epoch 71: train time 2616.98, inference time 266.79s, valid_top1 73.35 (best_top1 73.37), valid_top5 91.41
2021-11-06 11:20:51 (JOBID 31682) epoch 71: train time 2615.73, inference time 282.74s, valid_top1 73.35 (best_top1 73.37), valid_top5 91.41
2021-11-06 11:20:52 (JOBID 31682) epoch 71: train time 2624.25, inference time 283.45s, valid_top1 73.35 (best_top1 73.37), valid_top5 91.41
2021-11-06 11:20:49 train 0000, loss 8.723e-01, top1 76.47, top5 95.29
2021-11-06 11:21:04 train 0000, loss 1.233e+00, top1 69.41, top5 87.06
2021-11-06 11:21:04 train 0000, loss 1.233e+00, top1 69.41, top5 89.41
2021-11-06 11:29:35 train 1000, loss 1.192e+00, top1 71.56, top5 88.95
2021-11-06 11:29:35 train 1000, loss 1.190e+00, top1 71.77, top5 89.03
2021-11-06 11:29:35 train 1000, loss 1.172e+00, top1 72.19, top5 89.13
2021-11-06 11:38:09 train 2000, loss 1.186e+00, top1 71.73, top5 89.13
2021-11-06 11:38:10 train 2000, loss 1.190e+00, top1 71.70, top5 89.04
2021-11-06 11:38:10 train 2000, loss 1.184e+00, top1 71.86, top5 89.05
2021-11-06 11:46:52 train 3000, loss 1.191e+00, top1 71.60, top5 89.01
2021-11-06 11:46:52 train 3000, loss 1.189e+00, top1 71.70, top5 89.06
2021-11-06 11:46:52 train 3000, loss 1.187e+00, top1 71.78, top5 89.02
2021-11-06 11:55:36 train 4000, loss 1.190e+00, top1 71.65, top5 89.05
2021-11-06 11:55:36 train 4000, loss 1.194e+00, top1 71.56, top5 88.94
2021-11-06 11:55:36 train 4000, loss 1.190e+00, top1 71.69, top5 88.99
2021-11-06 12:04:26 train 5000, loss 1.191e+00, top1 71.64, top5 89.04
2021-11-06 12:04:26 train 5000, loss 1.193e+00, top1 71.58, top5 88.99
2021-11-06 12:04:26 train 5000, loss 1.190e+00, top1 71.69, top5 88.99
2021-11-06 12:04:49 valid 0000, loss 4.542e-01, top1 89.41, top5 98.82
2021-11-06 12:04:49 valid 0000, loss 4.542e-01, top1 89.41, top5 98.82
2021-11-06 12:04:49 valid 0000, loss 4.542e-01, top1 89.41, top5 98.82
2021-11-06 12:09:16 (JOBID 31682) epoch 72: train time 2627.68, inference time 276.98s, valid_top1 73.28 (best_top1 73.37), valid_top5 91.51
2021-11-06 12:09:22 (JOBID 31682) epoch 72: train time 2628.20, inference time 282.83s, valid_top1 73.28 (best_top1 73.37), valid_top5 91.51
2021-11-06 12:09:22 (JOBID 31682) epoch 72: train time 2643.98, inference time 282.74s, valid_top1 73.28 (best_top1 73.37), valid_top5 91.51
2021-11-06 12:09:35 train 0000, loss 1.115e+00, top1 75.29, top5 88.24
2021-11-06 12:09:30 train 0000, loss 1.374e+00, top1 70.59, top5 84.71
2021-11-06 12:09:35 train 0000, loss 1.053e+00, top1 77.65, top5 89.41
2021-11-06 12:18:20 train 1000, loss 1.176e+00, top1 72.11, top5 89.30
2021-11-06 12:18:20 train 1000, loss 1.176e+00, top1 71.93, top5 89.15
2021-11-06 12:18:20 train 1000, loss 1.189e+00, top1 71.73, top5 89.03
2021-11-06 12:27:06 train 2000, loss 1.181e+00, top1 71.89, top5 89.16
2021-11-06 12:27:06 train 2000, loss 1.186e+00, top1 71.81, top5 89.06
2021-11-06 12:27:06 train 2000, loss 1.181e+00, top1 71.97, top5 89.06
2021-11-06 12:35:52 train 3000, loss 1.184e+00, top1 71.78, top5 89.10
2021-11-06 12:35:52 train 3000, loss 1.184e+00, top1 71.86, top5 89.05
2021-11-06 12:35:52 train 3000, loss 1.186e+00, top1 71.76, top5 89.07
2021-11-06 12:44:39 train 4000, loss 1.184e+00, top1 71.81, top5 89.06
2021-11-06 12:44:39 train 4000, loss 1.185e+00, top1 71.77, top5 89.07
2021-11-06 12:44:39 train 4000, loss 1.186e+00, top1 71.71, top5 89.06
2021-11-06 12:53:29 train 5000, loss 1.187e+00, top1 71.74, top5 89.03
2021-11-06 12:53:29 train 5000, loss 1.186e+00, top1 71.74, top5 89.04
2021-11-06 12:53:30 train 5000, loss 1.189e+00, top1 71.67, top5 89.03
2021-11-06 12:53:53 valid 0000, loss 4.190e-01, top1 90.59, top5 98.82
2021-11-06 12:53:53 valid 0000, loss 4.190e-01, top1 90.59, top5 98.82
2021-11-06 12:53:53 valid 0000, loss 4.190e-01, top1 90.59, top5 98.82
2021-11-06 12:58:28 (JOBID 31682) epoch 73: train time 2666.63, inference time 284.82s, valid_top1 73.23 (best_top1 73.37), valid_top5 91.50
2021-11-06 12:58:28 (JOBID 31682) epoch 73: train time 2660.99, inference time 284.88s, valid_top1 73.23 (best_top1 73.37), valid_top5 91.50
2021-11-06 12:58:28 (JOBID 31682) epoch 73: train time 2660.91, inference time 284.88s, valid_top1 73.23 (best_top1 73.37), valid_top5 91.50
2021-11-06 12:58:42 train 0000, loss 1.624e+00, top1 64.71, top5 81.18
2021-11-06 12:58:42 train 0000, loss 1.087e+00, top1 76.47, top5 90.59
2021-11-06 12:58:42 train 0000, loss 1.380e+00, top1 67.06, top5 87.06
2021-11-06 13:07:41 train 1000, loss 1.183e+00, top1 72.01, top5 89.03
2021-11-06 13:07:41 train 1000, loss 1.168e+00, top1 72.10, top5 89.29
2021-11-06 13:07:41 train 1000, loss 1.179e+00, top1 71.92, top5 89.19
2021-11-06 13:16:17 train 2000, loss 1.178e+00, top1 71.92, top5 89.15
2021-11-06 13:16:17 train 2000, loss 1.186e+00, top1 71.86, top5 88.98
2021-11-06 13:16:17 train 2000, loss 1.181e+00, top1 71.92, top5 89.16
2021-11-06 13:24:53 train 3000, loss 1.181e+00, top1 71.84, top5 89.09
2021-11-06 13:24:53 train 3000, loss 1.185e+00, top1 71.82, top5 89.06
2021-11-06 13:24:53 train 3000, loss 1.183e+00, top1 71.85, top5 89.14
2021-11-06 13:33:28 train 4000, loss 1.182e+00, top1 71.85, top5 89.09
2021-11-06 13:33:28 train 4000, loss 1.184e+00, top1 71.83, top5 89.08
2021-11-06 13:33:28 train 4000, loss 1.181e+00, top1 71.86, top5 89.16
2021-11-06 13:42:10 train 5000, loss 1.183e+00, top1 71.85, top5 89.07
2021-11-06 13:42:10 train 5000, loss 1.186e+00, top1 71.78, top5 89.08
2021-11-06 13:42:10 train 5000, loss 1.179e+00, top1 71.87, top5 89.17
2021-11-06 13:42:32 valid 0000, loss 4.835e-01, top1 89.41, top5 97.65
2021-11-06 13:42:32 valid 0000, loss 4.835e-01, top1 89.41, top5 97.65
2021-11-06 13:42:32 valid 0000, loss 4.835e-01, top1 89.41, top5 97.65
2021-11-06 13:46:48 (JOBID 31682) epoch 74: train time 2634.77, inference time 264.43s, valid_top1 73.45 (best_top1 73.45), valid_top5 91.50
2021-11-06 13:47:00 (JOBID 31682) epoch 74: train time 2634.95, inference time 277.51s, valid_top1 73.45 (best_top1 73.45), valid_top5 91.50
2021-11-06 13:47:02 (JOBID 31682) epoch 74: train time 2635.13, inference time 279.18s, valid_top1 73.45 (best_top1 73.45), valid_top5 91.50
2021-11-06 13:47:14 train 0000, loss 1.156e+00, top1 75.29, top5 87.06
2021-11-06 13:47:01 train 0000, loss 1.278e+00, top1 67.06, top5 84.71
2021-11-06 13:47:16 train 0000, loss 1.388e+00, top1 65.88, top5 87.06
2021-11-06 13:56:03 train 1000, loss 1.172e+00, top1 72.08, top5 89.18
2021-11-06 13:56:02 train 1000, loss 1.184e+00, top1 71.91, top5 89.11
2021-11-06 13:56:03 train 1000, loss 1.166e+00, top1 72.11, top5 89.32
2021-11-06 14:04:43 train 2000, loss 1.176e+00, top1 72.02, top5 89.22
2021-11-06 14:04:43 train 2000, loss 1.175e+00, top1 71.98, top5 89.18
2021-11-06 14:04:43 train 2000, loss 1.170e+00, top1 72.01, top5 89.24
2021-11-06 14:13:26 train 3000, loss 1.175e+00, top1 71.99, top5 89.19
2021-11-06 14:13:26 train 3000, loss 1.176e+00, top1 72.00, top5 89.22
2021-11-06 14:13:26 train 3000, loss 1.173e+00, top1 72.01, top5 89.17
2021-11-06 14:22:18 train 4000, loss 1.178e+00, top1 71.94, top5 89.14
2021-11-06 14:22:18 train 4000, loss 1.177e+00, top1 72.01, top5 89.19
2021-11-06 14:22:18 train 4000, loss 1.175e+00, top1 71.94, top5 89.17
2021-11-06 14:31:03 train 5000, loss 1.180e+00, top1 71.94, top5 89.14
2021-11-06 14:31:03 train 5000, loss 1.180e+00, top1 71.89, top5 89.13
2021-11-06 14:31:03 train 5000, loss 1.176e+00, top1 71.94, top5 89.18
2021-11-06 14:31:26 valid 0000, loss 4.338e-01, top1 91.76, top5 97.65
2021-11-06 14:31:26 valid 0000, loss 4.338e-01, top1 91.76, top5 97.65
2021-11-06 14:31:26 valid 0000, loss 4.338e-01, top1 91.76, top5 97.65
2021-11-06 14:35:40 (JOBID 31682) epoch 75: train time 2654.06, inference time 263.99s, valid_top1 73.54 (best_top1 73.54), valid_top5 91.61
2021-11-06 14:35:58 (JOBID 31682) epoch 75: train time 2655.90, inference time 282.36s, valid_top1 73.54 (best_top1 73.54), valid_top5 91.61
2021-11-06 14:35:59 (JOBID 31682) epoch 75: train time 2668.45, inference time 282.31s, valid_top1 73.54 (best_top1 73.54), valid_top5 91.61
2021-11-06 14:35:54 train 0000, loss 1.224e+00, top1 69.41, top5 88.24
2021-11-06 14:36:12 train 0000, loss 1.415e+00, top1 72.94, top5 89.41
2021-11-06 14:36:12 train 0000, loss 1.220e+00, top1 71.76, top5 87.06
2021-11-06 14:44:53 train 1000, loss 1.176e+00, top1 72.13, top5 89.14
2021-11-06 14:44:53 train 1000, loss 1.168e+00, top1 72.05, top5 89.25
2021-11-06 14:44:53 train 1000, loss 1.169e+00, top1 72.16, top5 89.27
2021-11-06 14:53:31 train 2000, loss 1.173e+00, top1 72.12, top5 89.21
2021-11-06 14:53:31 train 2000, loss 1.171e+00, top1 71.93, top5 89.24
2021-11-06 14:53:31 train 2000, loss 1.176e+00, top1 72.09, top5 89.19
2021-11-06 15:02:08 train 3000, loss 1.170e+00, top1 72.00, top5 89.27
2021-11-06 15:02:08 train 3000, loss 1.173e+00, top1 72.07, top5 89.22
2021-11-06 15:02:08 train 3000, loss 1.177e+00, top1 71.96, top5 89.21
2021-11-06 15:10:56 train 4000, loss 1.173e+00, top1 72.08, top5 89.22
2021-11-06 15:10:56 train 4000, loss 1.175e+00, top1 71.92, top5 89.20
2021-11-06 15:10:57 train 4000, loss 1.179e+00, top1 71.92, top5 89.18
2021-11-06 15:19:41 train 5000, loss 1.177e+00, top1 71.89, top5 89.18
2021-11-06 15:19:41 train 5000, loss 1.172e+00, top1 72.08, top5 89.25
2021-11-06 15:19:41 train 5000, loss 1.179e+00, top1 71.92, top5 89.17
2021-11-06 15:20:04 valid 0000, loss 4.808e-01, top1 89.41, top5 97.65
2021-11-06 15:20:04 valid 0000, loss 4.808e-01, top1 89.41, top5 97.65
2021-11-06 15:20:04 valid 0000, loss 4.808e-01, top1 89.41, top5 97.65
2021-11-06 15:24:36 (JOBID 31682) epoch 76: train time 2653.98, inference time 282.46s, valid_top1 73.47 (best_top1 73.54), valid_top5 91.58
2021-11-06 15:24:38 (JOBID 31682) epoch 76: train time 2635.63, inference time 283.70s, valid_top1 73.47 (best_top1 73.54), valid_top5 91.58
2021-11-06 15:24:39 (JOBID 31682) epoch 76: train time 2635.18, inference time 284.88s, valid_top1 73.47 (best_top1 73.54), valid_top5 91.58
2021-11-06 15:24:52 train 0000, loss 1.171e+00, top1 71.76, top5 89.41
2021-11-06 15:24:51 train 0000, loss 9.701e-01, top1 74.12, top5 89.41
2021-11-06 15:24:53 train 0000, loss 1.200e+00, top1 67.06, top5 87.06
2021-11-06 15:33:33 train 1000, loss 1.158e+00, top1 72.38, top5 89.48
2021-11-06 15:33:33 train 1000, loss 1.168e+00, top1 72.35, top5 89.28
2021-11-06 15:33:33 train 1000, loss 1.172e+00, top1 72.02, top5 89.15
2021-11-06 15:42:19 train 2000, loss 1.169e+00, top1 72.23, top5 89.24
2021-11-06 15:42:19 train 2000, loss 1.162e+00, top1 72.29, top5 89.40
2021-11-06 15:42:19 train 2000, loss 1.173e+00, top1 72.04, top5 89.16
2021-11-06 15:50:58 train 3000, loss 1.170e+00, top1 72.21, top5 89.26
2021-11-06 15:50:58 train 3000, loss 1.164e+00, top1 72.23, top5 89.36
2021-11-06 15:50:58 train 3000, loss 1.173e+00, top1 72.08, top5 89.19
2021-11-06 15:59:34 train 4000, loss 1.173e+00, top1 72.12, top5 89.20
2021-11-06 15:59:34 train 4000, loss 1.169e+00, top1 72.10, top5 89.27
2021-11-06 15:59:34 train 4000, loss 1.175e+00, top1 72.00, top5 89.16
2021-11-06 16:08:04 train 5000, loss 1.175e+00, top1 72.06, top5 89.19
2021-11-06 16:08:04 train 5000, loss 1.171e+00, top1 72.06, top5 89.25
2021-11-06 16:08:04 train 5000, loss 1.176e+00, top1 71.95, top5 89.15
2021-11-06 16:08:27 valid 0000, loss 4.486e-01, top1 90.59, top5 97.65
2021-11-06 16:08:27 valid 0000, loss 4.486e-01, top1 90.59, top5 97.65
2021-11-06 16:08:27 valid 0000, loss 4.486e-01, top1 90.59, top5 97.65
2021-11-06 16:12:57 (JOBID 31682) epoch 77: train time 2617.39, inference time 280.45s, valid_top1 73.36 (best_top1 73.54), valid_top5 91.63
2021-11-06 16:12:58 (JOBID 31682) epoch 77: train time 2619.94, inference time 281.24s, valid_top1 73.36 (best_top1 73.54), valid_top5 91.63
2021-11-06 16:12:58 (JOBID 31682) epoch 77: train time 2618.68, inference time 281.26s, valid_top1 73.36 (best_top1 73.54), valid_top5 91.63
2021-11-06 16:13:12 train 0000, loss 1.576e+00, top1 60.00, top5 84.71
2021-11-06 16:13:12 train 0000, loss 1.179e+00, top1 74.12, top5 87.06
2021-11-06 16:13:12 train 0000, loss 1.236e+00, top1 64.71, top5 87.06
2021-11-06 16:21:47 train 1000, loss 1.167e+00, top1 72.15, top5 89.29
2021-11-06 16:21:47 train 1000, loss 1.173e+00, top1 72.06, top5 89.13
2021-11-06 16:21:47 train 1000, loss 1.170e+00, top1 72.22, top5 89.26
2021-11-06 16:30:22 train 2000, loss 1.171e+00, top1 71.98, top5 89.28
2021-11-06 16:30:22 train 2000, loss 1.174e+00, top1 72.00, top5 89.21
2021-11-06 16:30:22 train 2000, loss 1.169e+00, top1 72.14, top5 89.26
2021-11-06 16:38:56 train 3000, loss 1.175e+00, top1 71.99, top5 89.16
2021-11-06 16:38:56 train 3000, loss 1.168e+00, top1 72.02, top5 89.32
2021-11-06 16:38:56 train 3000, loss 1.172e+00, top1 72.12, top5 89.20
2021-11-06 16:47:35 train 4000, loss 1.169e+00, top1 72.04, top5 89.31
2021-11-06 16:47:35 train 4000, loss 1.173e+00, top1 72.01, top5 89.20
2021-11-06 16:47:35 train 4000, loss 1.171e+00, top1 72.14, top5 89.22
2021-11-06 16:56:14 train 5000, loss 1.174e+00, top1 72.00, top5 89.19
2021-11-06 16:56:14 train 5000, loss 1.171e+00, top1 72.02, top5 89.26
2021-11-06 16:56:14 train 5000, loss 1.172e+00, top1 72.12, top5 89.20
2021-11-06 16:56:37 valid 0000, loss 4.897e-01, top1 87.06, top5 96.47
2021-11-06 16:56:37 valid 0000, loss 4.897e-01, top1 87.06, top5 96.47
2021-11-06 16:56:37 valid 0000, loss 4.897e-01, top1 87.06, top5 96.47
2021-11-06 17:01:11 (JOBID 31682) epoch 78: train time 2609.25, inference time 284.35s, valid_top1 73.20 (best_top1 73.54), valid_top5 91.55
2021-11-06 17:01:12 (JOBID 31682) epoch 78: train time 2608.74, inference time 285.76s, valid_top1 73.20 (best_top1 73.54), valid_top5 91.55
2021-11-06 17:01:13 (JOBID 31682) epoch 78: train time 2608.78, inference time 286.67s, valid_top1 73.20 (best_top1 73.54), valid_top5 91.55
2021-11-06 17:01:26 train 0000, loss 1.265e+00, top1 71.76, top5 88.24
2021-11-06 17:01:27 train 0000, loss 1.272e+00, top1 71.76, top5 85.88
2021-11-06 17:01:27 train 0000, loss 1.047e+00, top1 67.06, top5 94.12
2021-11-06 17:09:54 train 1000, loss 1.172e+00, top1 71.71, top5 89.27
2021-11-06 17:09:54 train 1000, loss 1.160e+00, top1 72.28, top5 89.37
2021-11-06 17:09:54 train 1000, loss 1.168e+00, top1 72.31, top5 89.28
2021-11-06 17:18:22 train 2000, loss 1.164e+00, top1 72.17, top5 89.29
2021-11-06 17:18:22 train 2000, loss 1.165e+00, top1 72.08, top5 89.32
2021-11-06 17:18:22 train 2000, loss 1.167e+00, top1 72.20, top5 89.31
2021-11-06 17:26:51 train 3000, loss 1.165e+00, top1 72.16, top5 89.25
2021-11-06 17:26:51 train 3000, loss 1.168e+00, top1 72.03, top5 89.30
2021-11-06 17:26:51 train 3000, loss 1.170e+00, top1 72.20, top5 89.28
2021-11-06 17:35:19 train 4000, loss 1.169e+00, top1 72.01, top5 89.30
2021-11-06 17:35:19 train 4000, loss 1.166e+00, top1 72.19, top5 89.26
2021-11-06 17:35:19 train 4000, loss 1.168e+00, top1 72.22, top5 89.32
2021-11-06 17:43:51 train 5000, loss 1.172e+00, top1 71.96, top5 89.24
2021-11-06 17:43:51 train 5000, loss 1.167e+00, top1 72.18, top5 89.28
2021-11-06 17:43:51 train 5000, loss 1.168e+00, top1 72.22, top5 89.29
2021-11-06 17:44:14 valid 0000, loss 4.407e-01, top1 90.59, top5 98.82
2021-11-06 17:44:14 valid 0000, loss 4.407e-01, top1 90.59, top5 98.82
2021-11-06 17:44:14 valid 0000, loss 4.407e-01, top1 90.59, top5 98.82
2021-11-06 17:48:43 (JOBID 31682) epoch 79: train time 2571.78, inference time 278.61s, valid_top1 73.46 (best_top1 73.54), valid_top5 91.56
2021-11-06 17:48:43 (JOBID 31682) epoch 79: train time 2572.97, inference time 278.52s, valid_top1 73.46 (best_top1 73.54), valid_top5 91.56
2021-11-06 17:48:43 (JOBID 31682) epoch 79: train time 2570.92, inference time 279.01s, valid_top1 73.46 (best_top1 73.54), valid_top5 91.56
2021-11-06 17:48:57 train 0000, loss 1.041e+00, top1 72.94, top5 91.76
2021-11-06 17:48:57 train 0000, loss 1.241e+00, top1 69.41, top5 83.53
2021-11-06 17:48:57 train 0000, loss 1.146e+00, top1 74.12, top5 90.59
2021-11-06 17:57:45 train 1000, loss 1.159e+00, top1 72.41, top5 89.48
2021-11-06 17:57:45 train 1000, loss 1.169e+00, top1 71.96, top5 89.29
2021-11-06 17:57:45 train 1000, loss 1.161e+00, top1 72.11, top5 89.37
2021-11-06 18:06:33 train 2000, loss 1.163e+00, top1 72.32, top5 89.38
2021-11-06 18:06:33 train 2000, loss 1.162e+00, top1 72.12, top5 89.35
2021-11-06 18:06:33 train 2000, loss 1.158e+00, top1 72.22, top5 89.41
2021-11-06 18:15:18 train 3000, loss 1.162e+00, top1 72.30, top5 89.35
2021-11-06 18:15:18 train 3000, loss 1.162e+00, top1 72.21, top5 89.36
2021-11-06 18:15:18 train 3000, loss 1.161e+00, top1 72.17, top5 89.35
2021-11-06 18:24:05 train 4000, loss 1.165e+00, top1 72.15, top5 89.31
2021-11-06 18:24:05 train 4000, loss 1.163e+00, top1 72.26, top5 89.34
2021-11-06 18:24:05 train 4000, loss 1.165e+00, top1 72.17, top5 89.32
2021-11-06 18:32:49 train 5000, loss 1.165e+00, top1 72.23, top5 89.33
2021-11-06 18:32:49 train 5000, loss 1.167e+00, top1 72.13, top5 89.29
2021-11-06 18:32:49 train 5000, loss 1.165e+00, top1 72.18, top5 89.32
2021-11-06 18:33:12 valid 0000, loss 4.937e-01, top1 89.41, top5 95.29
2021-11-06 18:33:12 valid 0000, loss 4.937e-01, top1 89.41, top5 95.29
2021-11-06 18:33:12 valid 0000, loss 4.937e-01, top1 89.41, top5 95.29
2021-11-06 18:37:42 (JOBID 31682) epoch 80: train time 2659.67, inference time 279.57s, valid_top1 73.59 (best_top1 73.59), valid_top5 91.66
2021-11-06 18:37:43 (JOBID 31682) epoch 80: train time 2659.80, inference time 281.06s, valid_top1 73.59 (best_top1 73.59), valid_top5 91.66
2021-11-06 18:37:47 (JOBID 31682) epoch 80: train time 2659.56, inference time 284.81s, valid_top1 73.59 (best_top1 73.59), valid_top5 91.66
2021-11-06 18:37:56 train 0000, loss 9.357e-01, top1 80.00, top5 92.94
2021-11-06 18:37:56 train 0000, loss 1.129e+00, top1 68.24, top5 91.76
2021-11-06 18:38:02 train 0000, loss 1.227e+00, top1 74.12, top5 85.88
2021-11-06 18:46:32 train 1000, loss 1.161e+00, top1 72.29, top5 89.43
2021-11-06 18:46:32 train 1000, loss 1.162e+00, top1 72.22, top5 89.38
2021-11-06 18:46:32 train 1000, loss 1.147e+00, top1 72.59, top5 89.54
2021-11-06 18:55:01 train 2000, loss 1.162e+00, top1 72.25, top5 89.38
2021-11-06 18:55:01 train 2000, loss 1.158e+00, top1 72.36, top5 89.40
2021-11-06 18:55:01 train 2000, loss 1.146e+00, top1 72.53, top5 89.60
2021-11-06 19:03:31 train 3000, loss 1.165e+00, top1 72.14, top5 89.35
2021-11-06 19:03:31 train 3000, loss 1.160e+00, top1 72.29, top5 89.36
2021-11-06 19:03:31 train 3000, loss 1.153e+00, top1 72.46, top5 89.52
2021-11-06 19:11:59 train 4000, loss 1.164e+00, top1 72.24, top5 89.29
2021-11-06 19:11:59 train 4000, loss 1.165e+00, top1 72.15, top5 89.36
2021-11-06 19:11:59 train 4000, loss 1.155e+00, top1 72.40, top5 89.47
2021-11-06 19:20:30 train 5000, loss 1.164e+00, top1 72.23, top5 89.30
2021-11-06 19:20:30 train 5000, loss 1.165e+00, top1 72.16, top5 89.35
2021-11-06 19:20:30 train 5000, loss 1.157e+00, top1 72.34, top5 89.46
2021-11-06 19:20:53 valid 0000, loss 5.113e-01, top1 89.41, top5 96.47
2021-11-06 19:20:53 valid 0000, loss 5.113e-01, top1 89.41, top5 96.47
2021-11-06 19:20:53 valid 0000, loss 5.113e-01, top1 89.41, top5 96.47
2021-11-06 19:25:16 (JOBID 31682) epoch 81: train time 2575.62, inference time 272.93s, valid_top1 73.46 (best_top1 73.59), valid_top5 91.50
2021-11-06 19:25:25 (JOBID 31682) epoch 81: train time 2579.45, inference time 282.56s, valid_top1 73.46 (best_top1 73.59), valid_top5 91.50
2021-11-06 19:25:27 (JOBID 31682) epoch 81: train time 2580.47, inference time 283.64s, valid_top1 73.46 (best_top1 73.59), valid_top5 91.50
2021-11-06 19:25:30 train 0000, loss 1.123e+00, top1 74.12, top5 89.41
2021-11-06 19:25:40 train 0000, loss 9.637e-01, top1 76.47, top5 92.94
2021-11-06 19:25:40 train 0000, loss 8.370e-01, top1 77.65, top5 91.76
2021-11-06 19:34:15 train 1000, loss 1.154e+00, top1 72.57, top5 89.48
2021-11-06 19:34:15 train 1000, loss 1.153e+00, top1 72.39, top5 89.56
2021-11-06 19:34:15 train 1000, loss 1.152e+00, top1 72.48, top5 89.44
2021-11-06 19:42:49 train 2000, loss 1.151e+00, top1 72.61, top5 89.49
2021-11-06 19:42:49 train 2000, loss 1.153e+00, top1 72.46, top5 89.48
2021-11-06 19:42:49 train 2000, loss 1.151e+00, top1 72.39, top5 89.46
2021-11-06 19:51:26 train 3000, loss 1.158e+00, top1 72.40, top5 89.43
2021-11-06 19:51:26 train 3000, loss 1.152e+00, top1 72.51, top5 89.47
2021-11-06 19:51:26 train 3000, loss 1.152e+00, top1 72.47, top5 89.48
2021-11-06 20:00:01 train 4000, loss 1.156e+00, top1 72.39, top5 89.44
2021-11-06 20:00:01 train 4000, loss 1.158e+00, top1 72.32, top5 89.42
2021-11-06 20:00:01 train 4000, loss 1.155e+00, top1 72.41, top5 89.43
2021-11-06 20:08:42 train 5000, loss 1.160e+00, top1 72.28, top5 89.40
2021-11-06 20:08:42 train 5000, loss 1.160e+00, top1 72.29, top5 89.39
2021-11-06 20:08:42 train 5000, loss 1.159e+00, top1 72.34, top5 89.36
2021-11-06 20:09:05 valid 0000, loss 4.192e-01, top1 89.41, top5 97.65
2021-11-06 20:09:05 valid 0000, loss 4.192e-01, top1 89.41, top5 97.65
2021-11-06 20:09:05 valid 0000, loss 4.192e-01, top1 89.41, top5 97.65
2021-11-06 20:13:31 (JOBID 31682) epoch 82: train time 2618.71, inference time 276.44s, valid_top1 73.42 (best_top1 73.59), valid_top5 91.58
2021-11-06 20:13:33 (JOBID 31682) epoch 82: train time 2609.26, inference time 278.78s, valid_top1 73.42 (best_top1 73.59), valid_top5 91.58
2021-11-06 20:13:34 (JOBID 31682) epoch 82: train time 2607.95, inference time 279.14s, valid_top1 73.42 (best_top1 73.59), valid_top5 91.58
2021-11-06 20:13:47 train 0000, loss 1.488e+00, top1 68.24, top5 85.88
2021-11-06 20:13:47 train 0000, loss 1.021e+00, top1 75.29, top5 85.88
2021-11-06 20:13:47 train 0000, loss 1.347e+00, top1 71.76, top5 89.41
2021-11-06 20:22:16 train 1000, loss 1.149e+00, top1 72.62, top5 89.50
2021-11-06 20:22:16 train 1000, loss 1.153e+00, top1 72.61, top5 89.52
2021-11-06 20:22:16 train 1000, loss 1.151e+00, top1 72.51, top5 89.63
2021-11-06 20:30:45 train 2000, loss 1.151e+00, top1 72.55, top5 89.45
2021-11-06 20:30:45 train 2000, loss 1.157e+00, top1 72.44, top5 89.41
2021-11-06 20:30:45 train 2000, loss 1.158e+00, top1 72.34, top5 89.47
2021-11-06 20:40:42 train 3000, loss 1.152e+00, top1 72.53, top5 89.46
2021-11-06 20:40:42 train 3000, loss 1.160e+00, top1 72.33, top5 89.35
2021-11-06 20:40:42 train 3000, loss 1.158e+00, top1 72.30, top5 89.40
2021-11-06 20:49:52 train 4000, loss 1.153e+00, top1 72.47, top5 89.46
2021-11-06 20:49:52 train 4000, loss 1.159e+00, top1 72.37, top5 89.38
2021-11-06 20:49:52 train 4000, loss 1.158e+00, top1 72.33, top5 89.42
2021-11-06 20:58:29 train 5000, loss 1.155e+00, top1 72.41, top5 89.48
2021-11-06 20:58:29 train 5000, loss 1.161e+00, top1 72.34, top5 89.35
2021-11-06 20:58:29 train 5000, loss 1.160e+00, top1 72.29, top5 89.40
2021-11-06 20:58:52 valid 0000, loss 4.292e-01, top1 88.24, top5 98.82
2021-11-06 20:58:52 valid 0000, loss 4.292e-01, top1 88.24, top5 98.82
2021-11-06 20:58:52 valid 0000, loss 4.292e-01, top1 88.24, top5 98.82
2021-11-06 21:03:27 (JOBID 31682) epoch 83: train time 2710.51, inference time 285.76s, valid_top1 73.51 (best_top1 73.59), valid_top5 91.67
2021-11-06 21:03:28 (JOBID 31682) epoch 83: train time 2707.59, inference time 286.27s, valid_top1 73.51 (best_top1 73.59), valid_top5 91.67
2021-11-06 21:03:28 (JOBID 31682) epoch 83: train time 2708.16, inference time 286.86s, valid_top1 73.51 (best_top1 73.59), valid_top5 91.67
2021-11-06 21:03:42 train 0000, loss 1.193e+00, top1 71.76, top5 89.41
2021-11-06 21:03:42 train 0000, loss 1.220e+00, top1 71.76, top5 88.24
2021-11-06 21:03:42 train 0000, loss 1.129e+00, top1 70.59, top5 95.29
2021-11-06 21:12:22 train 1000, loss 1.141e+00, top1 72.66, top5 89.67
2021-11-06 21:12:22 train 1000, loss 1.151e+00, top1 72.50, top5 89.53
2021-11-06 21:12:22 train 1000, loss 1.150e+00, top1 72.47, top5 89.52
2021-11-06 21:21:01 train 2000, loss 1.153e+00, top1 72.51, top5 89.47
2021-11-06 21:21:01 train 2000, loss 1.146e+00, top1 72.54, top5 89.49
2021-11-06 21:21:01 train 2000, loss 1.151e+00, top1 72.50, top5 89.54
2021-11-06 21:29:41 train 3000, loss 1.150e+00, top1 72.48, top5 89.45
2021-11-06 21:29:41 train 3000, loss 1.153e+00, top1 72.48, top5 89.47
2021-11-06 21:29:41 train 3000, loss 1.153e+00, top1 72.45, top5 89.49
2021-11-06 21:38:25 train 4000, loss 1.152e+00, top1 72.46, top5 89.42
2021-11-06 21:38:25 train 4000, loss 1.154e+00, top1 72.43, top5 89.47
2021-11-06 21:38:26 train 4000, loss 1.157e+00, top1 72.34, top5 89.44
2021-11-06 21:47:06 train 5000, loss 1.153e+00, top1 72.44, top5 89.49
2021-11-06 21:47:06 train 5000, loss 1.155e+00, top1 72.40, top5 89.41
2021-11-06 21:47:06 train 5000, loss 1.159e+00, top1 72.26, top5 89.42
2021-11-06 21:47:30 valid 0000, loss 4.511e-01, top1 89.41, top5 98.82
2021-11-06 21:47:30 valid 0000, loss 4.511e-01, top1 89.41, top5 98.82
2021-11-06 21:47:30 valid 0000, loss 4.511e-01, top1 89.41, top5 98.82
2021-11-06 21:51:53 (JOBID 31682) epoch 84: train time 2631.78, inference time 273.36s, valid_top1 73.55 (best_top1 73.59), valid_top5 91.65
2021-11-06 21:51:58 (JOBID 31682) epoch 84: train time 2631.05, inference time 278.99s, valid_top1 73.55 (best_top1 73.59), valid_top5 91.65
2021-11-06 21:51:59 (JOBID 31682) epoch 84: train time 2630.68, inference time 279.64s, valid_top1 73.55 (best_top1 73.59), valid_top5 91.65
2021-11-06 21:52:12 train 0000, loss 1.021e+00, top1 80.00, top5 92.94
2021-11-06 21:52:08 train 0000, loss 8.720e-01, top1 78.82, top5 91.76
2021-11-06 21:52:12 train 0000, loss 7.904e-01, top1 80.00, top5 96.47
2021-11-06 22:00:45 train 1000, loss 1.142e+00, top1 72.89, top5 89.57
2021-11-06 22:00:45 train 1000, loss 1.148e+00, top1 72.48, top5 89.53
2021-11-06 22:00:45 train 1000, loss 1.143e+00, top1 72.68, top5 89.54
2021-11-06 22:09:19 train 2000, loss 1.145e+00, top1 72.66, top5 89.57
2021-11-06 22:09:19 train 2000, loss 1.152e+00, top1 72.38, top5 89.46
2021-11-06 22:09:20 train 2000, loss 1.143e+00, top1 72.63, top5 89.53
2021-11-06 22:18:07 train 3000, loss 1.156e+00, top1 72.35, top5 89.41
2021-11-06 22:18:07 train 3000, loss 1.150e+00, top1 72.56, top5 89.49
2021-11-06 22:18:07 train 3000, loss 1.148e+00, top1 72.49, top5 89.49
2021-11-06 22:26:51 train 4000, loss 1.156e+00, top1 72.37, top5 89.40
2021-11-06 22:26:50 train 4000, loss 1.150e+00, top1 72.52, top5 89.48
2021-11-06 22:26:51 train 4000, loss 1.150e+00, top1 72.45, top5 89.48
2021-11-06 22:35:41 train 5000, loss 1.153e+00, top1 72.47, top5 89.46
2021-11-06 22:35:41 train 5000, loss 1.158e+00, top1 72.33, top5 89.37
2021-11-06 22:35:41 train 5000, loss 1.152e+00, top1 72.45, top5 89.49
2021-11-06 22:36:05 valid 0000, loss 4.413e-01, top1 89.41, top5 97.65
2021-11-06 22:36:05 valid 0000, loss 4.413e-01, top1 89.41, top5 97.65
2021-11-06 22:36:05 valid 0000, loss 4.413e-01, top1 89.41, top5 97.65
2021-11-06 22:40:22 (JOBID 31682) epoch 85: train time 2641.66, inference time 267.88s, valid_top1 73.47 (best_top1 73.59), valid_top5 91.66
2021-11-06 22:40:35 (JOBID 31682) epoch 85: train time 2635.72, inference time 281.00s, valid_top1 73.47 (best_top1 73.59), valid_top5 91.66
2021-11-06 22:40:37 (JOBID 31682) epoch 85: train time 2635.31, inference time 282.65s, valid_top1 73.47 (best_top1 73.59), valid_top5 91.66
2021-11-06 22:40:36 train 0000, loss 1.195e+00, top1 76.47, top5 88.24
2021-11-06 22:40:50 train 0000, loss 1.173e+00, top1 72.94, top5 85.88
2021-11-06 22:40:50 train 0000, loss 1.072e+00, top1 71.76, top5 91.76
2021-11-06 22:49:26 train 1000, loss 1.152e+00, top1 72.45, top5 89.37
2021-11-06 22:49:26 train 1000, loss 1.147e+00, top1 72.49, top5 89.56
2021-11-06 22:49:26 train 1000, loss 1.153e+00, top1 72.38, top5 89.48
2021-11-06 22:58:03 train 2000, loss 1.151e+00, top1 72.43, top5 89.40
2021-11-06 22:58:03 train 2000, loss 1.152e+00, top1 72.43, top5 89.46
2021-11-06 22:58:03 train 2000, loss 1.148e+00, top1 72.47, top5 89.58
2021-11-06 23:06:37 train 3000, loss 1.152e+00, top1 72.46, top5 89.48
2021-11-06 23:06:37 train 3000, loss 1.151e+00, top1 72.49, top5 89.47
2021-11-06 23:06:37 train 3000, loss 1.147e+00, top1 72.52, top5 89.59
2021-11-06 23:15:11 train 4000, loss 1.149e+00, top1 72.53, top5 89.51
2021-11-06 23:15:11 train 4000, loss 1.154e+00, top1 72.44, top5 89.45
2021-11-06 23:15:11 train 4000, loss 1.150e+00, top1 72.48, top5 89.56
2021-11-06 23:23:47 train 5000, loss 1.155e+00, top1 72.41, top5 89.43
2021-11-06 23:23:47 train 5000, loss 1.151e+00, top1 72.46, top5 89.51
2021-11-06 23:23:47 train 5000, loss 1.152e+00, top1 72.45, top5 89.50
2021-11-06 23:24:10 valid 0000, loss 5.337e-01, top1 88.24, top5 96.47
2021-11-06 23:24:10 valid 0000, loss 5.337e-01, top1 88.24, top5 96.47
2021-11-06 23:24:10 valid 0000, loss 5.337e-01, top1 88.24, top5 96.47
2021-11-06 23:28:37 (JOBID 31682) epoch 86: train time 2604.77, inference time 276.97s, valid_top1 73.40 (best_top1 73.59), valid_top5 91.58
2021-11-06 23:28:38 (JOBID 31682) epoch 86: train time 2603.35, inference time 277.72s, valid_top1 73.40 (best_top1 73.59), valid_top5 91.58
2021-11-06 23:28:38 (JOBID 31682) epoch 86: train time 2618.09, inference time 277.72s, valid_top1 73.40 (best_top1 73.59), valid_top5 91.58
2021-11-06 23:28:52 train 0000, loss 1.133e+00, top1 70.59, top5 92.94
2021-11-06 23:28:52 train 0000, loss 1.276e+00, top1 69.41, top5 84.71
2021-11-06 23:28:52 train 0000, loss 1.380e+00, top1 72.94, top5 83.53
2021-11-06 23:37:19 train 1000, loss 1.139e+00, top1 72.64, top5 89.60
2021-11-06 23:37:19 train 1000, loss 1.150e+00, top1 72.57, top5 89.51
2021-11-06 23:37:20 train 1000, loss 1.141e+00, top1 72.73, top5 89.58
2021-11-06 23:45:47 train 2000, loss 1.144e+00, top1 72.60, top5 89.58
2021-11-06 23:45:47 train 2000, loss 1.143e+00, top1 72.69, top5 89.51
2021-11-06 23:45:47 train 2000, loss 1.147e+00, top1 72.66, top5 89.55
2021-11-06 23:54:16 train 3000, loss 1.148e+00, top1 72.50, top5 89.52
2021-11-06 23:54:16 train 3000, loss 1.149e+00, top1 72.57, top5 89.49
2021-11-06 23:54:16 train 3000, loss 1.145e+00, top1 72.65, top5 89.56
2021-11-07 00:02:44 train 4000, loss 1.151e+00, top1 72.49, top5 89.47
2021-11-07 00:02:44 train 4000, loss 1.151e+00, top1 72.48, top5 89.51
2021-11-07 00:02:44 train 4000, loss 1.147e+00, top1 72.60, top5 89.55
2021-11-07 00:11:14 train 5000, loss 1.151e+00, top1 72.50, top5 89.50
2021-11-07 00:11:14 train 5000, loss 1.150e+00, top1 72.50, top5 89.48
2021-11-07 00:11:14 train 5000, loss 1.149e+00, top1 72.55, top5 89.54
2021-11-07 00:11:37 valid 0000, loss 5.186e-01, top1 89.41, top5 96.47
2021-11-07 00:11:37 valid 0000, loss 5.186e-01, top1 89.41, top5 96.47
2021-11-07 00:11:37 valid 0000, loss 5.186e-01, top1 89.41, top5 96.47
2021-11-07 00:15:55 (JOBID 31682) epoch 87: train time 2569.50, inference time 268.17s, valid_top1 73.47 (best_top1 73.59), valid_top5 91.71
2021-11-07 00:16:13 (JOBID 31682) epoch 87: train time 2568.99, inference time 286.55s, valid_top1 73.47 (best_top1 73.59), valid_top5 91.71
2021-11-07 00:16:14 (JOBID 31682) epoch 87: train time 2569.04, inference time 286.64s, valid_top1 73.47 (best_top1 73.59), valid_top5 91.71
2021-11-07 00:16:27 train 0000, loss 1.393e+00, top1 68.24, top5 85.88
2021-11-07 00:16:10 train 0000, loss 1.248e+00, top1 70.59, top5 89.41
2021-11-07 00:16:27 train 0000, loss 1.065e+00, top1 71.76, top5 88.24
2021-11-07 00:25:06 train 1000, loss 1.140e+00, top1 72.78, top5 89.56
2021-11-07 00:25:06 train 1000, loss 1.143e+00, top1 72.67, top5 89.56
2021-11-07 00:25:06 train 1000, loss 1.152e+00, top1 72.54, top5 89.46
2021-11-07 00:33:47 train 2000, loss 1.141e+00, top1 72.76, top5 89.58
2021-11-07 00:33:47 train 2000, loss 1.154e+00, top1 72.41, top5 89.39
2021-11-07 00:33:47 train 2000, loss 1.150e+00, top1 72.55, top5 89.48
2021-11-07 00:42:30 train 3000, loss 1.152e+00, top1 72.47, top5 89.43
2021-11-07 00:42:30 train 3000, loss 1.148e+00, top1 72.51, top5 89.54
2021-11-07 00:42:30 train 3000, loss 1.142e+00, top1 72.72, top5 89.54
2021-11-07 00:51:10 train 4000, loss 1.152e+00, top1 72.47, top5 89.43
2021-11-07 00:51:10 train 4000, loss 1.145e+00, top1 72.64, top5 89.53
2021-11-07 00:51:10 train 4000, loss 1.147e+00, top1 72.55, top5 89.54
2021-11-07 00:59:52 train 5000, loss 1.148e+00, top1 72.56, top5 89.49
2021-11-07 00:59:52 train 5000, loss 1.154e+00, top1 72.46, top5 89.38
2021-11-07 00:59:53 train 5000, loss 1.145e+00, top1 72.58, top5 89.56
2021-11-07 01:00:15 valid 0000, loss 4.744e-01, top1 89.41, top5 98.82
2021-11-07 01:00:15 valid 0000, loss 4.744e-01, top1 89.41, top5 98.82
2021-11-07 01:00:15 valid 0000, loss 4.744e-01, top1 89.41, top5 98.82
2021-11-07 01:04:45 (JOBID 31682) epoch 88: train time 2631.69, inference time 279.47s, valid_top1 73.57 (best_top1 73.59), valid_top5 91.74
2021-11-07 01:04:45 (JOBID 31682) epoch 88: train time 2631.96, inference time 279.59s, valid_top1 73.57 (best_top1 73.59), valid_top5 91.74
2021-11-07 01:04:45 (JOBID 31682) epoch 88: train time 2650.16, inference time 279.44s, valid_top1 73.57 (best_top1 73.59), valid_top5 91.74
2021-11-07 01:04:59 train 0000, loss 1.538e+00, top1 65.88, top5 81.18
2021-11-07 01:04:59 train 0000, loss 1.376e+00, top1 61.18, top5 83.53
2021-11-07 01:04:59 train 0000, loss 9.970e-01, top1 76.47, top5 90.59
2021-11-07 01:13:27 train 1000, loss 1.149e+00, top1 72.63, top5 89.50
2021-11-07 01:13:27 train 1000, loss 1.142e+00, top1 72.79, top5 89.60
2021-11-07 01:13:27 train 1000, loss 1.139e+00, top1 72.55, top5 89.56
2021-11-07 01:21:55 train 2000, loss 1.140e+00, top1 72.78, top5 89.64
2021-11-07 01:21:55 train 2000, loss 1.147e+00, top1 72.60, top5 89.48
2021-11-07 01:21:55 train 2000, loss 1.142e+00, top1 72.61, top5 89.55
2021-11-07 01:30:24 train 3000, loss 1.146e+00, top1 72.59, top5 89.52
2021-11-07 01:30:24 train 3000, loss 1.138e+00, top1 72.83, top5 89.67
2021-11-07 01:30:24 train 3000, loss 1.146e+00, top1 72.55, top5 89.53
2021-11-07 01:38:54 train 4000, loss 1.141e+00, top1 72.78, top5 89.59
2021-11-07 01:38:54 train 4000, loss 1.145e+00, top1 72.56, top5 89.52
2021-11-07 01:38:54 train 4000, loss 1.147e+00, top1 72.51, top5 89.52
2021-11-07 01:47:25 train 5000, loss 1.142e+00, top1 72.74, top5 89.58
2021-11-07 01:47:25 train 5000, loss 1.147e+00, top1 72.55, top5 89.51
2021-11-07 01:47:25 train 5000, loss 1.147e+00, top1 72.57, top5 89.53
2021-11-07 01:47:48 valid 0000, loss 4.289e-01, top1 89.41, top5 98.82
2021-11-07 01:47:48 valid 0000, loss 4.289e-01, top1 89.41, top5 98.82
2021-11-07 01:47:48 valid 0000, loss 4.289e-01, top1 89.41, top5 98.82
2021-11-07 01:52:10 (JOBID 31682) epoch 89: train time 2572.44, inference time 272.71s, valid_top1 73.34 (best_top1 73.59), valid_top5 91.57
2021-11-07 01:52:20 (JOBID 31682) epoch 89: train time 2572.78, inference time 282.82s, valid_top1 73.34 (best_top1 73.59), valid_top5 91.57
2021-11-07 01:52:21 (JOBID 31682) epoch 89: train time 2572.43, inference time 283.88s, valid_top1 73.34 (best_top1 73.59), valid_top5 91.57
