2021-11-03 10:16:39 CARME Slurm ID: 31582
2021-11-03 10:16:39 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_1', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.46:23456', distributed=True, epochs=90, evaluate=False, gpu=0, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-03 10:16:39 CARME Slurm ID: 31582
2021-11-03 10:16:39 CARME Slurm ID: 31582
2021-11-03 10:16:39 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_1', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.46:23456', distributed=True, epochs=90, evaluate=False, gpu=1, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-03 10:16:39 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_1', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.46:23456', distributed=True, epochs=90, evaluate=False, gpu=2, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-03 10:16:40 => loading baseline model 'conv12_lr_0.001_momentum_0.9_wd_0.1_normalization_div_pretrained_True_20211031-110931/small_model_conv12_1e-06.pth.tar'
2021-11-03 10:16:40 => loading baseline model 'conv12_lr_0.001_momentum_0.9_wd_0.1_normalization_div_pretrained_True_20211031-110931/small_model_conv12_1e-06.pth.tar'
2021-11-03 10:16:40 => loading baseline model 'conv12_lr_0.001_momentum_0.9_wd_0.1_normalization_div_pretrained_True_20211031-110931/small_model_conv12_1e-06.pth.tar'
2021-11-03 10:16:41 => loaded baseline model 'conv12_lr_0.001_momentum_0.9_wd_0.1_normalization_div_pretrained_True_20211031-110931/small_model_conv12_1e-06.pth.tar'
2021-11-03 10:16:41 => loaded baseline model 'conv12_lr_0.001_momentum_0.9_wd_0.1_normalization_div_pretrained_True_20211031-110931/small_model_conv12_1e-06.pth.tar'
2021-11-03 10:16:41 => loaded baseline model 'conv12_lr_0.001_momentum_0.9_wd_0.1_normalization_div_pretrained_True_20211031-110931/small_model_conv12_1e-06.pth.tar'
2021-11-03 10:16:49 Computational complexity:       1.74 GMac
2021-11-03 10:16:49 Number of parameters:           12.36 M 
2021-11-03 10:16:49 Computational complexity:       1.74 GMac
2021-11-03 10:16:49 Number of parameters:           12.36 M 
2021-11-03 10:16:49 Computational complexity:       1.74 GMac
2021-11-03 10:16:49 Number of parameters:           12.36 M 
2021-11-03 10:17:07 valid 0000, loss 6.018e-01, top1 89.41, top5 95.29
2021-11-03 10:17:07 valid 0000, loss 6.018e-01, top1 89.41, top5 95.29
2021-11-03 10:17:07 valid 0000, loss 6.018e-01, top1 89.41, top5 95.29
2021-11-03 10:21:28 (JOBID 31582) epoch -1: valid_top1 72.45, valid_top5 90.55, inference time 274.33
2021-11-03 10:21:29 (JOBID 31582) epoch -1: valid_top1 72.45, valid_top5 90.55, inference time 275.29
2021-11-03 10:21:30 (JOBID 31582) epoch -1: valid_top1 72.45, valid_top5 90.55, inference time 275.89
2021-11-03 10:21:48 train 0000, loss 5.493e-01, top1 84.71, top5 96.47
2021-11-03 10:21:48 train 0000, loss 5.472e-01, top1 85.88, top5 96.47
2021-11-03 10:21:48 train 0000, loss 8.010e-01, top1 81.18, top5 92.94
2021-11-03 10:30:46 train 1000, loss 1.585e+00, top1 63.42, top5 83.28
2021-11-03 10:30:46 train 1000, loss 1.572e+00, top1 63.38, top5 83.49
2021-11-03 10:30:46 train 1000, loss 1.575e+00, top1 63.42, top5 83.52
2021-11-03 10:39:30 train 2000, loss 1.504e+00, top1 64.97, top5 84.41
2021-11-03 10:39:30 train 2000, loss 1.496e+00, top1 64.92, top5 84.62
2021-11-03 10:39:30 train 2000, loss 1.503e+00, top1 64.89, top5 84.54
2021-11-03 10:48:12 train 3000, loss 1.473e+00, top1 65.56, top5 84.92
2021-11-03 10:48:12 train 3000, loss 1.468e+00, top1 65.51, top5 85.08
2021-11-03 10:48:12 train 3000, loss 1.472e+00, top1 65.49, top5 84.98
2021-11-03 10:56:56 train 4000, loss 1.452e+00, top1 65.92, top5 85.30
2021-11-03 10:56:56 train 4000, loss 1.457e+00, top1 65.98, top5 85.18
2021-11-03 10:56:56 train 4000, loss 1.457e+00, top1 65.82, top5 85.22
2021-11-03 11:05:41 train 5000, loss 1.451e+00, top1 66.09, top5 85.30
2021-11-03 11:05:41 train 5000, loss 1.444e+00, top1 66.07, top5 85.43
2021-11-03 11:05:41 train 5000, loss 1.452e+00, top1 65.96, top5 85.29
2021-11-03 11:06:07 valid 0000, loss 1.043e+00, top1 83.53, top5 91.76
2021-11-03 11:06:07 valid 0000, loss 1.043e+00, top1 83.53, top5 91.76
2021-11-03 11:06:07 valid 0000, loss 1.043e+00, top1 83.53, top5 91.76
2021-11-03 11:10:30 (JOBID 31582) epoch 0: train time 2667.11, inference time 272.64s, valid_top1 63.94 (best_top1 63.94), valid_top5 85.29
2021-11-03 11:10:43 (JOBID 31582) epoch 0: train time 2668.65, inference time 284.50s, valid_top1 63.94 (best_top1 63.94), valid_top5 85.29
2021-11-03 11:10:45 (JOBID 31582) epoch 0: train time 2667.85, inference time 288.25s, valid_top1 63.94 (best_top1 63.94), valid_top5 85.29
2021-11-03 11:10:57 train 0000, loss 1.276e+00, top1 65.88, top5 89.41
2021-11-03 11:10:43 train 0000, loss 1.477e+00, top1 67.06, top5 84.71
2021-11-03 11:11:00 train 0000, loss 1.225e+00, top1 72.94, top5 89.41
2021-11-03 11:19:57 train 1000, loss 1.423e+00, top1 66.79, top5 85.77
2021-11-03 11:19:57 train 1000, loss 1.430e+00, top1 66.41, top5 85.83
2021-11-03 11:19:57 train 1000, loss 1.418e+00, top1 66.69, top5 85.98
2021-11-03 11:28:39 train 2000, loss 1.436e+00, top1 66.48, top5 85.65
2021-11-03 11:28:39 train 2000, loss 1.434e+00, top1 66.35, top5 85.85
2021-11-03 11:28:39 train 2000, loss 1.431e+00, top1 66.45, top5 85.87
2021-11-03 11:37:28 train 3000, loss 1.454e+00, top1 65.97, top5 85.58
2021-11-03 11:37:29 train 3000, loss 1.456e+00, top1 66.02, top5 85.47
2021-11-03 11:37:29 train 3000, loss 1.450e+00, top1 66.07, top5 85.65
2021-11-03 11:46:29 train 4000, loss 1.471e+00, top1 65.63, top5 85.37
2021-11-03 11:46:29 train 4000, loss 1.466e+00, top1 65.77, top5 85.43
2021-11-03 11:46:29 train 4000, loss 1.473e+00, top1 65.72, top5 85.25
2021-11-03 11:55:26 train 5000, loss 1.490e+00, top1 65.38, top5 85.04
2021-11-03 11:55:26 train 5000, loss 1.490e+00, top1 65.26, top5 85.13
2021-11-03 11:55:26 train 5000, loss 1.486e+00, top1 65.37, top5 85.19
2021-11-03 11:55:50 valid 0000, loss 8.180e-01, top1 85.88, top5 94.12
2021-11-03 11:55:50 valid 0000, loss 8.180e-01, top1 85.88, top5 94.12
2021-11-03 11:55:50 valid 0000, loss 8.180e-01, top1 85.88, top5 94.12
2021-11-03 12:00:20 (JOBID 31582) epoch 1: train time 2709.57, inference time 280.73s, valid_top1 61.66 (best_top1 63.94), valid_top5 83.88
2021-11-03 12:00:22 (JOBID 31582) epoch 1: train time 2693.93, inference time 282.27s, valid_top1 61.66 (best_top1 63.94), valid_top5 83.88
2021-11-03 12:00:23 (JOBID 31582) epoch 1: train time 2696.60, inference time 283.12s, valid_top1 61.66 (best_top1 63.94), valid_top5 83.88
2021-11-03 12:00:36 train 0000, loss 1.381e+00, top1 70.59, top5 87.06
2021-11-03 12:00:35 train 0000, loss 1.498e+00, top1 58.82, top5 92.94
2021-11-03 12:00:36 train 0000, loss 1.501e+00, top1 65.88, top5 83.53
2021-11-03 12:09:32 train 1000, loss 1.564e+00, top1 63.85, top5 84.14
2021-11-03 12:09:32 train 1000, loss 1.581e+00, top1 63.58, top5 83.99
2021-11-03 12:09:32 train 1000, loss 1.566e+00, top1 63.82, top5 84.27
2021-11-03 12:18:17 train 2000, loss 1.591e+00, top1 63.31, top5 83.88
2021-11-03 12:18:17 train 2000, loss 1.584e+00, top1 63.45, top5 83.94
2021-11-03 12:18:17 train 2000, loss 1.587e+00, top1 63.42, top5 83.95
2021-11-03 12:27:07 train 3000, loss 1.609e+00, top1 62.90, top5 83.69
2021-11-03 12:27:07 train 3000, loss 1.604e+00, top1 63.02, top5 83.74
2021-11-03 12:27:07 train 3000, loss 1.610e+00, top1 62.96, top5 83.68
2021-11-03 12:35:59 train 4000, loss 1.632e+00, top1 62.54, top5 83.37
2021-11-03 12:35:59 train 4000, loss 1.627e+00, top1 62.54, top5 83.47
2021-11-03 12:35:59 train 4000, loss 1.631e+00, top1 62.41, top5 83.36
2021-11-03 12:44:48 train 5000, loss 1.652e+00, top1 61.97, top5 83.07
2021-11-03 12:44:48 train 5000, loss 1.648e+00, top1 62.13, top5 83.17
2021-11-03 12:44:48 train 5000, loss 1.651e+00, top1 62.11, top5 83.12
2021-11-03 12:45:12 valid 0000, loss 1.119e+00, top1 80.00, top5 87.06
2021-11-03 12:45:12 valid 0000, loss 1.119e+00, top1 80.00, top5 87.06
2021-11-03 12:45:12 valid 0000, loss 1.119e+00, top1 80.00, top5 87.06
2021-11-03 12:50:02 (JOBID 31582) epoch 2: train time 2679.95, inference time 300.35s, valid_top1 60.07 (best_top1 63.94), valid_top5 83.14
2021-11-03 12:50:03 (JOBID 31582) epoch 2: train time 2678.82, inference time 301.13s, valid_top1 60.07 (best_top1 63.94), valid_top5 83.14
2021-11-03 12:50:03 (JOBID 31582) epoch 2: train time 2681.46, inference time 301.35s, valid_top1 60.07 (best_top1 63.94), valid_top5 83.14
2021-11-03 12:50:17 train 0000, loss 1.621e+00, top1 62.35, top5 82.35
2021-11-03 12:50:17 train 0000, loss 1.778e+00, top1 57.65, top5 80.00
2021-11-03 12:50:17 train 0000, loss 1.623e+00, top1 61.18, top5 82.35
2021-11-03 12:59:01 train 1000, loss 1.735e+00, top1 60.14, top5 81.92
2021-11-03 12:59:01 train 1000, loss 1.727e+00, top1 60.40, top5 82.09
2021-11-03 12:59:01 train 1000, loss 1.735e+00, top1 60.21, top5 81.95
2021-11-03 13:07:44 train 2000, loss 1.751e+00, top1 59.79, top5 81.67
2021-11-03 13:07:44 train 2000, loss 1.756e+00, top1 59.81, top5 81.62
2021-11-03 13:07:44 train 2000, loss 1.752e+00, top1 59.89, top5 81.81
2021-11-03 13:16:29 train 3000, loss 1.774e+00, top1 59.41, top5 81.36
2021-11-03 13:16:29 train 3000, loss 1.777e+00, top1 59.31, top5 81.31
2021-11-03 13:16:29 train 3000, loss 1.779e+00, top1 59.35, top5 81.43
2021-11-03 13:25:19 train 4000, loss 1.798e+00, top1 58.87, top5 81.02
2021-11-03 13:25:19 train 4000, loss 1.793e+00, top1 59.08, top5 81.14
2021-11-03 13:25:19 train 4000, loss 1.800e+00, top1 58.95, top5 81.11
2021-11-03 13:34:02 train 5000, loss 1.816e+00, top1 58.46, top5 80.76
2021-11-03 13:34:02 train 5000, loss 1.811e+00, top1 58.68, top5 80.84
2021-11-03 13:34:02 train 5000, loss 1.818e+00, top1 58.58, top5 80.83
2021-11-03 13:34:25 valid 0000, loss 1.371e+00, top1 65.88, top5 85.88
2021-11-03 13:34:25 valid 0000, loss 1.371e+00, top1 65.88, top5 85.88
2021-11-03 13:34:25 valid 0000, loss 1.371e+00, top1 65.88, top5 85.88
2021-11-03 13:38:50 (JOBID 31582) epoch 3: train time 2651.95, inference time 275.30s, valid_top1 55.62 (best_top1 63.94), valid_top5 80.35
2021-11-03 13:38:51 (JOBID 31582) epoch 3: train time 2651.85, inference time 275.86s, valid_top1 55.62 (best_top1 63.94), valid_top5 80.35
2021-11-03 13:39:00 (JOBID 31582) epoch 3: train time 2652.91, inference time 285.46s, valid_top1 55.62 (best_top1 63.94), valid_top5 80.35
2021-11-03 13:39:04 train 0000, loss 1.886e+00, top1 52.94, top5 74.12
2021-11-03 13:39:04 train 0000, loss 2.038e+00, top1 50.59, top5 76.47
2021-11-03 13:39:14 train 0000, loss 2.212e+00, top1 45.88, top5 70.59
2021-11-03 13:47:49 train 1000, loss 1.892e+00, top1 56.84, top5 79.88
2021-11-03 13:47:49 train 1000, loss 1.893e+00, top1 56.85, top5 79.70
2021-11-03 13:47:49 train 1000, loss 1.894e+00, top1 56.85, top5 79.86
2021-11-03 13:56:30 train 2000, loss 1.906e+00, top1 56.57, top5 79.47
2021-11-03 13:56:30 train 2000, loss 1.916e+00, top1 56.37, top5 79.48
2021-11-03 13:56:30 train 2000, loss 1.908e+00, top1 56.55, top5 79.57
2021-11-03 14:05:15 train 3000, loss 1.926e+00, top1 56.20, top5 79.30
2021-11-03 14:05:15 train 3000, loss 1.932e+00, top1 56.07, top5 79.18
2021-11-03 14:05:15 train 3000, loss 1.927e+00, top1 56.22, top5 79.19
2021-11-03 14:14:06 train 4000, loss 1.946e+00, top1 55.80, top5 78.92
2021-11-03 14:14:06 train 4000, loss 1.944e+00, top1 55.88, top5 78.92
2021-11-03 14:14:06 train 4000, loss 1.946e+00, top1 55.83, top5 78.99
2021-11-03 14:23:00 train 5000, loss 1.965e+00, top1 55.48, top5 78.61
2021-11-03 14:23:00 train 5000, loss 1.959e+00, top1 55.56, top5 78.69
2021-11-03 14:23:00 train 5000, loss 1.963e+00, top1 55.51, top5 78.71
2021-11-03 14:23:24 valid 0000, loss 9.258e-01, top1 81.18, top5 94.12
2021-11-03 14:23:24 valid 0000, loss 9.258e-01, top1 81.18, top5 94.12
2021-11-03 14:23:24 valid 0000, loss 9.258e-01, top1 81.18, top5 94.12
2021-11-03 14:27:56 (JOBID 31582) epoch 4: train time 2663.11, inference time 281.50s, valid_top1 52.95 (best_top1 63.94), valid_top5 78.00
2021-11-03 14:27:58 (JOBID 31582) epoch 4: train time 2653.58, inference time 283.88s, valid_top1 52.95 (best_top1 63.94), valid_top5 78.00
2021-11-03 14:27:58 (JOBID 31582) epoch 4: train time 2663.72, inference time 283.94s, valid_top1 52.95 (best_top1 63.94), valid_top5 78.00
2021-11-03 14:28:12 train 0000, loss 2.397e+00, top1 43.53, top5 69.41
2021-11-03 14:28:11 train 0000, loss 2.224e+00, top1 52.94, top5 70.59
2021-11-03 14:28:12 train 0000, loss 1.899e+00, top1 52.94, top5 77.65
2021-11-03 14:36:32 train 1000, loss 2.008e+00, top1 54.60, top5 78.02
2021-11-03 14:36:32 train 1000, loss 2.013e+00, top1 54.32, top5 78.02
2021-11-03 14:36:32 train 1000, loss 2.011e+00, top1 54.46, top5 77.87
2021-11-03 14:44:53 train 2000, loss 2.031e+00, top1 54.13, top5 77.67
2021-11-03 14:44:53 train 2000, loss 2.040e+00, top1 53.86, top5 77.50
2021-11-03 14:44:53 train 2000, loss 2.029e+00, top1 54.03, top5 77.62
2021-11-03 14:53:16 train 3000, loss 2.047e+00, top1 53.79, top5 77.32
2021-11-03 14:53:16 train 3000, loss 2.051e+00, top1 53.68, top5 77.36
2021-11-03 14:53:16 train 3000, loss 2.049e+00, top1 53.79, top5 77.36
2021-11-03 15:01:43 train 4000, loss 2.067e+00, top1 53.39, top5 77.02
2021-11-03 15:01:43 train 4000, loss 2.067e+00, top1 53.39, top5 77.06
2021-11-03 15:01:43 train 4000, loss 2.065e+00, top1 53.52, top5 77.06
2021-11-03 15:09:55 train 5000, loss 2.077e+00, top1 53.26, top5 76.87
2021-11-03 15:09:55 train 5000, loss 2.077e+00, top1 53.20, top5 76.86
2021-11-03 15:09:55 train 5000, loss 2.081e+00, top1 53.11, top5 76.86
2021-11-03 15:10:17 valid 0000, loss 9.769e-01, top1 82.35, top5 90.59
2021-11-03 15:10:17 valid 0000, loss 9.769e-01, top1 82.35, top5 90.59
2021-11-03 15:10:17 valid 0000, loss 9.769e-01, top1 82.35, top5 90.59
2021-11-03 15:14:42 (JOBID 31582) epoch 5: train time 2529.39, inference time 275.16s, valid_top1 52.71 (best_top1 63.94), valid_top5 78.20
2021-11-03 15:14:53 (JOBID 31582) epoch 5: train time 2529.53, inference time 285.29s, valid_top1 52.71 (best_top1 63.94), valid_top5 78.20
2021-11-03 15:14:53 (JOBID 31582) epoch 5: train time 2531.45, inference time 285.28s, valid_top1 52.71 (best_top1 63.94), valid_top5 78.20
2021-11-03 15:14:57 train 0000, loss 2.668e+00, top1 43.53, top5 72.94
2021-11-03 15:15:06 train 0000, loss 2.162e+00, top1 52.94, top5 78.82
2021-11-03 15:15:06 train 0000, loss 2.192e+00, top1 50.59, top5 72.94
2021-11-03 15:25:40 train 1000, loss 2.105e+00, top1 52.58, top5 76.45
2021-11-03 15:25:40 train 1000, loss 2.098e+00, top1 52.67, top5 76.69
2021-11-03 15:25:40 train 1000, loss 2.097e+00, top1 52.84, top5 76.59
2021-11-03 15:33:55 train 2000, loss 2.119e+00, top1 52.18, top5 76.26
2021-11-03 15:33:55 train 2000, loss 2.117e+00, top1 52.25, top5 76.36
2021-11-03 15:33:55 train 2000, loss 2.107e+00, top1 52.50, top5 76.45
2021-11-03 15:42:06 train 3000, loss 2.128e+00, top1 52.01, top5 76.19
2021-11-03 15:42:06 train 3000, loss 2.129e+00, top1 52.08, top5 76.08
2021-11-03 15:42:06 train 3000, loss 2.123e+00, top1 52.21, top5 76.22
2021-11-03 15:50:25 train 4000, loss 2.132e+00, top1 52.03, top5 76.07
2021-11-03 15:50:25 train 4000, loss 2.138e+00, top1 51.92, top5 75.91
2021-11-03 15:50:25 train 4000, loss 2.139e+00, top1 51.87, top5 75.96
2021-11-03 15:58:43 train 5000, loss 2.149e+00, top1 51.71, top5 75.76
2021-11-03 15:58:43 train 5000, loss 2.147e+00, top1 51.74, top5 75.79
2021-11-03 15:58:43 train 5000, loss 2.142e+00, top1 51.86, top5 75.91
2021-11-03 15:59:05 valid 0000, loss 8.205e-01, top1 84.71, top5 95.29
2021-11-03 15:59:05 valid 0000, loss 8.205e-01, top1 84.71, top5 95.29
2021-11-03 15:59:05 valid 0000, loss 8.205e-01, top1 84.71, top5 95.29
2021-11-03 16:03:23 (JOBID 31582) epoch 6: train time 2652.86, inference time 267.63s, valid_top1 53.78 (best_top1 63.94), valid_top5 78.92
2021-11-03 16:03:42 (JOBID 31582) epoch 6: train time 2642.50, inference time 286.96s, valid_top1 53.78 (best_top1 63.94), valid_top5 78.92
2021-11-03 16:03:45 (JOBID 31582) epoch 6: train time 2642.64, inference time 289.77s, valid_top1 53.78 (best_top1 63.94), valid_top5 78.92
2021-11-03 16:03:57 train 0000, loss 2.138e+00, top1 54.12, top5 75.29
2021-11-03 16:03:37 train 0000, loss 2.391e+00, top1 44.71, top5 74.12
2021-11-03 16:03:59 train 0000, loss 2.225e+00, top1 49.41, top5 75.29
2021-11-03 16:12:19 train 1000, loss 2.158e+00, top1 51.59, top5 75.58
2021-11-03 16:12:20 train 1000, loss 2.149e+00, top1 51.75, top5 75.82
2021-11-03 16:12:20 train 1000, loss 2.156e+00, top1 51.50, top5 75.74
2021-11-03 16:20:34 train 2000, loss 2.166e+00, top1 51.46, top5 75.50
2021-11-03 16:20:34 train 2000, loss 2.168e+00, top1 51.31, top5 75.50
2021-11-03 16:20:34 train 2000, loss 2.159e+00, top1 51.59, top5 75.65
2021-11-03 16:28:56 train 3000, loss 2.175e+00, top1 51.17, top5 75.37
2021-11-03 16:28:56 train 3000, loss 2.174e+00, top1 51.27, top5 75.36
2021-11-03 16:28:56 train 3000, loss 2.167e+00, top1 51.40, top5 75.54
2021-11-03 16:37:23 train 4000, loss 2.181e+00, top1 51.08, top5 75.31
2021-11-03 16:37:23 train 4000, loss 2.180e+00, top1 51.17, top5 75.27
2021-11-03 16:37:23 train 4000, loss 2.173e+00, top1 51.29, top5 75.44
2021-11-03 16:45:48 train 5000, loss 2.186e+00, top1 50.99, top5 75.22
2021-11-03 16:45:48 train 5000, loss 2.185e+00, top1 51.08, top5 75.20
2021-11-03 16:45:48 train 5000, loss 2.182e+00, top1 51.12, top5 75.29
2021-11-03 16:46:11 valid 0000, loss 1.090e+00, top1 77.65, top5 88.24
2021-11-03 16:46:11 valid 0000, loss 1.090e+00, top1 77.65, top5 88.24
2021-11-03 16:46:11 valid 0000, loss 1.090e+00, top1 77.65, top5 88.24
2021-11-03 16:50:51 (JOBID 31582) epoch 7: train time 2538.41, inference time 289.92s, valid_top1 52.79 (best_top1 63.94), valid_top5 77.96
2021-11-03 16:50:52 (JOBID 31582) epoch 7: train time 2558.12, inference time 290.60s, valid_top1 52.79 (best_top1 63.94), valid_top5 77.96
2021-11-03 16:50:52 (JOBID 31582) epoch 7: train time 2535.78, inference time 290.94s, valid_top1 52.79 (best_top1 63.94), valid_top5 77.96
2021-11-03 16:51:06 train 0000, loss 2.329e+00, top1 47.06, top5 69.41
2021-11-03 16:51:06 train 0000, loss 1.800e+00, top1 58.82, top5 82.35
2021-11-03 16:51:06 train 0000, loss 2.418e+00, top1 42.35, top5 69.41
2021-11-03 16:59:26 train 1000, loss 2.168e+00, top1 51.34, top5 75.33
2021-11-03 16:59:26 train 1000, loss 2.182e+00, top1 51.22, top5 75.28
2021-11-03 16:59:26 train 1000, loss 2.184e+00, top1 51.07, top5 75.26
2021-11-03 17:07:39 train 2000, loss 2.178e+00, top1 51.21, top5 75.21
2021-11-03 17:07:39 train 2000, loss 2.192e+00, top1 50.92, top5 75.13
2021-11-03 17:07:39 train 2000, loss 2.187e+00, top1 51.04, top5 75.22
2021-11-03 17:16:00 train 3000, loss 2.187e+00, top1 51.01, top5 75.16
2021-11-03 17:16:00 train 3000, loss 2.198e+00, top1 50.75, top5 75.04
2021-11-03 17:16:00 train 3000, loss 2.189e+00, top1 50.96, top5 75.20
2021-11-03 17:24:19 train 4000, loss 2.195e+00, top1 50.83, top5 75.04
2021-11-03 17:24:19 train 4000, loss 2.200e+00, top1 50.68, top5 75.00
2021-11-03 17:24:19 train 4000, loss 2.196e+00, top1 50.86, top5 75.07
2021-11-03 17:32:44 train 5000, loss 2.202e+00, top1 50.70, top5 74.93
2021-11-03 17:32:44 train 5000, loss 2.205e+00, top1 50.64, top5 74.90
2021-11-03 17:32:44 train 5000, loss 2.198e+00, top1 50.82, top5 75.03
2021-11-03 17:33:06 valid 0000, loss 1.419e+00, top1 68.24, top5 84.71
2021-11-03 17:33:06 valid 0000, loss 1.419e+00, top1 68.24, top5 84.71
2021-11-03 17:33:06 valid 0000, loss 1.419e+00, top1 68.24, top5 84.71
2021-11-03 17:37:38 (JOBID 31582) epoch 8: train time 2524.66, inference time 281.46s, valid_top1 53.26 (best_top1 63.94), valid_top5 78.54
2021-11-03 17:37:42 (JOBID 31582) epoch 8: train time 2524.86, inference time 285.88s, valid_top1 53.26 (best_top1 63.94), valid_top5 78.54
2021-11-03 17:37:44 (JOBID 31582) epoch 8: train time 2525.42, inference time 287.59s, valid_top1 53.26 (best_top1 63.94), valid_top5 78.54
2021-11-03 17:37:57 train 0000, loss 2.223e+00, top1 38.82, top5 77.65
2021-11-03 17:37:52 train 0000, loss 2.072e+00, top1 54.12, top5 71.76
2021-11-03 17:37:57 train 0000, loss 2.201e+00, top1 57.65, top5 74.12
2021-11-03 17:46:26 train 1000, loss 2.191e+00, top1 51.07, top5 75.01
2021-11-03 17:46:26 train 1000, loss 2.195e+00, top1 50.63, top5 75.07
2021-11-03 17:46:26 train 1000, loss 2.185e+00, top1 51.09, top5 75.11
2021-11-03 17:54:46 train 2000, loss 2.199e+00, top1 50.77, top5 74.90
2021-11-03 17:54:46 train 2000, loss 2.205e+00, top1 50.61, top5 74.91
2021-11-03 17:54:46 train 2000, loss 2.197e+00, top1 50.77, top5 74.97
2021-11-03 18:03:17 train 3000, loss 2.209e+00, top1 50.61, top5 74.83
2021-11-03 18:03:17 train 3000, loss 2.203e+00, top1 50.67, top5 74.86
2021-11-03 18:03:17 train 3000, loss 2.206e+00, top1 50.64, top5 74.81
2021-11-03 18:11:39 train 4000, loss 2.208e+00, top1 50.57, top5 74.75
2021-11-03 18:11:39 train 4000, loss 2.210e+00, top1 50.55, top5 74.82
2021-11-03 18:11:39 train 4000, loss 2.211e+00, top1 50.52, top5 74.71
2021-11-03 18:20:04 train 5000, loss 2.211e+00, top1 50.54, top5 74.75
2021-11-03 18:20:04 train 5000, loss 2.214e+00, top1 50.46, top5 74.77
2021-11-03 18:20:04 train 5000, loss 2.212e+00, top1 50.48, top5 74.69
2021-11-03 18:20:27 valid 0000, loss 1.257e+00, top1 74.12, top5 85.88
2021-11-03 18:20:27 valid 0000, loss 1.257e+00, top1 74.12, top5 85.88
2021-11-03 18:20:27 valid 0000, loss 1.257e+00, top1 74.12, top5 85.88
2021-11-03 18:24:51 (JOBID 31582) epoch 9: train time 2554.21, inference time 274.48s, valid_top1 54.10 (best_top1 63.94), valid_top5 79.45
2021-11-03 18:25:05 (JOBID 31582) epoch 9: train time 2552.35, inference time 288.08s, valid_top1 54.10 (best_top1 63.94), valid_top5 79.45
2021-11-03 18:25:10 (JOBID 31582) epoch 9: train time 2558.64, inference time 293.21s, valid_top1 54.10 (best_top1 63.94), valid_top5 79.45
2021-11-03 18:25:06 train 0000, loss 2.365e+00, top1 47.06, top5 74.12
2021-11-03 18:25:20 train 0000, loss 2.229e+00, top1 54.12, top5 70.59
2021-11-03 18:25:24 train 0000, loss 1.881e+00, top1 57.65, top5 84.71
2021-11-03 18:33:52 train 1000, loss 2.198e+00, top1 50.91, top5 75.19
2021-11-03 18:33:52 train 1000, loss 2.206e+00, top1 50.76, top5 74.78
2021-11-03 18:33:52 train 1000, loss 2.194e+00, top1 50.84, top5 75.04
2021-11-03 18:42:17 train 2000, loss 2.195e+00, top1 50.83, top5 75.20
2021-11-03 18:42:17 train 2000, loss 2.205e+00, top1 50.72, top5 74.78
2021-11-03 18:42:17 train 2000, loss 2.204e+00, top1 50.66, top5 74.85
2021-11-03 18:50:50 train 3000, loss 2.214e+00, top1 50.56, top5 74.66
2021-11-03 18:50:50 train 3000, loss 2.206e+00, top1 50.58, top5 74.95
2021-11-03 18:50:50 train 3000, loss 2.210e+00, top1 50.57, top5 74.76
2021-11-03 18:59:12 train 4000, loss 2.211e+00, top1 50.51, top5 74.85
2021-11-03 18:59:12 train 4000, loss 2.214e+00, top1 50.51, top5 74.66
2021-11-03 18:59:12 train 4000, loss 2.214e+00, top1 50.50, top5 74.69
2021-11-03 19:07:34 train 5000, loss 2.215e+00, top1 50.47, top5 74.79
2021-11-03 19:07:34 train 5000, loss 2.216e+00, top1 50.49, top5 74.62
2021-11-03 19:07:34 train 5000, loss 2.218e+00, top1 50.46, top5 74.64
2021-11-03 19:07:57 valid 0000, loss 1.415e+00, top1 76.47, top5 87.06
2021-11-03 19:07:57 valid 0000, loss 1.415e+00, top1 76.47, top5 87.06
2021-11-03 19:07:57 valid 0000, loss 1.415e+00, top1 76.47, top5 87.06
2021-11-03 19:12:15 (JOBID 31582) epoch 10: train time 2556.97, inference time 268.71s, valid_top1 51.72 (best_top1 63.94), valid_top5 77.38
2021-11-03 19:12:31 (JOBID 31582) epoch 10: train time 2575.63, inference time 283.95s, valid_top1 51.72 (best_top1 63.94), valid_top5 77.38
2021-11-03 19:12:33 (JOBID 31582) epoch 10: train time 2561.82, inference time 286.57s, valid_top1 51.72 (best_top1 63.94), valid_top5 77.38
2021-11-03 19:12:45 train 0000, loss 2.093e+00, top1 58.82, top5 74.12
2021-11-03 19:12:29 train 0000, loss 2.398e+00, top1 43.53, top5 65.88
2021-11-03 19:12:47 train 0000, loss 2.470e+00, top1 42.35, top5 71.76
2021-11-03 19:21:24 train 1000, loss 2.207e+00, top1 50.52, top5 74.93
2021-11-03 19:21:24 train 1000, loss 2.205e+00, top1 50.58, top5 74.95
2021-11-03 19:21:24 train 1000, loss 2.183e+00, top1 51.12, top5 75.19
2021-11-03 19:29:51 train 2000, loss 2.210e+00, top1 50.43, top5 74.81
2021-11-03 19:29:51 train 2000, loss 2.211e+00, top1 50.47, top5 74.85
2021-11-03 19:29:52 train 2000, loss 2.195e+00, top1 50.82, top5 74.98
2021-11-03 19:38:22 train 3000, loss 2.218e+00, top1 50.36, top5 74.67
2021-11-03 19:38:22 train 3000, loss 2.216e+00, top1 50.36, top5 74.69
2021-11-03 19:38:22 train 3000, loss 2.204e+00, top1 50.68, top5 74.90
2021-11-03 19:46:50 train 4000, loss 2.222e+00, top1 50.26, top5 74.61
2021-11-03 19:46:50 train 4000, loss 2.219e+00, top1 50.39, top5 74.70
2021-11-03 19:46:50 train 4000, loss 2.212e+00, top1 50.53, top5 74.76
2021-11-03 19:55:24 train 5000, loss 2.222e+00, top1 50.33, top5 74.66
2021-11-03 19:55:24 train 5000, loss 2.217e+00, top1 50.43, top5 74.66
2021-11-03 19:55:24 train 5000, loss 2.223e+00, top1 50.24, top5 74.60
2021-11-03 19:55:47 valid 0000, loss 1.202e+00, top1 75.29, top5 85.88
2021-11-03 19:55:47 valid 0000, loss 1.202e+00, top1 75.29, top5 85.88
2021-11-03 19:55:47 valid 0000, loss 1.202e+00, top1 75.29, top5 85.88
2021-11-03 20:00:16 (JOBID 31582) epoch 11: train time 2582.86, inference time 279.83s, valid_top1 49.38 (best_top1 63.94), valid_top5 75.72
2021-11-03 20:00:28 (JOBID 31582) epoch 11: train time 2585.90, inference time 291.85s, valid_top1 49.38 (best_top1 63.94), valid_top5 75.72
2021-11-03 20:00:29 (JOBID 31582) epoch 11: train time 2600.94, inference time 292.36s, valid_top1 49.38 (best_top1 63.94), valid_top5 75.72
2021-11-03 20:00:31 train 0000, loss 2.623e+00, top1 43.53, top5 72.94
2021-11-03 20:00:42 train 0000, loss 2.049e+00, top1 51.76, top5 77.65
2021-11-03 20:00:42 train 0000, loss 2.459e+00, top1 45.88, top5 76.47
2021-11-03 20:09:20 train 1000, loss 2.197e+00, top1 50.69, top5 75.02
2021-11-03 20:09:20 train 1000, loss 2.202e+00, top1 50.71, top5 74.98
2021-11-03 20:09:20 train 1000, loss 2.203e+00, top1 50.76, top5 74.87
2021-11-03 20:17:55 train 2000, loss 2.209e+00, top1 50.59, top5 74.89
2021-11-03 20:17:55 train 2000, loss 2.211e+00, top1 50.45, top5 74.78
2021-11-03 20:17:56 train 2000, loss 2.211e+00, top1 50.49, top5 74.74
2021-11-03 20:26:25 train 3000, loss 2.214e+00, top1 50.45, top5 74.77
2021-11-03 20:26:25 train 3000, loss 2.217e+00, top1 50.41, top5 74.69
2021-11-03 20:26:25 train 3000, loss 2.217e+00, top1 50.37, top5 74.63
2021-11-03 20:34:50 train 4000, loss 2.217e+00, top1 50.37, top5 74.72
2021-11-03 20:34:50 train 4000, loss 2.220e+00, top1 50.34, top5 74.66
2021-11-03 20:34:50 train 4000, loss 2.221e+00, top1 50.28, top5 74.57
2021-11-03 20:43:13 train 5000, loss 2.222e+00, top1 50.24, top5 74.63
2021-11-03 20:43:13 train 5000, loss 2.225e+00, top1 50.23, top5 74.57
2021-11-03 20:43:13 train 5000, loss 2.227e+00, top1 50.18, top5 74.49
2021-11-03 20:43:36 valid 0000, loss 8.593e-01, top1 80.00, top5 92.94
2021-11-03 20:43:36 valid 0000, loss 8.593e-01, top1 80.00, top5 92.94
2021-11-03 20:43:36 valid 0000, loss 8.593e-01, top1 80.00, top5 92.94
2021-11-03 20:47:55 (JOBID 31582) epoch 12: train time 2577.12, inference time 269.58s, valid_top1 52.68 (best_top1 63.94), valid_top5 78.18
2021-11-03 20:48:08 (JOBID 31582) epoch 12: train time 2589.10, inference time 282.39s, valid_top1 52.68 (best_top1 63.94), valid_top5 78.18
2021-11-03 20:48:09 (JOBID 31582) epoch 12: train time 2576.75, inference time 283.58s, valid_top1 52.68 (best_top1 63.94), valid_top5 78.18
2021-11-03 20:48:09 train 0000, loss 2.314e+00, top1 47.06, top5 74.12
2021-11-03 20:48:22 train 0000, loss 2.145e+00, top1 55.29, top5 75.29
2021-11-03 20:48:22 train 0000, loss 1.897e+00, top1 55.29, top5 80.00
2021-11-03 20:56:59 train 1000, loss 2.199e+00, top1 50.81, top5 74.88
2021-11-03 20:56:59 train 1000, loss 2.205e+00, top1 50.74, top5 74.88
2021-11-03 20:56:59 train 1000, loss 2.213e+00, top1 50.37, top5 74.73
2021-11-03 21:05:33 train 2000, loss 2.211e+00, top1 50.56, top5 74.71
2021-11-03 21:05:33 train 2000, loss 2.217e+00, top1 50.36, top5 74.65
2021-11-03 21:05:33 train 2000, loss 2.213e+00, top1 50.39, top5 74.74
2021-11-03 21:13:56 train 3000, loss 2.221e+00, top1 50.31, top5 74.59
2021-11-03 21:13:56 train 3000, loss 2.214e+00, top1 50.46, top5 74.62
2021-11-03 21:13:56 train 3000, loss 2.215e+00, top1 50.34, top5 74.75
2021-11-03 21:22:15 train 4000, loss 2.226e+00, top1 50.23, top5 74.49
2021-11-03 21:22:15 train 4000, loss 2.222e+00, top1 50.22, top5 74.60
2021-11-03 21:22:15 train 4000, loss 2.222e+00, top1 50.29, top5 74.51
2021-11-03 21:30:35 train 5000, loss 2.223e+00, top1 50.31, top5 74.52
2021-11-03 21:30:35 train 5000, loss 2.225e+00, top1 50.18, top5 74.56
2021-11-03 21:30:35 train 5000, loss 2.229e+00, top1 50.18, top5 74.49
2021-11-03 21:30:57 valid 0000, loss 1.479e+00, top1 67.06, top5 84.71
2021-11-03 21:30:57 valid 0000, loss 1.479e+00, top1 67.06, top5 84.71
2021-11-03 21:30:57 valid 0000, loss 1.479e+00, top1 67.06, top5 84.71
2021-11-03 21:35:48 (JOBID 31582) epoch 13: train time 2559.00, inference time 300.54s, valid_top1 52.30 (best_top1 63.94), valid_top5 77.79
2021-11-03 21:35:48 (JOBID 31582) epoch 13: train time 2572.02, inference time 300.95s, valid_top1 52.30 (best_top1 63.94), valid_top5 77.79
2021-11-03 21:35:48 (JOBID 31582) epoch 13: train time 2558.12, inference time 301.37s, valid_top1 52.30 (best_top1 63.94), valid_top5 77.79
2021-11-03 21:36:03 train 0000, loss 2.095e+00, top1 49.41, top5 76.47
2021-11-03 21:36:03 train 0000, loss 1.769e+00, top1 54.12, top5 78.82
2021-11-03 21:36:03 train 0000, loss 2.403e+00, top1 47.06, top5 70.59
2021-11-03 21:44:51 train 1000, loss 2.203e+00, top1 50.73, top5 74.87
2021-11-03 21:44:51 train 1000, loss 2.203e+00, top1 50.47, top5 74.75
2021-11-03 21:44:52 train 1000, loss 2.215e+00, top1 50.44, top5 74.66
2021-11-03 21:53:20 train 2000, loss 2.211e+00, top1 50.51, top5 74.73
2021-11-03 21:53:20 train 2000, loss 2.216e+00, top1 50.26, top5 74.63
2021-11-03 21:53:20 train 2000, loss 2.217e+00, top1 50.39, top5 74.65
2021-11-03 22:02:01 train 3000, loss 2.215e+00, top1 50.45, top5 74.68
2021-11-03 22:02:01 train 3000, loss 2.221e+00, top1 50.19, top5 74.58
2021-11-03 22:02:01 train 3000, loss 2.220e+00, top1 50.35, top5 74.67
2021-11-03 22:10:42 train 4000, loss 2.221e+00, top1 50.34, top5 74.57
2021-11-03 22:10:42 train 4000, loss 2.224e+00, top1 50.13, top5 74.51
2021-11-03 22:10:42 train 4000, loss 2.221e+00, top1 50.29, top5 74.63
2021-11-03 22:19:21 train 5000, loss 2.223e+00, top1 50.28, top5 74.56
2021-11-03 22:19:21 train 5000, loss 2.228e+00, top1 50.08, top5 74.46
2021-11-03 22:19:21 train 5000, loss 2.225e+00, top1 50.22, top5 74.57
2021-11-03 22:19:43 valid 0000, loss 1.062e+00, top1 76.47, top5 88.24
2021-11-03 22:19:43 valid 0000, loss 1.062e+00, top1 76.47, top5 88.24
2021-11-03 22:19:44 valid 0000, loss 1.062e+00, top1 76.47, top5 88.24
2021-11-03 22:24:04 (JOBID 31582) epoch 14: train time 2624.97, inference time 270.87s, valid_top1 52.79 (best_top1 63.94), valid_top5 78.63
2021-11-03 22:24:15 (JOBID 31582) epoch 14: train time 2625.71, inference time 281.75s, valid_top1 52.79 (best_top1 63.94), valid_top5 78.63
2021-11-03 22:24:18 (JOBID 31582) epoch 14: train time 2625.61, inference time 284.44s, valid_top1 52.79 (best_top1 63.94), valid_top5 78.63
2021-11-03 22:24:30 train 0000, loss 1.798e+00, top1 52.94, top5 84.71
2021-11-03 22:24:18 train 0000, loss 2.318e+00, top1 43.53, top5 70.59
2021-11-03 22:24:32 train 0000, loss 1.992e+00, top1 51.76, top5 78.82
2021-11-03 22:33:30 train 1000, loss 2.189e+00, top1 50.64, top5 75.21
2021-11-03 22:33:30 train 1000, loss 2.200e+00, top1 50.50, top5 75.02
2021-11-03 22:33:31 train 1000, loss 2.201e+00, top1 50.53, top5 74.98
2021-11-03 22:42:14 train 2000, loss 2.206e+00, top1 50.43, top5 74.89
2021-11-03 22:42:14 train 2000, loss 2.207e+00, top1 50.41, top5 74.93
2021-11-03 22:42:14 train 2000, loss 2.214e+00, top1 50.36, top5 74.72
2021-11-03 22:50:50 train 3000, loss 2.213e+00, top1 50.27, top5 74.75
2021-11-03 22:50:50 train 3000, loss 2.214e+00, top1 50.30, top5 74.82
2021-11-03 22:50:50 train 3000, loss 2.219e+00, top1 50.25, top5 74.63
2021-11-03 22:59:27 train 4000, loss 2.220e+00, top1 50.16, top5 74.64
2021-11-03 22:59:27 train 4000, loss 2.220e+00, top1 50.22, top5 74.72
2021-11-03 22:59:27 train 4000, loss 2.220e+00, top1 50.26, top5 74.62
2021-11-03 23:08:08 train 5000, loss 2.225e+00, top1 50.12, top5 74.62
2021-11-03 23:08:08 train 5000, loss 2.223e+00, top1 50.15, top5 74.62
2021-11-03 23:08:08 train 5000, loss 2.223e+00, top1 50.23, top5 74.60
2021-11-03 23:08:31 valid 0000, loss 8.292e-01, top1 78.82, top5 92.94
2021-11-03 23:08:31 valid 0000, loss 8.292e-01, top1 78.82, top5 92.94
2021-11-03 23:08:31 valid 0000, loss 8.292e-01, top1 78.82, top5 92.94
2021-11-03 23:13:20 (JOBID 31582) epoch 15: train time 2645.07, inference time 299.59s, valid_top1 52.69 (best_top1 63.94), valid_top5 78.08
2021-11-03 23:13:21 (JOBID 31582) epoch 15: train time 2642.59, inference time 300.33s, valid_top1 52.69 (best_top1 63.94), valid_top5 78.08
2021-11-03 23:13:22 (JOBID 31582) epoch 15: train time 2656.28, inference time 300.98s, valid_top1 52.69 (best_top1 63.94), valid_top5 78.08
2021-11-03 23:13:36 train 0000, loss 1.948e+00, top1 54.12, top5 78.82
2021-11-03 23:13:36 train 0000, loss 2.235e+00, top1 50.59, top5 71.76
2021-11-03 23:13:36 train 0000, loss 2.304e+00, top1 44.71, top5 77.65
2021-11-03 23:22:09 train 1000, loss 2.207e+00, top1 50.52, top5 74.68
2021-11-03 23:22:09 train 1000, loss 2.199e+00, top1 50.61, top5 74.96
2021-11-03 23:22:09 train 1000, loss 2.200e+00, top1 50.33, top5 74.93
2021-11-03 23:30:44 train 2000, loss 2.215e+00, top1 50.42, top5 74.54
2021-11-03 23:30:44 train 2000, loss 2.207e+00, top1 50.54, top5 74.86
2021-11-03 23:30:44 train 2000, loss 2.214e+00, top1 50.15, top5 74.69
2021-11-03 23:39:09 train 3000, loss 2.222e+00, top1 50.27, top5 74.53
2021-11-03 23:39:09 train 3000, loss 2.215e+00, top1 50.41, top5 74.70
2021-11-03 23:39:09 train 3000, loss 2.219e+00, top1 50.17, top5 74.66
2021-11-03 23:47:35 train 4000, loss 2.224e+00, top1 50.22, top5 74.48
2021-11-03 23:47:35 train 4000, loss 2.219e+00, top1 50.35, top5 74.65
2021-11-03 23:47:35 train 4000, loss 2.226e+00, top1 50.12, top5 74.53
2021-11-03 23:56:08 train 5000, loss 2.219e+00, top1 50.31, top5 74.63
2021-11-03 23:56:08 train 5000, loss 2.226e+00, top1 50.21, top5 74.45
2021-11-03 23:56:08 train 5000, loss 2.226e+00, top1 50.12, top5 74.54
2021-11-03 23:56:31 valid 0000, loss 8.250e-01, top1 81.18, top5 91.76
2021-11-03 23:56:31 valid 0000, loss 8.250e-01, top1 81.18, top5 91.76
2021-11-03 23:56:31 valid 0000, loss 8.250e-01, top1 81.18, top5 91.76
2021-11-04 00:01:08 (JOBID 31582) epoch 16: train time 2579.92, inference time 287.39s, valid_top1 48.97 (best_top1 63.94), valid_top5 75.03
2021-11-04 00:01:10 (JOBID 31582) epoch 16: train time 2579.43, inference time 288.65s, valid_top1 48.97 (best_top1 63.94), valid_top5 75.03
2021-11-04 00:01:11 (JOBID 31582) epoch 16: train time 2580.44, inference time 289.50s, valid_top1 48.97 (best_top1 63.94), valid_top5 75.03
2021-11-04 00:01:23 train 0000, loss 1.932e+00, top1 60.00, top5 78.82
2021-11-04 00:01:24 train 0000, loss 2.359e+00, top1 56.47, top5 68.24
2021-11-04 00:01:24 train 0000, loss 2.137e+00, top1 55.29, top5 77.65
2021-11-04 00:09:57 train 1000, loss 2.200e+00, top1 50.45, top5 74.99
2021-11-04 00:09:57 train 1000, loss 2.203e+00, top1 50.44, top5 74.88
2021-11-04 00:09:57 train 1000, loss 2.208e+00, top1 50.61, top5 74.78
2021-11-04 00:18:32 train 2000, loss 2.212e+00, top1 50.34, top5 74.70
2021-11-04 00:18:32 train 2000, loss 2.216e+00, top1 50.31, top5 74.74
2021-11-04 00:18:32 train 2000, loss 2.217e+00, top1 50.53, top5 74.57
2021-11-04 00:26:56 train 3000, loss 2.217e+00, top1 50.36, top5 74.64
2021-11-04 00:26:56 train 3000, loss 2.220e+00, top1 50.25, top5 74.69
2021-11-04 00:26:56 train 3000, loss 2.218e+00, top1 50.42, top5 74.58
2021-11-04 00:35:22 train 4000, loss 2.216e+00, top1 50.39, top5 74.67
2021-11-04 00:35:22 train 4000, loss 2.222e+00, top1 50.23, top5 74.66
2021-11-04 00:35:22 train 4000, loss 2.222e+00, top1 50.34, top5 74.52
2021-11-04 00:43:57 train 5000, loss 2.227e+00, top1 50.14, top5 74.57
2021-11-04 00:43:57 train 5000, loss 2.217e+00, top1 50.39, top5 74.67
2021-11-04 00:43:57 train 5000, loss 2.228e+00, top1 50.24, top5 74.43
2021-11-04 00:44:19 valid 0000, loss 7.591e-01, top1 82.35, top5 91.76
2021-11-04 00:44:19 valid 0000, loss 7.591e-01, top1 82.35, top5 91.76
2021-11-04 00:44:19 valid 0000, loss 7.591e-01, top1 82.35, top5 91.76
2021-11-04 00:48:41 (JOBID 31582) epoch 17: train time 2579.35, inference time 272.00s, valid_top1 48.92 (best_top1 63.94), valid_top5 74.61
2021-11-04 00:48:53 (JOBID 31582) epoch 17: train time 2578.33, inference time 283.35s, valid_top1 48.92 (best_top1 63.94), valid_top5 74.61
2021-11-04 00:48:55 (JOBID 31582) epoch 17: train time 2580.77, inference time 286.18s, valid_top1 48.92 (best_top1 63.94), valid_top5 74.61
2021-11-04 00:49:07 train 0000, loss 1.885e+00, top1 56.47, top5 81.18
2021-11-04 00:48:55 train 0000, loss 2.268e+00, top1 47.06, top5 76.47
2021-11-04 00:49:10 train 0000, loss 2.366e+00, top1 43.53, top5 68.24
2021-11-04 00:57:39 train 1000, loss 2.205e+00, top1 50.63, top5 74.77
2021-11-04 00:57:39 train 1000, loss 2.213e+00, top1 50.32, top5 74.68
2021-11-04 00:57:39 train 1000, loss 2.212e+00, top1 50.31, top5 74.85
2021-11-04 01:06:12 train 2000, loss 2.214e+00, top1 50.46, top5 74.73
2021-11-04 01:06:12 train 2000, loss 2.216e+00, top1 50.33, top5 74.64
2021-11-04 01:06:12 train 2000, loss 2.216e+00, top1 50.33, top5 74.72
2021-11-04 01:14:35 train 3000, loss 2.217e+00, top1 50.37, top5 74.66
2021-11-04 01:14:35 train 3000, loss 2.216e+00, top1 50.44, top5 74.66
2021-11-04 01:14:35 train 3000, loss 2.219e+00, top1 50.31, top5 74.64
2021-11-04 01:22:56 train 4000, loss 2.225e+00, top1 50.23, top5 74.54
2021-11-04 01:22:56 train 4000, loss 2.223e+00, top1 50.29, top5 74.55
2021-11-04 01:22:56 train 4000, loss 2.225e+00, top1 50.17, top5 74.55
2021-11-04 01:31:28 train 5000, loss 2.226e+00, top1 50.23, top5 74.51
2021-11-04 01:31:28 train 5000, loss 2.224e+00, top1 50.28, top5 74.54
2021-11-04 01:31:28 train 5000, loss 2.228e+00, top1 50.15, top5 74.50
2021-11-04 01:31:50 valid 0000, loss 8.778e-01, top1 81.18, top5 90.59
2021-11-04 01:31:50 valid 0000, loss 8.778e-01, top1 81.18, top5 90.59
2021-11-04 01:31:50 valid 0000, loss 8.778e-01, top1 81.18, top5 90.59
2021-11-04 01:36:24 (JOBID 31582) epoch 18: train time 2564.89, inference time 283.49s, valid_top1 52.02 (best_top1 63.94), valid_top5 77.64
2021-11-04 01:36:24 (JOBID 31582) epoch 18: train time 2579.01, inference time 283.94s, valid_top1 52.02 (best_top1 63.94), valid_top5 77.64
2021-11-04 01:36:25 (JOBID 31582) epoch 18: train time 2567.38, inference time 284.95s, valid_top1 52.02 (best_top1 63.94), valid_top5 77.64
2021-11-04 01:36:38 train 0000, loss 2.179e+00, top1 47.06, top5 76.47
2021-11-04 01:36:38 train 0000, loss 2.556e+00, top1 41.18, top5 63.53
2021-11-04 01:36:40 train 0000, loss 2.199e+00, top1 55.29, top5 76.47
2021-11-04 01:45:07 train 1000, loss 2.203e+00, top1 50.68, top5 74.87
2021-11-04 01:45:06 train 1000, loss 2.188e+00, top1 50.83, top5 75.19
2021-11-04 01:45:07 train 1000, loss 2.219e+00, top1 50.28, top5 74.66
2021-11-04 01:53:34 train 2000, loss 2.215e+00, top1 50.31, top5 74.70
2021-11-04 01:53:34 train 2000, loss 2.204e+00, top1 50.65, top5 74.95
2021-11-04 01:53:34 train 2000, loss 2.217e+00, top1 50.26, top5 74.68
2021-11-04 02:01:49 train 3000, loss 2.221e+00, top1 50.23, top5 74.61
2021-11-04 02:01:49 train 3000, loss 2.207e+00, top1 50.58, top5 74.87
2021-11-04 02:01:49 train 3000, loss 2.221e+00, top1 50.26, top5 74.59
2021-11-04 02:10:06 train 4000, loss 2.213e+00, top1 50.47, top5 74.74
2021-11-04 02:10:06 train 4000, loss 2.222e+00, top1 50.21, top5 74.60
2021-11-04 02:10:06 train 4000, loss 2.226e+00, top1 50.11, top5 74.52
2021-11-04 02:18:22 train 5000, loss 2.223e+00, top1 50.21, top5 74.58
2021-11-04 02:18:22 train 5000, loss 2.218e+00, top1 50.38, top5 74.68
2021-11-04 02:18:22 train 5000, loss 2.229e+00, top1 50.10, top5 74.45
2021-11-04 02:18:45 valid 0000, loss 1.577e+00, top1 64.71, top5 85.88
2021-11-04 02:18:45 valid 0000, loss 1.577e+00, top1 64.71, top5 85.88
2021-11-04 02:18:45 valid 0000, loss 1.577e+00, top1 64.71, top5 85.88
2021-11-04 02:23:20 (JOBID 31582) epoch 19: train time 2531.01, inference time 285.06s, valid_top1 52.43 (best_top1 63.94), valid_top5 77.68
2021-11-04 02:23:20 (JOBID 31582) epoch 19: train time 2530.64, inference time 285.27s, valid_top1 52.43 (best_top1 63.94), valid_top5 77.68
2021-11-04 02:23:23 (JOBID 31582) epoch 19: train time 2529.30, inference time 287.89s, valid_top1 52.43 (best_top1 63.94), valid_top5 77.68
2021-11-04 02:23:34 train 0000, loss 2.246e+00, top1 51.76, top5 74.12
2021-11-04 02:23:34 train 0000, loss 2.287e+00, top1 45.88, top5 72.94
2021-11-04 02:23:37 train 0000, loss 1.952e+00, top1 55.29, top5 74.12
2021-11-04 02:31:52 train 1000, loss 2.215e+00, top1 50.38, top5 74.81
2021-11-04 02:31:52 train 1000, loss 2.199e+00, top1 50.80, top5 74.96
2021-11-04 02:31:52 train 1000, loss 2.213e+00, top1 50.42, top5 74.75
2021-11-04 02:40:18 train 2000, loss 2.205e+00, top1 50.47, top5 74.87
2021-11-04 02:40:18 train 2000, loss 2.220e+00, top1 50.31, top5 74.74
2021-11-04 02:40:18 train 2000, loss 2.215e+00, top1 50.35, top5 74.71
2021-11-04 02:48:33 train 3000, loss 2.223e+00, top1 50.25, top5 74.66
2021-11-04 02:48:33 train 3000, loss 2.206e+00, top1 50.54, top5 74.84
2021-11-04 02:48:33 train 3000, loss 2.224e+00, top1 50.14, top5 74.59
2021-11-04 02:56:53 train 4000, loss 2.211e+00, top1 50.45, top5 74.78
2021-11-04 02:56:52 train 4000, loss 2.226e+00, top1 50.22, top5 74.59
2021-11-04 02:56:53 train 4000, loss 2.227e+00, top1 50.16, top5 74.52
2021-11-04 03:05:14 train 5000, loss 2.230e+00, top1 50.12, top5 74.53
2021-11-04 03:05:14 train 5000, loss 2.232e+00, top1 50.11, top5 74.42
2021-11-04 03:05:14 train 5000, loss 2.214e+00, top1 50.41, top5 74.70
2021-11-04 03:05:37 valid 0000, loss 1.020e+00, top1 78.82, top5 89.41
2021-11-04 03:05:37 valid 0000, loss 1.020e+00, top1 78.82, top5 89.41
2021-11-04 03:05:37 valid 0000, loss 1.020e+00, top1 78.82, top5 89.41
2021-11-04 03:09:55 (JOBID 31582) epoch 20: train time 2526.56, inference time 268.70s, valid_top1 52.66 (best_top1 63.94), valid_top5 77.93
2021-11-04 03:10:12 (JOBID 31582) epoch 20: train time 2526.72, inference time 285.84s, valid_top1 52.66 (best_top1 63.94), valid_top5 77.93
2021-11-04 03:10:13 (JOBID 31582) epoch 20: train time 2523.63, inference time 286.38s, valid_top1 52.66 (best_top1 63.94), valid_top5 77.93
2021-11-04 03:10:26 train 0000, loss 2.366e+00, top1 48.24, top5 71.76
2021-11-04 03:10:09 train 0000, loss 2.072e+00, top1 51.76, top5 75.29
2021-11-04 03:10:26 train 0000, loss 1.781e+00, top1 55.29, top5 82.35
2021-11-04 03:18:44 train 1000, loss 2.200e+00, top1 50.80, top5 75.04
2021-11-04 03:18:44 train 1000, loss 2.213e+00, top1 50.37, top5 74.72
2021-11-04 03:18:44 train 1000, loss 2.195e+00, top1 50.76, top5 74.88
2021-11-04 03:27:08 train 2000, loss 2.208e+00, top1 50.44, top5 74.85
2021-11-04 03:27:08 train 2000, loss 2.217e+00, top1 50.27, top5 74.67
2021-11-04 03:27:08 train 2000, loss 2.200e+00, top1 50.64, top5 74.89
2021-11-04 03:35:25 train 3000, loss 2.214e+00, top1 50.30, top5 74.71
2021-11-04 03:35:25 train 3000, loss 2.221e+00, top1 50.19, top5 74.62
2021-11-04 03:35:25 train 3000, loss 2.209e+00, top1 50.51, top5 74.80
2021-11-04 03:43:45 train 4000, loss 2.218e+00, top1 50.27, top5 74.70
2021-11-04 03:43:45 train 4000, loss 2.225e+00, top1 50.19, top5 74.53
2021-11-04 03:43:45 train 4000, loss 2.216e+00, top1 50.37, top5 74.66
2021-11-04 03:52:01 train 5000, loss 2.221e+00, top1 50.29, top5 74.62
2021-11-04 03:52:01 train 5000, loss 2.225e+00, top1 50.19, top5 74.51
2021-11-04 03:52:01 train 5000, loss 2.224e+00, top1 50.14, top5 74.60
2021-11-04 03:52:24 valid 0000, loss 1.366e+00, top1 69.41, top5 88.24
2021-11-04 03:52:24 valid 0000, loss 1.366e+00, top1 69.41, top5 88.24
2021-11-04 03:52:24 valid 0000, loss 1.366e+00, top1 69.41, top5 88.24
2021-11-04 03:56:44 (JOBID 31582) epoch 21: train time 2520.37, inference time 270.62s, valid_top1 51.86 (best_top1 63.94), valid_top5 77.21
2021-11-04 03:56:58 (JOBID 31582) epoch 21: train time 2521.18, inference time 284.19s, valid_top1 51.86 (best_top1 63.94), valid_top5 77.21
2021-11-04 03:57:00 (JOBID 31582) epoch 21: train time 2538.25, inference time 286.11s, valid_top1 51.86 (best_top1 63.94), valid_top5 77.21
2021-11-04 03:57:12 train 0000, loss 2.080e+00, top1 54.12, top5 80.00
2021-11-04 03:56:58 train 0000, loss 1.689e+00, top1 60.00, top5 84.71
2021-11-04 03:57:13 train 0000, loss 2.207e+00, top1 50.59, top5 75.29
2021-11-04 04:05:45 train 1000, loss 2.201e+00, top1 50.54, top5 74.96
2021-11-04 04:05:45 train 1000, loss 2.199e+00, top1 50.58, top5 74.92
2021-11-04 04:05:45 train 1000, loss 2.203e+00, top1 50.50, top5 75.06
2021-11-04 04:14:23 train 2000, loss 2.211e+00, top1 50.45, top5 74.80
2021-11-04 04:14:24 train 2000, loss 2.211e+00, top1 50.37, top5 74.86
2021-11-04 04:14:24 train 2000, loss 2.212e+00, top1 50.43, top5 74.76
2021-11-04 04:23:04 train 3000, loss 2.216e+00, top1 50.38, top5 74.66
2021-11-04 04:23:04 train 3000, loss 2.216e+00, top1 50.39, top5 74.67
2021-11-04 04:23:04 train 3000, loss 2.215e+00, top1 50.30, top5 74.77
2021-11-04 04:31:48 train 4000, loss 2.222e+00, top1 50.28, top5 74.62
2021-11-04 04:31:48 train 4000, loss 2.220e+00, top1 50.31, top5 74.59
2021-11-04 04:31:48 train 4000, loss 2.219e+00, top1 50.28, top5 74.68
2021-11-04 04:40:36 train 5000, loss 2.225e+00, top1 50.20, top5 74.59
2021-11-04 04:40:36 train 5000, loss 2.226e+00, top1 50.19, top5 74.51
2021-11-04 04:40:37 train 5000, loss 2.224e+00, top1 50.24, top5 74.58
2021-11-04 04:41:00 valid 0000, loss 1.243e+00, top1 71.76, top5 89.41
2021-11-04 04:41:00 valid 0000, loss 1.243e+00, top1 71.76, top5 89.41
2021-11-04 04:41:00 valid 0000, loss 1.243e+00, top1 71.76, top5 89.41
2021-11-04 04:45:43 (JOBID 31582) epoch 22: train time 2630.22, inference time 292.75s, valid_top1 48.61 (best_top1 63.94), valid_top5 74.29
2021-11-04 04:45:43 (JOBID 31582) epoch 22: train time 2632.09, inference time 292.74s, valid_top1 48.61 (best_top1 63.94), valid_top5 74.29
2021-11-04 04:45:45 (JOBID 31582) epoch 22: train time 2645.68, inference time 294.58s, valid_top1 48.61 (best_top1 63.94), valid_top5 74.29
2021-11-04 04:45:56 train 0000, loss 2.067e+00, top1 44.71, top5 76.47
2021-11-04 04:45:56 train 0000, loss 2.165e+00, top1 52.94, top5 74.12
2021-11-04 04:45:59 train 0000, loss 2.402e+00, top1 45.88, top5 75.29
2021-11-04 04:54:49 train 1000, loss 2.216e+00, top1 50.39, top5 74.57
2021-11-04 04:54:49 train 1000, loss 2.194e+00, top1 50.76, top5 74.93
2021-11-04 04:54:49 train 1000, loss 2.201e+00, top1 50.56, top5 75.07
2021-11-04 05:03:47 train 2000, loss 2.206e+00, top1 50.62, top5 74.71
2021-11-04 05:03:47 train 2000, loss 2.225e+00, top1 50.33, top5 74.50
2021-11-04 05:03:47 train 2000, loss 2.206e+00, top1 50.51, top5 74.86
2021-11-04 05:12:37 train 3000, loss 2.224e+00, top1 50.30, top5 74.58
2021-11-04 05:12:37 train 3000, loss 2.215e+00, top1 50.45, top5 74.67
2021-11-04 05:12:37 train 3000, loss 2.213e+00, top1 50.35, top5 74.74
2021-11-04 05:21:26 train 4000, loss 2.222e+00, top1 50.30, top5 74.62
2021-11-04 05:21:26 train 4000, loss 2.222e+00, top1 50.32, top5 74.54
2021-11-04 05:21:26 train 4000, loss 2.221e+00, top1 50.22, top5 74.63
2021-11-04 05:30:13 train 5000, loss 2.223e+00, top1 50.27, top5 74.59
2021-11-04 05:30:13 train 5000, loss 2.226e+00, top1 50.25, top5 74.50
2021-11-04 05:30:13 train 5000, loss 2.224e+00, top1 50.19, top5 74.57
2021-11-04 05:30:36 valid 0000, loss 9.105e-01, top1 77.65, top5 90.59
2021-11-04 05:30:36 valid 0000, loss 9.105e-01, top1 77.65, top5 90.59
2021-11-04 05:30:36 valid 0000, loss 9.105e-01, top1 77.65, top5 90.59
2021-11-04 05:35:09 (JOBID 31582) epoch 23: train time 2683.54, inference time 283.14s, valid_top1 53.33 (best_top1 63.94), valid_top5 78.75
2021-11-04 05:35:19 (JOBID 31582) epoch 23: train time 2681.26, inference time 292.44s, valid_top1 53.33 (best_top1 63.94), valid_top5 78.75
2021-11-04 05:35:19 (JOBID 31582) epoch 23: train time 2683.53, inference time 292.71s, valid_top1 53.33 (best_top1 63.94), valid_top5 78.75
2021-11-04 05:35:23 train 0000, loss 2.678e+00, top1 45.88, top5 68.24
2021-11-04 05:35:33 train 0000, loss 2.371e+00, top1 43.53, top5 74.12
2021-11-04 05:35:33 train 0000, loss 2.199e+00, top1 45.88, top5 72.94
2021-11-04 05:44:07 train 1000, loss 2.201e+00, top1 50.82, top5 74.87
2021-11-04 05:44:07 train 1000, loss 2.201e+00, top1 50.47, top5 74.90
2021-11-04 05:44:07 train 1000, loss 2.207e+00, top1 50.52, top5 74.78
2021-11-04 05:52:47 train 2000, loss 2.205e+00, top1 50.48, top5 74.82
2021-11-04 05:52:47 train 2000, loss 2.214e+00, top1 50.42, top5 74.61
2021-11-04 05:52:47 train 2000, loss 2.207e+00, top1 50.57, top5 74.80
2021-11-04 06:01:31 train 3000, loss 2.213e+00, top1 50.38, top5 74.72
2021-11-04 06:01:31 train 3000, loss 2.220e+00, top1 50.29, top5 74.56
2021-11-04 06:01:31 train 3000, loss 2.219e+00, top1 50.39, top5 74.56
2021-11-04 06:10:14 train 4000, loss 2.220e+00, top1 50.30, top5 74.59
2021-11-04 06:10:14 train 4000, loss 2.222e+00, top1 50.26, top5 74.53
2021-11-04 06:10:14 train 4000, loss 2.223e+00, top1 50.34, top5 74.51
2021-11-04 06:19:05 train 5000, loss 2.222e+00, top1 50.25, top5 74.53
2021-11-04 06:19:05 train 5000, loss 2.224e+00, top1 50.21, top5 74.51
2021-11-04 06:19:05 train 5000, loss 2.225e+00, top1 50.32, top5 74.50
2021-11-04 06:19:28 valid 0000, loss 9.268e-01, top1 80.00, top5 92.94
2021-11-04 06:19:28 valid 0000, loss 9.268e-01, top1 80.00, top5 92.94
2021-11-04 06:19:28 valid 0000, loss 9.268e-01, top1 80.00, top5 92.94
2021-11-04 06:23:59 (JOBID 31582) epoch 24: train time 2639.48, inference time 281.25s, valid_top1 51.91 (best_top1 63.94), valid_top5 77.74
2021-11-04 06:24:00 (JOBID 31582) epoch 24: train time 2649.18, inference time 281.13s, valid_top1 51.91 (best_top1 63.94), valid_top5 77.74
2021-11-04 06:24:06 (JOBID 31582) epoch 24: train time 2639.54, inference time 287.25s, valid_top1 51.91 (best_top1 63.94), valid_top5 77.74
2021-11-04 06:24:14 train 0000, loss 2.295e+00, top1 51.76, top5 74.12
2021-11-04 06:24:14 train 0000, loss 2.011e+00, top1 52.94, top5 81.18
2021-11-04 06:24:20 train 0000, loss 1.975e+00, top1 52.94, top5 85.88
2021-11-04 06:32:45 train 1000, loss 2.212e+00, top1 50.46, top5 74.69
2021-11-04 06:32:45 train 1000, loss 2.201e+00, top1 50.55, top5 74.98
2021-11-04 06:32:45 train 1000, loss 2.200e+00, top1 50.81, top5 74.96
2021-11-04 06:41:23 train 2000, loss 2.217e+00, top1 50.39, top5 74.63
2021-11-04 06:41:23 train 2000, loss 2.213e+00, top1 50.50, top5 74.75
2021-11-04 06:41:24 train 2000, loss 2.211e+00, top1 50.54, top5 74.77
2021-11-04 06:49:52 train 3000, loss 2.220e+00, top1 50.30, top5 74.56
2021-11-04 06:49:52 train 3000, loss 2.215e+00, top1 50.47, top5 74.75
2021-11-04 06:49:52 train 3000, loss 2.219e+00, top1 50.33, top5 74.61
2021-11-04 06:58:30 train 4000, loss 2.219e+00, top1 50.36, top5 74.67
2021-11-04 06:58:30 train 4000, loss 2.226e+00, top1 50.23, top5 74.51
2021-11-04 06:58:30 train 4000, loss 2.222e+00, top1 50.23, top5 74.58
2021-11-04 07:06:58 train 5000, loss 2.223e+00, top1 50.26, top5 74.61
2021-11-04 07:06:58 train 5000, loss 2.228e+00, top1 50.18, top5 74.44
2021-11-04 07:06:58 train 5000, loss 2.226e+00, top1 50.14, top5 74.50
2021-11-04 07:07:21 valid 0000, loss 1.106e+00, top1 74.12, top5 85.88
2021-11-04 07:07:21 valid 0000, loss 1.106e+00, top1 74.12, top5 85.88
2021-11-04 07:07:21 valid 0000, loss 1.106e+00, top1 74.12, top5 85.88
2021-11-04 07:11:40 (JOBID 31582) epoch 25: train time 2584.98, inference time 268.96s, valid_top1 50.18 (best_top1 63.94), valid_top5 76.33
2021-11-04 07:11:56 (JOBID 31582) epoch 25: train time 2591.24, inference time 285.36s, valid_top1 50.18 (best_top1 63.94), valid_top5 76.33
2021-11-04 07:11:57 (JOBID 31582) epoch 25: train time 2591.28, inference time 285.73s, valid_top1 50.18 (best_top1 63.94), valid_top5 76.33
2021-11-04 07:11:53 train 0000, loss 2.124e+00, top1 51.76, top5 77.65
2021-11-04 07:12:10 train 0000, loss 2.491e+00, top1 45.88, top5 69.41
2021-11-04 07:12:10 train 0000, loss 2.458e+00, top1 50.59, top5 69.41
2021-11-04 07:20:46 train 1000, loss 2.203e+00, top1 50.49, top5 74.90
2021-11-04 07:20:46 train 1000, loss 2.187e+00, top1 50.78, top5 75.16
2021-11-04 07:20:46 train 1000, loss 2.205e+00, top1 50.91, top5 74.89
2021-11-04 07:29:27 train 2000, loss 2.207e+00, top1 50.49, top5 74.86
2021-11-04 07:29:27 train 2000, loss 2.216e+00, top1 50.31, top5 74.65
2021-11-04 07:29:27 train 2000, loss 2.213e+00, top1 50.59, top5 74.71
2021-11-04 07:38:03 train 3000, loss 2.220e+00, top1 50.29, top5 74.58
2021-11-04 07:38:03 train 3000, loss 2.216e+00, top1 50.34, top5 74.65
2021-11-04 07:38:03 train 3000, loss 2.219e+00, top1 50.37, top5 74.59
2021-11-04 07:46:45 train 4000, loss 2.217e+00, top1 50.32, top5 74.65
2021-11-04 07:46:45 train 4000, loss 2.226e+00, top1 50.23, top5 74.52
2021-11-04 07:46:45 train 4000, loss 2.221e+00, top1 50.32, top5 74.53
2021-11-04 07:55:19 train 5000, loss 2.219e+00, top1 50.29, top5 74.63
2021-11-04 07:55:19 train 5000, loss 2.226e+00, top1 50.19, top5 74.50
2021-11-04 07:55:19 train 5000, loss 2.224e+00, top1 50.29, top5 74.50
2021-11-04 07:55:42 valid 0000, loss 8.429e-01, top1 82.35, top5 91.76
2021-11-04 07:55:42 valid 0000, loss 8.429e-01, top1 82.35, top5 91.76
2021-11-04 07:55:42 valid 0000, loss 8.429e-01, top1 82.35, top5 91.76
2021-11-04 08:00:21 (JOBID 31582) epoch 26: train time 2615.25, inference time 289.47s, valid_top1 51.17 (best_top1 63.94), valid_top5 76.66
2021-11-04 08:00:22 (JOBID 31582) epoch 26: train time 2615.63, inference time 290.72s, valid_top1 51.17 (best_top1 63.94), valid_top5 76.66
2021-11-04 08:00:23 (JOBID 31582) epoch 26: train time 2631.85, inference time 290.88s, valid_top1 51.17 (best_top1 63.94), valid_top5 76.66
2021-11-04 08:00:36 train 0000, loss 2.214e+00, top1 50.59, top5 74.12
2021-11-04 08:00:36 train 0000, loss 2.109e+00, top1 54.12, top5 76.47
2021-11-04 08:00:37 train 0000, loss 2.249e+00, top1 50.59, top5 72.94
2021-11-04 08:09:40 train 1000, loss 2.197e+00, top1 50.53, top5 74.88
2021-11-04 08:09:40 train 1000, loss 2.195e+00, top1 50.74, top5 74.81
2021-11-04 08:09:40 train 1000, loss 2.197e+00, top1 50.63, top5 75.01
2021-11-04 08:18:28 train 2000, loss 2.205e+00, top1 50.58, top5 74.76
2021-11-04 08:18:28 train 2000, loss 2.210e+00, top1 50.40, top5 74.68
2021-11-04 08:18:28 train 2000, loss 2.207e+00, top1 50.60, top5 74.90
2021-11-04 08:27:23 train 3000, loss 2.216e+00, top1 50.29, top5 74.61
2021-11-04 08:27:23 train 3000, loss 2.211e+00, top1 50.42, top5 74.66
2021-11-04 08:27:23 train 3000, loss 2.213e+00, top1 50.48, top5 74.82
2021-11-04 20:00:27 CARME Slurm ID: 31682
2021-11-04 20:00:27 CARME Slurm ID: 31682
2021-11-04 20:00:27 CARME Slurm ID: 31682
2021-11-04 20:00:27 args = Namespace(adaptive_lr=True, arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_1', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.42:23456', distributed=True, epochs=90, evaluate=False, gpu=1, lr=0.1, momentum=0.9, multiprocessing_distributed=True, normalization=None, path_to_resume='', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', pretrained=True, print_freq=1000, pruning_threshold=1e-06, rank=0, resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 20:00:27 args = Namespace(adaptive_lr=True, arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_1', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.42:23456', distributed=True, epochs=90, evaluate=False, gpu=0, lr=0.1, momentum=0.9, multiprocessing_distributed=True, normalization=None, path_to_resume='', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', pretrained=True, print_freq=1000, pruning_threshold=1e-06, rank=0, resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 20:00:27 args = Namespace(adaptive_lr=True, arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_1', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.42:23456', distributed=True, epochs=90, evaluate=False, gpu=2, lr=0.1, momentum=0.9, multiprocessing_distributed=True, normalization=None, path_to_resume='', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', pretrained=True, print_freq=1000, pruning_threshold=1e-06, rank=0, resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 20:00:34 prunable/total params (ratio): 15.65M/25.56M (61.22%)
2021-11-04 20:00:34 prunable/total params (ratio): 15.65M/25.56M (61.22%)
2021-11-04 20:00:34 prunable/total params (ratio): 15.65M/25.56M (61.22%)
2021-11-04 20:00:34 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635'
2021-11-04 20:00:34 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635'
2021-11-04 20:00:34 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635'
2021-11-04 20:02:39 CARME Slurm ID: 31682
2021-11-04 20:02:39 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_1', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.42:23456', distributed=True, epochs=90, evaluate=False, gpu=0, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 20:02:39 CARME Slurm ID: 31682
2021-11-04 20:02:39 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_1', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.42:23456', distributed=True, epochs=90, evaluate=False, gpu=2, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 20:02:39 CARME Slurm ID: 31682
2021-11-04 20:02:39 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_1', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.42:23456', distributed=True, epochs=90, evaluate=False, gpu=1, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 20:02:48 Computational complexity:       1.74 GMac
2021-11-04 20:02:48 Computational complexity:       1.74 GMac
2021-11-04 20:02:48 Number of parameters:           12.36 M 
2021-11-04 20:02:48 Number of parameters:           12.36 M 
2021-11-04 20:02:48 Computational complexity:       1.74 GMac
2021-11-04 20:02:48 Number of parameters:           12.36 M 
2021-11-04 20:02:48 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635'
2021-11-04 20:02:48 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635'
2021-11-04 20:02:48 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635'
2021-11-04 20:02:49 => loaded checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635' (epoch 27)
2021-11-04 20:02:49 => loaded checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635' (epoch 27)
2021-11-04 20:02:49 => loaded checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635' (epoch 27)
2021-11-04 20:51:50 CARME Slurm ID: 31682
2021-11-04 20:51:50 CARME Slurm ID: 31682
2021-11-04 20:51:50 CARME Slurm ID: 31682
2021-11-04 20:51:50 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_1', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.42:23456', distributed=True, epochs=90, evaluate=False, gpu=0, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 20:51:50 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_1', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.42:23456', distributed=True, epochs=90, evaluate=False, gpu=1, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 20:51:50 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_1', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.42:23456', distributed=True, epochs=90, evaluate=False, gpu=2, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-04 20:52:02 Computational complexity:       1.74 GMac
2021-11-04 20:52:02 Computational complexity:       1.74 GMac
2021-11-04 20:52:02 Computational complexity:       1.74 GMac
2021-11-04 20:52:02 Number of parameters:           12.36 M 
2021-11-04 20:52:02 Number of parameters:           12.36 M 
2021-11-04 20:52:02 Number of parameters:           12.36 M 
2021-11-04 20:52:02 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635'
2021-11-04 20:52:02 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635'
2021-11-04 20:52:02 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635'
2021-11-04 20:52:02 => loaded checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635' (epoch 27)
2021-11-04 20:52:02 => loaded checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635' (epoch 27)
2021-11-04 20:52:02 => loaded checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_1_20211103-101635' (epoch 27)
2021-11-04 20:52:21 valid 0000, loss 8.429e-01, top1 82.35, top5 91.76
2021-11-04 20:52:21 valid 0000, loss 8.429e-01, top1 82.35, top5 91.76
2021-11-04 20:52:21 valid 0000, loss 8.429e-01, top1 82.35, top5 91.76
2021-11-04 20:56:39 (JOBID 31682) epoch -1: valid_top1 51.17, valid_top5 76.66, inference time 272.17
2021-11-04 20:56:40 (JOBID 31682) epoch -1: valid_top1 51.17, valid_top5 76.66, inference time 273.06
2021-11-04 20:56:41 (JOBID 31682) epoch -1: valid_top1 51.17, valid_top5 76.66, inference time 273.55
2021-11-04 20:56:59 train 0000, loss 2.415e+00, top1 43.53, top5 71.76
2021-11-04 20:56:59 train 0000, loss 2.241e+00, top1 47.06, top5 76.47
2021-11-04 20:56:59 train 0000, loss 2.175e+00, top1 50.59, top5 75.29
2021-11-04 21:06:19 train 1000, loss 2.199e+00, top1 50.67, top5 74.94
2021-11-04 21:06:19 train 1000, loss 2.198e+00, top1 50.74, top5 74.74
2021-11-04 21:06:20 train 1000, loss 2.197e+00, top1 50.61, top5 75.03
2021-11-04 21:15:44 train 2000, loss 2.203e+00, top1 50.71, top5 74.80
2021-11-04 21:15:44 train 2000, loss 2.209e+00, top1 50.46, top5 74.80
2021-11-04 21:15:44 train 2000, loss 2.208e+00, top1 50.43, top5 74.80
2021-11-04 21:25:11 train 3000, loss 2.214e+00, top1 50.45, top5 74.73
2021-11-04 21:25:11 train 3000, loss 2.209e+00, top1 50.55, top5 74.76
2021-11-04 21:25:11 train 3000, loss 2.213e+00, top1 50.38, top5 74.77
2021-11-04 21:34:47 train 4000, loss 2.219e+00, top1 50.38, top5 74.64
2021-11-04 21:34:47 train 4000, loss 2.214e+00, top1 50.46, top5 74.67
2021-11-04 21:34:47 train 4000, loss 2.218e+00, top1 50.29, top5 74.71
2021-11-04 21:44:20 train 5000, loss 2.224e+00, top1 50.23, top5 74.58
2021-11-04 21:44:20 train 5000, loss 2.217e+00, top1 50.37, top5 74.63
2021-11-04 21:44:20 train 5000, loss 2.220e+00, top1 50.24, top5 74.65
2021-11-04 21:44:48 valid 0000, loss 8.499e-01, top1 82.35, top5 95.29
2021-11-04 21:44:48 valid 0000, loss 8.499e-01, top1 82.35, top5 95.29
2021-11-04 21:44:48 valid 0000, loss 8.499e-01, top1 82.35, top5 95.29
2021-11-04 21:48:57 (JOBID 31682) epoch 27: train time 2878.47, inference time 259.56s, valid_top1 45.80 (best_top1 63.94), valid_top5 72.05
2021-11-04 21:49:22 (JOBID 31682) epoch 27: train time 2877.55, inference time 284.24s, valid_top1 45.80 (best_top1 63.94), valid_top5 72.05
2021-11-04 21:49:22 (JOBID 31682) epoch 27: train time 2877.07, inference time 284.27s, valid_top1 45.80 (best_top1 63.94), valid_top5 72.05
2021-11-04 21:49:12 train 0000, loss 2.214e+00, top1 52.94, top5 71.76
2021-11-04 21:49:35 train 0000, loss 2.822e+00, top1 44.71, top5 67.06
2021-11-04 21:49:35 train 0000, loss 2.061e+00, top1 56.47, top5 78.82
2021-11-04 21:59:00 train 1000, loss 2.206e+00, top1 50.65, top5 74.88
2021-11-04 21:59:00 train 1000, loss 2.218e+00, top1 50.50, top5 74.68
2021-11-04 21:59:00 train 1000, loss 2.199e+00, top1 50.54, top5 74.93
2021-11-04 22:08:25 train 2000, loss 2.210e+00, top1 50.50, top5 74.90
2021-11-04 22:08:25 train 2000, loss 2.219e+00, top1 50.43, top5 74.71
2021-11-04 22:08:26 train 2000, loss 2.214e+00, top1 50.26, top5 74.75
2021-11-04 22:17:51 train 3000, loss 2.225e+00, top1 50.32, top5 74.57
2021-11-04 22:17:51 train 3000, loss 2.209e+00, top1 50.48, top5 74.90
2021-11-04 22:17:51 train 3000, loss 2.220e+00, top1 50.15, top5 74.65
2021-11-04 22:27:25 train 4000, loss 2.226e+00, top1 50.29, top5 74.53
2021-11-04 22:27:25 train 4000, loss 2.216e+00, top1 50.36, top5 74.78
2021-11-04 22:27:25 train 4000, loss 2.223e+00, top1 50.14, top5 74.60
2021-11-04 22:36:54 train 5000, loss 2.226e+00, top1 50.25, top5 74.52
2021-11-04 22:36:54 train 5000, loss 2.221e+00, top1 50.28, top5 74.67
2021-11-04 22:36:54 train 5000, loss 2.227e+00, top1 50.09, top5 74.52
2021-11-04 22:37:18 valid 0000, loss 1.334e+00, top1 72.94, top5 84.71
2021-11-04 22:37:18 valid 0000, loss 1.334e+00, top1 72.94, top5 84.71
2021-11-04 22:37:18 valid 0000, loss 1.334e+00, top1 72.94, top5 84.71
2021-11-04 22:42:00 (JOBID 31682) epoch 28: train time 2866.17, inference time 291.45s, valid_top1 53.57 (best_top1 63.94), valid_top5 79.02
2021-11-04 22:42:00 (JOBID 31682) epoch 28: train time 2865.98, inference time 291.67s, valid_top1 53.57 (best_top1 63.94), valid_top5 79.02
2021-11-04 22:42:00 (JOBID 31682) epoch 28: train time 2890.43, inference time 291.67s, valid_top1 53.57 (best_top1 63.94), valid_top5 79.02
2021-11-04 22:42:14 train 0000, loss 2.345e+00, top1 47.06, top5 81.18
2021-11-04 22:42:14 train 0000, loss 2.144e+00, top1 50.59, top5 76.47
2021-11-04 22:42:14 train 0000, loss 2.040e+00, top1 50.59, top5 76.47
2021-11-04 22:51:50 train 1000, loss 2.207e+00, top1 50.75, top5 74.71
2021-11-04 22:51:50 train 1000, loss 2.197e+00, top1 50.49, top5 74.90
2021-11-04 22:51:50 train 1000, loss 2.207e+00, top1 50.45, top5 74.83
2021-11-04 23:01:23 train 2000, loss 2.210e+00, top1 50.59, top5 74.74
2021-11-04 23:01:23 train 2000, loss 2.207e+00, top1 50.48, top5 74.88
2021-11-04 23:01:23 train 2000, loss 2.211e+00, top1 50.44, top5 74.80
2021-11-04 23:10:59 train 3000, loss 2.213e+00, top1 50.52, top5 74.69
2021-11-04 23:10:59 train 3000, loss 2.217e+00, top1 50.35, top5 74.72
2021-11-04 23:10:59 train 3000, loss 2.217e+00, top1 50.32, top5 74.65
2021-11-04 23:20:38 train 4000, loss 2.217e+00, top1 50.37, top5 74.67
2021-11-04 23:20:38 train 4000, loss 2.219e+00, top1 50.31, top5 74.64
2021-11-04 23:20:38 train 4000, loss 2.218e+00, top1 50.29, top5 74.66
2021-11-04 23:30:07 train 5000, loss 2.221e+00, top1 50.29, top5 74.64
2021-11-04 23:30:07 train 5000, loss 2.224e+00, top1 50.21, top5 74.59
2021-11-04 23:30:08 train 5000, loss 2.222e+00, top1 50.21, top5 74.59
2021-11-04 23:30:32 valid 0000, loss 1.258e+00, top1 76.47, top5 85.88
2021-11-04 23:30:32 valid 0000, loss 1.258e+00, top1 76.47, top5 85.88
2021-11-04 23:30:32 valid 0000, loss 1.258e+00, top1 76.47, top5 85.88
2021-11-04 23:34:52 (JOBID 31682) epoch 29: train time 2902.38, inference time 270.16s, valid_top1 52.83 (best_top1 63.94), valid_top5 78.08
2021-11-04 23:34:55 (JOBID 31682) epoch 29: train time 2902.14, inference time 273.77s, valid_top1 52.83 (best_top1 63.94), valid_top5 78.08
2021-11-04 23:34:57 (JOBID 31682) epoch 29: train time 2901.90, inference time 275.10s, valid_top1 52.83 (best_top1 63.94), valid_top5 78.08
2021-11-04 23:35:10 train 0000, loss 2.016e+00, top1 52.94, top5 78.82
2021-11-04 23:35:06 train 0000, loss 2.102e+00, top1 55.29, top5 77.65
2021-11-04 23:35:12 train 0000, loss 2.055e+00, top1 55.29, top5 76.47
2021-11-04 23:44:40 train 1000, loss 1.838e+00, top1 58.22, top5 80.29
2021-11-04 23:44:40 train 1000, loss 1.824e+00, top1 58.43, top5 80.39
2021-11-04 23:44:40 train 1000, loss 1.818e+00, top1 58.72, top5 80.55
2021-11-04 23:54:08 train 2000, loss 1.771e+00, top1 59.58, top5 81.15
2021-11-04 23:54:08 train 2000, loss 1.786e+00, top1 59.25, top5 80.97
2021-11-04 23:54:08 train 2000, loss 1.770e+00, top1 59.72, top5 81.16
2021-11-05 00:03:52 train 3000, loss 1.752e+00, top1 59.90, top5 81.46
2021-11-05 00:03:52 train 3000, loss 1.745e+00, top1 60.16, top5 81.53
2021-11-05 00:03:52 train 3000, loss 1.744e+00, top1 60.21, top5 81.53
2021-11-05 00:13:22 train 4000, loss 1.724e+00, top1 60.58, top5 81.83
2021-11-05 00:13:22 train 4000, loss 1.732e+00, top1 60.29, top5 81.76
2021-11-05 00:13:22 train 4000, loss 1.725e+00, top1 60.51, top5 81.84
2021-11-05 00:22:49 train 5000, loss 1.711e+00, top1 60.80, top5 82.01
2021-11-05 00:22:49 train 5000, loss 1.714e+00, top1 60.63, top5 82.03
2021-11-05 00:22:49 train 5000, loss 1.710e+00, top1 60.78, top5 82.07
2021-11-05 00:23:13 valid 0000, loss 6.790e-01, top1 87.06, top5 94.12
2021-11-05 00:23:13 valid 0000, loss 6.790e-01, top1 87.06, top5 94.12
2021-11-05 00:23:13 valid 0000, loss 6.790e-01, top1 87.06, top5 94.12
2021-11-05 00:27:33 (JOBID 31682) epoch 30: train time 2886.83, inference time 271.13s, valid_top1 67.18 (best_top1 67.18), valid_top5 87.92
2021-11-05 00:27:35 (JOBID 31682) epoch 30: train time 2885.27, inference time 271.95s, valid_top1 67.18 (best_top1 67.18), valid_top5 87.92
2021-11-05 00:27:39 (JOBID 31682) epoch 30: train time 2890.39, inference time 276.63s, valid_top1 67.18 (best_top1 67.18), valid_top5 87.92
2021-11-05 00:27:49 train 0000, loss 1.474e+00, top1 69.41, top5 83.53
2021-11-05 00:27:47 train 0000, loss 1.747e+00, top1 63.53, top5 78.82
2021-11-05 00:27:53 train 0000, loss 1.283e+00, top1 74.12, top5 88.24
2021-11-05 00:37:12 train 1000, loss 1.624e+00, top1 62.42, top5 83.29
2021-11-05 00:37:12 train 1000, loss 1.609e+00, top1 62.69, top5 83.52
2021-11-05 00:37:12 train 1000, loss 1.606e+00, top1 62.90, top5 83.45
2021-11-05 00:46:36 train 2000, loss 1.619e+00, top1 62.50, top5 83.30
2021-11-05 00:46:36 train 2000, loss 1.612e+00, top1 62.62, top5 83.41
2021-11-05 00:46:36 train 2000, loss 1.613e+00, top1 62.78, top5 83.41
2021-11-05 00:56:11 train 3000, loss 1.607e+00, top1 62.78, top5 83.52
2021-11-05 00:56:11 train 3000, loss 1.615e+00, top1 62.58, top5 83.36
2021-11-05 00:56:12 train 3000, loss 1.611e+00, top1 62.79, top5 83.46
2021-11-05 01:05:41 train 4000, loss 1.605e+00, top1 62.85, top5 83.56
2021-11-05 01:05:41 train 4000, loss 1.609e+00, top1 62.75, top5 83.45
2021-11-05 01:05:41 train 4000, loss 1.606e+00, top1 62.85, top5 83.51
2021-11-05 01:15:08 train 5000, loss 1.604e+00, top1 62.85, top5 83.57
2021-11-05 01:15:08 train 5000, loss 1.605e+00, top1 62.87, top5 83.47
2021-11-05 01:15:09 train 5000, loss 1.603e+00, top1 62.92, top5 83.56
2021-11-05 01:15:32 valid 0000, loss 7.111e-01, top1 88.24, top5 91.76
2021-11-05 01:15:32 valid 0000, loss 7.111e-01, top1 88.24, top5 91.76
2021-11-05 01:15:32 valid 0000, loss 7.111e-01, top1 88.24, top5 91.76
2021-11-05 01:19:59 (JOBID 31682) epoch 31: train time 2863.43, inference time 276.84s, valid_top1 67.59 (best_top1 67.59), valid_top5 88.16
2021-11-05 01:19:59 (JOBID 31682) epoch 31: train time 2868.88, inference time 277.09s, valid_top1 67.59 (best_top1 67.59), valid_top5 88.16
2021-11-05 01:20:00 (JOBID 31682) epoch 31: train time 2867.41, inference time 277.16s, valid_top1 67.59 (best_top1 67.59), valid_top5 88.16
2021-11-05 01:20:14 train 0000, loss 1.290e+00, top1 71.76, top5 87.06
2021-11-05 01:20:14 train 0000, loss 1.483e+00, top1 64.71, top5 83.53
2021-11-05 01:20:14 train 0000, loss 1.274e+00, top1 71.76, top5 89.41
2021-11-05 01:29:54 train 1000, loss 1.563e+00, top1 63.67, top5 84.16
2021-11-05 01:29:54 train 1000, loss 1.560e+00, top1 63.88, top5 84.12
2021-11-05 01:29:54 train 1000, loss 1.562e+00, top1 63.57, top5 84.09
2021-11-05 01:39:34 train 2000, loss 1.568e+00, top1 63.70, top5 84.07
2021-11-05 01:39:34 train 2000, loss 1.561e+00, top1 63.84, top5 84.18
2021-11-05 01:39:34 train 2000, loss 1.565e+00, top1 63.59, top5 84.10
2021-11-05 01:49:19 train 3000, loss 1.568e+00, top1 63.69, top5 84.06
2021-11-05 01:49:19 train 3000, loss 1.563e+00, top1 63.76, top5 84.16
2021-11-05 01:49:20 train 3000, loss 1.561e+00, top1 63.74, top5 84.12
2021-11-05 01:58:53 train 4000, loss 1.567e+00, top1 63.67, top5 84.04
2021-11-05 01:58:53 train 4000, loss 1.565e+00, top1 63.73, top5 84.13
2021-11-05 01:58:53 train 4000, loss 1.561e+00, top1 63.72, top5 84.12
2021-11-05 02:08:33 train 5000, loss 1.566e+00, top1 63.69, top5 84.15
2021-11-05 02:08:33 train 5000, loss 1.565e+00, top1 63.68, top5 84.04
2021-11-05 02:08:34 train 5000, loss 1.562e+00, top1 63.70, top5 84.11
2021-11-05 02:08:59 valid 0000, loss 5.023e-01, top1 88.24, top5 96.47
2021-11-05 02:08:59 valid 0000, loss 5.023e-01, top1 88.24, top5 96.47
2021-11-05 02:08:59 valid 0000, loss 5.023e-01, top1 88.24, top5 96.47
2021-11-05 02:13:32 (JOBID 31682) epoch 32: train time 2928.53, inference time 283.82s, valid_top1 68.30 (best_top1 68.30), valid_top5 88.61
2021-11-05 02:13:32 (JOBID 31682) epoch 32: train time 2928.41, inference time 283.94s, valid_top1 68.30 (best_top1 68.30), valid_top5 88.61
2021-11-05 02:13:32 (JOBID 31682) epoch 32: train time 2927.77, inference time 283.94s, valid_top1 68.30 (best_top1 68.30), valid_top5 88.61
2021-11-05 02:13:47 train 0000, loss 1.862e+00, top1 61.18, top5 76.47
2021-11-05 02:13:47 train 0000, loss 1.522e+00, top1 65.88, top5 87.06
2021-11-05 02:13:47 train 0000, loss 1.714e+00, top1 61.18, top5 83.53
2021-11-05 02:23:13 train 1000, loss 1.533e+00, top1 64.20, top5 84.51
2021-11-05 02:23:13 train 1000, loss 1.536e+00, top1 64.30, top5 84.37
2021-11-05 02:23:13 train 1000, loss 1.551e+00, top1 63.92, top5 84.28
2021-11-05 02:32:51 train 2000, loss 1.537e+00, top1 64.13, top5 84.45
2021-11-05 02:32:51 train 2000, loss 1.532e+00, top1 64.45, top5 84.53
2021-11-05 02:32:51 train 2000, loss 1.555e+00, top1 63.80, top5 84.25
2021-11-05 02:42:27 train 3000, loss 1.535e+00, top1 64.34, top5 84.51
2021-11-05 02:42:27 train 3000, loss 1.537e+00, top1 64.17, top5 84.47
2021-11-05 02:42:28 train 3000, loss 1.547e+00, top1 63.91, top5 84.37
2021-11-05 02:51:57 train 4000, loss 1.537e+00, top1 64.27, top5 84.48
2021-11-05 02:51:57 train 4000, loss 1.539e+00, top1 64.15, top5 84.42
2021-11-05 02:51:58 train 4000, loss 1.546e+00, top1 63.93, top5 84.37
2021-11-05 03:01:24 train 5000, loss 1.537e+00, top1 64.25, top5 84.47
2021-11-05 03:01:24 train 5000, loss 1.537e+00, top1 64.17, top5 84.46
2021-11-05 03:01:24 train 5000, loss 1.544e+00, top1 63.96, top5 84.39
2021-11-05 03:01:49 valid 0000, loss 7.365e-01, top1 83.53, top5 90.59
2021-11-05 03:01:49 valid 0000, loss 7.365e-01, top1 83.53, top5 90.59
2021-11-05 03:01:49 valid 0000, loss 7.365e-01, top1 83.53, top5 90.59
2021-11-05 03:06:10 (JOBID 31682) epoch 33: train time 2886.57, inference time 271.99s, valid_top1 68.45 (best_top1 68.45), valid_top5 88.82
2021-11-05 03:06:11 (JOBID 31682) epoch 33: train time 2886.35, inference time 272.59s, valid_top1 68.45 (best_top1 68.45), valid_top5 88.82
2021-11-05 03:06:11 (JOBID 31682) epoch 33: train time 2885.76, inference time 272.10s, valid_top1 68.45 (best_top1 68.45), valid_top5 88.82
2021-11-05 03:06:26 train 0000, loss 1.769e+00, top1 63.53, top5 80.00
2021-11-05 03:06:26 train 0000, loss 1.470e+00, top1 62.35, top5 87.06
2021-11-05 03:06:26 train 0000, loss 1.507e+00, top1 63.53, top5 87.06
2021-11-05 03:16:07 train 1000, loss 1.516e+00, top1 64.76, top5 84.81
2021-11-05 03:16:07 train 1000, loss 1.512e+00, top1 64.82, top5 84.83
2021-11-05 03:16:07 train 1000, loss 1.519e+00, top1 64.62, top5 84.67
2021-11-05 03:25:54 train 2000, loss 1.521e+00, top1 64.61, top5 84.80
2021-11-05 03:25:54 train 2000, loss 1.522e+00, top1 64.54, top5 84.72
2021-11-05 03:25:54 train 2000, loss 1.526e+00, top1 64.55, top5 84.64
2021-11-05 03:35:36 train 3000, loss 1.526e+00, top1 64.47, top5 84.66
2021-11-05 03:35:36 train 3000, loss 1.524e+00, top1 64.45, top5 84.70
2021-11-05 03:35:36 train 3000, loss 1.525e+00, top1 64.60, top5 84.64
2021-11-05 03:45:17 train 4000, loss 1.524e+00, top1 64.48, top5 84.67
2021-11-05 03:45:17 train 4000, loss 1.526e+00, top1 64.45, top5 84.68
2021-11-05 03:45:18 train 4000, loss 1.525e+00, top1 64.53, top5 84.67
2021-11-05 03:55:00 train 5000, loss 1.525e+00, top1 64.47, top5 84.70
2021-11-05 03:55:00 train 5000, loss 1.527e+00, top1 64.43, top5 84.62
2021-11-05 03:55:00 train 5000, loss 1.525e+00, top1 64.51, top5 84.67
2021-11-05 03:55:26 valid 0000, loss 6.582e-01, top1 83.53, top5 94.12
2021-11-05 03:55:26 valid 0000, loss 6.582e-01, top1 83.53, top5 94.12
2021-11-05 03:55:26 valid 0000, loss 6.582e-01, top1 83.53, top5 94.12
2021-11-05 04:00:00 (JOBID 31682) epoch 34: train time 2944.63, inference time 285.46s, valid_top1 68.58 (best_top1 68.58), valid_top5 88.95
2021-11-05 04:00:01 (JOBID 31682) epoch 34: train time 2944.16, inference time 286.21s, valid_top1 68.58 (best_top1 68.58), valid_top5 88.95
2021-11-05 04:00:02 (JOBID 31682) epoch 34: train time 2943.97, inference time 286.85s, valid_top1 68.58 (best_top1 68.58), valid_top5 88.95
2021-11-05 04:00:16 train 0000, loss 1.327e+00, top1 67.06, top5 87.06
2021-11-05 04:00:16 train 0000, loss 1.518e+00, top1 64.71, top5 84.71
2021-11-05 04:00:16 train 0000, loss 1.490e+00, top1 62.35, top5 87.06
2021-11-05 04:10:03 train 1000, loss 1.506e+00, top1 64.77, top5 84.89
2021-11-05 04:10:03 train 1000, loss 1.499e+00, top1 65.13, top5 85.02
2021-11-05 04:10:03 train 1000, loss 1.504e+00, top1 64.79, top5 85.00
2021-11-05 04:19:50 train 2000, loss 1.508e+00, top1 64.77, top5 84.87
2021-11-05 04:19:50 train 2000, loss 1.507e+00, top1 64.87, top5 84.91
2021-11-05 04:19:50 train 2000, loss 1.505e+00, top1 64.86, top5 84.98
2021-11-05 04:29:32 train 3000, loss 1.509e+00, top1 64.77, top5 84.81
2021-11-05 04:29:32 train 3000, loss 1.510e+00, top1 64.78, top5 84.90
2021-11-05 04:29:32 train 3000, loss 1.510e+00, top1 64.74, top5 84.89
2021-11-05 04:39:14 train 4000, loss 1.512e+00, top1 64.74, top5 84.78
2021-11-05 04:39:14 train 4000, loss 1.513e+00, top1 64.66, top5 84.85
2021-11-05 04:39:14 train 4000, loss 1.516e+00, top1 64.64, top5 84.79
2021-11-05 04:48:58 train 5000, loss 1.513e+00, top1 64.70, top5 84.80
2021-11-05 04:48:58 train 5000, loss 1.516e+00, top1 64.61, top5 84.80
2021-11-05 04:48:58 train 5000, loss 1.516e+00, top1 64.59, top5 84.79
2021-11-05 04:49:24 valid 0000, loss 6.852e-01, top1 84.71, top5 92.94
2021-11-05 04:49:24 valid 0000, loss 6.852e-01, top1 84.71, top5 92.94
2021-11-05 04:49:24 valid 0000, loss 6.852e-01, top1 84.71, top5 92.94
2021-11-05 04:53:48 (JOBID 31682) epoch 35: train time 2952.14, inference time 275.14s, valid_top1 68.69 (best_top1 68.69), valid_top5 88.94
2021-11-05 04:53:48 (JOBID 31682) epoch 35: train time 2951.25, inference time 275.46s, valid_top1 68.69 (best_top1 68.69), valid_top5 88.94
2021-11-05 04:53:48 (JOBID 31682) epoch 35: train time 2949.87, inference time 275.46s, valid_top1 68.69 (best_top1 68.69), valid_top5 88.94
2021-11-05 04:54:02 train 0000, loss 1.722e+00, top1 57.65, top5 84.71
2021-11-05 04:54:02 train 0000, loss 1.583e+00, top1 65.88, top5 84.71
2021-11-05 04:54:02 train 0000, loss 1.763e+00, top1 55.29, top5 78.82
2021-11-05 05:03:53 train 1000, loss 1.500e+00, top1 64.89, top5 85.04
2021-11-05 05:03:53 train 1000, loss 1.510e+00, top1 64.72, top5 84.88
2021-11-05 05:03:54 train 1000, loss 1.497e+00, top1 64.98, top5 85.11
2021-11-05 05:13:40 train 2000, loss 1.504e+00, top1 64.82, top5 84.97
2021-11-05 05:13:40 train 2000, loss 1.510e+00, top1 64.74, top5 84.92
2021-11-05 05:13:40 train 2000, loss 1.505e+00, top1 64.85, top5 84.99
2021-11-05 05:23:30 train 3000, loss 1.506e+00, top1 64.76, top5 84.97
2021-11-05 05:23:30 train 3000, loss 1.508e+00, top1 64.76, top5 84.91
2021-11-05 05:23:31 train 3000, loss 1.513e+00, top1 64.65, top5 84.85
2021-11-05 05:33:22 train 4000, loss 1.508e+00, top1 64.79, top5 84.90
2021-11-05 05:33:22 train 4000, loss 1.511e+00, top1 64.71, top5 84.85
2021-11-05 05:33:23 train 4000, loss 1.516e+00, top1 64.59, top5 84.82
2021-11-05 05:43:11 train 5000, loss 1.514e+00, top1 64.63, top5 84.82
2021-11-05 05:43:11 train 5000, loss 1.512e+00, top1 64.73, top5 84.84
2021-11-05 05:43:11 train 5000, loss 1.517e+00, top1 64.58, top5 84.78
2021-11-05 05:43:36 valid 0000, loss 6.412e-01, top1 84.71, top5 95.29
2021-11-05 05:43:36 valid 0000, loss 6.412e-01, top1 84.71, top5 95.29
2021-11-05 05:43:36 valid 0000, loss 6.412e-01, top1 84.71, top5 95.29
2021-11-05 05:48:01 (JOBID 31682) epoch 36: train time 2977.70, inference time 275.15s, valid_top1 68.52 (best_top1 68.69), valid_top5 88.82
2021-11-05 05:48:10 (JOBID 31682) epoch 36: train time 2977.15, inference time 284.29s, valid_top1 68.52 (best_top1 68.69), valid_top5 88.82
2021-11-05 05:48:12 (JOBID 31682) epoch 36: train time 2977.92, inference time 285.95s, valid_top1 68.52 (best_top1 68.69), valid_top5 88.82
2021-11-05 05:48:25 train 0000, loss 1.576e+00, top1 56.47, top5 83.53
2021-11-05 05:48:16 train 0000, loss 1.490e+00, top1 63.53, top5 87.06
2021-11-05 05:48:26 train 0000, loss 1.316e+00, top1 68.24, top5 88.24
2021-11-05 05:58:04 train 1000, loss 1.493e+00, top1 65.01, top5 85.14
2021-11-05 05:58:04 train 1000, loss 1.499e+00, top1 64.89, top5 85.03
2021-11-05 05:58:04 train 1000, loss 1.498e+00, top1 65.03, top5 84.88
2021-11-05 06:07:34 train 2000, loss 1.500e+00, top1 64.85, top5 84.96
2021-11-05 06:07:34 train 2000, loss 1.501e+00, top1 64.86, top5 85.05
2021-11-05 06:07:34 train 2000, loss 1.500e+00, top1 64.85, top5 84.89
2021-11-05 06:17:04 train 3000, loss 1.503e+00, top1 64.83, top5 84.94
2021-11-05 06:17:04 train 3000, loss 1.508e+00, top1 64.81, top5 84.95
2021-11-05 06:17:04 train 3000, loss 1.504e+00, top1 64.79, top5 84.85
2021-11-05 06:26:32 train 4000, loss 1.510e+00, top1 64.78, top5 84.91
2021-11-05 06:26:32 train 4000, loss 1.506e+00, top1 64.78, top5 84.88
2021-11-05 06:26:32 train 4000, loss 1.507e+00, top1 64.77, top5 84.82
2021-11-05 06:36:10 train 5000, loss 1.510e+00, top1 64.67, top5 84.83
2021-11-05 06:36:10 train 5000, loss 1.512e+00, top1 64.72, top5 84.89
2021-11-05 06:36:10 train 5000, loss 1.508e+00, top1 64.75, top5 84.81
2021-11-05 06:36:34 valid 0000, loss 7.074e-01, top1 85.88, top5 94.12
2021-11-05 06:36:34 valid 0000, loss 7.074e-01, top1 85.88, top5 94.12
2021-11-05 06:36:34 valid 0000, loss 7.074e-01, top1 85.88, top5 94.12
2021-11-05 06:40:59 (JOBID 31682) epoch 37: train time 2892.30, inference time 274.92s, valid_top1 68.77 (best_top1 68.77), valid_top5 88.88
2021-11-05 06:40:59 (JOBID 31682) epoch 37: train time 2903.05, inference time 275.30s, valid_top1 68.77 (best_top1 68.77), valid_top5 88.88
2021-11-05 06:41:00 (JOBID 31682) epoch 37: train time 2893.69, inference time 275.26s, valid_top1 68.77 (best_top1 68.77), valid_top5 88.88
2021-11-05 06:41:14 train 0000, loss 1.336e+00, top1 74.12, top5 87.06
2021-11-05 06:41:14 train 0000, loss 1.806e+00, top1 60.00, top5 81.18
2021-11-05 06:41:14 train 0000, loss 1.684e+00, top1 60.00, top5 82.35
2021-11-05 06:51:00 train 1000, loss 1.489e+00, top1 65.11, top5 85.14
2021-11-05 06:51:00 train 1000, loss 1.489e+00, top1 65.12, top5 85.24
2021-11-05 06:51:00 train 1000, loss 1.502e+00, top1 64.87, top5 84.93
2021-11-05 07:00:36 train 2000, loss 1.498e+00, top1 64.99, top5 85.04
2021-11-05 07:00:36 train 2000, loss 1.493e+00, top1 64.95, top5 85.19
2021-11-05 07:00:37 train 2000, loss 1.501e+00, top1 64.94, top5 84.96
2021-11-05 07:10:12 train 3000, loss 1.504e+00, top1 64.85, top5 84.98
2021-11-05 07:10:12 train 3000, loss 1.497e+00, top1 64.84, top5 85.12
2021-11-05 07:10:12 train 3000, loss 1.507e+00, top1 64.81, top5 84.86
2021-11-05 07:19:48 train 4000, loss 1.503e+00, top1 64.77, top5 85.01
2021-11-05 07:19:48 train 4000, loss 1.506e+00, top1 64.72, top5 84.95
2021-11-05 07:19:48 train 4000, loss 1.511e+00, top1 64.73, top5 84.84
2021-11-05 07:29:22 train 5000, loss 1.507e+00, top1 64.70, top5 84.97
2021-11-05 07:29:22 train 5000, loss 1.505e+00, top1 64.77, top5 84.95
2021-11-05 07:29:22 train 5000, loss 1.511e+00, top1 64.71, top5 84.81
2021-11-05 07:29:49 valid 0000, loss 6.717e-01, top1 85.88, top5 92.94
2021-11-05 07:29:49 valid 0000, loss 6.717e-01, top1 85.88, top5 92.94
2021-11-05 07:29:49 valid 0000, loss 6.717e-01, top1 85.88, top5 92.94
2021-11-05 07:34:22 (JOBID 31682) epoch 38: train time 2917.38, inference time 285.13s, valid_top1 68.53 (best_top1 68.77), valid_top5 88.82
2021-11-05 07:34:22 (JOBID 31682) epoch 38: train time 2917.26, inference time 285.48s, valid_top1 68.53 (best_top1 68.77), valid_top5 88.82
2021-11-05 07:34:23 (JOBID 31682) epoch 38: train time 2916.59, inference time 286.32s, valid_top1 68.53 (best_top1 68.77), valid_top5 88.82
2021-11-05 07:34:38 train 0000, loss 1.543e+00, top1 69.41, top5 83.53
2021-11-05 07:34:38 train 0000, loss 1.484e+00, top1 65.88, top5 85.88
2021-11-05 07:34:38 train 0000, loss 1.457e+00, top1 68.24, top5 85.88
2021-11-05 07:44:17 train 1000, loss 1.490e+00, top1 65.03, top5 85.05
2021-11-05 07:44:17 train 1000, loss 1.486e+00, top1 65.01, top5 85.30
2021-11-05 07:44:17 train 1000, loss 1.491e+00, top1 65.12, top5 85.10
2021-11-05 07:53:38 train 2000, loss 1.492e+00, top1 65.07, top5 85.18
2021-11-05 07:53:38 train 2000, loss 1.493e+00, top1 64.92, top5 85.10
2021-11-05 07:53:38 train 2000, loss 1.506e+00, top1 64.87, top5 84.90
2021-11-05 08:02:55 train 3000, loss 1.500e+00, top1 64.98, top5 85.05
2021-11-05 08:02:55 train 3000, loss 1.497e+00, top1 64.91, top5 85.09
2021-11-05 08:02:56 train 3000, loss 1.506e+00, top1 64.86, top5 84.91
2021-11-05 08:12:12 train 4000, loss 1.504e+00, top1 64.88, top5 84.99
2021-11-05 08:12:12 train 4000, loss 1.503e+00, top1 64.80, top5 84.99
2021-11-05 08:12:13 train 4000, loss 1.508e+00, top1 64.77, top5 84.92
