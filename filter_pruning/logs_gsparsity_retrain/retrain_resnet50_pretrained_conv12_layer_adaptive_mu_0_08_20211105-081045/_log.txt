2021-11-05 08:10:50 CARME Slurm ID: 31647
2021-11-05 08:10:50 CARME Slurm ID: 31647
2021-11-05 08:10:51 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_08', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.34:23456', distributed=True, epochs=90, evaluate=False, gpu=1, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-05 08:10:51 CARME Slurm ID: 31647
2021-11-05 08:10:51 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_08', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.34:23456', distributed=True, epochs=90, evaluate=False, gpu=0, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-05 08:10:51 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_08', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.34:23456', distributed=True, epochs=90, evaluate=False, gpu=2, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-05 08:10:52 => loading baseline model 'conv12_lr_0.001_momentum_0.9_wd_0.08_normalization_div_pretrained_True_20211102-092449/small_model_conv12_1e-06.pth.tar'
2021-11-05 08:10:52 => loading baseline model 'conv12_lr_0.001_momentum_0.9_wd_0.08_normalization_div_pretrained_True_20211102-092449/small_model_conv12_1e-06.pth.tar'
2021-11-05 08:10:52 => loading baseline model 'conv12_lr_0.001_momentum_0.9_wd_0.08_normalization_div_pretrained_True_20211102-092449/small_model_conv12_1e-06.pth.tar'
2021-11-05 08:10:53 => loaded baseline model 'conv12_lr_0.001_momentum_0.9_wd_0.08_normalization_div_pretrained_True_20211102-092449/small_model_conv12_1e-06.pth.tar'
2021-11-05 08:10:53 => loaded baseline model 'conv12_lr_0.001_momentum_0.9_wd_0.08_normalization_div_pretrained_True_20211102-092449/small_model_conv12_1e-06.pth.tar'
2021-11-05 08:10:53 => loaded baseline model 'conv12_lr_0.001_momentum_0.9_wd_0.08_normalization_div_pretrained_True_20211102-092449/small_model_conv12_1e-06.pth.tar'
2021-11-05 08:11:01 Computational complexity:       1.83 GMac
2021-11-05 08:11:01 Computational complexity:       1.83 GMac
2021-11-05 08:11:01 Number of parameters:           12.86 M 
2021-11-05 08:11:01 Computational complexity:       1.83 GMac
2021-11-05 08:11:01 Number of parameters:           12.86 M 
2021-11-05 08:11:01 Number of parameters:           12.86 M 
2021-11-05 08:11:21 valid 0000, loss 6.953e-01, top1 85.88, top5 96.47
2021-11-05 08:11:21 valid 0000, loss 6.953e-01, top1 85.88, top5 96.47
2021-11-05 08:11:21 valid 0000, loss 6.953e-01, top1 85.88, top5 96.47
2021-11-05 08:15:59 (JOBID 31647) epoch -1: valid_top1 72.73, valid_top5 90.81, inference time 291.84
2021-11-05 08:16:08 (JOBID 31647) epoch -1: valid_top1 72.73, valid_top5 90.81, inference time 300.86
2021-11-05 08:16:09 (JOBID 31647) epoch -1: valid_top1 72.73, valid_top5 90.81, inference time 301.17
2021-11-05 08:16:27 train 0000, loss 7.461e-01, top1 76.47, top5 94.12
2021-11-05 08:16:27 train 0000, loss 7.070e-01, top1 76.47, top5 96.47
2021-11-05 08:16:27 train 0000, loss 6.916e-01, top1 81.18, top5 96.47
2021-11-05 08:25:29 train 1000, loss 1.528e+00, top1 64.45, top5 84.09
2021-11-05 08:25:29 train 1000, loss 1.526e+00, top1 64.30, top5 84.20
2021-11-05 08:25:29 train 1000, loss 1.541e+00, top1 64.11, top5 83.92
2021-11-05 08:34:37 train 2000, loss 1.470e+00, top1 65.59, top5 84.92
2021-11-05 08:34:37 train 2000, loss 1.462e+00, top1 65.77, top5 85.04
2021-11-05 08:34:37 train 2000, loss 1.461e+00, top1 65.76, top5 85.15
2021-11-05 08:43:43 train 3000, loss 1.437e+00, top1 66.23, top5 85.39
2021-11-05 08:43:43 train 3000, loss 1.441e+00, top1 66.16, top5 85.36
2021-11-05 08:43:44 train 3000, loss 1.435e+00, top1 66.32, top5 85.48
2021-11-05 08:52:48 train 4000, loss 1.425e+00, top1 66.50, top5 85.59
2021-11-05 08:52:48 train 4000, loss 1.427e+00, top1 66.47, top5 85.55
2021-11-05 08:52:48 train 4000, loss 1.423e+00, top1 66.57, top5 85.67
2021-11-05 09:01:55 train 5000, loss 1.423e+00, top1 66.56, top5 85.66
2021-11-05 09:01:55 train 5000, loss 1.420e+00, top1 66.64, top5 85.70
2021-11-05 09:01:55 train 5000, loss 1.418e+00, top1 66.68, top5 85.77
2021-11-05 09:02:22 valid 0000, loss 7.569e-01, top1 88.24, top5 94.12
2021-11-05 09:02:22 valid 0000, loss 7.569e-01, top1 88.24, top5 94.12
2021-11-05 09:02:22 valid 0000, loss 7.569e-01, top1 88.24, top5 94.12
2021-11-05 09:07:26 (JOBID 31647) epoch 0: train time 2772.67, inference time 314.41s, valid_top1 66.00 (best_top1 66.00), valid_top5 86.45
2021-11-05 09:07:28 (JOBID 31647) epoch 0: train time 2763.65, inference time 314.66s, valid_top1 66.00 (best_top1 66.00), valid_top5 86.45
2021-11-05 09:07:29 (JOBID 31647) epoch 0: train time 2763.36, inference time 316.83s, valid_top1 66.00 (best_top1 66.00), valid_top5 86.45
2021-11-05 09:07:42 train 0000, loss 1.690e+00, top1 69.41, top5 83.53
2021-11-05 09:07:42 train 0000, loss 1.193e+00, top1 71.76, top5 87.06
2021-11-05 09:07:44 train 0000, loss 1.298e+00, top1 68.24, top5 89.41
2021-11-05 09:16:57 train 1000, loss 1.413e+00, top1 66.94, top5 85.94
2021-11-05 09:16:57 train 1000, loss 1.398e+00, top1 67.08, top5 86.15
2021-11-05 09:16:57 train 1000, loss 1.401e+00, top1 67.02, top5 86.25
2021-11-05 09:26:02 train 2000, loss 1.411e+00, top1 66.86, top5 86.08
2021-11-05 09:26:02 train 2000, loss 1.419e+00, top1 66.76, top5 86.04
2021-11-05 09:26:02 train 2000, loss 1.425e+00, top1 66.64, top5 85.81
2021-11-05 09:35:08 train 3000, loss 1.437e+00, top1 66.37, top5 85.80
2021-11-05 09:35:08 train 3000, loss 1.434e+00, top1 66.37, top5 85.82
2021-11-05 09:35:08 train 3000, loss 1.440e+00, top1 66.36, top5 85.68
2021-11-05 09:44:06 train 4000, loss 1.450e+00, top1 66.05, top5 85.63
2021-11-05 09:44:06 train 4000, loss 1.454e+00, top1 66.07, top5 85.58
2021-11-05 09:44:06 train 4000, loss 1.457e+00, top1 66.01, top5 85.48
2021-11-05 09:53:07 train 5000, loss 1.472e+00, top1 65.74, top5 85.34
2021-11-05 09:53:07 train 5000, loss 1.468e+00, top1 65.67, top5 85.41
2021-11-05 09:53:07 train 5000, loss 1.473e+00, top1 65.70, top5 85.29
2021-11-05 09:53:33 valid 0000, loss 7.120e-01, top1 87.06, top5 91.76
2021-11-05 09:53:33 valid 0000, loss 7.120e-01, top1 87.06, top5 91.76
2021-11-05 09:53:33 valid 0000, loss 7.120e-01, top1 87.06, top5 91.76
2021-11-05 09:58:30 (JOBID 31647) epoch 1: train time 2751.19, inference time 309.55s, valid_top1 63.16 (best_top1 66.00), valid_top5 84.88
2021-11-05 09:58:30 (JOBID 31647) epoch 1: train time 2753.63, inference time 309.55s, valid_top1 63.16 (best_top1 66.00), valid_top5 84.88
2021-11-05 09:58:30 (JOBID 31647) epoch 1: train time 2752.46, inference time 309.54s, valid_top1 63.16 (best_top1 66.00), valid_top5 84.88
2021-11-05 09:58:46 train 0000, loss 1.551e+00, top1 72.94, top5 85.88
2021-11-05 09:58:46 train 0000, loss 1.503e+00, top1 68.24, top5 82.35
2021-11-05 09:58:47 train 0000, loss 1.880e+00, top1 55.29, top5 80.00
2021-11-05 10:07:58 train 1000, loss 1.545e+00, top1 64.25, top5 84.32
2021-11-05 10:07:58 train 1000, loss 1.537e+00, top1 64.39, top5 84.74
2021-11-05 10:07:58 train 1000, loss 1.556e+00, top1 64.14, top5 84.25
2021-11-05 10:17:03 train 2000, loss 1.572e+00, top1 63.69, top5 84.08
2021-11-05 10:17:03 train 2000, loss 1.563e+00, top1 63.80, top5 84.39
2021-11-05 10:17:03 train 2000, loss 1.570e+00, top1 63.77, top5 84.08
2021-11-05 10:26:07 train 3000, loss 1.584e+00, top1 63.38, top5 84.03
2021-11-05 10:26:07 train 3000, loss 1.591e+00, top1 63.32, top5 83.86
2021-11-05 10:26:08 train 3000, loss 1.594e+00, top1 63.21, top5 83.79
2021-11-05 10:35:09 train 4000, loss 1.607e+00, top1 62.90, top5 83.70
2021-11-05 10:35:09 train 4000, loss 1.612e+00, top1 62.93, top5 83.58
2021-11-05 10:35:09 train 4000, loss 1.615e+00, top1 62.70, top5 83.52
2021-11-05 10:44:11 train 5000, loss 1.626e+00, top1 62.51, top5 83.46
2021-11-05 10:44:11 train 5000, loss 1.633e+00, top1 62.50, top5 83.32
2021-11-05 10:44:11 train 5000, loss 1.635e+00, top1 62.27, top5 83.26
2021-11-05 10:44:37 valid 0000, loss 9.730e-01, top1 80.00, top5 88.24
2021-11-05 10:44:37 valid 0000, loss 9.730e-01, top1 80.00, top5 88.24
2021-11-05 10:44:37 valid 0000, loss 9.730e-01, top1 80.00, top5 88.24
2021-11-05 10:49:17 (JOBID 31647) epoch 2: train time 2754.25, inference time 292.22s, valid_top1 61.64 (best_top1 66.00), valid_top5 84.28
2021-11-05 10:49:17 (JOBID 31647) epoch 2: train time 2754.79, inference time 292.57s, valid_top1 61.64 (best_top1 66.00), valid_top5 84.28
2021-11-05 10:49:18 (JOBID 31647) epoch 2: train time 2754.70, inference time 293.66s, valid_top1 61.64 (best_top1 66.00), valid_top5 84.28
2021-11-05 10:49:34 train 0000, loss 1.499e+00, top1 67.06, top5 89.41
2021-11-05 10:49:34 train 0000, loss 2.049e+00, top1 52.94, top5 76.47
2021-11-05 10:49:34 train 0000, loss 1.577e+00, top1 63.53, top5 87.06
2021-11-05 10:58:39 train 1000, loss 1.711e+00, top1 60.75, top5 82.31
2021-11-05 10:58:39 train 1000, loss 1.715e+00, top1 60.72, top5 82.21
2021-11-05 10:58:39 train 1000, loss 1.702e+00, top1 60.81, top5 82.64
2021-11-05 11:07:40 train 2000, loss 1.733e+00, top1 60.26, top5 82.02
2021-11-05 11:07:40 train 2000, loss 1.741e+00, top1 60.12, top5 81.84
2021-11-05 11:07:40 train 2000, loss 1.736e+00, top1 60.17, top5 82.04
2021-11-05 11:16:42 train 3000, loss 1.764e+00, top1 59.63, top5 81.52
2021-11-05 11:16:42 train 3000, loss 1.757e+00, top1 59.80, top5 81.69
2021-11-05 11:16:42 train 3000, loss 1.758e+00, top1 59.74, top5 81.73
2021-11-05 11:25:43 train 4000, loss 1.782e+00, top1 59.27, top5 81.26
2021-11-05 11:25:43 train 4000, loss 1.777e+00, top1 59.37, top5 81.40
2021-11-05 11:25:43 train 4000, loss 1.777e+00, top1 59.33, top5 81.41
2021-11-05 11:34:45 train 5000, loss 1.795e+00, top1 58.99, top5 81.14
2021-11-05 11:34:45 train 5000, loss 1.799e+00, top1 58.90, top5 81.07
2021-11-05 11:34:45 train 5000, loss 1.800e+00, top1 58.86, top5 80.98
2021-11-05 11:35:09 valid 0000, loss 1.203e+00, top1 70.59, top5 89.41
2021-11-05 11:35:09 valid 0000, loss 1.203e+00, top1 70.59, top5 89.41
2021-11-05 11:35:09 valid 0000, loss 1.203e+00, top1 70.59, top5 89.41
2021-11-05 11:39:47 (JOBID 31647) epoch 3: train time 2741.20, inference time 289.03s, valid_top1 59.90 (best_top1 66.00), valid_top5 82.95
2021-11-05 11:39:48 (JOBID 31647) epoch 3: train time 2741.48, inference time 289.59s, valid_top1 59.90 (best_top1 66.00), valid_top5 82.95
2021-11-05 11:39:49 (JOBID 31647) epoch 3: train time 2740.21, inference time 291.06s, valid_top1 59.90 (best_top1 66.00), valid_top5 82.95
2021-11-05 11:40:03 train 0000, loss 2.079e+00, top1 52.94, top5 77.65
2021-11-05 11:40:03 train 0000, loss 1.719e+00, top1 55.29, top5 82.35
2021-11-05 11:40:03 train 0000, loss 2.246e+00, top1 55.29, top5 71.76
2021-11-05 11:49:26 train 1000, loss 1.868e+00, top1 57.33, top5 80.03
2021-11-05 11:49:26 train 1000, loss 1.862e+00, top1 57.65, top5 80.33
2021-11-05 11:49:27 train 1000, loss 1.876e+00, top1 57.34, top5 79.89
2021-11-05 11:58:56 train 2000, loss 1.892e+00, top1 56.79, top5 79.61
2021-11-05 11:58:56 train 2000, loss 1.889e+00, top1 57.03, top5 79.84
2021-11-05 11:58:56 train 2000, loss 1.895e+00, top1 56.93, top5 79.64
2021-11-05 12:08:10 train 3000, loss 1.914e+00, top1 56.54, top5 79.47
2021-11-05 12:08:10 train 3000, loss 1.915e+00, top1 56.34, top5 79.31
2021-11-05 12:08:10 train 3000, loss 1.917e+00, top1 56.45, top5 79.34
2021-11-05 12:17:23 train 4000, loss 1.930e+00, top1 56.21, top5 79.18
2021-11-05 12:17:23 train 4000, loss 1.934e+00, top1 55.98, top5 79.03
2021-11-05 12:17:24 train 4000, loss 1.936e+00, top1 56.03, top5 79.03
2021-11-05 12:26:35 train 5000, loss 1.949e+00, top1 55.87, top5 78.88
2021-11-05 12:26:35 train 5000, loss 1.950e+00, top1 55.67, top5 78.82
2021-11-05 12:26:36 train 5000, loss 1.951e+00, top1 55.68, top5 78.81
2021-11-05 12:27:01 valid 0000, loss 8.936e-01, top1 80.00, top5 94.12
2021-11-05 12:27:01 valid 0000, loss 8.936e-01, top1 80.00, top5 94.12
2021-11-05 12:27:01 valid 0000, loss 8.936e-01, top1 80.00, top5 94.12
2021-11-05 12:31:33 (JOBID 31647) epoch 4: train time 2819.67, inference time 284.50s, valid_top1 56.80 (best_top1 66.00), valid_top5 81.03
2021-11-05 12:31:35 (JOBID 31647) epoch 4: train time 2821.70, inference time 286.23s, valid_top1 56.80 (best_top1 66.00), valid_top5 81.03
2021-11-05 12:31:36 (JOBID 31647) epoch 4: train time 2820.69, inference time 286.62s, valid_top1 56.80 (best_top1 66.00), valid_top5 81.03
2021-11-05 12:31:49 train 0000, loss 1.693e+00, top1 57.65, top5 82.35
2021-11-05 12:31:49 train 0000, loss 2.271e+00, top1 56.47, top5 76.47
2021-11-05 12:31:49 train 0000, loss 2.162e+00, top1 54.12, top5 77.65
2021-11-05 12:40:57 train 1000, loss 2.007e+00, top1 54.48, top5 77.90
2021-11-05 12:40:57 train 1000, loss 1.993e+00, top1 54.75, top5 78.20
2021-11-05 12:40:57 train 1000, loss 2.001e+00, top1 54.74, top5 78.09
2021-11-05 12:50:09 train 2000, loss 2.021e+00, top1 54.16, top5 77.73
2021-11-05 12:50:09 train 2000, loss 2.016e+00, top1 54.37, top5 77.78
2021-11-05 12:50:09 train 2000, loss 2.024e+00, top1 54.21, top5 77.71
2021-11-05 12:59:12 train 3000, loss 2.036e+00, top1 53.93, top5 77.50
2021-11-05 12:59:12 train 3000, loss 2.033e+00, top1 54.02, top5 77.56
2021-11-05 12:59:12 train 3000, loss 2.036e+00, top1 54.01, top5 77.51
2021-11-05 13:08:15 train 4000, loss 2.049e+00, top1 53.70, top5 77.30
2021-11-05 13:08:15 train 4000, loss 2.051e+00, top1 53.66, top5 77.26
2021-11-05 13:08:15 train 4000, loss 2.050e+00, top1 53.75, top5 77.28
2021-11-05 13:17:21 train 5000, loss 2.062e+00, top1 53.49, top5 77.08
2021-11-05 13:17:21 train 5000, loss 2.062e+00, top1 53.43, top5 77.13
2021-11-05 13:17:21 train 5000, loss 2.060e+00, top1 53.50, top5 77.10
2021-11-05 13:17:45 valid 0000, loss 1.290e+00, top1 76.47, top5 87.06
2021-11-05 13:17:45 valid 0000, loss 1.290e+00, top1 76.47, top5 87.06
2021-11-05 13:17:45 valid 0000, loss 1.290e+00, top1 76.47, top5 87.06
2021-11-05 13:22:24 (JOBID 31647) epoch 5: train time 2759.19, inference time 289.44s, valid_top1 51.55 (best_top1 66.00), valid_top5 77.34
2021-11-05 13:22:24 (JOBID 31647) epoch 5: train time 2760.78, inference time 289.65s, valid_top1 51.55 (best_top1 66.00), valid_top5 77.34
2021-11-05 13:22:24 (JOBID 31647) epoch 5: train time 2758.38, inference time 289.49s, valid_top1 51.55 (best_top1 66.00), valid_top5 77.34
2021-11-05 13:22:39 train 0000, loss 2.418e+00, top1 45.88, top5 71.76
2021-11-05 13:22:39 train 0000, loss 2.076e+00, top1 55.29, top5 76.47
2021-11-05 13:22:39 train 0000, loss 2.585e+00, top1 43.53, top5 71.76
2021-11-05 13:31:42 train 1000, loss 2.089e+00, top1 53.14, top5 76.62
2021-11-05 13:31:42 train 1000, loss 2.086e+00, top1 52.97, top5 76.67
2021-11-05 13:31:42 train 1000, loss 2.090e+00, top1 52.98, top5 76.70
2021-11-05 13:40:56 train 2000, loss 2.109e+00, top1 52.44, top5 76.41
2021-11-05 13:40:56 train 2000, loss 2.095e+00, top1 52.80, top5 76.65
2021-11-05 13:40:56 train 2000, loss 2.110e+00, top1 52.55, top5 76.39
2021-11-05 13:50:04 train 3000, loss 2.111e+00, top1 52.53, top5 76.38
2021-11-05 13:50:04 train 3000, loss 2.115e+00, top1 52.37, top5 76.28
2021-11-05 13:50:05 train 3000, loss 2.120e+00, top1 52.30, top5 76.24
2021-11-05 13:59:11 train 4000, loss 2.123e+00, top1 52.22, top5 76.15
2021-11-05 13:59:11 train 4000, loss 2.120e+00, top1 52.38, top5 76.27
2021-11-05 13:59:11 train 4000, loss 2.128e+00, top1 52.13, top5 76.09
2021-11-05 14:08:20 train 5000, loss 2.134e+00, top1 52.01, top5 76.00
2021-11-05 14:08:20 train 5000, loss 2.139e+00, top1 51.93, top5 75.93
2021-11-05 14:08:20 train 5000, loss 2.130e+00, top1 52.15, top5 76.10
2021-11-05 14:08:45 valid 0000, loss 7.332e-01, top1 84.71, top5 92.94
2021-11-05 14:08:45 valid 0000, loss 7.332e-01, top1 84.71, top5 92.94
2021-11-05 14:08:45 valid 0000, loss 7.332e-01, top1 84.71, top5 92.94
2021-11-05 14:13:10 (JOBID 31647) epoch 6: train time 2769.76, inference time 276.47s, valid_top1 53.42 (best_top1 66.00), valid_top5 78.56
2021-11-05 14:13:25 (JOBID 31647) epoch 6: train time 2769.46, inference time 290.77s, valid_top1 53.42 (best_top1 66.00), valid_top5 78.56
2021-11-05 14:13:27 (JOBID 31647) epoch 6: train time 2769.92, inference time 293.69s, valid_top1 53.42 (best_top1 66.00), valid_top5 78.56
2021-11-05 14:13:40 train 0000, loss 2.158e+00, top1 50.59, top5 75.29
2021-11-05 14:13:26 train 0000, loss 2.421e+00, top1 40.00, top5 76.47
2021-11-05 14:13:41 train 0000, loss 2.305e+00, top1 47.06, top5 78.82
2021-11-05 14:22:39 train 1000, loss 2.138e+00, top1 52.04, top5 75.83
2021-11-05 14:22:39 train 1000, loss 2.131e+00, top1 52.02, top5 76.18
2021-11-05 14:22:39 train 1000, loss 2.142e+00, top1 51.77, top5 75.77
2021-11-05 14:31:41 train 2000, loss 2.151e+00, top1 51.69, top5 75.79
2021-11-05 14:31:41 train 2000, loss 2.149e+00, top1 51.84, top5 75.73
2021-11-05 14:31:41 train 2000, loss 2.146e+00, top1 51.76, top5 75.75
2021-11-05 14:40:43 train 3000, loss 2.159e+00, top1 51.52, top5 75.68
2021-11-05 14:40:43 train 3000, loss 2.152e+00, top1 51.59, top5 75.69
2021-11-05 14:40:43 train 3000, loss 2.159e+00, top1 51.61, top5 75.57
2021-11-05 14:49:42 train 4000, loss 2.166e+00, top1 51.48, top5 75.49
2021-11-05 14:49:42 train 4000, loss 2.164e+00, top1 51.43, top5 75.56
2021-11-05 14:49:42 train 4000, loss 2.159e+00, top1 51.49, top5 75.58
2021-11-05 14:58:41 train 5000, loss 2.169e+00, top1 51.33, top5 75.47
2021-11-05 14:58:41 train 5000, loss 2.167e+00, top1 51.35, top5 75.47
2021-11-05 14:58:41 train 5000, loss 2.175e+00, top1 51.34, top5 75.35
2021-11-05 14:59:05 valid 0000, loss 1.347e+00, top1 78.82, top5 88.24
2021-11-05 14:59:05 valid 0000, loss 1.347e+00, top1 78.82, top5 88.24
2021-11-05 14:59:05 valid 0000, loss 1.347e+00, top1 78.82, top5 88.24
2021-11-05 15:03:44 (JOBID 31647) epoch 7: train time 2729.61, inference time 289.00s, valid_top1 51.09 (best_top1 66.00), valid_top5 76.52
2021-11-05 15:03:44 (JOBID 31647) epoch 7: train time 2744.38, inference time 289.41s, valid_top1 51.09 (best_top1 66.00), valid_top5 76.52
2021-11-05 15:03:44 (JOBID 31647) epoch 7: train time 2726.90, inference time 289.92s, valid_top1 51.09 (best_top1 66.00), valid_top5 76.52
2021-11-05 15:03:58 train 0000, loss 2.064e+00, top1 49.41, top5 78.82
2021-11-05 15:03:58 train 0000, loss 2.603e+00, top1 40.00, top5 70.59
2021-11-05 15:03:58 train 0000, loss 2.540e+00, top1 37.65, top5 64.71
2021-11-05 15:13:07 train 1000, loss 2.154e+00, top1 51.49, top5 75.67
2021-11-05 15:13:07 train 1000, loss 2.167e+00, top1 51.51, top5 75.45
2021-11-05 15:13:08 train 1000, loss 2.169e+00, top1 51.51, top5 75.49
2021-11-05 15:22:23 train 2000, loss 2.164e+00, top1 51.44, top5 75.49
2021-11-05 15:22:23 train 2000, loss 2.170e+00, top1 51.38, top5 75.39
2021-11-05 15:22:23 train 2000, loss 2.175e+00, top1 51.33, top5 75.35
2021-11-05 15:31:32 train 3000, loss 2.173e+00, top1 51.21, top5 75.35
2021-11-05 15:31:32 train 3000, loss 2.176e+00, top1 51.21, top5 75.31
2021-11-05 15:31:33 train 3000, loss 2.183e+00, top1 51.12, top5 75.21
2021-11-05 15:40:43 train 4000, loss 2.186e+00, top1 51.07, top5 75.17
2021-11-05 15:40:43 train 4000, loss 2.181e+00, top1 51.05, top5 75.22
2021-11-05 15:40:43 train 4000, loss 2.180e+00, top1 51.10, top5 75.20
2021-11-05 15:49:50 train 5000, loss 2.184e+00, top1 51.04, top5 75.16
2021-11-05 15:49:50 train 5000, loss 2.188e+00, top1 50.92, top5 75.11
2021-11-05 15:49:50 train 5000, loss 2.190e+00, top1 50.94, top5 75.12
2021-11-05 15:50:14 valid 0000, loss 1.136e+00, top1 77.65, top5 89.41
2021-11-05 15:50:14 valid 0000, loss 1.136e+00, top1 77.65, top5 89.41
2021-11-05 15:50:14 valid 0000, loss 1.136e+00, top1 77.65, top5 89.41
2021-11-05 15:54:47 (JOBID 31647) epoch 8: train time 2779.31, inference time 283.87s, valid_top1 49.72 (best_top1 66.00), valid_top5 75.38
2021-11-05 15:54:54 (JOBID 31647) epoch 8: train time 2779.67, inference time 290.57s, valid_top1 49.72 (best_top1 66.00), valid_top5 75.38
2021-11-05 15:54:56 (JOBID 31647) epoch 8: train time 2779.89, inference time 292.19s, valid_top1 49.72 (best_top1 66.00), valid_top5 75.38
2021-11-05 15:55:08 train 0000, loss 2.395e+00, top1 43.53, top5 74.12
2021-11-05 15:55:02 train 0000, loss 1.990e+00, top1 55.29, top5 76.47
2021-11-05 15:55:10 train 0000, loss 1.800e+00, top1 62.35, top5 82.35
2021-11-05 16:04:17 train 1000, loss 2.185e+00, top1 50.84, top5 75.16
2021-11-05 16:04:17 train 1000, loss 2.174e+00, top1 51.30, top5 75.35
2021-11-05 16:04:17 train 1000, loss 2.174e+00, top1 50.98, top5 75.36
2021-11-05 16:13:31 train 2000, loss 2.188e+00, top1 50.89, top5 75.15
2021-11-05 16:13:31 train 2000, loss 2.191e+00, top1 50.70, top5 75.11
2021-11-05 16:13:31 train 2000, loss 2.184e+00, top1 51.06, top5 75.17
2021-11-05 16:22:48 train 3000, loss 2.191e+00, top1 50.88, top5 75.12
2021-11-05 16:22:48 train 3000, loss 2.190e+00, top1 50.95, top5 75.14
2021-11-05 16:22:48 train 3000, loss 2.195e+00, top1 50.70, top5 75.04
2021-11-05 16:33:37 train 4000, loss 2.200e+00, top1 50.74, top5 74.99
2021-11-05 16:33:37 train 4000, loss 2.194e+00, top1 50.84, top5 75.07
2021-11-05 16:33:37 train 4000, loss 2.196e+00, top1 50.73, top5 75.07
2021-11-05 16:42:38 train 5000, loss 2.197e+00, top1 50.81, top5 75.02
2021-11-05 16:42:38 train 5000, loss 2.202e+00, top1 50.71, top5 74.94
2021-11-05 16:42:38 train 5000, loss 2.200e+00, top1 50.69, top5 74.99
2021-11-05 16:43:04 valid 0000, loss 1.107e+00, top1 78.82, top5 89.41
2021-11-05 16:43:04 valid 0000, loss 1.107e+00, top1 78.82, top5 89.41
2021-11-05 16:43:04 valid 0000, loss 1.107e+00, top1 78.82, top5 89.41
2021-11-05 16:47:29 (JOBID 31647) epoch 9: train time 2875.38, inference time 276.71s, valid_top1 48.55 (best_top1 66.00), valid_top5 74.64
2021-11-05 16:47:37 (JOBID 31647) epoch 9: train time 2884.03, inference time 285.82s, valid_top1 48.55 (best_top1 66.00), valid_top5 74.64
2021-11-05 16:47:43 (JOBID 31647) epoch 9: train time 2877.42, inference time 291.80s, valid_top1 48.55 (best_top1 66.00), valid_top5 74.64
2021-11-05 16:47:51 train 0000, loss 1.941e+00, top1 49.41, top5 80.00
2021-11-05 16:47:45 train 0000, loss 2.223e+00, top1 55.29, top5 72.94
2021-11-05 16:47:57 train 0000, loss 2.235e+00, top1 50.59, top5 68.24
2021-11-05 16:56:57 train 1000, loss 2.185e+00, top1 50.96, top5 75.15
2021-11-05 16:56:57 train 1000, loss 2.183e+00, top1 50.88, top5 75.12
2021-11-05 16:56:58 train 1000, loss 2.184e+00, top1 51.16, top5 75.01
2021-11-05 17:06:02 train 2000, loss 2.188e+00, top1 50.85, top5 75.09
2021-11-05 17:06:02 train 2000, loss 2.189e+00, top1 51.02, top5 75.00
2021-11-05 17:06:02 train 2000, loss 2.189e+00, top1 50.90, top5 75.05
2021-11-05 17:15:00 train 3000, loss 2.191e+00, top1 50.88, top5 75.08
2021-11-05 17:15:00 train 3000, loss 2.196e+00, top1 50.76, top5 75.01
2021-11-05 17:15:00 train 3000, loss 2.196e+00, top1 50.93, top5 74.93
2021-11-05 17:24:47 train 4000, loss 2.199e+00, top1 50.77, top5 74.95
2021-11-05 17:24:47 train 4000, loss 2.200e+00, top1 50.66, top5 74.95
2021-11-05 17:24:47 train 4000, loss 2.202e+00, top1 50.73, top5 74.88
2021-11-05 17:33:49 train 5000, loss 2.201e+00, top1 50.61, top5 74.94
2021-11-05 17:33:49 train 5000, loss 2.203e+00, top1 50.70, top5 74.92
2021-11-05 17:33:49 train 5000, loss 2.206e+00, top1 50.66, top5 74.84
2021-11-05 17:34:12 valid 0000, loss 1.201e+00, top1 76.47, top5 88.24
2021-11-05 17:34:12 valid 0000, loss 1.201e+00, top1 76.47, top5 88.24
2021-11-05 17:34:12 valid 0000, loss 1.201e+00, top1 76.47, top5 88.24
2021-11-05 17:39:04 (JOBID 31647) epoch 10: train time 2784.72, inference time 302.15s, valid_top1 51.22 (best_top1 66.00), valid_top5 77.03
2021-11-05 17:39:05 (JOBID 31647) epoch 10: train time 2778.63, inference time 302.66s, valid_top1 51.22 (best_top1 66.00), valid_top5 77.03
2021-11-05 17:39:05 (JOBID 31647) epoch 10: train time 2793.20, inference time 302.61s, valid_top1 51.22 (best_top1 66.00), valid_top5 77.03
2021-11-05 17:39:19 train 0000, loss 2.138e+00, top1 55.29, top5 70.59
2021-11-05 17:39:19 train 0000, loss 2.083e+00, top1 49.41, top5 75.29
2021-11-05 17:39:19 train 0000, loss 2.312e+00, top1 44.71, top5 71.76
2021-11-05 17:48:21 train 1000, loss 2.188e+00, top1 50.84, top5 75.27
2021-11-05 17:48:21 train 1000, loss 2.171e+00, top1 51.14, top5 75.48
2021-11-05 17:48:22 train 1000, loss 2.192e+00, top1 50.74, top5 75.22
2021-11-05 17:57:32 train 2000, loss 2.203e+00, top1 50.62, top5 74.96
2021-11-05 17:57:32 train 2000, loss 2.174e+00, top1 51.05, top5 75.33
2021-11-05 17:57:33 train 2000, loss 2.198e+00, top1 50.72, top5 75.01
2021-11-05 18:07:28 train 3000, loss 2.183e+00, top1 50.94, top5 75.23
2021-11-05 18:07:28 train 3000, loss 2.205e+00, top1 50.59, top5 74.91
2021-11-05 18:07:28 train 3000, loss 2.204e+00, top1 50.59, top5 74.89
2021-11-05 18:16:29 train 4000, loss 2.209e+00, top1 50.51, top5 74.81
2021-11-05 18:16:29 train 4000, loss 2.194e+00, top1 50.81, top5 75.08
2021-11-05 18:16:30 train 4000, loss 2.207e+00, top1 50.53, top5 74.80
2021-11-05 18:25:40 train 5000, loss 2.211e+00, top1 50.47, top5 74.76
2021-11-05 18:25:40 train 5000, loss 2.200e+00, top1 50.69, top5 74.99
2021-11-05 18:25:40 train 5000, loss 2.212e+00, top1 50.49, top5 74.74
2021-11-05 18:26:04 valid 0000, loss 9.589e-01, top1 81.18, top5 89.41
2021-11-05 18:26:04 valid 0000, loss 9.589e-01, top1 81.18, top5 89.41
2021-11-05 18:26:04 valid 0000, loss 9.589e-01, top1 81.18, top5 89.41
2021-11-05 18:31:00 (JOBID 31647) epoch 11: train time 2809.58, inference time 306.60s, valid_top1 50.03 (best_top1 66.00), valid_top5 75.77
2021-11-05 18:31:00 (JOBID 31647) epoch 11: train time 2809.08, inference time 306.60s, valid_top1 50.03 (best_top1 66.00), valid_top5 75.77
2021-11-05 18:31:01 (JOBID 31647) epoch 11: train time 2808.69, inference time 306.50s, valid_top1 50.03 (best_top1 66.00), valid_top5 75.77
2021-11-05 18:31:15 train 0000, loss 2.047e+00, top1 60.00, top5 75.29
2021-11-05 18:31:15 train 0000, loss 2.010e+00, top1 56.47, top5 77.65
2021-11-05 18:31:15 train 0000, loss 2.547e+00, top1 42.35, top5 68.24
2021-11-05 18:40:20 train 1000, loss 2.187e+00, top1 51.03, top5 74.92
2021-11-05 18:40:20 train 1000, loss 2.199e+00, top1 50.65, top5 74.87
2021-11-05 18:40:20 train 1000, loss 2.182e+00, top1 50.98, top5 75.24
2021-11-05 18:49:30 train 2000, loss 2.198e+00, top1 50.73, top5 74.93
2021-11-05 18:49:30 train 2000, loss 2.196e+00, top1 50.89, top5 74.87
2021-11-05 18:49:30 train 2000, loss 2.196e+00, top1 50.75, top5 74.97
2021-11-05 18:58:33 train 3000, loss 2.201e+00, top1 50.64, top5 74.87
2021-11-05 18:58:33 train 3000, loss 2.201e+00, top1 50.74, top5 74.83
2021-11-05 18:58:33 train 3000, loss 2.200e+00, top1 50.67, top5 74.97
2021-11-05 19:07:33 train 4000, loss 2.205e+00, top1 50.56, top5 74.89
2021-11-05 19:07:33 train 4000, loss 2.206e+00, top1 50.59, top5 74.82
2021-11-05 19:07:33 train 4000, loss 2.205e+00, top1 50.64, top5 74.77
2021-11-05 19:16:34 train 5000, loss 2.212e+00, top1 50.51, top5 74.70
2021-11-05 19:16:34 train 5000, loss 2.211e+00, top1 50.46, top5 74.80
2021-11-05 19:16:34 train 5000, loss 2.212e+00, top1 50.53, top5 74.70
2021-11-05 19:16:58 valid 0000, loss 1.201e+00, top1 77.65, top5 89.41
2021-11-05 19:16:58 valid 0000, loss 1.201e+00, top1 77.65, top5 89.41
2021-11-05 19:16:58 valid 0000, loss 1.201e+00, top1 77.65, top5 89.41
2021-11-05 19:21:42 (JOBID 31647) epoch 12: train time 2747.36, inference time 292.33s, valid_top1 50.59 (best_top1 66.00), valid_top5 76.45
2021-11-05 19:21:45 (JOBID 31647) epoch 12: train time 2747.64, inference time 297.01s, valid_top1 50.59 (best_top1 66.00), valid_top5 76.45
2021-11-05 19:21:51 (JOBID 31647) epoch 12: train time 2747.66, inference time 302.79s, valid_top1 50.59 (best_top1 66.00), valid_top5 76.45
2021-11-05 19:21:58 train 0000, loss 2.107e+00, top1 50.59, top5 74.12
2021-11-05 19:21:56 train 0000, loss 2.115e+00, top1 48.24, top5 70.59
2021-11-05 19:22:05 train 0000, loss 2.250e+00, top1 47.06, top5 72.94
2021-11-05 19:31:18 train 1000, loss 2.198e+00, top1 50.84, top5 75.02
2021-11-05 19:31:18 train 1000, loss 2.196e+00, top1 50.58, top5 74.92
2021-11-05 19:31:18 train 1000, loss 2.198e+00, top1 50.60, top5 75.00
2021-11-05 19:40:33 train 2000, loss 2.196e+00, top1 50.67, top5 75.02
2021-11-05 19:40:33 train 2000, loss 2.201e+00, top1 50.72, top5 74.87
2021-11-05 19:40:33 train 2000, loss 2.210e+00, top1 50.46, top5 74.77
2021-11-05 19:49:47 train 3000, loss 2.205e+00, top1 50.58, top5 74.84
2021-11-05 19:49:47 train 3000, loss 2.202e+00, top1 50.53, top5 74.92
2021-11-05 19:49:47 train 3000, loss 2.214e+00, top1 50.42, top5 74.68
2021-11-05 19:59:01 train 4000, loss 2.210e+00, top1 50.47, top5 74.80
2021-11-05 19:59:01 train 4000, loss 2.208e+00, top1 50.45, top5 74.82
2021-11-05 19:59:01 train 4000, loss 2.220e+00, top1 50.33, top5 74.61
2021-11-05 20:08:10 train 5000, loss 2.211e+00, top1 50.40, top5 74.78
2021-11-05 20:08:09 train 5000, loss 2.211e+00, top1 50.48, top5 74.76
2021-11-05 20:08:10 train 5000, loss 2.220e+00, top1 50.32, top5 74.65
2021-11-05 20:08:33 valid 0000, loss 1.266e+00, top1 75.29, top5 83.53
2021-11-05 20:08:33 valid 0000, loss 1.266e+00, top1 75.29, top5 83.53
2021-11-05 20:08:33 valid 0000, loss 1.266e+00, top1 75.29, top5 83.53
2021-11-05 20:13:38 (JOBID 31647) epoch 13: train time 2798.18, inference time 314.56s, valid_top1 52.37 (best_top1 66.00), valid_top5 77.96
2021-11-05 20:13:38 (JOBID 31647) epoch 13: train time 2801.69, inference time 314.78s, valid_top1 52.37 (best_top1 66.00), valid_top5 77.96
2021-11-05 20:13:38 (JOBID 31647) epoch 13: train time 2792.37, inference time 315.26s, valid_top1 52.37 (best_top1 66.00), valid_top5 77.96
2021-11-05 20:13:52 train 0000, loss 2.096e+00, top1 48.24, top5 75.29
2021-11-05 20:13:52 train 0000, loss 2.093e+00, top1 52.94, top5 72.94
2021-11-05 20:13:52 train 0000, loss 1.925e+00, top1 62.35, top5 81.18
2021-11-05 20:22:58 train 1000, loss 2.195e+00, top1 50.76, top5 74.82
2021-11-05 20:22:58 train 1000, loss 2.196e+00, top1 50.76, top5 75.10
2021-11-05 20:22:58 train 1000, loss 2.172e+00, top1 51.13, top5 75.37
2021-11-05 20:32:06 train 2000, loss 2.200e+00, top1 50.66, top5 75.03
2021-11-05 20:32:05 train 2000, loss 2.204e+00, top1 50.59, top5 74.73
2021-11-05 20:32:06 train 2000, loss 2.191e+00, top1 50.81, top5 75.06
2021-11-05 20:41:06 train 3000, loss 2.206e+00, top1 50.58, top5 74.74
2021-11-05 20:41:06 train 3000, loss 2.209e+00, top1 50.53, top5 74.88
2021-11-05 20:41:06 train 3000, loss 2.199e+00, top1 50.60, top5 74.92
2021-11-05 20:50:13 train 4000, loss 2.214e+00, top1 50.49, top5 74.64
2021-11-05 20:50:13 train 4000, loss 2.210e+00, top1 50.51, top5 74.89
2021-11-05 20:50:13 train 4000, loss 2.204e+00, top1 50.56, top5 74.86
2021-11-05 20:59:16 train 5000, loss 2.216e+00, top1 50.43, top5 74.61
2021-11-05 20:59:16 train 5000, loss 2.212e+00, top1 50.50, top5 74.81
2021-11-05 20:59:16 train 5000, loss 2.209e+00, top1 50.50, top5 74.76
2021-11-05 20:59:40 valid 0000, loss 8.292e-01, top1 82.35, top5 94.12
2021-11-05 20:59:40 valid 0000, loss 8.292e-01, top1 82.35, top5 94.12
2021-11-05 20:59:40 valid 0000, loss 8.292e-01, top1 82.35, top5 94.12
2021-11-05 21:04:41 (JOBID 31647) epoch 14: train time 2750.67, inference time 311.97s, valid_top1 53.18 (best_top1 66.00), valid_top5 78.79
2021-11-05 21:04:41 (JOBID 31647) epoch 14: train time 2751.36, inference time 312.40s, valid_top1 53.18 (best_top1 66.00), valid_top5 78.79
2021-11-05 21:04:42 (JOBID 31647) epoch 14: train time 2750.92, inference time 312.14s, valid_top1 53.18 (best_top1 66.00), valid_top5 78.79
2021-11-05 21:04:56 train 0000, loss 1.870e+00, top1 61.18, top5 78.82
2021-11-05 21:04:56 train 0000, loss 1.795e+00, top1 61.18, top5 81.18
2021-11-05 21:04:56 train 0000, loss 1.947e+00, top1 49.41, top5 77.65
2021-11-05 21:13:59 train 1000, loss 2.188e+00, top1 51.02, top5 75.04
2021-11-05 21:13:59 train 1000, loss 2.171e+00, top1 51.18, top5 75.41
2021-11-05 21:13:59 train 1000, loss 2.186e+00, top1 51.02, top5 75.23
2021-11-05 21:23:06 train 2000, loss 2.190e+00, top1 50.80, top5 75.10
2021-11-05 21:23:06 train 2000, loss 2.197e+00, top1 50.81, top5 75.04
2021-11-05 21:23:06 train 2000, loss 2.200e+00, top1 50.74, top5 74.85
2021-11-05 21:32:09 train 3000, loss 2.199e+00, top1 50.70, top5 74.97
2021-11-05 21:32:10 train 3000, loss 2.209e+00, top1 50.57, top5 74.77
2021-11-05 21:32:10 train 3000, loss 2.207e+00, top1 50.59, top5 74.88
2021-11-05 21:41:22 train 4000, loss 2.204e+00, top1 50.53, top5 74.91
2021-11-05 21:41:22 train 4000, loss 2.211e+00, top1 50.56, top5 74.71
2021-11-05 21:41:22 train 4000, loss 2.212e+00, top1 50.45, top5 74.78
2021-11-05 21:52:19 train 5000, loss 2.216e+00, top1 50.48, top5 74.61
2021-11-05 21:52:19 train 5000, loss 2.214e+00, top1 50.38, top5 74.74
2021-11-05 21:52:19 train 5000, loss 2.209e+00, top1 50.46, top5 74.81
2021-11-05 21:52:50 valid 0000, loss 1.217e+00, top1 75.29, top5 88.24
2021-11-05 21:52:50 valid 0000, loss 1.217e+00, top1 75.29, top5 88.24
2021-11-05 21:52:50 valid 0000, loss 1.217e+00, top1 75.29, top5 88.24
2021-11-05 21:58:04 (JOBID 31647) epoch 15: train time 2872.00, inference time 330.55s, valid_top1 50.85 (best_top1 66.00), valid_top5 76.47
2021-11-05 21:58:04 (JOBID 31647) epoch 15: train time 2871.59, inference time 330.54s, valid_top1 50.85 (best_top1 66.00), valid_top5 76.47
2021-11-05 21:58:04 (JOBID 31647) epoch 15: train time 2871.41, inference time 330.54s, valid_top1 50.85 (best_top1 66.00), valid_top5 76.47
2021-11-05 21:58:18 train 0000, loss 2.023e+00, top1 61.18, top5 78.82
2021-11-05 21:58:18 train 0000, loss 2.007e+00, top1 55.29, top5 76.47
2021-11-05 21:58:18 train 0000, loss 2.192e+00, top1 48.24, top5 77.65
2021-11-05 22:07:47 train 1000, loss 2.195e+00, top1 50.82, top5 74.96
2021-11-05 22:07:47 train 1000, loss 2.203e+00, top1 50.51, top5 74.84
2021-11-05 22:07:47 train 1000, loss 2.192e+00, top1 50.79, top5 75.07
2021-11-05 22:17:13 train 2000, loss 2.203e+00, top1 50.48, top5 74.84
2021-11-05 22:17:13 train 2000, loss 2.202e+00, top1 50.60, top5 74.94
2021-11-05 22:17:13 train 2000, loss 2.196e+00, top1 50.80, top5 74.97
2021-11-05 22:26:36 train 3000, loss 2.209e+00, top1 50.47, top5 74.84
2021-11-05 22:26:36 train 3000, loss 2.210e+00, top1 50.35, top5 74.73
2021-11-05 22:26:36 train 3000, loss 2.206e+00, top1 50.66, top5 74.82
2021-11-05 22:36:07 train 4000, loss 2.215e+00, top1 50.30, top5 74.67
2021-11-05 22:36:07 train 4000, loss 2.211e+00, top1 50.41, top5 74.81
2021-11-05 22:36:07 train 4000, loss 2.209e+00, top1 50.55, top5 74.79
2021-11-05 22:45:34 train 5000, loss 2.214e+00, top1 50.37, top5 74.73
2021-11-05 22:45:34 train 5000, loss 2.219e+00, top1 50.22, top5 74.63
2021-11-05 22:45:34 train 5000, loss 2.211e+00, top1 50.52, top5 74.73
2021-11-05 22:45:58 valid 0000, loss 9.596e-01, top1 80.00, top5 89.41
2021-11-05 22:45:58 valid 0000, loss 9.596e-01, top1 80.00, top5 89.41
2021-11-05 22:45:58 valid 0000, loss 9.596e-01, top1 80.00, top5 89.41
2021-11-05 22:50:56 (JOBID 31647) epoch 16: train time 2863.99, inference time 308.26s, valid_top1 48.20 (best_top1 66.00), valid_top5 73.89
2021-11-05 22:51:00 (JOBID 31647) epoch 16: train time 2863.89, inference time 311.45s, valid_top1 48.20 (best_top1 66.00), valid_top5 73.89
2021-11-05 22:51:01 (JOBID 31647) epoch 16: train time 2863.97, inference time 313.14s, valid_top1 48.20 (best_top1 66.00), valid_top5 73.89
2021-11-05 22:51:14 train 0000, loss 1.898e+00, top1 57.65, top5 78.82
2021-11-05 22:51:11 train 0000, loss 2.302e+00, top1 47.06, top5 72.94
2021-11-05 22:51:14 train 0000, loss 2.362e+00, top1 43.53, top5 72.94
2021-11-05 23:00:19 train 1000, loss 2.192e+00, top1 50.47, top5 75.18
2021-11-05 23:00:19 train 1000, loss 2.194e+00, top1 50.66, top5 74.95
2021-11-05 23:00:19 train 1000, loss 2.191e+00, top1 50.87, top5 74.96
2021-11-05 23:09:24 train 2000, loss 2.209e+00, top1 50.68, top5 74.69
2021-11-05 23:09:24 train 2000, loss 2.199e+00, top1 50.52, top5 74.97
2021-11-05 23:09:24 train 2000, loss 2.202e+00, top1 50.59, top5 74.86
2021-11-05 23:18:28 train 3000, loss 2.206e+00, top1 50.56, top5 74.84
2021-11-05 23:18:28 train 3000, loss 2.212e+00, top1 50.50, top5 74.67
2021-11-05 23:18:28 train 3000, loss 2.207e+00, top1 50.51, top5 74.77
2021-11-05 23:27:32 train 4000, loss 2.209e+00, top1 50.50, top5 74.77
2021-11-05 23:27:32 train 4000, loss 2.208e+00, top1 50.57, top5 74.80
2021-11-05 23:27:32 train 4000, loss 2.214e+00, top1 50.41, top5 74.64
2021-11-05 23:36:32 train 5000, loss 2.215e+00, top1 50.42, top5 74.71
2021-11-05 23:36:31 train 5000, loss 2.209e+00, top1 50.52, top5 74.81
2021-11-05 23:36:32 train 5000, loss 2.216e+00, top1 50.36, top5 74.63
2021-11-05 23:36:55 valid 0000, loss 9.710e-01, top1 80.00, top5 87.06
2021-11-05 23:36:55 valid 0000, loss 9.710e-01, top1 80.00, top5 87.06
2021-11-05 23:36:55 valid 0000, loss 9.710e-01, top1 80.00, top5 87.06
2021-11-05 23:41:40 (JOBID 31647) epoch 17: train time 2744.09, inference time 295.26s, valid_top1 51.70 (best_top1 66.00), valid_top5 77.04
2021-11-05 23:41:40 (JOBID 31647) epoch 17: train time 2748.95, inference time 295.63s, valid_top1 51.70 (best_top1 66.00), valid_top5 77.04
2021-11-05 23:41:41 (JOBID 31647) epoch 17: train time 2744.57, inference time 295.78s, valid_top1 51.70 (best_top1 66.00), valid_top5 77.04
2021-11-05 23:41:55 train 0000, loss 2.254e+00, top1 54.12, top5 71.76
2021-11-05 23:41:55 train 0000, loss 2.007e+00, top1 54.12, top5 76.47
2021-11-05 23:41:55 train 0000, loss 2.441e+00, top1 42.35, top5 70.59
2021-11-05 23:51:02 train 1000, loss 2.203e+00, top1 50.78, top5 74.83
2021-11-05 23:51:02 train 1000, loss 2.203e+00, top1 50.84, top5 74.91
2021-11-05 23:51:02 train 1000, loss 2.196e+00, top1 50.86, top5 74.86
2021-11-06 00:00:08 train 2000, loss 2.206e+00, top1 50.67, top5 74.86
2021-11-06 00:00:08 train 2000, loss 2.204e+00, top1 50.76, top5 74.88
2021-11-06 00:00:09 train 2000, loss 2.199e+00, top1 50.73, top5 74.87
2021-11-06 00:09:11 train 3000, loss 2.200e+00, top1 50.72, top5 74.90
2021-11-06 00:09:11 train 3000, loss 2.208e+00, top1 50.63, top5 74.83
2021-11-06 00:09:12 train 3000, loss 2.207e+00, top1 50.59, top5 74.88
2021-11-06 00:18:12 train 4000, loss 2.212e+00, top1 50.49, top5 74.79
2021-11-06 00:18:12 train 4000, loss 2.212e+00, top1 50.48, top5 74.78
2021-11-06 00:18:12 train 4000, loss 2.209e+00, top1 50.60, top5 74.79
2021-11-06 00:27:19 train 5000, loss 2.215e+00, top1 50.48, top5 74.73
2021-11-06 00:27:19 train 5000, loss 2.213e+00, top1 50.46, top5 74.77
2021-11-06 00:27:19 train 5000, loss 2.209e+00, top1 50.60, top5 74.80
2021-11-06 00:27:42 valid 0000, loss 1.105e+00, top1 76.47, top5 88.24
2021-11-06 00:27:42 valid 0000, loss 1.105e+00, top1 76.47, top5 88.24
2021-11-06 00:27:42 valid 0000, loss 1.105e+00, top1 76.47, top5 88.24
2021-11-06 00:32:27 (JOBID 31647) epoch 18: train time 2752.34, inference time 294.43s, valid_top1 52.44 (best_top1 66.00), valid_top5 77.86
2021-11-06 00:32:28 (JOBID 31647) epoch 18: train time 2751.89, inference time 295.28s, valid_top1 52.44 (best_top1 66.00), valid_top5 77.86
2021-11-06 00:32:30 (JOBID 31647) epoch 18: train time 2751.48, inference time 297.22s, valid_top1 52.44 (best_top1 66.00), valid_top5 77.86
2021-11-06 00:32:42 train 0000, loss 2.462e+00, top1 41.18, top5 65.88
2021-11-06 00:32:42 train 0000, loss 1.947e+00, top1 41.18, top5 77.65
2021-11-06 00:32:45 train 0000, loss 2.403e+00, top1 45.88, top5 75.29
2021-11-06 00:42:00 train 1000, loss 2.199e+00, top1 50.49, top5 74.98
2021-11-06 00:42:00 train 1000, loss 2.196e+00, top1 50.81, top5 75.00
2021-11-06 00:42:00 train 1000, loss 2.183e+00, top1 50.96, top5 75.20
2021-11-06 00:51:06 train 2000, loss 2.199e+00, top1 50.78, top5 74.90
2021-11-06 00:51:06 train 2000, loss 2.202e+00, top1 50.59, top5 74.87
2021-11-06 00:51:06 train 2000, loss 2.195e+00, top1 50.68, top5 75.00
2021-11-06 01:00:13 train 3000, loss 2.206e+00, top1 50.53, top5 74.85
2021-11-06 01:00:13 train 3000, loss 2.209e+00, top1 50.58, top5 74.76
2021-11-06 01:00:13 train 3000, loss 2.200e+00, top1 50.61, top5 75.00
2021-11-06 01:09:13 train 4000, loss 2.214e+00, top1 50.42, top5 74.65
2021-11-06 01:09:13 train 4000, loss 2.212e+00, top1 50.42, top5 74.73
2021-11-06 01:09:13 train 4000, loss 2.206e+00, top1 50.45, top5 74.89
2021-11-06 01:18:19 train 5000, loss 2.217e+00, top1 50.37, top5 74.61
2021-11-06 01:18:19 train 5000, loss 2.215e+00, top1 50.37, top5 74.67
2021-11-06 01:18:19 train 5000, loss 2.212e+00, top1 50.35, top5 74.80
2021-11-06 01:18:42 valid 0000, loss 1.482e+00, top1 61.18, top5 88.24
2021-11-06 01:18:42 valid 0000, loss 1.482e+00, top1 61.18, top5 88.24
2021-11-06 01:18:42 valid 0000, loss 1.482e+00, top1 61.18, top5 88.24
2021-11-06 01:23:36 (JOBID 31647) epoch 19: train time 2765.48, inference time 303.93s, valid_top1 52.64 (best_top1 66.00), valid_top5 78.23
2021-11-06 01:23:37 (JOBID 31647) epoch 19: train time 2764.59, inference time 304.89s, valid_top1 52.64 (best_top1 66.00), valid_top5 78.23
2021-11-06 01:23:37 (JOBID 31647) epoch 19: train time 2762.38, inference time 304.70s, valid_top1 52.64 (best_top1 66.00), valid_top5 78.23
2021-11-06 01:23:51 train 0000, loss 2.538e+00, top1 45.88, top5 70.59
2021-11-06 01:23:51 train 0000, loss 2.136e+00, top1 48.24, top5 77.65
2021-11-06 01:23:51 train 0000, loss 2.276e+00, top1 43.53, top5 71.76
2021-11-06 01:32:51 train 1000, loss 2.200e+00, top1 50.65, top5 74.79
2021-11-06 01:32:51 train 1000, loss 2.203e+00, top1 50.66, top5 75.01
2021-11-06 01:32:51 train 1000, loss 2.191e+00, top1 50.79, top5 75.08
2021-11-06 01:41:51 train 2000, loss 2.209e+00, top1 50.39, top5 74.81
2021-11-06 01:41:51 train 2000, loss 2.195e+00, top1 50.72, top5 74.96
2021-11-06 01:41:51 train 2000, loss 2.212e+00, top1 50.31, top5 74.76
2021-11-06 01:50:52 train 3000, loss 2.215e+00, top1 50.27, top5 74.74
2021-11-06 01:50:52 train 3000, loss 2.198e+00, top1 50.64, top5 74.89
2021-11-06 01:50:52 train 3000, loss 2.213e+00, top1 50.33, top5 74.74
2021-11-06 01:59:53 train 4000, loss 2.202e+00, top1 50.61, top5 74.85
2021-11-06 01:59:53 train 4000, loss 2.214e+00, top1 50.33, top5 74.72
2021-11-06 01:59:53 train 4000, loss 2.218e+00, top1 50.28, top5 74.65
2021-11-06 02:08:53 train 5000, loss 2.206e+00, top1 50.56, top5 74.80
2021-11-06 02:08:54 train 5000, loss 2.219e+00, top1 50.26, top5 74.63
2021-11-06 02:08:54 train 5000, loss 2.222e+00, top1 50.22, top5 74.56
2021-11-06 02:09:17 valid 0000, loss 1.544e+00, top1 67.06, top5 82.35
2021-11-06 02:09:17 valid 0000, loss 1.544e+00, top1 67.06, top5 82.35
2021-11-06 02:09:17 valid 0000, loss 1.544e+00, top1 67.06, top5 82.35
2021-11-06 02:14:00 (JOBID 31647) epoch 20: train time 2729.87, inference time 293.16s, valid_top1 53.19 (best_top1 66.00), valid_top5 78.61
2021-11-06 02:14:00 (JOBID 31647) epoch 20: train time 2730.72, inference time 293.15s, valid_top1 53.19 (best_top1 66.00), valid_top5 78.61
2021-11-06 02:14:00 (JOBID 31647) epoch 20: train time 2729.70, inference time 293.08s, valid_top1 53.19 (best_top1 66.00), valid_top5 78.61
2021-11-06 02:14:15 train 0000, loss 2.122e+00, top1 54.12, top5 72.94
2021-11-06 02:14:15 train 0000, loss 2.088e+00, top1 50.59, top5 76.47
2021-11-06 02:14:15 train 0000, loss 2.350e+00, top1 45.88, top5 76.47
2021-11-06 02:23:20 train 1000, loss 2.188e+00, top1 50.91, top5 75.15
2021-11-06 02:23:20 train 1000, loss 2.191e+00, top1 50.81, top5 74.95
2021-11-06 02:23:20 train 1000, loss 2.196e+00, top1 50.77, top5 74.89
2021-11-06 02:32:28 train 2000, loss 2.198e+00, top1 50.73, top5 74.97
2021-11-06 02:32:28 train 2000, loss 2.202e+00, top1 50.66, top5 74.83
2021-11-06 02:32:28 train 2000, loss 2.194e+00, top1 50.84, top5 75.03
2021-11-06 02:41:29 train 3000, loss 2.201e+00, top1 50.71, top5 74.91
2021-11-06 02:41:29 train 3000, loss 2.203e+00, top1 50.69, top5 74.85
2021-11-06 02:41:30 train 3000, loss 2.208e+00, top1 50.51, top5 74.75
2021-11-06 02:50:32 train 4000, loss 2.206e+00, top1 50.61, top5 74.79
2021-11-06 02:50:32 train 4000, loss 2.209e+00, top1 50.56, top5 74.80
2021-11-06 02:50:32 train 4000, loss 2.212e+00, top1 50.46, top5 74.70
2021-11-06 02:59:32 train 5000, loss 2.213e+00, top1 50.53, top5 74.77
2021-11-06 02:59:32 train 5000, loss 2.212e+00, top1 50.53, top5 74.73
2021-11-06 02:59:32 train 5000, loss 2.213e+00, top1 50.44, top5 74.69
2021-11-06 02:59:56 valid 0000, loss 8.241e-01, top1 80.00, top5 92.94
2021-11-06 02:59:56 valid 0000, loss 8.241e-01, top1 80.00, top5 92.94
2021-11-06 02:59:56 valid 0000, loss 8.241e-01, top1 80.00, top5 92.94
2021-11-06 03:05:11 (JOBID 31647) epoch 21: train time 2745.27, inference time 326.07s, valid_top1 53.67 (best_top1 66.00), valid_top5 79.19
2021-11-06 03:05:12 (JOBID 31647) epoch 21: train time 2744.96, inference time 326.03s, valid_top1 53.67 (best_top1 66.00), valid_top5 79.19
2021-11-06 03:05:12 (JOBID 31647) epoch 21: train time 2745.27, inference time 326.43s, valid_top1 53.67 (best_top1 66.00), valid_top5 79.19
2021-11-06 03:05:26 train 0000, loss 2.082e+00, top1 52.94, top5 77.65
2021-11-06 03:05:26 train 0000, loss 2.285e+00, top1 52.94, top5 74.12
2021-11-06 03:05:26 train 0000, loss 1.959e+00, top1 58.82, top5 81.18
2021-11-06 03:14:27 train 1000, loss 2.188e+00, top1 50.81, top5 75.13
2021-11-06 03:14:27 train 1000, loss 2.187e+00, top1 50.76, top5 75.14
2021-11-06 03:14:27 train 1000, loss 2.188e+00, top1 51.21, top5 75.14
2021-11-06 03:23:25 train 2000, loss 2.196e+00, top1 50.76, top5 75.01
2021-11-06 03:23:25 train 2000, loss 2.200e+00, top1 50.44, top5 74.93
2021-11-06 03:23:25 train 2000, loss 2.202e+00, top1 50.78, top5 74.89
2021-11-06 03:32:22 train 3000, loss 2.207e+00, top1 50.66, top5 74.79
2021-11-06 03:32:22 train 3000, loss 2.204e+00, top1 50.46, top5 74.85
2021-11-06 03:32:22 train 3000, loss 2.202e+00, top1 50.69, top5 74.87
2021-11-06 03:41:19 train 4000, loss 2.207e+00, top1 50.61, top5 74.80
2021-11-06 03:41:19 train 4000, loss 2.208e+00, top1 50.45, top5 74.80
2021-11-06 03:41:19 train 4000, loss 2.211e+00, top1 50.62, top5 74.74
2021-11-06 03:50:22 train 5000, loss 2.212e+00, top1 50.35, top5 74.71
2021-11-06 03:50:22 train 5000, loss 2.212e+00, top1 50.52, top5 74.72
2021-11-06 03:50:22 train 5000, loss 2.217e+00, top1 50.50, top5 74.64
2021-11-06 03:50:46 valid 0000, loss 8.807e-01, top1 80.00, top5 91.76
2021-11-06 03:50:46 valid 0000, loss 8.807e-01, top1 80.00, top5 91.76
2021-11-06 03:50:46 valid 0000, loss 8.807e-01, top1 80.00, top5 91.76
2021-11-06 03:55:31 (JOBID 31647) epoch 22: train time 2723.43, inference time 295.66s, valid_top1 52.22 (best_top1 66.00), valid_top5 78.51
2021-11-06 03:55:31 (JOBID 31647) epoch 22: train time 2723.80, inference time 296.05s, valid_top1 52.22 (best_top1 66.00), valid_top5 78.51
2021-11-06 03:55:32 (JOBID 31647) epoch 22: train time 2723.58, inference time 295.92s, valid_top1 52.22 (best_top1 66.00), valid_top5 78.51
2021-11-06 03:55:46 train 0000, loss 2.461e+00, top1 47.06, top5 74.12
2021-11-06 03:55:46 train 0000, loss 2.148e+00, top1 45.88, top5 78.82
2021-11-06 03:55:46 train 0000, loss 2.222e+00, top1 55.29, top5 75.29
2021-11-06 04:04:51 train 1000, loss 2.194e+00, top1 50.64, top5 75.13
2021-11-06 04:04:51 train 1000, loss 2.203e+00, top1 50.56, top5 75.01
2021-11-06 04:04:51 train 1000, loss 2.183e+00, top1 50.77, top5 75.24
2021-11-06 04:13:53 train 2000, loss 2.207e+00, top1 50.48, top5 74.85
2021-11-06 04:13:54 train 2000, loss 2.198e+00, top1 50.63, top5 74.93
2021-11-06 04:13:54 train 2000, loss 2.190e+00, top1 50.75, top5 75.10
2021-11-06 04:23:02 train 3000, loss 2.208e+00, top1 50.53, top5 74.82
2021-11-06 04:23:02 train 3000, loss 2.202e+00, top1 50.61, top5 74.91
2021-11-06 04:23:02 train 3000, loss 2.199e+00, top1 50.58, top5 74.95
2021-11-06 04:32:07 train 4000, loss 2.209e+00, top1 50.47, top5 74.82
2021-11-06 04:32:07 train 4000, loss 2.209e+00, top1 50.50, top5 74.82
2021-11-06 04:32:07 train 4000, loss 2.205e+00, top1 50.49, top5 74.85
2021-11-06 04:41:11 train 5000, loss 2.215e+00, top1 50.43, top5 74.73
2021-11-06 04:41:12 train 5000, loss 2.209e+00, top1 50.46, top5 74.77
2021-11-06 04:41:12 train 5000, loss 2.209e+00, top1 50.44, top5 74.82
2021-11-06 04:41:36 valid 0000, loss 1.818e+00, top1 64.71, top5 84.71
2021-11-06 04:41:36 valid 0000, loss 1.818e+00, top1 64.71, top5 84.71
2021-11-06 04:41:36 valid 0000, loss 1.818e+00, top1 64.71, top5 84.71
2021-11-06 04:46:08 (JOBID 31647) epoch 23: train time 2753.41, inference time 282.14s, valid_top1 52.18 (best_top1 66.00), valid_top5 77.71
2021-11-06 04:46:08 (JOBID 31647) epoch 23: train time 2753.78, inference time 282.78s, valid_top1 52.18 (best_top1 66.00), valid_top5 77.71
2021-11-06 04:46:09 (JOBID 31647) epoch 23: train time 2754.11, inference time 283.67s, valid_top1 52.18 (best_top1 66.00), valid_top5 77.71
2021-11-06 04:46:22 train 0000, loss 2.265e+00, top1 54.12, top5 76.47
2021-11-06 04:46:22 train 0000, loss 1.844e+00, top1 55.29, top5 81.18
2021-11-06 04:46:22 train 0000, loss 2.434e+00, top1 40.00, top5 72.94
2021-11-06 04:55:30 train 1000, loss 2.191e+00, top1 50.93, top5 74.87
2021-11-06 04:55:30 train 1000, loss 2.195e+00, top1 50.69, top5 75.13
2021-11-06 04:55:31 train 1000, loss 2.171e+00, top1 51.31, top5 75.34
2021-11-06 05:04:27 train 2000, loss 2.199e+00, top1 50.87, top5 74.81
2021-11-06 05:04:27 train 2000, loss 2.196e+00, top1 50.70, top5 75.11
2021-11-06 05:04:28 train 2000, loss 2.194e+00, top1 50.75, top5 75.11
2021-11-06 05:13:26 train 3000, loss 2.207e+00, top1 50.66, top5 74.69
2021-11-06 05:13:26 train 3000, loss 2.203e+00, top1 50.59, top5 74.98
2021-11-06 05:13:26 train 3000, loss 2.201e+00, top1 50.61, top5 74.97
2021-11-06 05:22:30 train 4000, loss 2.207e+00, top1 50.57, top5 74.88
2021-11-06 05:22:30 train 4000, loss 2.212e+00, top1 50.54, top5 74.67
2021-11-06 05:22:30 train 4000, loss 2.206e+00, top1 50.52, top5 74.89
2021-11-06 05:31:34 train 5000, loss 2.209e+00, top1 50.57, top5 74.80
2021-11-06 05:31:34 train 5000, loss 2.213e+00, top1 50.50, top5 74.69
2021-11-06 05:31:34 train 5000, loss 2.208e+00, top1 50.49, top5 74.82
2021-11-06 05:32:00 valid 0000, loss 6.729e-01, top1 88.24, top5 94.12
2021-11-06 05:32:00 valid 0000, loss 6.729e-01, top1 88.24, top5 94.12
2021-11-06 05:32:00 valid 0000, loss 6.729e-01, top1 88.24, top5 94.12
2021-11-06 05:36:40 (JOBID 31647) epoch 24: train time 2739.28, inference time 292.97s, valid_top1 49.52 (best_top1 66.00), valid_top5 75.78
2021-11-06 05:36:40 (JOBID 31647) epoch 24: train time 2739.67, inference time 292.62s, valid_top1 49.52 (best_top1 66.00), valid_top5 75.78
2021-11-06 05:36:42 (JOBID 31647) epoch 24: train time 2738.49, inference time 295.14s, valid_top1 49.52 (best_top1 66.00), valid_top5 75.78
2021-11-06 05:36:58 train 0000, loss 2.134e+00, top1 45.88, top5 80.00
2021-11-06 05:36:58 train 0000, loss 2.084e+00, top1 54.12, top5 81.18
2021-11-06 05:36:58 train 0000, loss 2.153e+00, top1 61.18, top5 75.29
2021-11-06 05:46:08 train 1000, loss 2.212e+00, top1 50.47, top5 74.91
2021-11-06 05:46:08 train 1000, loss 2.195e+00, top1 50.95, top5 75.17
2021-11-06 05:46:08 train 1000, loss 2.194e+00, top1 50.78, top5 74.96
2021-11-06 05:55:13 train 2000, loss 2.202e+00, top1 50.70, top5 74.85
2021-11-06 05:55:13 train 2000, loss 2.200e+00, top1 50.77, top5 75.02
2021-11-06 05:55:13 train 2000, loss 2.209e+00, top1 50.57, top5 74.96
2021-11-06 06:04:14 train 3000, loss 2.203e+00, top1 50.67, top5 74.78
2021-11-06 06:04:14 train 3000, loss 2.208e+00, top1 50.54, top5 74.87
2021-11-06 06:04:14 train 3000, loss 2.214e+00, top1 50.46, top5 74.82
2021-11-06 06:13:22 train 4000, loss 2.210e+00, top1 50.44, top5 74.86
2021-11-06 06:13:22 train 4000, loss 2.209e+00, top1 50.53, top5 74.71
2021-11-06 06:13:22 train 4000, loss 2.218e+00, top1 50.34, top5 74.72
2021-11-06 06:22:30 train 5000, loss 2.212e+00, top1 50.43, top5 74.82
2021-11-06 06:22:30 train 5000, loss 2.211e+00, top1 50.46, top5 74.67
2021-11-06 06:22:30 train 5000, loss 2.217e+00, top1 50.37, top5 74.70
2021-11-06 06:22:55 valid 0000, loss 1.070e+00, top1 82.35, top5 85.88
2021-11-06 06:22:55 valid 0000, loss 1.070e+00, top1 82.35, top5 85.88
2021-11-06 06:22:55 valid 0000, loss 1.070e+00, top1 82.35, top5 85.88
2021-11-06 06:27:29 (JOBID 31647) epoch 25: train time 2763.45, inference time 285.72s, valid_top1 53.67 (best_top1 66.00), valid_top5 79.27
2021-11-06 06:27:30 (JOBID 31647) epoch 25: train time 2763.45, inference time 285.85s, valid_top1 53.67 (best_top1 66.00), valid_top5 79.27
2021-11-06 06:27:30 (JOBID 31647) epoch 25: train time 2761.24, inference time 286.84s, valid_top1 53.67 (best_top1 66.00), valid_top5 79.27
2021-11-06 06:27:44 train 0000, loss 2.142e+00, top1 55.29, top5 74.12
2021-11-06 06:27:44 train 0000, loss 2.290e+00, top1 45.88, top5 75.29
2021-11-06 06:27:44 train 0000, loss 2.306e+00, top1 52.94, top5 75.29
2021-11-06 06:36:52 train 1000, loss 2.187e+00, top1 50.79, top5 75.23
2021-11-06 06:36:52 train 1000, loss 2.184e+00, top1 50.82, top5 75.28
2021-11-06 06:36:52 train 1000, loss 2.197e+00, top1 50.66, top5 74.94
2021-11-06 06:45:59 train 2000, loss 2.193e+00, top1 50.74, top5 75.04
2021-11-06 06:45:59 train 2000, loss 2.200e+00, top1 50.60, top5 74.96
2021-11-06 06:45:59 train 2000, loss 2.200e+00, top1 50.58, top5 74.90
2021-11-06 06:55:09 train 3000, loss 2.203e+00, top1 50.56, top5 74.91
2021-11-06 06:55:09 train 3000, loss 2.208e+00, top1 50.44, top5 74.79
2021-11-06 06:55:09 train 3000, loss 2.206e+00, top1 50.59, top5 74.77
2021-11-06 07:04:15 train 4000, loss 2.208e+00, top1 50.46, top5 74.81
2021-11-06 07:04:15 train 4000, loss 2.204e+00, top1 50.54, top5 74.89
2021-11-06 07:04:15 train 4000, loss 2.213e+00, top1 50.50, top5 74.70
2021-11-06 07:13:20 train 5000, loss 2.208e+00, top1 50.49, top5 74.82
2021-11-06 07:13:20 train 5000, loss 2.209e+00, top1 50.48, top5 74.80
2021-11-06 07:13:21 train 5000, loss 2.215e+00, top1 50.41, top5 74.67
2021-11-06 07:13:44 valid 0000, loss 7.079e-01, top1 85.88, top5 97.65
2021-11-06 07:13:44 valid 0000, loss 7.079e-01, top1 85.88, top5 97.65
2021-11-06 07:13:44 valid 0000, loss 7.079e-01, top1 85.88, top5 97.65
2021-11-06 07:18:13 (JOBID 31647) epoch 26: train time 2763.35, inference time 279.28s, valid_top1 47.26 (best_top1 66.00), valid_top5 73.04
2021-11-06 07:18:16 (JOBID 31647) epoch 26: train time 2764.05, inference time 281.90s, valid_top1 47.26 (best_top1 66.00), valid_top5 73.04
2021-11-06 07:18:18 (JOBID 31647) epoch 26: train time 2764.47, inference time 284.70s, valid_top1 47.26 (best_top1 66.00), valid_top5 73.04
2021-11-06 07:18:31 train 0000, loss 2.200e+00, top1 55.29, top5 71.76
2021-11-06 07:18:27 train 0000, loss 2.372e+00, top1 49.41, top5 74.12
2021-11-06 07:18:33 train 0000, loss 2.154e+00, top1 51.76, top5 72.94
2021-11-06 07:27:39 train 1000, loss 2.186e+00, top1 50.86, top5 75.17
2021-11-06 07:27:39 train 1000, loss 2.191e+00, top1 50.82, top5 75.01
2021-11-06 07:27:39 train 1000, loss 2.192e+00, top1 50.88, top5 74.92
2021-11-06 07:36:40 train 2000, loss 2.202e+00, top1 50.66, top5 74.88
2021-11-06 07:36:40 train 2000, loss 2.193e+00, top1 50.79, top5 75.08
2021-11-06 07:36:40 train 2000, loss 2.202e+00, top1 50.65, top5 74.79
2021-11-06 07:45:39 train 3000, loss 2.205e+00, top1 50.61, top5 74.77
2021-11-06 07:45:39 train 3000, loss 2.206e+00, top1 50.60, top5 74.80
2021-11-06 07:45:39 train 3000, loss 2.197e+00, top1 50.77, top5 75.00
2021-11-06 07:54:44 train 4000, loss 2.205e+00, top1 50.64, top5 74.87
2021-11-06 07:54:44 train 4000, loss 2.212e+00, top1 50.48, top5 74.71
2021-11-06 07:54:44 train 4000, loss 2.211e+00, top1 50.51, top5 74.70
2021-11-06 08:03:45 train 5000, loss 2.209e+00, top1 50.51, top5 74.79
2021-11-06 08:03:45 train 5000, loss 2.216e+00, top1 50.42, top5 74.64
2021-11-06 08:03:45 train 5000, loss 2.213e+00, top1 50.46, top5 74.71
2021-11-06 08:04:08 valid 0000, loss 5.792e-01, top1 84.71, top5 94.12
2021-11-06 08:04:08 valid 0000, loss 5.792e-01, top1 84.71, top5 94.12
2021-11-06 08:04:08 valid 0000, loss 5.792e-01, top1 84.71, top5 94.12
2021-11-06 08:09:08 (JOBID 31647) epoch 27: train time 2745.31, inference time 310.06s, valid_top1 52.50 (best_top1 66.00), valid_top5 78.05
2021-11-06 08:09:09 (JOBID 31647) epoch 27: train time 2742.27, inference time 310.26s, valid_top1 52.50 (best_top1 66.00), valid_top5 78.05
2021-11-06 08:09:11 (JOBID 31647) epoch 27: train time 2739.86, inference time 312.68s, valid_top1 52.50 (best_top1 66.00), valid_top5 78.05
2021-11-06 08:09:23 train 0000, loss 1.851e+00, top1 58.82, top5 82.35
2021-11-06 08:09:23 train 0000, loss 2.257e+00, top1 51.76, top5 77.65
2021-11-06 08:09:26 train 0000, loss 2.626e+00, top1 40.00, top5 68.24
2021-11-06 08:19:11 train 1000, loss 2.190e+00, top1 50.86, top5 74.99
2021-11-06 08:19:11 train 1000, loss 2.196e+00, top1 50.81, top5 74.85
2021-11-06 08:19:11 train 1000, loss 2.187e+00, top1 50.55, top5 75.08
2021-11-06 08:28:52 train 2000, loss 2.197e+00, top1 50.69, top5 74.92
2021-11-06 08:28:52 train 2000, loss 2.199e+00, top1 50.60, top5 74.91
2021-11-06 08:28:52 train 2000, loss 2.195e+00, top1 50.48, top5 74.97
2021-11-06 08:38:37 train 3000, loss 2.204e+00, top1 50.57, top5 74.81
2021-11-06 08:38:37 train 3000, loss 2.202e+00, top1 50.63, top5 74.91
2021-11-06 08:38:37 train 3000, loss 2.202e+00, top1 50.44, top5 74.86
2021-11-06 08:48:23 train 4000, loss 2.210e+00, top1 50.48, top5 74.79
2021-11-06 08:48:22 train 4000, loss 2.210e+00, top1 50.51, top5 74.72
2021-11-06 08:48:23 train 4000, loss 2.207e+00, top1 50.43, top5 74.80
2021-11-06 08:58:19 train 5000, loss 2.211e+00, top1 50.46, top5 74.72
2021-11-06 08:58:19 train 5000, loss 2.212e+00, top1 50.42, top5 74.74
2021-11-06 08:58:19 train 5000, loss 2.212e+00, top1 50.38, top5 74.73
2021-11-06 08:58:44 valid 0000, loss 1.432e+00, top1 68.24, top5 87.06
2021-11-06 08:58:44 valid 0000, loss 1.432e+00, top1 68.24, top5 87.06
2021-11-06 08:58:44 valid 0000, loss 1.432e+00, top1 68.24, top5 87.06
2021-11-06 09:03:25 (JOBID 31647) epoch 28: train time 2965.37, inference time 291.49s, valid_top1 52.02 (best_top1 66.00), valid_top5 77.65
2021-11-06 09:03:53 (JOBID 31647) epoch 28: train time 2962.58, inference time 319.05s, valid_top1 52.02 (best_top1 66.00), valid_top5 77.65
2021-11-06 09:03:53 (JOBID 31647) epoch 28: train time 2964.75, inference time 319.08s, valid_top1 52.02 (best_top1 66.00), valid_top5 77.65
2021-11-06 09:03:40 train 0000, loss 2.076e+00, top1 49.41, top5 81.18
2021-11-06 09:04:07 train 0000, loss 2.071e+00, top1 57.65, top5 75.29
2021-11-06 09:04:07 train 0000, loss 2.215e+00, top1 47.06, top5 75.29
2021-11-06 09:13:11 train 1000, loss 2.192e+00, top1 50.74, top5 75.07
2021-11-06 09:13:11 train 1000, loss 2.203e+00, top1 50.58, top5 74.84
2021-11-06 09:13:11 train 1000, loss 2.195e+00, top1 50.74, top5 75.06
2021-11-06 09:22:16 train 2000, loss 2.196e+00, top1 50.67, top5 75.02
2021-11-06 09:22:16 train 2000, loss 2.200e+00, top1 50.70, top5 74.96
2021-11-06 09:22:16 train 2000, loss 2.202e+00, top1 50.52, top5 74.86
2021-11-06 09:31:21 train 3000, loss 2.205e+00, top1 50.54, top5 74.86
2021-11-06 09:31:21 train 3000, loss 2.207e+00, top1 50.55, top5 74.89
2021-11-06 09:31:21 train 3000, loss 2.205e+00, top1 50.47, top5 74.84
2021-11-06 09:40:23 train 4000, loss 2.209e+00, top1 50.52, top5 74.85
2021-11-06 09:40:23 train 4000, loss 2.207e+00, top1 50.48, top5 74.79
2021-11-06 09:40:23 train 4000, loss 2.208e+00, top1 50.45, top5 74.78
2021-11-06 09:49:32 train 5000, loss 2.213e+00, top1 50.42, top5 74.71
2021-11-06 09:49:32 train 5000, loss 2.212e+00, top1 50.44, top5 74.73
2021-11-06 09:49:32 train 5000, loss 2.210e+00, top1 50.39, top5 74.75
2021-11-06 09:49:55 valid 0000, loss 9.196e-01, top1 82.35, top5 87.06
2021-11-06 09:49:55 valid 0000, loss 9.196e-01, top1 82.35, top5 87.06
2021-11-06 09:49:55 valid 0000, loss 9.196e-01, top1 82.35, top5 87.06
2021-11-06 09:54:30 (JOBID 31647) epoch 29: train time 2752.52, inference time 284.60s, valid_top1 50.72 (best_top1 66.00), valid_top5 76.07
2021-11-06 09:54:31 (JOBID 31647) epoch 29: train time 2752.70, inference time 285.42s, valid_top1 50.72 (best_top1 66.00), valid_top5 76.07
2021-11-06 09:54:32 (JOBID 31647) epoch 29: train time 2780.05, inference time 286.70s, valid_top1 50.72 (best_top1 66.00), valid_top5 76.07
2021-11-06 09:54:45 train 0000, loss 2.136e+00, top1 57.65, top5 76.47
2021-11-06 09:54:45 train 0000, loss 2.412e+00, top1 49.41, top5 75.29
2021-11-06 09:54:47 train 0000, loss 1.991e+00, top1 55.29, top5 75.29
2021-11-06 10:03:44 train 1000, loss 1.813e+00, top1 58.83, top5 80.48
2021-11-06 10:03:44 train 1000, loss 1.824e+00, top1 58.59, top5 80.54
2021-11-06 10:03:44 train 1000, loss 1.811e+00, top1 58.56, top5 80.67
2021-11-06 10:12:45 train 2000, loss 1.763e+00, top1 59.72, top5 81.21
2021-11-06 10:12:45 train 2000, loss 1.772e+00, top1 59.52, top5 81.18
2021-11-06 10:12:45 train 2000, loss 1.758e+00, top1 59.65, top5 81.39
2021-11-06 10:21:47 train 3000, loss 1.731e+00, top1 60.36, top5 81.70
2021-11-06 10:21:46 train 3000, loss 1.740e+00, top1 60.16, top5 81.63
2021-11-06 10:21:47 train 3000, loss 1.734e+00, top1 60.23, top5 81.74
2021-11-06 10:30:52 train 4000, loss 1.720e+00, top1 60.58, top5 81.92
2021-11-06 10:30:52 train 4000, loss 1.712e+00, top1 60.70, top5 82.01
2021-11-06 10:30:52 train 4000, loss 1.712e+00, top1 60.67, top5 82.02
2021-11-06 10:39:55 train 5000, loss 1.696e+00, top1 61.02, top5 82.21
2021-11-06 10:39:55 train 5000, loss 1.704e+00, top1 60.92, top5 82.12
2021-11-06 10:39:55 train 5000, loss 1.696e+00, top1 61.00, top5 82.23
2021-11-06 10:40:18 valid 0000, loss 6.216e-01, top1 87.06, top5 92.94
2021-11-06 10:40:18 valid 0000, loss 6.216e-01, top1 87.06, top5 92.94
2021-11-06 10:40:18 valid 0000, loss 6.216e-01, top1 87.06, top5 92.94
2021-11-06 10:44:48 (JOBID 31647) epoch 30: train time 2737.73, inference time 279.51s, valid_top1 67.46 (best_top1 67.46), valid_top5 88.12
2021-11-06 10:44:54 (JOBID 31647) epoch 30: train time 2738.41, inference time 284.76s, valid_top1 67.46 (best_top1 67.46), valid_top5 88.12
2021-11-06 10:44:54 (JOBID 31647) epoch 30: train time 2736.50, inference time 285.71s, valid_top1 67.46 (best_top1 67.46), valid_top5 88.12
2021-11-06 10:45:08 train 0000, loss 1.360e+00, top1 70.59, top5 84.71
2021-11-06 10:45:02 train 0000, loss 1.559e+00, top1 58.82, top5 84.71
2021-11-06 10:45:08 train 0000, loss 1.343e+00, top1 70.59, top5 85.88
2021-11-06 10:54:08 train 1000, loss 1.605e+00, top1 63.00, top5 83.47
2021-11-06 10:54:08 train 1000, loss 1.608e+00, top1 62.86, top5 83.60
2021-11-06 10:54:08 train 1000, loss 1.596e+00, top1 62.90, top5 83.64
2021-11-06 11:03:03 train 2000, loss 1.602e+00, top1 62.98, top5 83.53
2021-11-06 11:03:03 train 2000, loss 1.603e+00, top1 62.89, top5 83.67
2021-11-06 11:03:03 train 2000, loss 1.601e+00, top1 62.87, top5 83.52
2021-11-06 11:12:05 train 3000, loss 1.597e+00, top1 62.98, top5 83.58
2021-11-06 11:12:05 train 3000, loss 1.598e+00, top1 62.98, top5 83.63
2021-11-06 11:12:05 train 3000, loss 1.597e+00, top1 63.04, top5 83.58
2021-11-06 11:21:07 train 4000, loss 1.595e+00, top1 63.06, top5 83.63
2021-11-06 11:21:07 train 4000, loss 1.592e+00, top1 63.11, top5 83.67
2021-11-06 11:21:07 train 4000, loss 1.593e+00, top1 63.11, top5 83.70
2021-11-06 11:30:06 train 5000, loss 1.589e+00, top1 63.16, top5 83.72
2021-11-06 11:30:06 train 5000, loss 1.591e+00, top1 63.10, top5 83.73
2021-11-06 11:30:06 train 5000, loss 1.592e+00, top1 63.10, top5 83.70
2021-11-06 11:30:29 valid 0000, loss 5.644e-01, top1 88.24, top5 94.12
2021-11-06 11:30:29 valid 0000, loss 5.644e-01, top1 88.24, top5 94.12
2021-11-06 11:30:29 valid 0000, loss 5.644e-01, top1 88.24, top5 94.12
2021-11-06 15:52:48 CARME Slurm ID: 31684
2021-11-06 15:52:48 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_08', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.33:23456', distributed=True, epochs=90, evaluate=False, gpu=2, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-06 15:52:48 CARME Slurm ID: 31684
2021-11-06 15:52:48 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_08', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.33:23456', distributed=True, epochs=90, evaluate=False, gpu=0, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-06 15:52:48 CARME Slurm ID: 31684
2021-11-06 15:52:48 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_08', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.33:23456', distributed=True, epochs=90, evaluate=False, gpu=1, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-06 15:52:57 Computational complexity:       1.83 GMac
2021-11-06 15:52:57 Computational complexity:       1.83 GMac
2021-11-06 15:52:57 Number of parameters:           12.86 M 
2021-11-06 15:52:57 Number of parameters:           12.86 M 
2021-11-06 15:52:57 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045'
2021-11-06 15:52:57 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045'
2021-11-06 15:52:57 Computational complexity:       1.83 GMac
2021-11-06 15:52:57 Number of parameters:           12.86 M 
2021-11-06 15:52:57 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045'
2021-11-06 15:52:57 => loaded checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045' (epoch 31)
2021-11-06 15:52:57 => loaded checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045' (epoch 31)
2021-11-06 15:52:57 => loaded checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045' (epoch 31)
2021-11-06 18:19:58 CARME Slurm ID: 31684
2021-11-06 18:19:58 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_08', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.33:23456', distributed=True, epochs=90, evaluate=False, gpu=2, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-06 18:19:58 CARME Slurm ID: 31684
2021-11-06 18:19:58 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_08', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.33:23456', distributed=True, epochs=90, evaluate=False, gpu=1, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-06 18:19:58 CARME Slurm ID: 31684
2021-11-06 18:19:58 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_08', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.33:23456', distributed=True, epochs=90, evaluate=False, gpu=0, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-06 18:20:10 Computational complexity:       1.83 GMac
2021-11-06 18:20:10 Computational complexity:       1.83 GMac
2021-11-06 18:20:10 Number of parameters:           12.86 M 
2021-11-06 18:20:10 Computational complexity:       1.83 GMac
2021-11-06 18:20:10 Number of parameters:           12.86 M 
2021-11-06 18:20:10 Number of parameters:           12.86 M 
2021-11-06 18:20:10 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045'
2021-11-06 18:20:10 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045'
2021-11-06 18:20:10 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045'
2021-11-06 18:20:10 => loaded checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045' (epoch 31)
2021-11-06 18:20:10 => loaded checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045' (epoch 31)
2021-11-06 18:20:10 => loaded checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_08_20211105-081045' (epoch 31)
2021-11-06 18:20:28 valid 0000, loss 6.216e-01, top1 87.06, top5 92.94
2021-11-06 18:20:28 valid 0000, loss 6.216e-01, top1 87.06, top5 92.94
2021-11-06 18:20:28 valid 0000, loss 6.216e-01, top1 87.06, top5 92.94
2021-11-06 18:24:39 (JOBID 31684) epoch -1: valid_top1 67.46, valid_top5 88.12, inference time 263.92
2021-11-06 18:25:01 (JOBID 31684) epoch -1: valid_top1 67.46, valid_top5 88.12, inference time 286.10
2021-11-06 18:25:04 (JOBID 31684) epoch -1: valid_top1 67.46, valid_top5 88.12, inference time 288.75
2021-11-06 18:25:22 train 0000, loss 1.300e+00, top1 68.24, top5 87.06
2021-11-06 18:25:22 train 0000, loss 1.787e+00, top1 58.82, top5 80.00
2021-11-06 18:25:22 train 0000, loss 1.289e+00, top1 71.76, top5 87.06
2021-11-06 18:34:13 train 1000, loss 1.603e+00, top1 62.95, top5 83.54
2021-11-06 18:34:13 train 1000, loss 1.593e+00, top1 63.03, top5 83.65
2021-11-06 18:34:14 train 1000, loss 1.603e+00, top1 63.11, top5 83.46
2021-11-06 18:43:06 train 2000, loss 1.599e+00, top1 63.04, top5 83.59
2021-11-06 18:43:06 train 2000, loss 1.604e+00, top1 62.90, top5 83.49
2021-11-06 18:43:06 train 2000, loss 1.598e+00, top1 63.09, top5 83.63
2021-11-06 18:52:02 train 3000, loss 1.597e+00, top1 63.08, top5 83.56
2021-11-06 18:52:02 train 3000, loss 1.598e+00, top1 63.05, top5 83.61
2021-11-06 18:52:02 train 3000, loss 1.600e+00, top1 63.00, top5 83.58
2021-11-06 19:01:06 train 4000, loss 1.593e+00, top1 63.15, top5 83.64
2021-11-06 19:01:06 train 4000, loss 1.594e+00, top1 63.10, top5 83.65
2021-11-06 19:01:06 train 4000, loss 1.595e+00, top1 63.10, top5 83.68
2021-11-06 19:10:14 train 5000, loss 1.593e+00, top1 63.15, top5 83.70
2021-11-06 19:10:14 train 5000, loss 1.593e+00, top1 63.10, top5 83.67
2021-11-06 19:10:14 train 5000, loss 1.589e+00, top1 63.26, top5 83.70
2021-11-06 19:10:41 valid 0000, loss 6.530e-01, top1 87.06, top5 90.59
2021-11-06 19:10:41 valid 0000, loss 6.530e-01, top1 87.06, top5 90.59
2021-11-06 19:10:41 valid 0000, loss 6.530e-01, top1 87.06, top5 90.59
2021-11-06 19:15:07 (JOBID 31684) epoch 31: train time 2727.42, inference time 275.61s, valid_top1 68.14 (best_top1 68.14), valid_top5 88.37
2021-11-06 19:15:09 (JOBID 31684) epoch 31: train time 2752.26, inference time 278.13s, valid_top1 68.14 (best_top1 68.14), valid_top5 88.37
2021-11-06 19:15:10 (JOBID 31684) epoch 31: train time 2730.23, inference time 278.06s, valid_top1 68.14 (best_top1 68.14), valid_top5 88.37
2021-11-06 19:15:23 train 0000, loss 1.552e+00, top1 65.88, top5 87.06
2021-11-06 19:15:22 train 0000, loss 1.400e+00, top1 62.35, top5 85.88
2021-11-06 19:15:23 train 0000, loss 1.866e+00, top1 61.18, top5 77.65
2021-11-06 19:23:52 train 1000, loss 1.541e+00, top1 64.09, top5 84.36
2021-11-06 19:23:51 train 1000, loss 1.548e+00, top1 64.08, top5 84.39
2021-11-06 19:23:52 train 1000, loss 1.547e+00, top1 63.90, top5 84.27
2021-11-06 19:32:17 train 2000, loss 1.548e+00, top1 63.99, top5 84.32
2021-11-06 19:32:17 train 2000, loss 1.553e+00, top1 63.99, top5 84.29
2021-11-06 19:32:17 train 2000, loss 1.549e+00, top1 63.89, top5 84.27
2021-11-06 19:40:41 train 3000, loss 1.553e+00, top1 63.99, top5 84.26
2021-11-06 19:40:41 train 3000, loss 1.548e+00, top1 64.02, top5 84.28
2021-11-06 19:40:41 train 3000, loss 1.550e+00, top1 63.93, top5 84.26
2021-11-06 19:49:11 train 4000, loss 1.548e+00, top1 64.04, top5 84.27
2021-11-06 19:49:11 train 4000, loss 1.551e+00, top1 64.00, top5 84.28
2021-11-06 19:49:11 train 4000, loss 1.548e+00, top1 63.96, top5 84.30
2021-11-06 19:57:42 train 5000, loss 1.548e+00, top1 64.01, top5 84.34
2021-11-06 19:57:43 train 5000, loss 1.549e+00, top1 64.02, top5 84.30
2021-11-06 19:57:43 train 5000, loss 1.549e+00, top1 63.98, top5 84.27
2021-11-06 19:58:05 valid 0000, loss 5.676e-01, top1 88.24, top5 92.94
2021-11-06 19:58:05 valid 0000, loss 5.676e-01, top1 88.24, top5 92.94
2021-11-06 19:58:05 valid 0000, loss 5.676e-01, top1 88.24, top5 92.94
2021-11-06 20:02:36 (JOBID 31684) epoch 32: train time 2565.35, inference time 280.78s, valid_top1 68.24 (best_top1 68.24), valid_top5 88.67
2021-11-06 20:02:36 (JOBID 31684) epoch 32: train time 2565.90, inference time 281.29s, valid_top1 68.24 (best_top1 68.24), valid_top5 88.67
2021-11-06 20:02:37 (JOBID 31684) epoch 32: train time 2568.47, inference time 281.90s, valid_top1 68.24 (best_top1 68.24), valid_top5 88.67
2021-11-06 20:02:51 train 0000, loss 1.372e+00, top1 65.88, top5 90.59
2021-11-06 20:02:51 train 0000, loss 1.644e+00, top1 62.35, top5 83.53
2021-11-06 20:02:51 train 0000, loss 1.922e+00, top1 61.18, top5 78.82
2021-11-06 20:11:21 train 1000, loss 1.521e+00, top1 64.44, top5 84.86
2021-11-06 20:11:21 train 1000, loss 1.521e+00, top1 64.38, top5 84.71
2021-11-06 20:11:21 train 1000, loss 1.535e+00, top1 64.32, top5 84.52
2021-11-06 20:19:50 train 2000, loss 1.526e+00, top1 64.37, top5 84.65
2021-11-06 20:19:50 train 2000, loss 1.522e+00, top1 64.44, top5 84.76
2021-11-06 20:19:50 train 2000, loss 1.536e+00, top1 64.14, top5 84.52
2021-11-06 20:28:19 train 3000, loss 1.519e+00, top1 64.46, top5 84.81
2021-11-06 20:28:19 train 3000, loss 1.529e+00, top1 64.33, top5 84.59
2021-11-06 20:28:19 train 3000, loss 1.531e+00, top1 64.34, top5 84.56
2021-11-06 20:38:05 train 4000, loss 1.522e+00, top1 64.43, top5 84.75
2021-11-06 20:38:05 train 4000, loss 1.529e+00, top1 64.34, top5 84.58
2021-11-06 20:38:05 train 4000, loss 1.531e+00, top1 64.35, top5 84.54
2021-11-06 20:47:09 train 5000, loss 1.527e+00, top1 64.37, top5 84.59
2021-11-06 20:47:09 train 5000, loss 1.523e+00, top1 64.43, top5 84.72
2021-11-06 20:47:09 train 5000, loss 1.529e+00, top1 64.41, top5 84.56
2021-11-06 20:47:32 valid 0000, loss 6.622e-01, top1 87.06, top5 92.94
2021-11-06 20:47:32 valid 0000, loss 6.622e-01, top1 87.06, top5 92.94
2021-11-06 20:47:32 valid 0000, loss 6.622e-01, top1 87.06, top5 92.94
2021-11-06 20:52:02 (JOBID 31684) epoch 33: train time 2684.21, inference time 280.26s, valid_top1 68.77 (best_top1 68.77), valid_top5 89.12
2021-11-06 20:52:02 (JOBID 31684) epoch 33: train time 2684.90, inference time 280.21s, valid_top1 68.77 (best_top1 68.77), valid_top5 89.12
2021-11-06 20:52:06 (JOBID 31684) epoch 33: train time 2684.98, inference time 284.12s, valid_top1 68.77 (best_top1 68.77), valid_top5 89.12
2021-11-06 20:52:17 train 0000, loss 1.356e+00, top1 64.71, top5 89.41
2021-11-06 20:52:17 train 0000, loss 1.159e+00, top1 71.76, top5 91.76
2021-11-06 20:52:20 train 0000, loss 1.647e+00, top1 64.71, top5 85.88
2021-11-06 21:00:55 train 1000, loss 1.500e+00, top1 65.19, top5 84.91
2021-11-06 21:00:55 train 1000, loss 1.505e+00, top1 65.05, top5 84.91
2021-11-06 21:00:55 train 1000, loss 1.503e+00, top1 64.81, top5 84.95
2021-11-06 21:09:30 train 2000, loss 1.508e+00, top1 64.89, top5 84.79
2021-11-06 21:09:30 train 2000, loss 1.505e+00, top1 64.92, top5 84.95
2021-11-06 21:09:30 train 2000, loss 1.506e+00, top1 64.69, top5 84.88
2021-11-06 21:18:08 train 3000, loss 1.510e+00, top1 64.82, top5 84.80
2021-11-06 21:18:08 train 3000, loss 1.505e+00, top1 64.73, top5 84.88
2021-11-06 21:18:08 train 3000, loss 1.512e+00, top1 64.75, top5 84.82
2021-11-06 21:27:03 train 4000, loss 1.512e+00, top1 64.74, top5 84.79
2021-11-06 21:27:03 train 4000, loss 1.514e+00, top1 64.70, top5 84.80
2021-11-06 21:27:03 train 4000, loss 1.505e+00, top1 64.72, top5 84.90
2021-11-06 21:36:04 train 5000, loss 1.513e+00, top1 64.68, top5 84.78
2021-11-06 21:36:04 train 5000, loss 1.506e+00, top1 64.71, top5 84.89
2021-11-06 21:36:05 train 5000, loss 1.517e+00, top1 64.64, top5 84.77
2021-11-06 21:36:30 valid 0000, loss 6.279e-01, top1 84.71, top5 95.29
2021-11-06 21:36:30 valid 0000, loss 6.279e-01, top1 84.71, top5 95.29
2021-11-06 21:36:30 valid 0000, loss 6.279e-01, top1 84.71, top5 95.29
2021-11-06 21:40:45 (JOBID 31684) epoch 34: train time 2655.77, inference time 267.74s, valid_top1 69.39 (best_top1 69.39), valid_top5 89.34
2021-11-06 21:40:52 (JOBID 31684) epoch 34: train time 2655.83, inference time 274.43s, valid_top1 69.39 (best_top1 69.39), valid_top5 89.34
2021-11-06 21:41:04 (JOBID 31684) epoch 34: train time 2650.99, inference time 286.58s, valid_top1 69.39 (best_top1 69.39), valid_top5 89.34
2021-11-06 21:41:06 train 0000, loss 1.445e+00, top1 70.59, top5 87.06
2021-11-06 21:41:00 train 0000, loss 1.117e+00, top1 70.59, top5 87.06
2021-11-06 21:41:18 train 0000, loss 1.285e+00, top1 72.94, top5 87.06
2021-11-06 21:50:36 train 1000, loss 1.484e+00, top1 65.34, top5 85.16
2021-11-06 21:50:36 train 1000, loss 1.484e+00, top1 65.10, top5 85.22
2021-11-06 21:50:36 train 1000, loss 1.485e+00, top1 65.24, top5 85.32
2021-11-06 22:00:02 train 2000, loss 1.492e+00, top1 65.10, top5 85.06
2021-11-06 22:00:02 train 2000, loss 1.487e+00, top1 65.16, top5 85.28
2021-11-06 22:00:02 train 2000, loss 1.489e+00, top1 65.15, top5 85.09
2021-11-06 22:09:29 train 3000, loss 1.488e+00, top1 65.21, top5 85.26
2021-11-06 22:09:29 train 3000, loss 1.500e+00, top1 64.94, top5 84.91
2021-11-06 22:09:29 train 3000, loss 1.492e+00, top1 65.03, top5 85.07
2021-11-06 22:18:59 train 4000, loss 1.496e+00, top1 64.92, top5 85.02
2021-11-06 22:18:59 train 4000, loss 1.502e+00, top1 64.91, top5 84.89
2021-11-06 22:18:59 train 4000, loss 1.491e+00, top1 65.09, top5 85.24
2021-11-06 22:28:26 train 5000, loss 1.500e+00, top1 64.86, top5 84.99
2021-11-06 22:28:26 train 5000, loss 1.504e+00, top1 64.88, top5 84.86
2021-11-06 22:28:26 train 5000, loss 1.496e+00, top1 65.00, top5 85.14
2021-11-06 22:28:52 valid 0000, loss 5.408e-01, top1 88.24, top5 94.12
2021-11-06 22:28:52 valid 0000, loss 5.408e-01, top1 88.24, top5 94.12
2021-11-06 22:28:52 valid 0000, loss 5.408e-01, top1 88.24, top5 94.12
2021-11-06 22:33:13 (JOBID 31684) epoch 35: train time 2875.16, inference time 273.14s, valid_top1 69.31 (best_top1 69.39), valid_top5 89.21
2021-11-06 22:33:20 (JOBID 31684) epoch 35: train time 2868.43, inference time 280.27s, valid_top1 69.31 (best_top1 69.39), valid_top5 89.21
2021-11-06 22:33:25 (JOBID 31684) epoch 35: train time 2855.72, inference time 284.13s, valid_top1 69.31 (best_top1 69.39), valid_top5 89.21
2021-11-06 22:33:34 train 0000, loss 1.296e+00, top1 75.29, top5 87.06
2021-11-06 22:33:28 train 0000, loss 1.638e+00, top1 58.82, top5 81.18
2021-11-06 22:33:38 train 0000, loss 1.734e+00, top1 58.82, top5 81.18
2021-11-06 22:42:03 train 1000, loss 1.485e+00, top1 65.14, top5 85.22
2021-11-06 22:42:03 train 1000, loss 1.471e+00, top1 65.49, top5 85.38
2021-11-06 22:42:03 train 1000, loss 1.477e+00, top1 65.36, top5 85.36
2021-11-06 22:50:27 train 2000, loss 1.485e+00, top1 65.27, top5 85.18
2021-11-06 22:50:27 train 2000, loss 1.492e+00, top1 65.11, top5 85.08
2021-11-06 22:50:27 train 2000, loss 1.481e+00, top1 65.25, top5 85.29
2021-11-06 22:58:51 train 3000, loss 1.488e+00, top1 65.12, top5 85.17
2021-11-06 22:58:51 train 3000, loss 1.495e+00, top1 64.99, top5 85.03
2021-11-06 22:58:51 train 3000, loss 1.484e+00, top1 65.24, top5 85.21
2021-11-06 23:07:18 train 4000, loss 1.497e+00, top1 64.98, top5 85.01
2021-11-06 23:07:18 train 4000, loss 1.495e+00, top1 64.96, top5 85.06
2021-11-06 23:07:18 train 4000, loss 1.487e+00, top1 65.19, top5 85.17
2021-11-06 23:15:43 train 5000, loss 1.497e+00, top1 64.96, top5 85.02
2021-11-06 23:15:43 train 5000, loss 1.501e+00, top1 64.88, top5 84.97
2021-11-06 23:15:43 train 5000, loss 1.489e+00, top1 65.15, top5 85.14
2021-11-06 23:16:05 valid 0000, loss 6.944e-01, top1 85.88, top5 91.76
2021-11-06 23:16:05 valid 0000, loss 6.944e-01, top1 85.88, top5 91.76
2021-11-06 23:16:05 valid 0000, loss 6.944e-01, top1 85.88, top5 91.76
2021-11-06 23:20:34 (JOBID 31684) epoch 36: train time 2561.60, inference time 278.90s, valid_top1 68.78 (best_top1 69.39), valid_top5 89.21
2021-11-06 23:20:37 (JOBID 31684) epoch 36: train time 2550.37, inference time 281.19s, valid_top1 68.78 (best_top1 69.39), valid_top5 89.21
2021-11-06 23:20:41 (JOBID 31684) epoch 36: train time 2554.57, inference time 285.75s, valid_top1 68.78 (best_top1 69.39), valid_top5 89.21
2021-11-06 23:20:52 train 0000, loss 1.558e+00, top1 63.53, top5 88.24
2021-11-06 23:20:49 train 0000, loss 1.118e+00, top1 69.41, top5 89.41
2021-11-06 23:20:54 train 0000, loss 1.333e+00, top1 65.88, top5 88.24
2021-11-06 23:29:17 train 1000, loss 1.478e+00, top1 65.44, top5 85.27
2021-11-06 23:29:17 train 1000, loss 1.467e+00, top1 65.61, top5 85.52
2021-11-06 23:29:18 train 1000, loss 1.478e+00, top1 65.22, top5 85.34
2021-11-06 23:37:40 train 2000, loss 1.477e+00, top1 65.40, top5 85.36
2021-11-06 23:37:39 train 2000, loss 1.486e+00, top1 65.14, top5 85.16
2021-11-06 23:37:40 train 2000, loss 1.480e+00, top1 65.27, top5 85.30
2021-11-06 23:46:02 train 3000, loss 1.494e+00, top1 65.01, top5 85.03
2021-11-06 23:46:01 train 3000, loss 1.482e+00, top1 65.26, top5 85.27
2021-11-06 23:46:02 train 3000, loss 1.487e+00, top1 65.19, top5 85.20
2021-11-06 23:54:24 train 4000, loss 1.496e+00, top1 64.99, top5 85.00
2021-11-06 23:54:24 train 4000, loss 1.485e+00, top1 65.20, top5 85.23
2021-11-06 23:54:24 train 4000, loss 1.492e+00, top1 65.12, top5 85.13
2021-11-07 00:02:52 train 5000, loss 1.489e+00, top1 65.16, top5 85.19
2021-11-07 00:02:52 train 5000, loss 1.494e+00, top1 65.05, top5 85.10
2021-11-07 00:02:52 train 5000, loss 1.497e+00, top1 64.95, top5 84.98
2021-11-07 00:03:15 valid 0000, loss 7.543e-01, top1 84.71, top5 91.76
2021-11-07 00:03:15 valid 0000, loss 7.543e-01, top1 84.71, top5 91.76
2021-11-07 00:03:15 valid 0000, loss 7.543e-01, top1 84.71, top5 91.76
2021-11-07 00:07:28 (JOBID 31684) epoch 37: train time 2544.10, inference time 263.08s, valid_top1 68.97 (best_top1 69.39), valid_top5 89.15
2021-11-07 00:07:43 (JOBID 31684) epoch 37: train time 2551.01, inference time 277.92s, valid_top1 68.97 (best_top1 69.39), valid_top5 89.15
2021-11-07 00:07:47 (JOBID 31684) epoch 37: train time 2548.37, inference time 281.65s, valid_top1 68.97 (best_top1 69.39), valid_top5 89.15
2021-11-07 00:07:57 train 0000, loss 1.766e+00, top1 65.88, top5 84.71
2021-11-07 00:07:42 train 0000, loss 1.183e+00, top1 67.06, top5 92.94
2021-11-07 00:08:01 train 0000, loss 1.380e+00, top1 65.88, top5 90.59
2021-11-07 00:16:28 train 1000, loss 1.485e+00, top1 64.99, top5 85.20
2021-11-07 00:16:29 train 1000, loss 1.474e+00, top1 65.27, top5 85.21
2021-11-07 00:16:29 train 1000, loss 1.482e+00, top1 65.30, top5 85.38
2021-11-07 00:24:57 train 2000, loss 1.485e+00, top1 65.09, top5 85.13
2021-11-07 00:24:57 train 2000, loss 1.486e+00, top1 65.27, top5 85.25
2021-11-07 00:24:57 train 2000, loss 1.481e+00, top1 65.14, top5 85.23
2021-11-07 00:33:27 train 3000, loss 1.490e+00, top1 65.09, top5 85.08
2021-11-07 00:33:27 train 3000, loss 1.493e+00, top1 65.16, top5 85.12
2021-11-07 00:33:27 train 3000, loss 1.484e+00, top1 65.09, top5 85.21
2021-11-07 00:41:58 train 4000, loss 1.495e+00, top1 64.98, top5 85.02
2021-11-07 00:41:58 train 4000, loss 1.489e+00, top1 65.03, top5 85.15
2021-11-07 00:41:58 train 4000, loss 1.495e+00, top1 65.09, top5 85.11
2021-11-07 00:50:28 train 5000, loss 1.492e+00, top1 65.00, top5 85.10
2021-11-07 00:50:28 train 5000, loss 1.496e+00, top1 65.05, top5 85.09
2021-11-07 00:50:28 train 5000, loss 1.497e+00, top1 64.92, top5 85.00
2021-11-07 00:50:50 valid 0000, loss 6.195e-01, top1 87.06, top5 94.12
2021-11-07 00:50:50 valid 0000, loss 6.195e-01, top1 87.06, top5 94.12
2021-11-07 00:50:50 valid 0000, loss 6.195e-01, top1 87.06, top5 94.12
2021-11-07 00:55:09 (JOBID 31684) epoch 38: train time 2573.57, inference time 268.10s, valid_top1 68.72 (best_top1 69.39), valid_top5 89.06
2021-11-07 00:55:19 (JOBID 31684) epoch 38: train time 2592.40, inference time 278.15s, valid_top1 68.72 (best_top1 69.39), valid_top5 89.06
2021-11-07 00:55:21 (JOBID 31684) epoch 38: train time 2577.63, inference time 280.40s, valid_top1 68.72 (best_top1 69.39), valid_top5 89.06
2021-11-07 00:55:33 train 0000, loss 1.398e+00, top1 71.76, top5 87.06
2021-11-07 00:55:23 train 0000, loss 1.202e+00, top1 71.76, top5 89.41
2021-11-07 00:55:35 train 0000, loss 1.496e+00, top1 63.53, top5 82.35
2021-11-07 01:04:02 train 1000, loss 1.479e+00, top1 65.43, top5 85.19
2021-11-07 01:04:02 train 1000, loss 1.479e+00, top1 65.43, top5 85.31
2021-11-07 01:04:02 train 1000, loss 1.472e+00, top1 65.45, top5 85.44
2021-11-07 01:12:29 train 2000, loss 1.486e+00, top1 65.23, top5 85.21
2021-11-07 01:12:29 train 2000, loss 1.481e+00, top1 65.42, top5 85.22
2021-11-07 01:12:29 train 2000, loss 1.482e+00, top1 65.25, top5 85.26
2021-11-07 01:20:52 train 3000, loss 1.487e+00, top1 65.25, top5 85.18
2021-11-07 01:20:52 train 3000, loss 1.486e+00, top1 65.17, top5 85.18
2021-11-07 01:20:52 train 3000, loss 1.489e+00, top1 65.18, top5 85.16
2021-11-07 01:29:22 train 4000, loss 1.491e+00, top1 65.11, top5 85.14
2021-11-07 01:29:22 train 4000, loss 1.487e+00, top1 65.20, top5 85.19
2021-11-07 01:29:22 train 4000, loss 1.488e+00, top1 65.15, top5 85.17
2021-11-07 01:37:53 train 5000, loss 1.492e+00, top1 65.14, top5 85.11
2021-11-07 01:37:53 train 5000, loss 1.492e+00, top1 65.06, top5 85.12
2021-11-07 01:37:53 train 5000, loss 1.494e+00, top1 65.02, top5 85.07
2021-11-07 01:38:16 valid 0000, loss 7.651e-01, top1 85.88, top5 91.76
2021-11-07 01:38:16 valid 0000, loss 7.651e-01, top1 85.88, top5 91.76
2021-11-07 01:38:16 valid 0000, loss 7.651e-01, top1 85.88, top5 91.76
2021-11-07 01:42:30 (JOBID 31684) epoch 39: train time 2564.59, inference time 264.62s, valid_top1 68.85 (best_top1 69.39), valid_top5 89.08
2021-11-07 01:42:48 (JOBID 31684) epoch 39: train time 2566.88, inference time 282.11s, valid_top1 68.85 (best_top1 69.39), valid_top5 89.08
2021-11-07 01:42:48 (JOBID 31684) epoch 39: train time 2576.61, inference time 282.15s, valid_top1 68.85 (best_top1 69.39), valid_top5 89.08
2021-11-07 01:42:43 train 0000, loss 1.801e+00, top1 55.29, top5 75.29
2021-11-07 01:43:01 train 0000, loss 1.506e+00, top1 67.06, top5 84.71
2021-11-07 01:43:01 train 0000, loss 1.465e+00, top1 72.94, top5 83.53
2021-11-07 01:51:25 train 1000, loss 1.470e+00, top1 65.45, top5 85.45
2021-11-07 01:51:25 train 1000, loss 1.492e+00, top1 65.08, top5 85.27
2021-11-07 01:51:25 train 1000, loss 1.480e+00, top1 65.30, top5 85.28
2021-11-07 01:59:52 train 2000, loss 1.478e+00, top1 65.29, top5 85.26
2021-11-07 01:59:51 train 2000, loss 1.483e+00, top1 65.16, top5 85.24
2021-11-07 01:59:52 train 2000, loss 1.491e+00, top1 65.04, top5 85.25
2021-11-07 02:08:18 train 3000, loss 1.487e+00, top1 65.13, top5 85.16
2021-11-07 02:08:18 train 3000, loss 1.486e+00, top1 65.15, top5 85.20
2021-11-07 02:08:18 train 3000, loss 1.496e+00, top1 64.96, top5 85.12
2021-11-07 02:16:45 train 4000, loss 1.489e+00, top1 65.09, top5 85.17
2021-11-07 02:16:45 train 4000, loss 1.497e+00, top1 64.92, top5 85.09
2021-11-07 02:16:45 train 4000, loss 1.489e+00, top1 65.15, top5 85.17
2021-11-07 02:25:14 train 5000, loss 1.496e+00, top1 65.00, top5 85.06
2021-11-07 02:25:14 train 5000, loss 1.492e+00, top1 65.05, top5 85.14
2021-11-07 02:25:14 train 5000, loss 1.501e+00, top1 64.86, top5 85.01
2021-11-07 02:25:37 valid 0000, loss 8.416e-01, top1 83.53, top5 90.59
2021-11-07 02:25:37 valid 0000, loss 8.416e-01, top1 83.53, top5 90.59
2021-11-07 02:25:37 valid 0000, loss 8.416e-01, top1 83.53, top5 90.59
2021-11-07 02:30:11 (JOBID 31684) epoch 40: train time 2576.90, inference time 284.43s, valid_top1 67.19 (best_top1 69.39), valid_top5 88.05
2021-11-07 02:30:11 (JOBID 31684) epoch 40: train time 2559.45, inference time 284.44s, valid_top1 67.19 (best_top1 69.39), valid_top5 88.05
2021-11-07 02:30:12 (JOBID 31684) epoch 40: train time 2559.08, inference time 284.52s, valid_top1 67.19 (best_top1 69.39), valid_top5 88.05
2021-11-07 02:30:26 train 0000, loss 1.485e+00, top1 65.88, top5 88.24
2021-11-07 02:30:26 train 0000, loss 1.785e+00, top1 65.88, top5 82.35
2021-11-07 02:30:26 train 0000, loss 1.317e+00, top1 65.88, top5 87.06
2021-11-07 02:38:50 train 1000, loss 1.472e+00, top1 65.50, top5 85.37
2021-11-07 02:38:50 train 1000, loss 1.490e+00, top1 65.07, top5 85.10
2021-11-07 02:38:50 train 1000, loss 1.478e+00, top1 65.27, top5 85.34
2021-11-07 02:47:15 train 2000, loss 1.488e+00, top1 65.18, top5 85.19
2021-11-07 02:47:15 train 2000, loss 1.491e+00, top1 65.08, top5 85.08
2021-11-07 02:47:15 train 2000, loss 1.480e+00, top1 65.37, top5 85.33
2021-11-07 02:55:43 train 3000, loss 1.487e+00, top1 65.15, top5 85.24
2021-11-07 02:55:43 train 3000, loss 1.494e+00, top1 65.08, top5 85.09
2021-11-07 02:55:43 train 3000, loss 1.492e+00, top1 65.08, top5 85.08
2021-11-07 03:04:13 train 4000, loss 1.488e+00, top1 65.13, top5 85.20
2021-11-07 03:04:13 train 4000, loss 1.499e+00, top1 64.95, top5 85.01
2021-11-07 03:04:13 train 4000, loss 1.494e+00, top1 65.02, top5 85.04
2021-11-07 03:12:40 train 5000, loss 1.497e+00, top1 64.96, top5 85.01
2021-11-07 03:12:40 train 5000, loss 1.493e+00, top1 65.00, top5 85.14
2021-11-07 03:12:40 train 5000, loss 1.501e+00, top1 64.86, top5 85.01
2021-11-07 03:13:03 valid 0000, loss 6.255e-01, top1 84.71, top5 91.76
2021-11-07 03:13:03 valid 0000, loss 6.255e-01, top1 84.71, top5 91.76
2021-11-07 03:13:03 valid 0000, loss 6.255e-01, top1 84.71, top5 91.76
2021-11-07 03:17:33 (JOBID 31684) epoch 41: train time 2561.28, inference time 280.27s, valid_top1 68.70 (best_top1 69.39), valid_top5 88.86
2021-11-07 03:17:33 (JOBID 31684) epoch 41: train time 2561.11, inference time 280.40s, valid_top1 68.70 (best_top1 69.39), valid_top5 88.86
2021-11-07 03:17:39 (JOBID 31684) epoch 41: train time 2560.94, inference time 286.39s, valid_top1 68.70 (best_top1 69.39), valid_top5 88.86
2021-11-07 03:17:47 train 0000, loss 1.361e+00, top1 60.00, top5 90.59
2021-11-07 03:17:47 train 0000, loss 1.305e+00, top1 67.06, top5 85.88
2021-11-07 03:17:53 train 0000, loss 1.679e+00, top1 65.88, top5 84.71
2021-11-07 03:26:38 train 1000, loss 1.469e+00, top1 65.53, top5 85.44
2021-11-07 03:26:39 train 1000, loss 1.486e+00, top1 65.12, top5 85.19
2021-11-07 03:26:39 train 1000, loss 1.485e+00, top1 65.21, top5 85.11
2021-11-07 03:35:24 train 2000, loss 1.482e+00, top1 65.25, top5 85.25
2021-11-07 03:35:24 train 2000, loss 1.489e+00, top1 65.04, top5 85.10
2021-11-07 03:35:24 train 2000, loss 1.491e+00, top1 65.05, top5 85.08
2021-11-07 03:44:16 train 3000, loss 1.493e+00, top1 64.95, top5 85.08
2021-11-07 03:44:16 train 3000, loss 1.486e+00, top1 65.15, top5 85.19
2021-11-07 03:44:17 train 3000, loss 1.494e+00, top1 65.00, top5 85.06
2021-11-07 03:53:13 train 4000, loss 1.493e+00, top1 65.01, top5 85.12
2021-11-07 03:53:13 train 4000, loss 1.496e+00, top1 64.96, top5 85.05
2021-11-07 03:53:13 train 4000, loss 1.495e+00, top1 64.90, top5 85.06
2021-11-07 04:02:16 train 5000, loss 1.496e+00, top1 64.93, top5 85.07
2021-11-07 04:02:16 train 5000, loss 1.498e+00, top1 64.84, top5 85.03
2021-11-07 04:02:16 train 5000, loss 1.501e+00, top1 64.90, top5 84.99
2021-11-07 04:02:40 valid 0000, loss 5.290e-01, top1 87.06, top5 96.47
2021-11-07 04:02:40 valid 0000, loss 5.290e-01, top1 87.06, top5 96.47
2021-11-07 04:02:40 valid 0000, loss 5.290e-01, top1 87.06, top5 96.47
2021-11-07 04:06:44 (JOBID 31684) epoch 42: train time 2696.17, inference time 255.05s, valid_top1 68.34 (best_top1 69.39), valid_top5 88.61
2021-11-07 04:07:17 (JOBID 31684) epoch 42: train time 2696.14, inference time 288.10s, valid_top1 68.34 (best_top1 69.39), valid_top5 88.61
2021-11-07 04:07:28 (JOBID 31684) epoch 42: train time 2689.84, inference time 298.38s, valid_top1 68.34 (best_top1 69.39), valid_top5 88.61
2021-11-07 04:06:59 train 0000, loss 1.436e+00, top1 65.88, top5 85.88
2021-11-07 04:07:31 train 0000, loss 1.370e+00, top1 64.71, top5 89.41
2021-11-07 04:07:42 train 0000, loss 1.425e+00, top1 67.06, top5 81.18
2021-11-07 04:16:11 train 1000, loss 1.473e+00, top1 65.34, top5 85.47
2021-11-07 04:16:11 train 1000, loss 1.482e+00, top1 65.23, top5 85.33
2021-11-07 04:16:11 train 1000, loss 1.479e+00, top1 65.40, top5 85.24
2021-11-07 04:24:40 train 2000, loss 1.489e+00, top1 65.05, top5 85.25
2021-11-07 04:24:40 train 2000, loss 1.485e+00, top1 65.12, top5 85.25
2021-11-07 04:24:41 train 2000, loss 1.487e+00, top1 65.15, top5 85.12
2021-11-07 04:33:07 train 3000, loss 1.493e+00, top1 64.96, top5 85.11
2021-11-07 04:33:07 train 3000, loss 1.491e+00, top1 64.98, top5 85.19
2021-11-07 04:33:07 train 3000, loss 1.490e+00, top1 64.98, top5 85.16
2021-11-07 04:41:33 train 4000, loss 1.494e+00, top1 64.94, top5 85.18
2021-11-07 04:41:33 train 4000, loss 1.495e+00, top1 64.93, top5 85.09
2021-11-07 04:41:34 train 4000, loss 1.495e+00, top1 64.88, top5 85.08
2021-11-07 04:50:06 train 5000, loss 1.499e+00, top1 64.87, top5 85.12
2021-11-07 04:50:07 train 5000, loss 1.498e+00, top1 64.85, top5 85.02
2021-11-07 04:50:07 train 5000, loss 1.498e+00, top1 64.88, top5 85.05
2021-11-07 04:50:29 valid 0000, loss 4.941e-01, top1 89.41, top5 95.29
2021-11-07 04:50:29 valid 0000, loss 4.941e-01, top1 89.41, top5 95.29
2021-11-07 04:50:29 valid 0000, loss 4.941e-01, top1 89.41, top5 95.29
2021-11-07 04:55:00 (JOBID 31684) epoch 43: train time 2614.77, inference time 280.66s, valid_top1 68.50 (best_top1 69.39), valid_top5 89.14
2021-11-07 04:55:00 (JOBID 31684) epoch 43: train time 2581.86, inference time 280.83s, valid_top1 68.50 (best_top1 69.39), valid_top5 89.14
2021-11-07 04:55:01 (JOBID 31684) epoch 43: train time 2571.16, inference time 281.26s, valid_top1 68.50 (best_top1 69.39), valid_top5 89.14
2021-11-07 04:55:14 train 0000, loss 1.534e+00, top1 64.71, top5 87.06
2021-11-07 04:55:14 train 0000, loss 1.098e+00, top1 70.59, top5 91.76
2021-11-07 04:55:14 train 0000, loss 1.354e+00, top1 64.71, top5 91.76
2021-11-07 05:03:40 train 1000, loss 1.492e+00, top1 65.10, top5 85.23
2021-11-07 05:03:40 train 1000, loss 1.481e+00, top1 65.43, top5 85.22
2021-11-07 05:03:40 train 1000, loss 1.480e+00, top1 65.32, top5 85.43
2021-11-07 05:12:05 train 2000, loss 1.485e+00, top1 65.16, top5 85.32
2021-11-07 05:12:05 train 2000, loss 1.493e+00, top1 65.07, top5 85.21
2021-11-07 05:12:05 train 2000, loss 1.491e+00, top1 65.23, top5 85.17
2021-11-07 05:20:30 train 3000, loss 1.489e+00, top1 64.99, top5 85.25
2021-11-07 05:20:30 train 3000, loss 1.494e+00, top1 65.07, top5 85.14
2021-11-07 05:20:31 train 3000, loss 1.493e+00, top1 65.09, top5 85.12
2021-11-07 05:28:58 train 4000, loss 1.494e+00, top1 64.87, top5 85.17
2021-11-07 05:28:58 train 4000, loss 1.498e+00, top1 64.98, top5 85.06
2021-11-07 05:28:58 train 4000, loss 1.497e+00, top1 64.98, top5 85.09
2021-11-07 05:37:31 train 5000, loss 1.503e+00, top1 64.87, top5 84.99
2021-11-07 05:37:31 train 5000, loss 1.498e+00, top1 64.82, top5 85.13
2021-11-07 05:37:31 train 5000, loss 1.500e+00, top1 64.92, top5 85.06
2021-11-07 05:37:54 valid 0000, loss 6.757e-01, top1 84.71, top5 92.94
2021-11-07 05:37:54 valid 0000, loss 6.757e-01, top1 84.71, top5 92.94
2021-11-07 05:37:54 valid 0000, loss 6.757e-01, top1 84.71, top5 92.94
2021-11-07 05:42:21 (JOBID 31684) epoch 44: train time 2563.17, inference time 277.27s, valid_top1 67.19 (best_top1 69.39), valid_top5 88.16
2021-11-07 05:42:22 (JOBID 31684) epoch 44: train time 2563.86, inference time 277.88s, valid_top1 67.19 (best_top1 69.39), valid_top5 88.16
2021-11-07 05:42:28 (JOBID 31684) epoch 44: train time 2564.21, inference time 284.57s, valid_top1 67.19 (best_top1 69.39), valid_top5 88.16
2021-11-07 05:42:35 train 0000, loss 1.545e+00, top1 67.06, top5 82.35
2021-11-07 05:42:35 train 0000, loss 1.474e+00, top1 63.53, top5 91.76
2021-11-07 05:42:42 train 0000, loss 1.669e+00, top1 62.35, top5 81.18
2021-11-07 05:51:31 train 1000, loss 1.478e+00, top1 65.33, top5 85.39
2021-11-07 05:51:31 train 1000, loss 1.485e+00, top1 65.23, top5 85.14
2021-11-07 05:51:31 train 1000, loss 1.489e+00, top1 65.06, top5 85.14
2021-11-07 06:00:25 train 2000, loss 1.486e+00, top1 65.14, top5 85.25
2021-11-07 06:00:25 train 2000, loss 1.493e+00, top1 64.93, top5 85.12
2021-11-07 06:00:25 train 2000, loss 1.486e+00, top1 65.12, top5 85.20
2021-11-07 06:09:17 train 3000, loss 1.493e+00, top1 65.01, top5 85.13
2021-11-07 06:09:17 train 3000, loss 1.500e+00, top1 64.83, top5 85.02
2021-11-07 06:09:17 train 3000, loss 1.493e+00, top1 64.95, top5 85.06
2021-11-07 06:18:16 train 4000, loss 1.498e+00, top1 64.90, top5 85.05
2021-11-07 06:18:16 train 4000, loss 1.500e+00, top1 64.81, top5 85.02
2021-11-07 06:18:16 train 4000, loss 1.499e+00, top1 64.85, top5 84.99
2021-11-07 06:27:20 train 5000, loss 1.503e+00, top1 64.78, top5 84.96
2021-11-07 06:27:20 train 5000, loss 1.501e+00, top1 64.88, top5 85.00
2021-11-07 06:27:20 train 5000, loss 1.504e+00, top1 64.77, top5 84.91
2021-11-07 06:27:43 valid 0000, loss 5.348e-01, top1 89.41, top5 92.94
2021-11-07 06:27:43 valid 0000, loss 5.348e-01, top1 89.41, top5 92.94
2021-11-07 06:27:43 valid 0000, loss 5.348e-01, top1 89.41, top5 92.94
2021-11-07 06:32:15 (JOBID 31684) epoch 45: train time 2711.36, inference time 282.40s, valid_top1 67.88 (best_top1 69.39), valid_top5 88.64
2021-11-07 06:32:16 (JOBID 31684) epoch 45: train time 2704.56, inference time 283.02s, valid_top1 67.88 (best_top1 69.39), valid_top5 88.64
2021-11-07 06:32:17 (JOBID 31684) epoch 45: train time 2711.76, inference time 283.34s, valid_top1 67.88 (best_top1 69.39), valid_top5 88.64
2021-11-07 06:32:30 train 0000, loss 1.286e+00, top1 64.71, top5 90.59
2021-11-07 06:32:30 train 0000, loss 1.157e+00, top1 70.59, top5 90.59
2021-11-07 06:32:30 train 0000, loss 1.345e+00, top1 70.59, top5 87.06
2021-11-07 06:41:17 train 1000, loss 1.488e+00, top1 65.27, top5 85.27
2021-11-07 06:41:17 train 1000, loss 1.487e+00, top1 65.15, top5 85.28
2021-11-07 06:41:17 train 1000, loss 1.470e+00, top1 65.55, top5 85.47
2021-11-07 06:50:04 train 2000, loss 1.496e+00, top1 64.97, top5 85.14
2021-11-07 06:50:04 train 2000, loss 1.489e+00, top1 65.09, top5 85.22
2021-11-07 06:50:04 train 2000, loss 1.487e+00, top1 65.21, top5 85.22
2021-11-07 06:59:02 train 3000, loss 1.495e+00, top1 65.00, top5 85.09
2021-11-07 06:59:02 train 3000, loss 1.497e+00, top1 64.94, top5 85.15
2021-11-07 06:59:02 train 3000, loss 1.495e+00, top1 64.91, top5 85.15
2021-11-07 07:07:55 train 4000, loss 1.500e+00, top1 64.84, top5 85.06
2021-11-07 07:07:55 train 4000, loss 1.498e+00, top1 64.83, top5 85.15
2021-11-07 07:07:55 train 4000, loss 1.499e+00, top1 64.83, top5 85.05
2021-11-07 07:16:54 train 5000, loss 1.503e+00, top1 64.78, top5 85.04
2021-11-07 07:16:54 train 5000, loss 1.503e+00, top1 64.73, top5 85.07
2021-11-07 07:16:54 train 5000, loss 1.503e+00, top1 64.77, top5 84.96
2021-11-07 07:17:17 valid 0000, loss 7.966e-01, top1 83.53, top5 90.59
2021-11-07 07:17:17 valid 0000, loss 7.966e-01, top1 83.53, top5 90.59
2021-11-07 07:17:17 valid 0000, loss 7.966e-01, top1 83.53, top5 90.59
2021-11-07 07:21:49 (JOBID 31684) epoch 46: train time 2691.69, inference time 282.28s, valid_top1 65.85 (best_top1 69.39), valid_top5 87.00
2021-11-07 07:21:50 (JOBID 31684) epoch 46: train time 2691.01, inference time 283.06s, valid_top1 65.85 (best_top1 69.39), valid_top5 87.00
2021-11-07 07:21:52 (JOBID 31684) epoch 46: train time 2690.19, inference time 284.38s, valid_top1 65.85 (best_top1 69.39), valid_top5 87.00
2021-11-07 07:22:04 train 0000, loss 1.594e+00, top1 63.53, top5 88.24
2021-11-07 07:22:04 train 0000, loss 1.734e+00, top1 62.35, top5 80.00
2021-11-07 07:22:06 train 0000, loss 1.438e+00, top1 64.71, top5 85.88
2021-11-07 07:30:33 train 1000, loss 1.478e+00, top1 65.39, top5 85.39
2021-11-07 07:30:33 train 1000, loss 1.493e+00, top1 65.01, top5 85.10
2021-11-07 07:30:33 train 1000, loss 1.487e+00, top1 65.22, top5 85.23
2021-11-07 07:38:59 train 2000, loss 1.485e+00, top1 65.17, top5 85.30
2021-11-07 07:38:59 train 2000, loss 1.496e+00, top1 64.94, top5 85.12
2021-11-07 07:39:00 train 2000, loss 1.493e+00, top1 65.04, top5 85.12
2021-11-07 07:47:29 train 3000, loss 1.497e+00, top1 64.98, top5 85.06
2021-11-07 07:47:29 train 3000, loss 1.503e+00, top1 64.78, top5 84.96
2021-11-07 07:47:29 train 3000, loss 1.490e+00, top1 65.12, top5 85.19
2021-11-07 07:55:59 train 4000, loss 1.504e+00, top1 64.79, top5 84.95
2021-11-07 07:55:59 train 4000, loss 1.502e+00, top1 64.87, top5 84.99
2021-11-07 07:55:59 train 4000, loss 1.494e+00, top1 65.03, top5 85.12
2021-11-07 08:04:35 train 5000, loss 1.509e+00, top1 64.71, top5 84.87
2021-11-07 08:04:35 train 5000, loss 1.501e+00, top1 64.88, top5 85.02
2021-11-07 08:04:35 train 5000, loss 1.499e+00, top1 64.92, top5 85.07
2021-11-07 08:04:58 valid 0000, loss 6.275e-01, top1 85.88, top5 92.94
2021-11-07 08:04:58 valid 0000, loss 6.275e-01, top1 85.88, top5 92.94
2021-11-07 08:04:58 valid 0000, loss 6.275e-01, top1 85.88, top5 92.94
2021-11-07 08:09:44 (JOBID 31684) epoch 47: train time 2578.53, inference time 296.55s, valid_top1 68.24 (best_top1 69.39), valid_top5 88.78
2021-11-07 08:09:46 (JOBID 31684) epoch 47: train time 2576.13, inference time 297.81s, valid_top1 68.24 (best_top1 69.39), valid_top5 88.78
2021-11-07 08:09:46 (JOBID 31684) epoch 47: train time 2577.78, inference time 298.29s, valid_top1 68.24 (best_top1 69.39), valid_top5 88.78
2021-11-07 08:09:59 train 0000, loss 1.904e+00, top1 55.29, top5 75.29
2021-11-07 08:09:59 train 0000, loss 1.490e+00, top1 61.18, top5 85.88
2021-11-07 08:09:59 train 0000, loss 1.451e+00, top1 62.35, top5 85.88
2021-11-07 08:18:29 train 1000, loss 1.478e+00, top1 65.24, top5 85.31
2021-11-07 08:18:29 train 1000, loss 1.476e+00, top1 65.15, top5 85.30
2021-11-07 08:18:29 train 1000, loss 1.486e+00, top1 65.21, top5 85.22
2021-11-07 08:26:56 train 2000, loss 1.489e+00, top1 65.00, top5 85.18
2021-11-07 08:26:56 train 2000, loss 1.486e+00, top1 65.09, top5 85.20
2021-11-07 08:26:56 train 2000, loss 1.497e+00, top1 64.93, top5 85.08
2021-11-07 08:35:28 train 3000, loss 1.494e+00, top1 64.88, top5 85.05
2021-11-07 08:35:29 train 3000, loss 1.501e+00, top1 64.81, top5 85.04
2021-11-07 08:35:29 train 3000, loss 1.495e+00, top1 64.85, top5 85.11
2021-11-07 08:43:58 train 4000, loss 1.503e+00, top1 64.76, top5 85.01
2021-11-07 08:43:58 train 4000, loss 1.496e+00, top1 64.81, top5 85.05
2021-11-07 08:43:58 train 4000, loss 1.495e+00, top1 64.83, top5 85.12
2021-11-07 08:52:29 train 5000, loss 1.499e+00, top1 64.75, top5 85.03
2021-11-07 08:52:29 train 5000, loss 1.500e+00, top1 64.80, top5 85.00
2021-11-07 08:52:29 train 5000, loss 1.507e+00, top1 64.66, top5 84.95
2021-11-07 08:52:53 valid 0000, loss 5.241e-01, top1 87.06, top5 96.47
2021-11-07 08:52:53 valid 0000, loss 5.241e-01, top1 87.06, top5 96.47
2021-11-07 08:52:53 valid 0000, loss 5.241e-01, top1 87.06, top5 96.47
2021-11-07 08:57:13 (JOBID 31684) epoch 48: train time 2576.11, inference time 270.86s, valid_top1 68.41 (best_top1 69.39), valid_top5 88.93
2021-11-07 08:57:24 (JOBID 31684) epoch 48: train time 2577.42, inference time 281.89s, valid_top1 68.41 (best_top1 69.39), valid_top5 88.93
2021-11-07 08:57:24 (JOBID 31684) epoch 48: train time 2575.89, inference time 282.18s, valid_top1 68.41 (best_top1 69.39), valid_top5 88.93
2021-11-07 08:57:28 train 0000, loss 1.545e+00, top1 58.82, top5 87.06
2021-11-07 08:57:38 train 0000, loss 1.333e+00, top1 68.24, top5 81.18
2021-11-07 08:57:38 train 0000, loss 1.116e+00, top1 71.76, top5 95.29
2021-11-07 09:06:33 train 1000, loss 1.490e+00, top1 65.02, top5 85.19
2021-11-07 09:06:33 train 1000, loss 1.485e+00, top1 65.26, top5 85.26
2021-11-07 09:06:33 train 1000, loss 1.477e+00, top1 65.46, top5 85.37
2021-11-07 09:15:28 train 2000, loss 1.486e+00, top1 65.08, top5 85.31
2021-11-07 09:15:28 train 2000, loss 1.490e+00, top1 65.09, top5 85.19
2021-11-07 09:15:28 train 2000, loss 1.498e+00, top1 64.87, top5 85.06
2021-11-07 09:24:26 train 3000, loss 1.499e+00, top1 64.88, top5 85.02
2021-11-07 09:24:26 train 3000, loss 1.491e+00, top1 64.99, top5 85.21
2021-11-07 09:24:26 train 3000, loss 1.495e+00, top1 64.88, top5 85.11
2021-11-07 09:33:27 train 4000, loss 1.503e+00, top1 64.78, top5 84.98
2021-11-07 09:33:27 train 4000, loss 1.495e+00, top1 64.89, top5 85.11
2021-11-07 09:33:27 train 4000, loss 1.501e+00, top1 64.84, top5 85.02
2021-11-07 09:42:33 train 5000, loss 1.506e+00, top1 64.74, top5 84.95
2021-11-07 09:42:33 train 5000, loss 1.497e+00, top1 64.85, top5 85.07
2021-11-07 09:42:33 train 5000, loss 1.504e+00, top1 64.76, top5 85.01
2021-11-07 09:42:57 valid 0000, loss 5.348e-01, top1 85.88, top5 97.65
2021-11-07 09:42:57 valid 0000, loss 5.348e-01, top1 85.88, top5 97.65
2021-11-07 09:42:57 valid 0000, loss 5.348e-01, top1 85.88, top5 97.65
2021-11-07 09:47:24 (JOBID 31684) epoch 49: train time 2722.65, inference time 277.31s, valid_top1 67.21 (best_top1 69.39), valid_top5 88.19
2021-11-07 09:47:24 (JOBID 31684) epoch 49: train time 2733.68, inference time 277.38s, valid_top1 67.21 (best_top1 69.39), valid_top5 88.19
2021-11-07 09:47:36 (JOBID 31684) epoch 49: train time 2723.00, inference time 288.94s, valid_top1 67.21 (best_top1 69.39), valid_top5 88.19
2021-11-07 09:47:39 train 0000, loss 1.725e+00, top1 64.71, top5 81.18
2021-11-07 09:47:39 train 0000, loss 1.626e+00, top1 64.71, top5 82.35
2021-11-07 09:47:50 train 0000, loss 1.498e+00, top1 63.53, top5 83.53
2021-11-07 09:56:39 train 1000, loss 1.490e+00, top1 65.26, top5 85.11
2021-11-07 09:56:39 train 1000, loss 1.481e+00, top1 65.35, top5 85.27
2021-11-07 09:56:39 train 1000, loss 1.489e+00, top1 65.07, top5 85.31
2021-11-07 10:05:31 train 2000, loss 1.491e+00, top1 65.17, top5 85.07
2021-11-07 10:05:31 train 2000, loss 1.491e+00, top1 65.06, top5 85.28
2021-11-07 10:05:31 train 2000, loss 1.490e+00, top1 65.04, top5 85.20
2021-11-07 10:14:29 train 3000, loss 1.496e+00, top1 64.97, top5 85.15
2021-11-07 10:14:28 train 3000, loss 1.495e+00, top1 65.07, top5 85.05
2021-11-07 10:14:29 train 3000, loss 1.497e+00, top1 64.92, top5 85.09
2021-11-07 10:23:31 train 4000, loss 1.497e+00, top1 65.01, top5 85.04
2021-11-07 10:23:31 train 4000, loss 1.501e+00, top1 64.81, top5 85.02
2021-11-07 10:23:31 train 4000, loss 1.499e+00, top1 64.90, top5 85.12
2021-11-07 10:32:36 train 5000, loss 1.501e+00, top1 64.80, top5 85.07
2021-11-07 10:32:35 train 5000, loss 1.503e+00, top1 64.87, top5 84.97
2021-11-07 10:32:36 train 5000, loss 1.503e+00, top1 64.76, top5 85.00
2021-11-07 10:33:10 valid 0000, loss 7.769e-01, top1 84.71, top5 91.76
2021-11-07 10:33:10 valid 0000, loss 7.769e-01, top1 84.71, top5 91.76
2021-11-07 10:33:10 valid 0000, loss 7.769e-01, top1 84.71, top5 91.76
2021-11-07 10:37:31 (JOBID 31684) epoch 50: train time 2726.26, inference time 280.31s, valid_top1 67.64 (best_top1 69.39), valid_top5 88.42
2021-11-07 10:37:38 (JOBID 31684) epoch 50: train time 2714.69, inference time 287.59s, valid_top1 67.64 (best_top1 69.39), valid_top5 88.42
2021-11-07 10:37:43 (JOBID 31684) epoch 50: train time 2726.03, inference time 291.30s, valid_top1 67.64 (best_top1 69.39), valid_top5 88.42
2021-11-07 10:37:53 train 0000, loss 1.267e+00, top1 69.41, top5 89.41
2021-11-07 10:37:57 train 0000, loss 1.832e+00, top1 61.18, top5 77.65
2021-11-07 10:38:00 train 0000, loss 1.314e+00, top1 71.76, top5 84.71
2021-11-07 10:46:25 train 1000, loss 1.471e+00, top1 65.33, top5 85.45
2021-11-07 10:46:25 train 1000, loss 1.489e+00, top1 65.19, top5 85.16
2021-11-07 10:46:25 train 1000, loss 1.484e+00, top1 65.04, top5 85.24
2021-11-07 10:54:56 train 2000, loss 1.493e+00, top1 65.17, top5 85.15
2021-11-07 10:54:56 train 2000, loss 1.484e+00, top1 65.13, top5 85.19
2021-11-07 10:54:56 train 2000, loss 1.489e+00, top1 64.94, top5 85.23
2021-11-07 11:03:19 train 3000, loss 1.494e+00, top1 64.87, top5 85.11
2021-11-07 11:03:19 train 3000, loss 1.493e+00, top1 65.11, top5 85.15
2021-11-07 11:03:20 train 3000, loss 1.490e+00, top1 65.03, top5 85.14
2021-11-07 11:11:47 train 4000, loss 1.496e+00, top1 65.04, top5 85.11
2021-11-07 11:11:47 train 4000, loss 1.494e+00, top1 64.92, top5 85.13
2021-11-07 11:11:47 train 4000, loss 1.501e+00, top1 64.77, top5 85.03
2021-11-07 11:20:21 train 5000, loss 1.501e+00, top1 64.93, top5 85.02
2021-11-07 11:20:21 train 5000, loss 1.498e+00, top1 64.82, top5 85.09
2021-11-07 11:20:21 train 5000, loss 1.503e+00, top1 64.73, top5 84.98
2021-11-07 11:20:53 valid 0000, loss 6.695e-01, top1 84.71, top5 92.94
2021-11-07 11:20:53 valid 0000, loss 6.695e-01, top1 84.71, top5 92.94
2021-11-07 11:20:53 valid 0000, loss 6.695e-01, top1 84.71, top5 92.94
2021-11-07 11:25:22 (JOBID 31684) epoch 51: train time 2575.59, inference time 287.89s, valid_top1 67.78 (best_top1 69.39), valid_top5 88.26
2021-11-07 11:25:22 (JOBID 31684) epoch 51: train time 2582.94, inference time 288.36s, valid_top1 67.78 (best_top1 69.39), valid_top5 88.26
2021-11-07 11:25:24 (JOBID 31684) epoch 51: train time 2570.95, inference time 288.31s, valid_top1 67.78 (best_top1 69.39), valid_top5 88.26
2021-11-07 11:25:45 train 0000, loss 1.685e+00, top1 61.18, top5 88.24
2021-11-07 11:25:45 train 0000, loss 1.401e+00, top1 69.41, top5 91.76
2021-11-07 11:25:45 train 0000, loss 1.564e+00, top1 61.18, top5 84.71
2021-11-07 11:34:14 train 1000, loss 1.480e+00, top1 65.30, top5 85.32
2021-11-07 11:34:14 train 1000, loss 1.480e+00, top1 65.13, top5 85.28
2021-11-07 11:34:14 train 1000, loss 1.489e+00, top1 65.09, top5 85.16
2021-11-07 11:42:42 train 2000, loss 1.483e+00, top1 65.19, top5 85.21
2021-11-07 11:42:42 train 2000, loss 1.485e+00, top1 65.05, top5 85.29
2021-11-07 11:42:42 train 2000, loss 1.492e+00, top1 65.05, top5 85.12
2021-11-07 11:51:10 train 3000, loss 1.489e+00, top1 64.98, top5 85.23
2021-11-07 11:51:11 train 3000, loss 1.496e+00, top1 64.94, top5 85.02
2021-11-07 11:51:11 train 3000, loss 1.488e+00, top1 65.05, top5 85.18
2021-11-07 11:59:35 train 4000, loss 1.496e+00, top1 64.87, top5 85.17
2021-11-07 11:59:36 train 4000, loss 1.501e+00, top1 64.85, top5 84.96
2021-11-07 11:59:36 train 4000, loss 1.494e+00, top1 64.93, top5 85.10
2021-11-07 12:08:04 train 5000, loss 1.497e+00, top1 64.90, top5 85.06
2021-11-07 12:08:04 train 5000, loss 1.501e+00, top1 64.78, top5 85.06
2021-11-07 12:08:04 train 5000, loss 1.504e+00, top1 64.80, top5 84.93
2021-11-07 12:08:27 valid 0000, loss 7.951e-01, top1 82.35, top5 91.76
2021-11-07 12:08:27 valid 0000, loss 7.951e-01, top1 82.35, top5 91.76
2021-11-07 12:08:27 valid 0000, loss 7.951e-01, top1 82.35, top5 91.76
2021-11-07 12:12:45 (JOBID 31684) epoch 52: train time 2575.42, inference time 267.85s, valid_top1 67.56 (best_top1 69.39), valid_top5 88.20
2021-11-07 12:13:00 (JOBID 31684) epoch 52: train time 2573.33, inference time 282.98s, valid_top1 67.56 (best_top1 69.39), valid_top5 88.20
2021-11-07 12:13:01 (JOBID 31684) epoch 52: train time 2574.86, inference time 284.55s, valid_top1 67.56 (best_top1 69.39), valid_top5 88.20
2021-11-07 12:12:59 train 0000, loss 2.037e+00, top1 65.88, top5 81.18
2021-11-07 12:13:15 train 0000, loss 1.450e+00, top1 67.06, top5 87.06
2021-11-07 12:13:15 train 0000, loss 1.387e+00, top1 67.06, top5 84.71
2021-11-07 12:21:41 train 1000, loss 1.478e+00, top1 65.30, top5 85.34
2021-11-07 12:21:41 train 1000, loss 1.480e+00, top1 65.22, top5 85.33
2021-11-07 12:21:41 train 1000, loss 1.489e+00, top1 65.12, top5 85.25
2021-11-07 12:30:09 train 2000, loss 1.486e+00, top1 65.04, top5 85.26
2021-11-07 12:30:09 train 2000, loss 1.482e+00, top1 65.20, top5 85.30
2021-11-07 12:30:09 train 2000, loss 1.486e+00, top1 65.16, top5 85.23
2021-11-07 12:38:38 train 3000, loss 1.493e+00, top1 64.97, top5 85.16
2021-11-07 12:38:38 train 3000, loss 1.490e+00, top1 64.96, top5 85.15
2021-11-07 12:38:38 train 3000, loss 1.494e+00, top1 65.01, top5 85.08
2021-11-07 12:47:06 train 4000, loss 1.497e+00, top1 64.83, top5 85.07
2021-11-07 12:47:06 train 4000, loss 1.493e+00, top1 64.88, top5 85.11
2021-11-07 12:47:06 train 4000, loss 1.497e+00, top1 64.91, top5 85.09
2021-11-07 12:55:34 train 5000, loss 1.499e+00, top1 64.80, top5 85.04
2021-11-07 12:55:34 train 5000, loss 1.496e+00, top1 64.86, top5 85.07
2021-11-07 12:55:34 train 5000, loss 1.500e+00, top1 64.86, top5 85.04
2021-11-07 12:55:58 valid 0000, loss 9.485e-01, top1 80.00, top5 87.06
2021-11-07 12:55:58 valid 0000, loss 9.485e-01, top1 80.00, top5 87.06
2021-11-07 12:55:58 valid 0000, loss 9.485e-01, top1 80.00, top5 87.06
2021-11-07 13:00:25 (JOBID 31684) epoch 53: train time 2565.56, inference time 278.27s, valid_top1 67.87 (best_top1 69.39), valid_top5 88.63
2021-11-07 13:00:26 (JOBID 31684) epoch 53: train time 2566.79, inference time 278.27s, valid_top1 67.87 (best_top1 69.39), valid_top5 88.63
2021-11-07 13:00:29 (JOBID 31684) epoch 53: train time 2582.15, inference time 282.25s, valid_top1 67.87 (best_top1 69.39), valid_top5 88.63
2021-11-07 13:00:40 train 0000, loss 1.714e+00, top1 57.65, top5 80.00
2021-11-07 13:00:40 train 0000, loss 1.255e+00, top1 64.71, top5 88.24
2021-11-07 13:00:43 train 0000, loss 1.105e+00, top1 69.41, top5 91.76
2021-11-07 13:09:25 train 1000, loss 1.480e+00, top1 65.41, top5 85.21
2021-11-07 13:09:25 train 1000, loss 1.476e+00, top1 65.32, top5 85.46
2021-11-07 13:09:25 train 1000, loss 1.475e+00, top1 65.24, top5 85.46
2021-11-07 13:18:06 train 2000, loss 1.494e+00, top1 65.02, top5 85.02
2021-11-07 13:18:06 train 2000, loss 1.479e+00, top1 65.21, top5 85.38
2021-11-07 13:18:06 train 2000, loss 1.485e+00, top1 65.19, top5 85.26
2021-11-07 13:26:53 train 3000, loss 1.500e+00, top1 64.85, top5 84.95
2021-11-07 13:26:53 train 3000, loss 1.488e+00, top1 65.01, top5 85.21
2021-11-07 13:26:53 train 3000, loss 1.493e+00, top1 65.00, top5 85.15
2021-11-07 13:35:37 train 4000, loss 1.499e+00, top1 64.87, top5 84.98
2021-11-07 13:35:37 train 4000, loss 1.494e+00, top1 64.95, top5 85.15
2021-11-07 13:35:38 train 4000, loss 1.492e+00, top1 64.96, top5 85.15
2021-11-07 13:44:20 train 5000, loss 1.501e+00, top1 64.81, top5 84.96
2021-11-07 13:44:20 train 5000, loss 1.496e+00, top1 64.90, top5 85.13
2021-11-07 13:44:20 train 5000, loss 1.496e+00, top1 64.90, top5 85.09
2021-11-07 13:44:44 valid 0000, loss 5.756e-01, top1 89.41, top5 94.12
2021-11-07 13:44:44 valid 0000, loss 5.756e-01, top1 89.41, top5 94.12
2021-11-07 13:44:44 valid 0000, loss 5.756e-01, top1 89.41, top5 94.12
2021-11-07 13:49:11 (JOBID 31684) epoch 54: train time 2647.22, inference time 277.71s, valid_top1 67.71 (best_top1 69.39), valid_top5 88.44
2021-11-07 13:49:15 (JOBID 31684) epoch 54: train time 2647.47, inference time 282.64s, valid_top1 67.71 (best_top1 69.39), valid_top5 88.44
2021-11-07 13:49:15 (JOBID 31684) epoch 54: train time 2643.51, inference time 282.64s, valid_top1 67.71 (best_top1 69.39), valid_top5 88.44
2021-11-07 13:49:29 train 0000, loss 1.532e+00, top1 62.35, top5 83.53
2021-11-07 13:49:26 train 0000, loss 1.526e+00, top1 63.53, top5 78.82
2021-11-07 13:49:29 train 0000, loss 1.451e+00, top1 61.18, top5 87.06
2021-11-07 13:58:04 train 1000, loss 1.476e+00, top1 65.05, top5 85.32
2021-11-07 13:58:04 train 1000, loss 1.469e+00, top1 65.52, top5 85.37
2021-11-07 13:58:04 train 1000, loss 1.474e+00, top1 65.41, top5 85.42
2021-11-07 14:06:35 train 2000, loss 1.483e+00, top1 65.16, top5 85.20
2021-11-07 14:06:35 train 2000, loss 1.484e+00, top1 65.18, top5 85.30
2021-11-07 14:06:35 train 2000, loss 1.485e+00, top1 65.14, top5 85.21
2021-11-07 14:15:07 train 3000, loss 1.487e+00, top1 65.18, top5 85.26
2021-11-07 14:15:07 train 3000, loss 1.495e+00, top1 64.95, top5 85.05
2021-11-07 14:15:07 train 3000, loss 1.486e+00, top1 65.10, top5 85.14
2021-11-07 14:23:48 train 4000, loss 1.495e+00, top1 64.93, top5 85.09
2021-11-07 14:23:48 train 4000, loss 1.490e+00, top1 65.02, top5 85.12
2021-11-07 14:23:48 train 4000, loss 1.491e+00, top1 65.05, top5 85.18
2021-11-07 14:32:21 train 5000, loss 1.495e+00, top1 64.95, top5 85.04
2021-11-07 14:32:20 train 5000, loss 1.499e+00, top1 64.83, top5 85.01
2021-11-07 14:32:21 train 5000, loss 1.497e+00, top1 64.94, top5 85.08
2021-11-07 14:32:44 valid 0000, loss 5.811e-01, top1 88.24, top5 96.47
2021-11-07 14:32:44 valid 0000, loss 5.811e-01, top1 88.24, top5 96.47
2021-11-07 14:32:44 valid 0000, loss 5.811e-01, top1 88.24, top5 96.47
2021-11-07 14:37:04 (JOBID 31684) epoch 55: train time 2598.06, inference time 270.28s, valid_top1 67.62 (best_top1 69.39), valid_top5 88.35
2021-11-07 14:37:08 (JOBID 31684) epoch 55: train time 2597.97, inference time 274.94s, valid_top1 67.62 (best_top1 69.39), valid_top5 88.35
2021-11-07 14:37:20 (JOBID 31684) epoch 55: train time 2602.68, inference time 286.41s, valid_top1 67.62 (best_top1 69.39), valid_top5 88.35
2021-11-07 14:37:19 train 0000, loss 1.823e+00, top1 60.00, top5 76.47
2021-11-07 14:37:24 train 0000, loss 1.660e+00, top1 68.24, top5 78.82
2021-11-07 14:37:34 train 0000, loss 1.631e+00, top1 70.59, top5 81.18
2021-11-07 14:46:10 train 1000, loss 1.466e+00, top1 65.45, top5 85.47
2021-11-07 14:46:10 train 1000, loss 1.480e+00, top1 65.16, top5 85.20
2021-11-07 14:46:10 train 1000, loss 1.465e+00, top1 65.39, top5 85.51
2021-11-07 14:54:46 train 2000, loss 1.471e+00, top1 65.32, top5 85.48
2021-11-07 14:54:46 train 2000, loss 1.477e+00, top1 65.26, top5 85.35
2021-11-07 14:54:46 train 2000, loss 1.486e+00, top1 65.14, top5 85.15
2021-11-07 15:03:20 train 3000, loss 1.486e+00, top1 65.11, top5 85.26
2021-11-07 15:03:20 train 3000, loss 1.480e+00, top1 65.18, top5 85.31
2021-11-07 15:03:20 train 3000, loss 1.488e+00, top1 65.01, top5 85.15
2021-11-07 15:11:59 train 4000, loss 1.486e+00, top1 65.08, top5 85.22
2021-11-07 15:11:59 train 4000, loss 1.493e+00, top1 64.97, top5 85.09
2021-11-07 15:12:00 train 4000, loss 1.490e+00, top1 64.99, top5 85.21
2021-11-07 15:20:32 train 5000, loss 1.495e+00, top1 64.89, top5 85.15
2021-11-07 15:20:31 train 5000, loss 1.493e+00, top1 64.95, top5 85.13
2021-11-07 15:20:32 train 5000, loss 1.497e+00, top1 64.88, top5 85.04
2021-11-07 15:20:55 valid 0000, loss 6.465e-01, top1 84.71, top5 94.12
2021-11-07 15:20:55 valid 0000, loss 6.465e-01, top1 84.71, top5 94.12
2021-11-07 15:20:55 valid 0000, loss 6.465e-01, top1 84.71, top5 94.12
2021-11-07 15:25:14 (JOBID 31684) epoch 56: train time 2620.62, inference time 269.59s, valid_top1 67.91 (best_top1 69.39), valid_top5 88.46
2021-11-07 15:25:28 (JOBID 31684) epoch 56: train time 2616.09, inference time 283.55s, valid_top1 67.91 (best_top1 69.39), valid_top5 88.46
2021-11-07 15:25:28 (JOBID 31684) epoch 56: train time 2604.35, inference time 283.73s, valid_top1 67.91 (best_top1 69.39), valid_top5 88.46
2021-11-07 15:25:27 train 0000, loss 1.344e+00, top1 65.88, top5 89.41
2021-11-07 15:25:42 train 0000, loss 1.722e+00, top1 65.88, top5 87.06
2021-11-07 15:25:42 train 0000, loss 2.032e+00, top1 60.00, top5 76.47
2021-11-07 15:34:25 train 1000, loss 1.465e+00, top1 65.38, top5 85.55
2021-11-07 15:34:25 train 1000, loss 1.476e+00, top1 65.24, top5 85.25
2021-11-07 15:34:25 train 1000, loss 1.470e+00, top1 65.29, top5 85.56
2021-11-07 15:42:46 train 2000, loss 1.487e+00, top1 65.05, top5 85.17
2021-11-07 15:42:46 train 2000, loss 1.474e+00, top1 65.26, top5 85.44
2021-11-07 15:42:46 train 2000, loss 1.481e+00, top1 65.17, top5 85.32
2021-11-07 15:51:07 train 3000, loss 1.484e+00, top1 65.11, top5 85.30
2021-11-07 15:51:07 train 3000, loss 1.490e+00, top1 65.04, top5 85.17
2021-11-07 15:51:08 train 3000, loss 1.481e+00, top1 65.19, top5 85.26
2021-11-07 15:59:31 train 4000, loss 1.495e+00, top1 64.91, top5 85.08
2021-11-07 15:59:31 train 4000, loss 1.487e+00, top1 65.03, top5 85.21
2021-11-07 15:59:31 train 4000, loss 1.490e+00, top1 65.05, top5 85.17
2021-11-07 16:07:57 train 5000, loss 1.499e+00, top1 64.79, top5 85.04
2021-11-07 16:07:57 train 5000, loss 1.492e+00, top1 64.98, top5 85.13
2021-11-07 16:07:57 train 5000, loss 1.493e+00, top1 64.89, top5 85.15
2021-11-07 16:08:20 valid 0000, loss 6.516e-01, top1 84.71, top5 95.29
2021-11-07 16:08:20 valid 0000, loss 6.516e-01, top1 84.71, top5 95.29
2021-11-07 16:08:20 valid 0000, loss 6.516e-01, top1 84.71, top5 95.29
2021-11-07 16:12:54 (JOBID 31684) epoch 57: train time 2561.71, inference time 284.41s, valid_top1 68.49 (best_top1 69.39), valid_top5 88.90
2021-11-07 16:12:54 (JOBID 31684) epoch 57: train time 2575.61, inference time 284.53s, valid_top1 68.49 (best_top1 69.39), valid_top5 88.90
2021-11-07 16:12:54 (JOBID 31684) epoch 57: train time 2561.30, inference time 284.52s, valid_top1 68.49 (best_top1 69.39), valid_top5 88.90
2021-11-07 16:13:08 train 0000, loss 1.247e+00, top1 69.41, top5 90.59
2021-11-07 16:13:08 train 0000, loss 1.463e+00, top1 64.71, top5 90.59
2021-11-07 16:13:09 train 0000, loss 1.238e+00, top1 71.76, top5 90.59
2021-11-07 16:22:23 train 1000, loss 1.467e+00, top1 65.64, top5 85.47
2021-11-07 16:22:23 train 1000, loss 1.468e+00, top1 65.44, top5 85.41
2021-11-07 16:22:23 train 1000, loss 1.476e+00, top1 65.12, top5 85.41
2021-11-07 16:31:37 train 2000, loss 1.487e+00, top1 65.12, top5 85.17
2021-11-07 16:31:37 train 2000, loss 1.481e+00, top1 65.20, top5 85.35
2021-11-07 16:31:37 train 2000, loss 1.473e+00, top1 65.57, top5 85.38
2021-11-07 16:40:52 train 3000, loss 1.479e+00, top1 65.42, top5 85.30
2021-11-07 16:40:52 train 3000, loss 1.490e+00, top1 65.09, top5 85.14
2021-11-07 16:40:52 train 3000, loss 1.486e+00, top1 65.08, top5 85.27
2021-11-07 16:50:13 train 4000, loss 1.489e+00, top1 65.05, top5 85.19
2021-11-07 16:50:13 train 4000, loss 1.485e+00, top1 65.25, top5 85.19
2021-11-07 16:50:13 train 4000, loss 1.489e+00, top1 65.06, top5 85.23
2021-11-07 16:59:35 train 5000, loss 1.490e+00, top1 65.11, top5 85.16
2021-11-07 16:59:35 train 5000, loss 1.493e+00, top1 64.96, top5 85.17
2021-11-07 16:59:35 train 5000, loss 1.493e+00, top1 64.95, top5 85.13
2021-11-07 16:59:59 valid 0000, loss 7.835e-01, top1 83.53, top5 92.94
2021-11-07 16:59:59 valid 0000, loss 7.835e-01, top1 83.53, top5 92.94
2021-11-07 16:59:59 valid 0000, loss 7.835e-01, top1 83.53, top5 92.94
2021-11-07 17:04:25 (JOBID 31684) epoch 58: train time 2815.21, inference time 275.31s, valid_top1 68.57 (best_top1 69.39), valid_top5 88.93
2021-11-07 17:04:25 (JOBID 31684) epoch 58: train time 2814.99, inference time 275.52s, valid_top1 68.57 (best_top1 69.39), valid_top5 88.93
2021-11-07 17:04:31 (JOBID 31684) epoch 58: train time 2814.74, inference time 281.56s, valid_top1 68.57 (best_top1 69.39), valid_top5 88.93
2021-11-07 17:04:38 train 0000, loss 1.379e+00, top1 62.35, top5 85.88
2021-11-07 17:04:38 train 0000, loss 1.200e+00, top1 69.41, top5 90.59
2021-11-07 17:04:44 train 0000, loss 1.469e+00, top1 68.24, top5 88.24
2021-11-07 17:13:11 train 1000, loss 1.481e+00, top1 65.32, top5 85.36
2021-11-07 17:13:11 train 1000, loss 1.481e+00, top1 64.94, top5 85.42
2021-11-07 17:13:11 train 1000, loss 1.474e+00, top1 65.29, top5 85.31
2021-11-07 17:21:36 train 2000, loss 1.484e+00, top1 65.25, top5 85.25
2021-11-07 17:21:36 train 2000, loss 1.488e+00, top1 65.02, top5 85.24
2021-11-07 17:21:36 train 2000, loss 1.480e+00, top1 65.17, top5 85.22
2021-11-07 17:30:01 train 3000, loss 1.489e+00, top1 65.00, top5 85.19
2021-11-07 17:30:01 train 3000, loss 1.482e+00, top1 65.20, top5 85.23
2021-11-07 17:30:02 train 3000, loss 1.484e+00, top1 65.19, top5 85.21
2021-11-07 17:38:30 train 4000, loss 1.484e+00, top1 65.13, top5 85.19
2021-11-07 17:38:30 train 4000, loss 1.492e+00, top1 64.89, top5 85.13
2021-11-07 17:38:30 train 4000, loss 1.489e+00, top1 65.09, top5 85.15
2021-11-07 17:46:57 train 5000, loss 1.490e+00, top1 65.09, top5 85.13
2021-11-07 17:46:57 train 5000, loss 1.493e+00, top1 64.89, top5 85.11
2021-11-07 17:46:57 train 5000, loss 1.488e+00, top1 65.04, top5 85.12
2021-11-07 17:47:19 valid 0000, loss 7.260e-01, top1 87.06, top5 91.76
2021-11-07 17:47:19 valid 0000, loss 7.260e-01, top1 87.06, top5 91.76
2021-11-07 17:47:19 valid 0000, loss 7.260e-01, top1 87.06, top5 91.76
2021-11-07 17:51:43 (JOBID 31684) epoch 59: train time 2565.05, inference time 273.73s, valid_top1 68.53 (best_top1 69.39), valid_top5 88.74
2021-11-07 17:51:50 (JOBID 31684) epoch 59: train time 2565.07, inference time 280.25s, valid_top1 68.53 (best_top1 69.39), valid_top5 88.74
2021-11-07 17:51:51 (JOBID 31684) epoch 59: train time 2558.80, inference time 281.28s, valid_top1 68.53 (best_top1 69.39), valid_top5 88.74
2021-11-07 17:51:58 train 0000, loss 1.436e+00, top1 68.24, top5 88.24
2021-11-07 17:52:04 train 0000, loss 1.316e+00, top1 70.59, top5 85.88
2021-11-07 17:52:04 train 0000, loss 1.529e+00, top1 70.59, top5 81.18
2021-11-07 18:00:36 train 1000, loss 1.350e+00, top1 68.10, top5 86.96
2021-11-07 18:00:36 train 1000, loss 1.341e+00, top1 68.35, top5 87.07
2021-11-07 18:00:36 train 1000, loss 1.348e+00, top1 68.35, top5 86.90
2021-11-07 18:09:10 train 2000, loss 1.328e+00, top1 68.64, top5 87.25
2021-11-07 18:09:09 train 2000, loss 1.323e+00, top1 68.79, top5 87.32
2021-11-07 18:09:10 train 2000, loss 1.331e+00, top1 68.71, top5 87.11
2021-11-07 18:17:46 train 3000, loss 1.316e+00, top1 69.04, top5 87.32
2021-11-07 18:17:46 train 3000, loss 1.311e+00, top1 68.98, top5 87.47
2021-11-07 18:17:47 train 3000, loss 1.315e+00, top1 68.91, top5 87.45
2021-11-07 18:26:26 train 4000, loss 1.302e+00, top1 69.19, top5 87.57
2021-11-07 18:26:26 train 4000, loss 1.307e+00, top1 69.27, top5 87.43
2021-11-07 18:26:26 train 4000, loss 1.307e+00, top1 69.07, top5 87.54
2021-11-07 18:35:15 train 5000, loss 1.297e+00, top1 69.30, top5 87.66
2021-11-07 18:35:15 train 5000, loss 1.302e+00, top1 69.22, top5 87.60
2021-11-07 18:35:15 train 5000, loss 1.301e+00, top1 69.39, top5 87.52
2021-11-07 18:35:38 valid 0000, loss 5.475e-01, top1 87.06, top5 97.65
2021-11-07 18:35:38 valid 0000, loss 5.475e-01, top1 87.06, top5 97.65
2021-11-07 18:35:38 valid 0000, loss 5.475e-01, top1 87.06, top5 97.65
2021-11-07 18:40:09 (JOBID 31684) epoch 60: train time 2625.14, inference time 280.08s, valid_top1 72.54 (best_top1 72.54), valid_top5 91.06
2021-11-07 18:40:10 (JOBID 31684) epoch 60: train time 2617.17, inference time 281.13s, valid_top1 72.54 (best_top1 72.54), valid_top5 91.06
2021-11-07 18:40:10 (JOBID 31684) epoch 60: train time 2618.74, inference time 281.73s, valid_top1 72.54 (best_top1 72.54), valid_top5 91.06
2021-11-07 18:40:23 train 0000, loss 1.569e+00, top1 61.18, top5 82.35
2021-11-07 18:40:23 train 0000, loss 1.124e+00, top1 65.88, top5 87.06
2021-11-07 18:40:24 train 0000, loss 1.536e+00, top1 60.00, top5 83.53
2021-11-07 18:48:58 train 1000, loss 1.265e+00, top1 70.10, top5 88.09
2021-11-07 18:48:58 train 1000, loss 1.273e+00, top1 69.80, top5 88.01
2021-11-07 18:48:58 train 1000, loss 1.256e+00, top1 70.22, top5 88.10
2021-11-07 18:57:36 train 2000, loss 1.253e+00, top1 70.28, top5 88.15
2021-11-07 18:57:36 train 2000, loss 1.262e+00, top1 70.09, top5 88.16
2021-11-07 18:57:36 train 2000, loss 1.264e+00, top1 70.12, top5 88.09
2021-11-07 19:06:26 train 3000, loss 1.261e+00, top1 70.21, top5 88.13
2021-11-07 19:06:26 train 3000, loss 1.251e+00, top1 70.40, top5 88.18
2021-11-07 19:06:26 train 3000, loss 1.256e+00, top1 70.24, top5 88.20
2021-11-07 19:15:29 train 4000, loss 1.249e+00, top1 70.40, top5 88.27
2021-11-07 19:15:29 train 4000, loss 1.254e+00, top1 70.30, top5 88.23
2021-11-07 19:15:29 train 4000, loss 1.258e+00, top1 70.25, top5 88.16
2021-11-07 19:24:35 train 5000, loss 1.248e+00, top1 70.46, top5 88.28
2021-11-07 19:24:35 train 5000, loss 1.255e+00, top1 70.29, top5 88.18
2021-11-07 19:24:35 train 5000, loss 1.254e+00, top1 70.28, top5 88.24
2021-11-07 19:24:58 valid 0000, loss 5.367e-01, top1 87.06, top5 94.12
2021-11-07 19:24:58 valid 0000, loss 5.367e-01, top1 87.06, top5 94.12
2021-11-07 19:24:58 valid 0000, loss 5.367e-01, top1 87.06, top5 94.12
2021-11-07 19:29:29 (JOBID 31684) epoch 61: train time 2678.16, inference time 279.99s, valid_top1 72.89 (best_top1 72.89), valid_top5 91.17
2021-11-07 19:29:29 (JOBID 31684) epoch 61: train time 2679.96, inference time 280.60s, valid_top1 72.89 (best_top1 72.89), valid_top5 91.17
2021-11-07 19:29:29 (JOBID 31684) epoch 61: train time 2678.27, inference time 280.17s, valid_top1 72.89 (best_top1 72.89), valid_top5 91.17
2021-11-07 19:29:43 train 0000, loss 1.255e+00, top1 65.88, top5 91.76
2021-11-07 19:29:43 train 0000, loss 1.240e+00, top1 65.88, top5 88.24
2021-11-07 19:29:43 train 0000, loss 1.466e+00, top1 67.06, top5 88.24
2021-11-07 19:38:15 train 1000, loss 1.232e+00, top1 70.95, top5 88.45
2021-11-07 19:38:15 train 1000, loss 1.228e+00, top1 70.98, top5 88.49
2021-11-07 19:38:15 train 1000, loss 1.233e+00, top1 70.77, top5 88.53
2021-11-07 19:46:52 train 2000, loss 1.231e+00, top1 70.74, top5 88.52
2021-11-07 19:46:52 train 2000, loss 1.232e+00, top1 70.78, top5 88.45
2021-11-07 19:46:52 train 2000, loss 1.235e+00, top1 70.73, top5 88.35
2021-11-07 19:55:27 train 3000, loss 1.234e+00, top1 70.81, top5 88.44
2021-11-07 19:55:28 train 3000, loss 1.235e+00, top1 70.74, top5 88.38
2021-11-07 19:55:28 train 3000, loss 1.236e+00, top1 70.68, top5 88.42
2021-11-07 20:04:06 train 4000, loss 1.233e+00, top1 70.80, top5 88.45
2021-11-07 20:04:06 train 4000, loss 1.235e+00, top1 70.73, top5 88.43
2021-11-07 20:04:06 train 4000, loss 1.233e+00, top1 70.70, top5 88.49
2021-11-07 20:12:44 train 5000, loss 1.233e+00, top1 70.77, top5 88.45
2021-11-07 20:12:44 train 5000, loss 1.235e+00, top1 70.74, top5 88.40
2021-11-07 20:12:44 train 5000, loss 1.234e+00, top1 70.69, top5 88.48
2021-11-07 20:13:09 valid 0000, loss 5.559e-01, top1 85.88, top5 96.47
2021-11-07 20:13:09 valid 0000, loss 5.559e-01, top1 85.88, top5 96.47
2021-11-07 20:13:09 valid 0000, loss 5.559e-01, top1 85.88, top5 96.47
2021-11-07 20:17:34 (JOBID 31684) epoch 62: train time 2608.33, inference time 276.02s, valid_top1 73.06 (best_top1 73.06), valid_top5 91.23
2021-11-07 20:17:34 (JOBID 31684) epoch 62: train time 2609.15, inference time 276.77s, valid_top1 73.06 (best_top1 73.06), valid_top5 91.23
2021-11-07 20:17:38 (JOBID 31684) epoch 62: train time 2608.62, inference time 280.06s, valid_top1 73.06 (best_top1 73.06), valid_top5 91.23
2021-11-07 20:17:49 train 0000, loss 1.080e+00, top1 71.76, top5 91.76
2021-11-07 20:17:49 train 0000, loss 1.473e+00, top1 64.71, top5 80.00
2021-11-07 20:17:52 train 0000, loss 1.130e+00, top1 72.94, top5 89.41
2021-11-07 20:26:10 train 1000, loss 1.231e+00, top1 70.77, top5 88.41
2021-11-07 20:26:10 train 1000, loss 1.217e+00, top1 70.97, top5 88.68
2021-11-07 20:26:10 train 1000, loss 1.217e+00, top1 71.11, top5 88.80
2021-11-07 20:34:26 train 2000, loss 1.228e+00, top1 70.92, top5 88.52
2021-11-07 20:34:26 train 2000, loss 1.217e+00, top1 71.03, top5 88.65
2021-11-07 20:34:26 train 2000, loss 1.214e+00, top1 71.14, top5 88.80
2021-11-07 20:42:41 train 3000, loss 1.224e+00, top1 71.01, top5 88.60
2021-11-07 20:42:41 train 3000, loss 1.219e+00, top1 71.12, top5 88.68
2021-11-07 20:42:41 train 3000, loss 1.217e+00, top1 70.99, top5 88.67
2021-11-07 20:50:57 train 4000, loss 1.216e+00, top1 70.99, top5 88.66
2021-11-07 20:50:57 train 4000, loss 1.222e+00, top1 71.10, top5 88.62
2021-11-07 20:50:57 train 4000, loss 1.222e+00, top1 71.01, top5 88.62
2021-11-07 20:59:15 train 5000, loss 1.216e+00, top1 71.03, top5 88.68
2021-11-07 20:59:15 train 5000, loss 1.226e+00, top1 71.01, top5 88.56
2021-11-07 20:59:15 train 5000, loss 1.221e+00, top1 71.04, top5 88.60
2021-11-07 20:59:37 valid 0000, loss 5.459e-01, top1 87.06, top5 95.29
2021-11-07 20:59:37 valid 0000, loss 5.459e-01, top1 87.06, top5 95.29
2021-11-07 20:59:37 valid 0000, loss 5.459e-01, top1 87.06, top5 95.29
2021-11-07 21:04:16 (JOBID 31684) epoch 63: train time 2512.70, inference time 288.13s, valid_top1 73.15 (best_top1 73.15), valid_top5 91.35
2021-11-07 21:04:18 (JOBID 31684) epoch 63: train time 2512.53, inference time 291.16s, valid_top1 73.15 (best_top1 73.15), valid_top5 91.35
2021-11-07 21:04:19 (JOBID 31684) epoch 63: train time 2509.12, inference time 292.02s, valid_top1 73.15 (best_top1 73.15), valid_top5 91.35
2021-11-07 21:04:33 train 0000, loss 1.384e+00, top1 70.59, top5 87.06
2021-11-07 21:04:31 train 0000, loss 1.507e+00, top1 65.88, top5 85.88
2021-11-07 21:04:33 train 0000, loss 9.194e-01, top1 78.82, top5 92.94
2021-11-07 21:12:53 train 1000, loss 1.222e+00, top1 70.99, top5 88.52
2021-11-07 21:12:53 train 1000, loss 1.205e+00, top1 71.47, top5 88.90
2021-11-07 21:12:53 train 1000, loss 1.207e+00, top1 71.46, top5 88.89
2021-11-07 21:21:13 train 2000, loss 1.213e+00, top1 71.31, top5 88.70
2021-11-07 21:21:13 train 2000, loss 1.216e+00, top1 71.11, top5 88.60
2021-11-07 21:21:13 train 2000, loss 1.215e+00, top1 71.17, top5 88.71
2021-11-07 21:29:34 train 3000, loss 1.214e+00, top1 71.11, top5 88.67
2021-11-07 21:29:34 train 3000, loss 1.218e+00, top1 71.12, top5 88.65
2021-11-07 21:29:34 train 3000, loss 1.213e+00, top1 71.19, top5 88.70
2021-11-07 21:37:53 train 4000, loss 1.214e+00, top1 71.15, top5 88.66
2021-11-07 21:37:53 train 4000, loss 1.218e+00, top1 71.14, top5 88.67
2021-11-07 21:37:53 train 4000, loss 1.214e+00, top1 71.19, top5 88.68
2021-11-07 21:46:15 train 5000, loss 1.212e+00, top1 71.25, top5 88.70
2021-11-07 21:46:15 train 5000, loss 1.219e+00, top1 71.08, top5 88.67
2021-11-07 21:46:15 train 5000, loss 1.214e+00, top1 71.13, top5 88.64
2021-11-07 21:46:38 valid 0000, loss 5.208e-01, top1 88.24, top5 97.65
2021-11-07 21:46:38 valid 0000, loss 5.208e-01, top1 88.24, top5 97.65
2021-11-07 21:46:38 valid 0000, loss 5.208e-01, top1 88.24, top5 97.65
2021-11-07 21:51:16 (JOBID 31684) epoch 64: train time 2529.44, inference time 287.95s, valid_top1 73.21 (best_top1 73.21), valid_top5 91.41
2021-11-07 21:51:16 (JOBID 31684) epoch 64: train time 2528.57, inference time 288.01s, valid_top1 73.21 (best_top1 73.21), valid_top5 91.41
2021-11-07 21:51:16 (JOBID 31684) epoch 64: train time 2531.67, inference time 288.10s, valid_top1 73.21 (best_top1 73.21), valid_top5 91.41
2021-11-07 21:51:30 train 0000, loss 1.220e+00, top1 76.47, top5 87.06
2021-11-07 21:51:30 train 0000, loss 1.120e+00, top1 76.47, top5 90.59
2021-11-07 21:51:30 train 0000, loss 1.249e+00, top1 65.88, top5 91.76
2021-11-07 21:59:50 train 1000, loss 1.199e+00, top1 71.51, top5 88.90
2021-11-07 21:59:50 train 1000, loss 1.208e+00, top1 71.25, top5 88.74
2021-11-07 21:59:50 train 1000, loss 1.192e+00, top1 71.49, top5 89.00
2021-11-07 22:08:06 train 2000, loss 1.199e+00, top1 71.46, top5 88.88
2021-11-07 22:08:06 train 2000, loss 1.211e+00, top1 71.20, top5 88.76
2021-11-07 22:08:06 train 2000, loss 1.200e+00, top1 71.33, top5 88.93
2021-11-07 22:16:22 train 3000, loss 1.204e+00, top1 71.27, top5 88.87
2021-11-07 22:16:22 train 3000, loss 1.202e+00, top1 71.37, top5 88.83
2021-11-07 22:16:22 train 3000, loss 1.209e+00, top1 71.21, top5 88.78
2021-11-07 22:24:39 train 4000, loss 1.202e+00, top1 71.39, top5 88.83
2021-11-07 22:24:39 train 4000, loss 1.206e+00, top1 71.31, top5 88.81
2021-11-07 22:24:39 train 4000, loss 1.205e+00, top1 71.31, top5 88.84
2021-11-07 22:32:54 train 5000, loss 1.203e+00, top1 71.36, top5 88.85
2021-11-07 22:32:54 train 5000, loss 1.207e+00, top1 71.30, top5 88.80
2021-11-07 22:32:54 train 5000, loss 1.205e+00, top1 71.32, top5 88.85
2021-11-07 22:33:17 valid 0000, loss 5.905e-01, top1 85.88, top5 95.29
2021-11-07 22:33:17 valid 0000, loss 5.905e-01, top1 85.88, top5 95.29
2021-11-07 22:33:17 valid 0000, loss 5.905e-01, top1 85.88, top5 95.29
2021-11-07 22:37:33 (JOBID 31684) epoch 65: train time 2511.02, inference time 266.22s, valid_top1 73.33 (best_top1 73.33), valid_top5 91.41
2021-11-07 22:37:53 (JOBID 31684) epoch 65: train time 2511.08, inference time 285.91s, valid_top1 73.33 (best_top1 73.33), valid_top5 91.41
2021-11-07 22:37:53 (JOBID 31684) epoch 65: train time 2510.48, inference time 285.68s, valid_top1 73.33 (best_top1 73.33), valid_top5 91.41
2021-11-07 22:37:46 train 0000, loss 9.925e-01, top1 70.59, top5 91.76
2021-11-07 22:38:06 train 0000, loss 1.349e+00, top1 69.41, top5 87.06
2021-11-07 22:38:06 train 0000, loss 1.247e+00, top1 68.24, top5 90.59
2021-11-07 22:46:46 train 1000, loss 1.191e+00, top1 71.47, top5 89.09
2021-11-07 22:46:46 train 1000, loss 1.196e+00, top1 71.69, top5 89.05
2021-11-07 22:46:46 train 1000, loss 1.198e+00, top1 71.32, top5 88.84
2021-11-07 22:55:22 train 2000, loss 1.200e+00, top1 71.38, top5 88.88
2021-11-07 22:55:22 train 2000, loss 1.192e+00, top1 71.68, top5 89.03
2021-11-07 22:55:22 train 2000, loss 1.196e+00, top1 71.45, top5 88.99
2021-11-07 23:04:04 train 3000, loss 1.200e+00, top1 71.35, top5 88.88
2021-11-07 23:04:04 train 3000, loss 1.195e+00, top1 71.59, top5 88.99
2021-11-07 23:04:04 train 3000, loss 1.199e+00, top1 71.44, top5 88.92
2021-11-07 23:12:48 train 4000, loss 1.198e+00, top1 71.45, top5 88.93
2021-11-07 23:12:48 train 4000, loss 1.196e+00, top1 71.59, top5 88.96
2021-11-07 23:12:48 train 4000, loss 1.200e+00, top1 71.40, top5 88.89
2021-11-07 23:21:41 train 5000, loss 1.195e+00, top1 71.57, top5 88.95
2021-11-07 23:21:41 train 5000, loss 1.198e+00, top1 71.47, top5 88.93
2021-11-07 23:21:41 train 5000, loss 1.200e+00, top1 71.39, top5 88.87
2021-11-07 23:22:03 valid 0000, loss 5.749e-01, top1 88.24, top5 95.29
2021-11-07 23:22:03 valid 0000, loss 5.749e-01, top1 88.24, top5 95.29
2021-11-07 23:22:03 valid 0000, loss 5.749e-01, top1 88.24, top5 95.29
2021-11-07 23:26:32 (JOBID 31684) epoch 66: train time 2640.58, inference time 278.92s, valid_top1 73.58 (best_top1 73.58), valid_top5 91.51
2021-11-07 23:26:39 (JOBID 31684) epoch 66: train time 2640.15, inference time 284.75s, valid_top1 73.58 (best_top1 73.58), valid_top5 91.51
2021-11-07 23:26:39 (JOBID 31684) epoch 66: train time 2660.34, inference time 285.69s, valid_top1 73.58 (best_top1 73.58), valid_top5 91.51
2021-11-07 23:26:47 train 0000, loss 1.147e+00, top1 72.94, top5 89.41
2021-11-07 23:26:52 train 0000, loss 1.144e+00, top1 71.76, top5 91.76
2021-11-07 23:26:52 train 0000, loss 1.282e+00, top1 69.41, top5 84.71
2021-11-07 23:35:30 train 1000, loss 1.182e+00, top1 71.90, top5 89.08
2021-11-07 23:35:30 train 1000, loss 1.195e+00, top1 71.30, top5 88.94
2021-11-07 23:35:30 train 1000, loss 1.178e+00, top1 72.06, top5 89.14
2021-11-07 23:44:08 train 2000, loss 1.192e+00, top1 71.44, top5 89.00
2021-11-07 23:44:08 train 2000, loss 1.185e+00, top1 71.84, top5 89.12
2021-11-07 23:44:08 train 2000, loss 1.182e+00, top1 71.83, top5 89.13
2021-11-07 23:52:53 train 3000, loss 1.192e+00, top1 71.50, top5 89.01
2021-11-07 23:52:53 train 3000, loss 1.188e+00, top1 71.76, top5 89.06
2021-11-07 23:52:53 train 3000, loss 1.188e+00, top1 71.68, top5 89.04
2021-11-08 00:01:42 train 4000, loss 1.194e+00, top1 71.48, top5 88.96
2021-11-08 00:01:42 train 4000, loss 1.190e+00, top1 71.63, top5 89.04
2021-11-08 00:01:43 train 4000, loss 1.190e+00, top1 71.68, top5 89.01
2021-11-08 00:10:30 train 5000, loss 1.192e+00, top1 71.62, top5 89.02
2021-11-08 00:10:30 train 5000, loss 1.195e+00, top1 71.58, top5 88.94
2021-11-08 00:10:30 train 5000, loss 1.193e+00, top1 71.51, top5 88.98
2021-11-08 00:10:54 valid 0000, loss 5.330e-01, top1 87.06, top5 95.29
2021-11-08 00:10:54 valid 0000, loss 5.330e-01, top1 87.06, top5 95.29
2021-11-08 00:10:54 valid 0000, loss 5.330e-01, top1 87.06, top5 95.29
2021-11-08 00:15:25 (JOBID 31684) epoch 67: train time 2645.19, inference time 281.22s, valid_top1 73.39 (best_top1 73.58), valid_top5 91.44
2021-11-08 00:15:26 (JOBID 31684) epoch 67: train time 2645.38, inference time 282.03s, valid_top1 73.39 (best_top1 73.58), valid_top5 91.44
2021-11-08 00:15:27 (JOBID 31684) epoch 67: train time 2651.94, inference time 283.27s, valid_top1 73.39 (best_top1 73.58), valid_top5 91.44
2021-11-08 00:15:40 train 0000, loss 1.153e+00, top1 75.29, top5 89.41
2021-11-08 00:15:40 train 0000, loss 1.230e+00, top1 67.06, top5 85.88
2021-11-08 00:15:40 train 0000, loss 1.070e+00, top1 72.94, top5 87.06
2021-11-08 00:23:58 train 1000, loss 1.184e+00, top1 71.80, top5 89.12
2021-11-08 00:23:57 train 1000, loss 1.193e+00, top1 71.63, top5 88.94
2021-11-08 00:23:58 train 1000, loss 1.174e+00, top1 71.89, top5 89.21
2021-11-08 00:32:15 train 2000, loss 1.189e+00, top1 71.68, top5 88.97
2021-11-08 00:32:15 train 2000, loss 1.180e+00, top1 71.84, top5 89.09
2021-11-08 00:32:15 train 2000, loss 1.185e+00, top1 71.66, top5 89.11
2021-11-08 00:40:32 train 3000, loss 1.186e+00, top1 71.70, top5 89.06
2021-11-08 00:40:32 train 3000, loss 1.189e+00, top1 71.66, top5 89.00
2021-11-08 00:40:32 train 3000, loss 1.184e+00, top1 71.79, top5 89.04
2021-11-08 00:48:47 train 4000, loss 1.188e+00, top1 71.73, top5 88.99
2021-11-08 00:48:47 train 4000, loss 1.186e+00, top1 71.66, top5 89.04
2021-11-08 00:48:47 train 4000, loss 1.192e+00, top1 71.62, top5 88.99
2021-11-08 00:57:03 train 5000, loss 1.191e+00, top1 71.60, top5 88.99
2021-11-08 00:57:03 train 5000, loss 1.187e+00, top1 71.65, top5 89.02
2021-11-08 00:57:03 train 5000, loss 1.188e+00, top1 71.72, top5 89.01
2021-11-08 00:57:25 valid 0000, loss 5.760e-01, top1 88.24, top5 96.47
2021-11-08 00:57:25 valid 0000, loss 5.760e-01, top1 88.24, top5 96.47
2021-11-08 00:57:25 valid 0000, loss 5.760e-01, top1 88.24, top5 96.47
2021-11-08 01:01:47 (JOBID 31684) epoch 68: train time 2508.88, inference time 271.28s, valid_top1 73.54 (best_top1 73.58), valid_top5 91.55
2021-11-08 01:02:00 (JOBID 31684) epoch 68: train time 2510.16, inference time 284.29s, valid_top1 73.54 (best_top1 73.58), valid_top5 91.55
2021-11-08 01:02:00 (JOBID 31684) epoch 68: train time 2508.11, inference time 284.38s, valid_top1 73.54 (best_top1 73.58), valid_top5 91.55
2021-11-08 01:02:13 train 0000, loss 1.008e+00, top1 72.94, top5 91.76
2021-11-08 01:02:00 train 0000, loss 1.214e+00, top1 71.76, top5 88.24
2021-11-08 01:02:14 train 0000, loss 1.304e+00, top1 71.76, top5 82.35
2021-11-08 01:10:33 train 1000, loss 1.182e+00, top1 71.94, top5 89.15
2021-11-08 01:10:33 train 1000, loss 1.178e+00, top1 71.68, top5 89.16
2021-11-08 01:10:33 train 1000, loss 1.182e+00, top1 72.01, top5 89.06
2021-11-08 01:18:57 train 2000, loss 1.172e+00, top1 71.81, top5 89.33
2021-11-08 01:18:57 train 2000, loss 1.180e+00, top1 71.95, top5 89.12
2021-11-08 01:18:57 train 2000, loss 1.182e+00, top1 71.85, top5 89.14
2021-11-08 01:27:21 train 3000, loss 1.172e+00, top1 71.84, top5 89.34
2021-11-08 01:27:21 train 3000, loss 1.183e+00, top1 71.86, top5 89.10
2021-11-08 01:27:21 train 3000, loss 1.180e+00, top1 71.87, top5 89.15
2021-11-08 01:35:43 train 4000, loss 1.174e+00, top1 71.88, top5 89.30
2021-11-08 01:35:43 train 4000, loss 1.182e+00, top1 71.83, top5 89.11
2021-11-08 01:35:43 train 4000, loss 1.182e+00, top1 71.84, top5 89.13
2021-11-08 01:44:03 train 5000, loss 1.184e+00, top1 71.81, top5 89.07
2021-11-08 01:44:03 train 5000, loss 1.183e+00, top1 71.82, top5 89.08
2021-11-08 01:44:04 train 5000, loss 1.179e+00, top1 71.81, top5 89.21
2021-11-08 01:44:26 valid 0000, loss 5.714e-01, top1 87.06, top5 95.29
2021-11-08 01:44:26 valid 0000, loss 5.714e-01, top1 87.06, top5 95.29
2021-11-08 01:44:26 valid 0000, loss 5.714e-01, top1 87.06, top5 95.29
2021-11-08 01:48:57 (JOBID 31684) epoch 69: train time 2536.25, inference time 281.30s, valid_top1 73.39 (best_top1 73.58), valid_top5 91.57
2021-11-08 01:48:58 (JOBID 31684) epoch 69: train time 2536.38, inference time 281.60s, valid_top1 73.39 (best_top1 73.58), valid_top5 91.57
2021-11-08 01:48:58 (JOBID 31684) epoch 69: train time 2549.29, inference time 281.63s, valid_top1 73.39 (best_top1 73.58), valid_top5 91.57
2021-11-08 01:49:12 train 0000, loss 1.151e+00, top1 75.29, top5 88.24
2021-11-08 01:49:12 train 0000, loss 9.725e-01, top1 77.65, top5 91.76
2021-11-08 01:49:12 train 0000, loss 1.403e+00, top1 76.47, top5 84.71
2021-11-08 01:57:37 train 1000, loss 1.181e+00, top1 71.82, top5 89.09
2021-11-08 01:57:37 train 1000, loss 1.172e+00, top1 72.13, top5 89.25
2021-11-08 01:57:37 train 1000, loss 1.177e+00, top1 71.95, top5 89.05
2021-11-08 02:06:07 train 2000, loss 1.177e+00, top1 71.92, top5 89.13
2021-11-08 02:06:07 train 2000, loss 1.179e+00, top1 71.88, top5 89.07
2021-11-08 02:06:07 train 2000, loss 1.177e+00, top1 72.02, top5 89.15
2021-11-08 02:14:45 train 3000, loss 1.177e+00, top1 71.94, top5 89.09
2021-11-08 02:14:45 train 3000, loss 1.178e+00, top1 71.96, top5 89.14
2021-11-08 02:14:45 train 3000, loss 1.178e+00, top1 71.89, top5 89.11
2021-11-08 02:23:24 train 4000, loss 1.179e+00, top1 71.89, top5 89.07
2021-11-08 02:23:24 train 4000, loss 1.179e+00, top1 71.89, top5 89.09
2021-11-08 02:23:24 train 4000, loss 1.178e+00, top1 71.94, top5 89.11
2021-11-08 02:32:07 train 5000, loss 1.177e+00, top1 71.97, top5 89.17
2021-11-08 02:32:06 train 5000, loss 1.180e+00, top1 71.90, top5 89.11
2021-11-08 02:32:07 train 5000, loss 1.180e+00, top1 71.90, top5 89.12
2021-11-08 02:32:29 valid 0000, loss 5.492e-01, top1 88.24, top5 96.47
2021-11-08 02:32:29 valid 0000, loss 5.492e-01, top1 88.24, top5 96.47
2021-11-08 02:32:29 valid 0000, loss 5.492e-01, top1 88.24, top5 96.47
2021-11-08 02:36:51 (JOBID 31684) epoch 70: train time 2601.55, inference time 271.42s, valid_top1 73.64 (best_top1 73.64), valid_top5 91.55
2021-11-08 02:37:07 (JOBID 31684) epoch 70: train time 2601.81, inference time 287.06s, valid_top1 73.64 (best_top1 73.64), valid_top5 91.55
2021-11-08 02:37:07 (JOBID 31684) epoch 70: train time 2602.03, inference time 287.83s, valid_top1 73.64 (best_top1 73.64), valid_top5 91.55
2021-11-08 02:37:21 train 0000, loss 1.079e+00, top1 71.76, top5 90.59
2021-11-08 02:37:05 train 0000, loss 1.061e+00, top1 75.29, top5 89.41
2021-11-08 02:37:21 train 0000, loss 6.796e-01, top1 82.35, top5 96.47
2021-11-08 02:45:41 train 1000, loss 1.159e+00, top1 72.33, top5 89.41
2021-11-08 02:45:41 train 1000, loss 1.187e+00, top1 71.90, top5 89.02
2021-11-08 02:45:41 train 1000, loss 1.162e+00, top1 72.11, top5 89.41
2021-11-08 02:54:01 train 2000, loss 1.167e+00, top1 72.16, top5 89.27
2021-11-08 02:54:01 train 2000, loss 1.179e+00, top1 72.03, top5 89.16
2021-11-08 02:54:01 train 2000, loss 1.163e+00, top1 72.19, top5 89.37
2021-11-08 03:02:20 train 3000, loss 1.169e+00, top1 72.17, top5 89.23
2021-11-08 03:02:20 train 3000, loss 1.168e+00, top1 72.07, top5 89.28
2021-11-08 03:02:20 train 3000, loss 1.181e+00, top1 71.95, top5 89.12
2021-11-08 03:10:37 train 4000, loss 1.171e+00, top1 72.05, top5 89.22
2021-11-08 03:10:37 train 4000, loss 1.179e+00, top1 72.01, top5 89.13
2021-11-08 03:10:37 train 4000, loss 1.169e+00, top1 72.14, top5 89.23
2021-11-08 03:18:54 train 5000, loss 1.172e+00, top1 72.06, top5 89.21
2021-11-08 03:18:54 train 5000, loss 1.180e+00, top1 71.96, top5 89.10
2021-11-08 03:18:54 train 5000, loss 1.169e+00, top1 72.09, top5 89.27
2021-11-08 03:19:16 valid 0000, loss 5.413e-01, top1 88.24, top5 95.29
2021-11-08 03:19:16 valid 0000, loss 5.413e-01, top1 88.24, top5 95.29
2021-11-08 03:19:16 valid 0000, loss 5.413e-01, top1 88.24, top5 95.29
2021-11-08 03:23:41 (JOBID 31684) epoch 71: train time 2518.76, inference time 275.15s, valid_top1 73.64 (best_top1 73.64), valid_top5 91.52
2021-11-08 03:23:42 (JOBID 31684) epoch 71: train time 2519.41, inference time 276.11s, valid_top1 73.64 (best_top1 73.64), valid_top5 91.52
2021-11-08 03:23:45 (JOBID 31684) epoch 71: train time 2534.56, inference time 278.62s, valid_top1 73.64 (best_top1 73.64), valid_top5 91.52
2021-11-08 03:23:57 train 0000, loss 1.148e+00, top1 74.12, top5 88.24
2021-11-08 03:23:57 train 0000, loss 1.316e+00, top1 72.94, top5 84.71
2021-11-08 03:23:59 train 0000, loss 1.183e+00, top1 71.76, top5 88.24
2021-11-08 03:32:21 train 1000, loss 1.173e+00, top1 72.02, top5 89.31
2021-11-08 03:32:21 train 1000, loss 1.170e+00, top1 72.42, top5 89.22
2021-11-08 03:32:21 train 1000, loss 1.159e+00, top1 72.20, top5 89.39
2021-11-08 03:40:42 train 2000, loss 1.168e+00, top1 72.34, top5 89.28
2021-11-08 03:40:42 train 2000, loss 1.166e+00, top1 72.17, top5 89.39
2021-11-08 03:40:42 train 2000, loss 1.160e+00, top1 72.28, top5 89.38
2021-11-08 03:49:04 train 3000, loss 1.164e+00, top1 72.22, top5 89.30
2021-11-08 03:49:04 train 3000, loss 1.166e+00, top1 72.16, top5 89.36
2021-11-08 03:49:04 train 3000, loss 1.169e+00, top1 72.24, top5 89.30
2021-11-08 03:57:27 train 4000, loss 1.171e+00, top1 72.11, top5 89.28
2021-11-08 03:57:27 train 4000, loss 1.169e+00, top1 72.15, top5 89.30
2021-11-08 03:57:27 train 4000, loss 1.165e+00, top1 72.19, top5 89.32
2021-11-08 04:05:50 train 5000, loss 1.170e+00, top1 72.15, top5 89.29
2021-11-08 04:05:50 train 5000, loss 1.167e+00, top1 72.14, top5 89.31
2021-11-08 04:05:50 train 5000, loss 1.171e+00, top1 72.12, top5 89.29
2021-11-08 04:06:13 valid 0000, loss 5.648e-01, top1 85.88, top5 96.47
2021-11-08 04:06:13 valid 0000, loss 5.648e-01, top1 85.88, top5 96.47
2021-11-08 04:06:13 valid 0000, loss 5.648e-01, top1 85.88, top5 96.47
2021-11-08 04:10:29 (JOBID 31684) epoch 72: train time 2541.66, inference time 265.90s, valid_top1 73.60 (best_top1 73.64), valid_top5 91.59
2021-11-08 04:10:37 (JOBID 31684) epoch 72: train time 2540.68, inference time 274.73s, valid_top1 73.60 (best_top1 73.64), valid_top5 91.59
2021-11-08 04:10:41 (JOBID 31684) epoch 72: train time 2537.63, inference time 278.49s, valid_top1 73.60 (best_top1 73.64), valid_top5 91.59
2021-11-08 04:10:52 train 0000, loss 8.221e-01, top1 77.65, top5 95.29
2021-11-08 04:10:43 train 0000, loss 1.155e+00, top1 72.94, top5 88.24
2021-11-08 04:10:55 train 0000, loss 1.143e+00, top1 77.65, top5 90.59
2021-11-08 04:19:19 train 1000, loss 1.167e+00, top1 72.17, top5 89.31
2021-11-08 04:19:19 train 1000, loss 1.158e+00, top1 72.35, top5 89.31
2021-11-08 04:19:19 train 1000, loss 1.157e+00, top1 72.38, top5 89.43
2021-11-08 04:27:43 train 2000, loss 1.167e+00, top1 72.15, top5 89.30
2021-11-08 04:27:43 train 2000, loss 1.157e+00, top1 72.29, top5 89.39
2021-11-08 04:27:43 train 2000, loss 1.160e+00, top1 72.38, top5 89.42
2021-11-08 04:36:07 train 3000, loss 1.168e+00, top1 72.11, top5 89.27
2021-11-08 04:36:06 train 3000, loss 1.163e+00, top1 72.29, top5 89.35
2021-11-08 04:36:07 train 3000, loss 1.159e+00, top1 72.30, top5 89.33
2021-11-08 04:44:34 train 4000, loss 1.164e+00, top1 72.25, top5 89.32
2021-11-08 04:44:34 train 4000, loss 1.167e+00, top1 72.16, top5 89.27
2021-11-08 04:44:34 train 4000, loss 1.161e+00, top1 72.25, top5 89.34
2021-11-08 04:53:01 train 5000, loss 1.171e+00, top1 72.09, top5 89.21
2021-11-08 04:53:01 train 5000, loss 1.161e+00, top1 72.25, top5 89.35
2021-11-08 04:53:01 train 5000, loss 1.167e+00, top1 72.20, top5 89.25
2021-11-08 04:53:23 valid 0000, loss 5.350e-01, top1 88.24, top5 95.29
2021-11-08 04:53:23 valid 0000, loss 5.350e-01, top1 88.24, top5 95.29
2021-11-08 04:53:23 valid 0000, loss 5.350e-01, top1 88.24, top5 95.29
2021-11-08 04:57:58 (JOBID 31684) epoch 73: train time 2564.52, inference time 284.49s, valid_top1 73.63 (best_top1 73.64), valid_top5 91.63
2021-11-08 04:57:58 (JOBID 31684) epoch 73: train time 2555.70, inference time 284.50s, valid_top1 73.63 (best_top1 73.64), valid_top5 91.63
2021-11-08 04:57:58 (JOBID 31684) epoch 73: train time 2551.75, inference time 284.46s, valid_top1 73.63 (best_top1 73.64), valid_top5 91.63
2021-11-08 04:58:12 train 0000, loss 1.024e+00, top1 72.94, top5 90.59
2021-11-08 04:58:12 train 0000, loss 1.404e+00, top1 64.71, top5 84.71
2021-11-08 04:58:12 train 0000, loss 1.298e+00, top1 67.06, top5 91.76
2021-11-08 05:06:33 train 1000, loss 1.154e+00, top1 72.46, top5 89.55
2021-11-08 05:06:33 train 1000, loss 1.154e+00, top1 72.38, top5 89.43
2021-11-08 05:06:33 train 1000, loss 1.168e+00, top1 72.07, top5 89.31
2021-11-08 05:14:56 train 2000, loss 1.159e+00, top1 72.35, top5 89.42
2021-11-08 05:14:56 train 2000, loss 1.156e+00, top1 72.34, top5 89.44
2021-11-08 05:14:56 train 2000, loss 1.162e+00, top1 72.21, top5 89.32
2021-11-08 05:23:19 train 3000, loss 1.158e+00, top1 72.32, top5 89.37
2021-11-08 05:23:19 train 3000, loss 1.161e+00, top1 72.27, top5 89.37
2021-11-08 05:23:19 train 3000, loss 1.162e+00, top1 72.24, top5 89.35
2021-11-08 05:31:40 train 4000, loss 1.164e+00, top1 72.21, top5 89.31
2021-11-08 05:31:41 train 4000, loss 1.162e+00, top1 72.20, top5 89.35
2021-11-08 05:31:41 train 4000, loss 1.159e+00, top1 72.28, top5 89.39
2021-11-08 05:40:02 train 5000, loss 1.159e+00, top1 72.26, top5 89.38
2021-11-08 05:40:02 train 5000, loss 1.162e+00, top1 72.19, top5 89.34
2021-11-08 05:40:02 train 5000, loss 1.163e+00, top1 72.20, top5 89.32
2021-11-08 05:40:25 valid 0000, loss 5.835e-01, top1 85.88, top5 95.29
2021-11-08 05:40:25 valid 0000, loss 5.835e-01, top1 85.88, top5 95.29
2021-11-08 05:40:25 valid 0000, loss 5.835e-01, top1 85.88, top5 95.29
2021-11-08 05:44:47 (JOBID 31684) epoch 74: train time 2537.12, inference time 270.96s, valid_top1 73.70 (best_top1 73.70), valid_top5 91.71
2021-11-08 05:44:47 (JOBID 31684) epoch 74: train time 2537.31, inference time 272.21s, valid_top1 73.70 (best_top1 73.70), valid_top5 91.71
2021-11-08 05:44:52 (JOBID 31684) epoch 74: train time 2537.31, inference time 277.06s, valid_top1 73.70 (best_top1 73.70), valid_top5 91.71
2021-11-08 05:45:00 train 0000, loss 1.386e+00, top1 69.41, top5 83.53
2021-11-08 05:45:00 train 0000, loss 1.133e+00, top1 75.29, top5 90.59
2021-11-08 05:45:06 train 0000, loss 1.444e+00, top1 65.88, top5 84.71
2021-11-08 05:54:47 train 1000, loss 1.162e+00, top1 72.26, top5 89.34
2021-11-08 05:54:47 train 1000, loss 1.154e+00, top1 72.37, top5 89.47
2021-11-08 05:54:47 train 1000, loss 1.155e+00, top1 72.47, top5 89.38
2021-11-08 06:04:34 train 2000, loss 1.159e+00, top1 72.34, top5 89.33
2021-11-08 06:04:34 train 2000, loss 1.156e+00, top1 72.43, top5 89.43
2021-11-08 06:04:34 train 2000, loss 1.154e+00, top1 72.43, top5 89.49
2021-11-08 06:14:21 train 3000, loss 1.156e+00, top1 72.35, top5 89.44
2021-11-08 06:14:21 train 3000, loss 1.153e+00, top1 72.45, top5 89.44
2021-11-08 06:14:21 train 3000, loss 1.157e+00, top1 72.34, top5 89.37
2021-11-08 06:24:11 train 4000, loss 1.158e+00, top1 72.35, top5 89.38
2021-11-08 06:24:11 train 4000, loss 1.158e+00, top1 72.36, top5 89.42
2021-11-08 06:24:11 train 4000, loss 1.155e+00, top1 72.40, top5 89.45
2021-11-08 06:34:02 train 5000, loss 1.159e+00, top1 72.31, top5 89.37
2021-11-08 06:34:02 train 5000, loss 1.155e+00, top1 72.40, top5 89.44
2021-11-08 06:34:02 train 5000, loss 1.160e+00, top1 72.30, top5 89.40
2021-11-08 06:34:26 valid 0000, loss 4.937e-01, top1 89.41, top5 96.47
2021-11-08 06:34:26 valid 0000, loss 4.937e-01, top1 89.41, top5 96.47
2021-11-08 06:34:26 valid 0000, loss 4.937e-01, top1 89.41, top5 96.47
2021-11-08 06:39:01 (JOBID 31684) epoch 75: train time 2969.38, inference time 284.39s, valid_top1 73.71 (best_top1 73.71), valid_top5 91.77
2021-11-08 06:39:01 (JOBID 31684) epoch 75: train time 2968.62, inference time 285.08s, valid_top1 73.71 (best_top1 73.71), valid_top5 91.77
2021-11-08 06:39:01 (JOBID 31684) epoch 75: train time 2963.75, inference time 285.50s, valid_top1 73.71 (best_top1 73.71), valid_top5 91.77
2021-11-08 06:39:15 train 0000, loss 1.256e+00, top1 67.06, top5 88.24
2021-11-08 06:39:15 train 0000, loss 9.040e-01, top1 81.18, top5 91.76
2021-11-08 06:39:15 train 0000, loss 1.203e+00, top1 71.76, top5 89.41
2021-11-08 06:47:42 train 1000, loss 1.150e+00, top1 72.59, top5 89.52
2021-11-08 06:47:42 train 1000, loss 1.140e+00, top1 72.51, top5 89.64
2021-11-08 06:47:42 train 1000, loss 1.158e+00, top1 72.36, top5 89.38
2021-11-08 06:56:08 train 2000, loss 1.155e+00, top1 72.52, top5 89.44
2021-11-08 06:56:08 train 2000, loss 1.159e+00, top1 72.32, top5 89.35
2021-11-08 06:56:08 train 2000, loss 1.151e+00, top1 72.30, top5 89.50
2021-11-08 07:04:37 train 3000, loss 1.153e+00, top1 72.33, top5 89.45
2021-11-08 07:04:37 train 3000, loss 1.158e+00, top1 72.45, top5 89.45
2021-11-08 07:04:37 train 3000, loss 1.156e+00, top1 72.39, top5 89.41
2021-11-08 07:13:06 train 4000, loss 1.156e+00, top1 72.34, top5 89.43
2021-11-08 07:13:06 train 4000, loss 1.159e+00, top1 72.44, top5 89.42
2021-11-08 07:13:06 train 4000, loss 1.157e+00, top1 72.28, top5 89.43
2021-11-08 07:21:36 train 5000, loss 1.155e+00, top1 72.32, top5 89.47
2021-11-08 07:21:36 train 5000, loss 1.160e+00, top1 72.39, top5 89.37
2021-11-08 07:21:36 train 5000, loss 1.156e+00, top1 72.37, top5 89.43
2021-11-08 07:21:58 valid 0000, loss 5.306e-01, top1 89.41, top5 96.47
2021-11-08 07:21:58 valid 0000, loss 5.306e-01, top1 89.41, top5 96.47
2021-11-08 07:21:58 valid 0000, loss 5.306e-01, top1 89.41, top5 96.47
2021-11-08 07:26:22 (JOBID 31684) epoch 76: train time 2566.89, inference time 273.49s, valid_top1 73.73 (best_top1 73.73), valid_top5 91.74
2021-11-08 07:26:25 (JOBID 31684) epoch 76: train time 2567.47, inference time 275.85s, valid_top1 73.73 (best_top1 73.73), valid_top5 91.74
2021-11-08 07:26:26 (JOBID 31684) epoch 76: train time 2567.43, inference time 277.84s, valid_top1 73.73 (best_top1 73.73), valid_top5 91.74
2021-11-08 07:26:36 train 0000, loss 9.850e-01, top1 72.94, top5 94.12
2021-11-08 07:26:38 train 0000, loss 9.632e-01, top1 77.65, top5 94.12
2021-11-08 07:26:40 train 0000, loss 8.502e-01, top1 80.00, top5 95.29
2021-11-08 07:35:10 train 1000, loss 1.151e+00, top1 72.40, top5 89.48
2021-11-08 07:35:10 train 1000, loss 1.140e+00, top1 72.62, top5 89.50
2021-11-08 07:35:10 train 1000, loss 1.146e+00, top1 72.55, top5 89.57
2021-11-08 07:43:38 train 2000, loss 1.141e+00, top1 72.70, top5 89.55
2021-11-08 07:43:38 train 2000, loss 1.152e+00, top1 72.43, top5 89.47
2021-11-08 07:43:38 train 2000, loss 1.149e+00, top1 72.47, top5 89.53
2021-11-08 07:52:05 train 3000, loss 1.144e+00, top1 72.69, top5 89.47
2021-11-08 07:52:05 train 3000, loss 1.151e+00, top1 72.47, top5 89.45
2021-11-08 07:52:05 train 3000, loss 1.151e+00, top1 72.48, top5 89.49
2021-11-08 08:00:33 train 4000, loss 1.147e+00, top1 72.58, top5 89.46
2021-11-08 08:00:33 train 4000, loss 1.156e+00, top1 72.47, top5 89.39
2021-11-08 08:00:33 train 4000, loss 1.154e+00, top1 72.41, top5 89.46
2021-11-08 08:09:32 train 5000, loss 1.149e+00, top1 72.50, top5 89.43
2021-11-08 08:09:32 train 5000, loss 1.156e+00, top1 72.37, top5 89.45
2021-11-08 08:09:32 train 5000, loss 1.155e+00, top1 72.51, top5 89.41
2021-11-08 08:09:55 valid 0000, loss 4.677e-01, top1 90.59, top5 96.47
2021-11-08 08:09:55 valid 0000, loss 4.677e-01, top1 90.59, top5 96.47
2021-11-08 08:09:55 valid 0000, loss 4.677e-01, top1 90.59, top5 96.47
2021-11-08 08:14:16 (JOBID 31684) epoch 77: train time 2600.52, inference time 270.51s, valid_top1 73.72 (best_top1 73.73), valid_top5 91.70
2021-11-08 08:14:24 (JOBID 31684) epoch 77: train time 2599.00, inference time 278.63s, valid_top1 73.72 (best_top1 73.73), valid_top5 91.70
2021-11-08 08:14:27 (JOBID 31684) epoch 77: train time 2603.47, inference time 282.18s, valid_top1 73.72 (best_top1 73.73), valid_top5 91.70
2021-11-08 08:14:38 train 0000, loss 1.325e+00, top1 71.76, top5 85.88
2021-11-08 08:14:31 train 0000, loss 1.173e+00, top1 72.94, top5 85.88
2021-11-08 08:14:42 train 0000, loss 1.042e+00, top1 70.59, top5 90.59
2021-11-08 08:24:14 train 1000, loss 1.156e+00, top1 72.50, top5 89.37
2021-11-08 08:24:14 train 1000, loss 1.145e+00, top1 72.48, top5 89.54
2021-11-08 08:24:14 train 1000, loss 1.149e+00, top1 72.62, top5 89.51
2021-11-08 08:33:52 train 2000, loss 1.147e+00, top1 72.56, top5 89.56
2021-11-08 08:33:52 train 2000, loss 1.146e+00, top1 72.57, top5 89.54
2021-11-08 08:33:52 train 2000, loss 1.149e+00, top1 72.56, top5 89.52
2021-11-08 08:43:28 train 3000, loss 1.150e+00, top1 72.55, top5 89.50
2021-11-08 08:43:28 train 3000, loss 1.145e+00, top1 72.60, top5 89.58
2021-11-08 08:43:28 train 3000, loss 1.148e+00, top1 72.63, top5 89.51
2021-11-08 08:53:07 train 4000, loss 1.149e+00, top1 72.57, top5 89.52
2021-11-08 08:53:07 train 4000, loss 1.149e+00, top1 72.59, top5 89.48
2021-11-08 08:53:08 train 4000, loss 1.145e+00, top1 72.58, top5 89.55
2021-11-08 09:02:52 train 5000, loss 1.148e+00, top1 72.50, top5 89.52
2021-11-08 09:02:52 train 5000, loss 1.149e+00, top1 72.54, top5 89.52
2021-11-08 09:02:52 train 5000, loss 1.150e+00, top1 72.55, top5 89.48
2021-11-08 09:03:16 valid 0000, loss 5.780e-01, top1 87.06, top5 97.65
2021-11-08 09:03:16 valid 0000, loss 5.780e-01, top1 87.06, top5 97.65
2021-11-08 09:03:16 valid 0000, loss 5.780e-01, top1 87.06, top5 97.65
2021-11-08 09:07:41 (JOBID 31684) epoch 78: train time 2922.76, inference time 274.23s, valid_top1 73.92 (best_top1 73.92), valid_top5 91.71
2021-11-08 09:07:53 (JOBID 31684) epoch 78: train time 2919.05, inference time 286.30s, valid_top1 73.92 (best_top1 73.92), valid_top5 91.71
2021-11-08 09:07:53 (JOBID 31684) epoch 78: train time 2930.53, inference time 286.29s, valid_top1 73.92 (best_top1 73.92), valid_top5 91.71
2021-11-08 09:07:55 train 0000, loss 9.362e-01, top1 78.82, top5 94.12
2021-11-08 09:08:06 train 0000, loss 1.619e+00, top1 62.35, top5 82.35
2021-11-08 09:08:06 train 0000, loss 1.569e+00, top1 62.35, top5 83.53
2021-11-08 09:16:34 train 1000, loss 1.134e+00, top1 72.82, top5 89.60
2021-11-08 09:16:34 train 1000, loss 1.147e+00, top1 72.42, top5 89.48
2021-11-08 09:16:34 train 1000, loss 1.147e+00, top1 72.63, top5 89.55
2021-11-08 09:25:01 train 2000, loss 1.146e+00, top1 72.59, top5 89.53
2021-11-08 09:25:01 train 2000, loss 1.145e+00, top1 72.66, top5 89.49
2021-11-08 09:25:02 train 2000, loss 1.142e+00, top1 72.59, top5 89.56
2021-11-08 09:33:27 train 3000, loss 1.148e+00, top1 72.61, top5 89.48
2021-11-08 09:33:27 train 3000, loss 1.149e+00, top1 72.55, top5 89.51
2021-11-08 09:33:27 train 3000, loss 1.145e+00, top1 72.55, top5 89.53
2021-11-08 09:41:55 train 4000, loss 1.148e+00, top1 72.50, top5 89.54
2021-11-08 09:41:55 train 4000, loss 1.145e+00, top1 72.63, top5 89.56
2021-11-08 09:41:55 train 4000, loss 1.144e+00, top1 72.56, top5 89.57
2021-11-08 09:50:25 train 5000, loss 1.145e+00, top1 72.53, top5 89.55
2021-11-08 09:50:25 train 5000, loss 1.151e+00, top1 72.47, top5 89.50
2021-11-08 09:50:25 train 5000, loss 1.146e+00, top1 72.59, top5 89.59
2021-11-08 09:50:48 valid 0000, loss 4.511e-01, top1 90.59, top5 96.47
2021-11-08 09:50:48 valid 0000, loss 4.511e-01, top1 90.59, top5 96.47
2021-11-08 09:50:48 valid 0000, loss 4.511e-01, top1 90.59, top5 96.47
2021-11-08 09:55:10 (JOBID 31684) epoch 79: train time 2576.57, inference time 273.06s, valid_top1 73.66 (best_top1 73.92), valid_top5 91.68
2021-11-08 09:55:12 (JOBID 31684) epoch 79: train time 2564.74, inference time 274.77s, valid_top1 73.66 (best_top1 73.92), valid_top5 91.68
2021-11-08 09:55:13 (JOBID 31684) epoch 79: train time 2564.21, inference time 275.60s, valid_top1 73.66 (best_top1 73.92), valid_top5 91.68
2021-11-08 09:55:26 train 0000, loss 1.157e+00, top1 75.29, top5 90.59
2021-11-08 09:55:26 train 0000, loss 1.259e+00, top1 70.59, top5 89.41
2021-11-08 09:55:26 train 0000, loss 1.182e+00, top1 72.94, top5 89.41
2021-11-08 10:04:19 train 1000, loss 1.138e+00, top1 72.84, top5 89.58
2021-11-08 10:04:19 train 1000, loss 1.137e+00, top1 72.84, top5 89.73
2021-11-08 10:04:19 train 1000, loss 1.148e+00, top1 72.59, top5 89.54
2021-11-08 10:13:14 train 2000, loss 1.142e+00, top1 72.70, top5 89.60
2021-11-08 10:13:14 train 2000, loss 1.136e+00, top1 72.83, top5 89.65
2021-11-08 10:13:14 train 2000, loss 1.143e+00, top1 72.66, top5 89.59
2021-11-08 10:22:12 train 3000, loss 1.144e+00, top1 72.68, top5 89.59
2021-11-08 10:22:12 train 3000, loss 1.140e+00, top1 72.73, top5 89.61
2021-11-08 10:22:13 train 3000, loss 1.143e+00, top1 72.66, top5 89.59
2021-11-08 10:31:17 train 4000, loss 1.146e+00, top1 72.67, top5 89.54
2021-11-08 10:31:17 train 4000, loss 1.140e+00, top1 72.72, top5 89.62
2021-11-08 10:31:17 train 4000, loss 1.144e+00, top1 72.63, top5 89.58
2021-11-08 10:40:20 train 5000, loss 1.143e+00, top1 72.66, top5 89.59
2021-11-08 10:40:20 train 5000, loss 1.145e+00, top1 72.59, top5 89.55
2021-11-08 10:40:20 train 5000, loss 1.147e+00, top1 72.63, top5 89.56
2021-11-08 10:40:43 valid 0000, loss 5.896e-01, top1 88.24, top5 94.12
2021-11-08 10:40:43 valid 0000, loss 5.896e-01, top1 88.24, top5 94.12
2021-11-08 10:40:43 valid 0000, loss 5.896e-01, top1 88.24, top5 94.12
2021-11-08 10:45:06 (JOBID 31684) epoch 80: train time 2721.07, inference time 273.14s, valid_top1 73.80 (best_top1 73.92), valid_top5 91.77
2021-11-08 10:45:07 (JOBID 31684) epoch 80: train time 2722.97, inference time 273.73s, valid_top1 73.80 (best_top1 73.92), valid_top5 91.77
2021-11-08 10:45:08 (JOBID 31684) epoch 80: train time 2720.02, inference time 274.10s, valid_top1 73.80 (best_top1 73.92), valid_top5 91.77
2021-11-08 10:45:21 train 0000, loss 1.208e+00, top1 77.65, top5 90.59
2021-11-08 10:45:21 train 0000, loss 8.232e-01, top1 81.18, top5 94.12
2021-11-08 10:45:21 train 0000, loss 9.802e-01, top1 70.59, top5 92.94
2021-11-08 10:53:48 train 1000, loss 1.137e+00, top1 72.74, top5 89.79
2021-11-08 10:53:48 train 1000, loss 1.143e+00, top1 72.68, top5 89.50
2021-11-08 10:53:48 train 1000, loss 1.139e+00, top1 72.94, top5 89.62
2021-11-08 11:02:20 train 2000, loss 1.136e+00, top1 72.75, top5 89.73
2021-11-08 11:02:20 train 2000, loss 1.138e+00, top1 72.82, top5 89.61
2021-11-08 11:02:20 train 2000, loss 1.138e+00, top1 72.89, top5 89.59
2021-11-08 11:10:47 train 3000, loss 1.142e+00, top1 72.63, top5 89.63
2021-11-08 11:10:47 train 3000, loss 1.140e+00, top1 72.79, top5 89.60
2021-11-08 11:10:47 train 3000, loss 1.138e+00, top1 72.88, top5 89.63
2021-11-08 11:19:16 train 4000, loss 1.146e+00, top1 72.57, top5 89.54
2021-11-08 11:19:16 train 4000, loss 1.138e+00, top1 72.79, top5 89.62
2021-11-08 11:19:16 train 4000, loss 1.140e+00, top1 72.80, top5 89.60
2021-11-08 11:27:45 train 5000, loss 1.142e+00, top1 72.70, top5 89.58
2021-11-08 11:27:45 train 5000, loss 1.145e+00, top1 72.61, top5 89.55
2021-11-08 11:27:45 train 5000, loss 1.143e+00, top1 72.72, top5 89.58
2021-11-08 11:28:07 valid 0000, loss 5.463e-01, top1 85.88, top5 97.65
2021-11-08 11:28:07 valid 0000, loss 5.463e-01, top1 85.88, top5 97.65
2021-11-08 11:28:07 valid 0000, loss 5.463e-01, top1 85.88, top5 97.65
2021-11-08 11:32:42 (JOBID 31684) epoch 81: train time 2570.09, inference time 285.16s, valid_top1 73.87 (best_top1 73.92), valid_top5 91.73
2021-11-08 11:32:42 (JOBID 31684) epoch 81: train time 2570.84, inference time 285.13s, valid_top1 73.87 (best_top1 73.92), valid_top5 91.73
2021-11-08 11:32:43 (JOBID 31684) epoch 81: train time 2569.55, inference time 285.17s, valid_top1 73.87 (best_top1 73.92), valid_top5 91.73
2021-11-08 11:32:56 train 0000, loss 1.231e+00, top1 70.59, top5 88.24
2021-11-08 11:32:56 train 0000, loss 9.836e-01, top1 81.18, top5 90.59
2021-11-08 11:32:56 train 0000, loss 9.838e-01, top1 75.29, top5 88.24
2021-11-08 11:42:29 train 1000, loss 1.133e+00, top1 72.82, top5 89.71
2021-11-08 11:42:28 train 1000, loss 1.125e+00, top1 73.20, top5 89.73
2021-11-08 11:42:29 train 1000, loss 1.137e+00, top1 72.93, top5 89.60
2021-11-08 11:52:04 train 2000, loss 1.137e+00, top1 72.88, top5 89.66
2021-11-08 11:52:04 train 2000, loss 1.128e+00, top1 73.05, top5 89.73
2021-11-08 11:52:04 train 2000, loss 1.130e+00, top1 72.93, top5 89.72
2021-11-08 12:01:41 train 3000, loss 1.132e+00, top1 72.92, top5 89.71
2021-11-08 12:01:41 train 3000, loss 1.139e+00, top1 72.82, top5 89.64
2021-11-08 12:01:41 train 3000, loss 1.129e+00, top1 72.99, top5 89.73
2021-11-08 12:11:16 train 4000, loss 1.136e+00, top1 72.84, top5 89.69
2021-11-08 12:11:16 train 4000, loss 1.133e+00, top1 72.88, top5 89.69
2021-11-08 12:11:17 train 4000, loss 1.133e+00, top1 72.88, top5 89.72
2021-11-08 12:20:54 train 5000, loss 1.136e+00, top1 72.81, top5 89.68
2021-11-08 12:20:53 train 5000, loss 1.139e+00, top1 72.77, top5 89.65
2021-11-08 12:20:54 train 5000, loss 1.140e+00, top1 72.72, top5 89.60
2021-11-08 12:21:19 valid 0000, loss 5.494e-01, top1 87.06, top5 97.65
2021-11-08 12:21:19 valid 0000, loss 5.494e-01, top1 87.06, top5 97.65
2021-11-08 12:21:19 valid 0000, loss 5.494e-01, top1 87.06, top5 97.65
2021-11-08 12:25:51 (JOBID 31684) epoch 82: train time 2905.44, inference time 282.81s, valid_top1 73.93 (best_top1 73.93), valid_top5 91.83
2021-11-08 12:25:51 (JOBID 31684) epoch 82: train time 2905.47, inference time 282.99s, valid_top1 73.93 (best_top1 73.93), valid_top5 91.83
2021-11-08 12:25:51 (JOBID 31684) epoch 82: train time 2905.27, inference time 282.95s, valid_top1 73.93 (best_top1 73.93), valid_top5 91.83
2021-11-08 12:26:06 train 0000, loss 1.240e+00, top1 70.59, top5 87.06
2021-11-08 12:26:06 train 0000, loss 1.129e+00, top1 77.65, top5 91.76
2021-11-08 12:26:06 train 0000, loss 1.111e+00, top1 75.29, top5 89.41
2021-11-08 12:34:35 train 1000, loss 1.134e+00, top1 72.98, top5 89.69
2021-11-08 12:34:35 train 1000, loss 1.131e+00, top1 73.08, top5 89.70
2021-11-08 12:34:35 train 1000, loss 1.130e+00, top1 73.05, top5 89.66
2021-11-08 12:43:03 train 2000, loss 1.133e+00, top1 72.98, top5 89.65
2021-11-08 12:43:03 train 2000, loss 1.130e+00, top1 72.97, top5 89.71
2021-11-08 12:43:03 train 2000, loss 1.135e+00, top1 72.87, top5 89.61
2021-11-08 12:51:41 train 3000, loss 1.132e+00, top1 72.88, top5 89.70
2021-11-08 12:51:41 train 3000, loss 1.131e+00, top1 72.91, top5 89.70
2021-11-08 12:51:41 train 3000, loss 1.134e+00, top1 72.82, top5 89.66
2021-11-08 13:00:09 train 4000, loss 1.133e+00, top1 72.85, top5 89.66
2021-11-08 13:00:09 train 4000, loss 1.136e+00, top1 72.76, top5 89.65
2021-11-08 13:00:09 train 4000, loss 1.131e+00, top1 72.90, top5 89.71
2021-11-08 13:08:38 train 5000, loss 1.135e+00, top1 72.80, top5 89.67
2021-11-08 13:08:38 train 5000, loss 1.134e+00, top1 72.85, top5 89.66
2021-11-08 13:08:38 train 5000, loss 1.139e+00, top1 72.72, top5 89.65
2021-11-08 13:09:01 valid 0000, loss 4.430e-01, top1 88.24, top5 98.82
2021-11-08 13:09:01 valid 0000, loss 4.430e-01, top1 88.24, top5 98.82
2021-11-08 13:09:01 valid 0000, loss 4.430e-01, top1 88.24, top5 98.82
2021-11-08 13:13:12 (JOBID 31684) epoch 83: train time 2579.56, inference time 262.14s, valid_top1 73.88 (best_top1 73.93), valid_top5 91.64
2021-11-08 13:13:35 (JOBID 31684) epoch 83: train time 2579.39, inference time 284.36s, valid_top1 73.88 (best_top1 73.93), valid_top5 91.64
2021-11-08 13:13:39 (JOBID 31684) epoch 83: train time 2578.72, inference time 288.75s, valid_top1 73.88 (best_top1 73.93), valid_top5 91.64
2021-11-08 13:13:26 train 0000, loss 1.224e+00, top1 67.06, top5 88.24
2021-11-08 13:13:48 train 0000, loss 1.057e+00, top1 67.06, top5 92.94
2021-11-08 13:13:53 train 0000, loss 1.031e+00, top1 70.59, top5 88.24
2021-11-08 13:23:12 train 1000, loss 1.126e+00, top1 73.14, top5 89.77
2021-11-08 13:23:12 train 1000, loss 1.121e+00, top1 73.33, top5 89.79
2021-11-08 13:23:12 train 1000, loss 1.130e+00, top1 72.93, top5 89.68
2021-11-08 13:32:31 train 2000, loss 1.136e+00, top1 72.82, top5 89.65
2021-11-08 13:32:31 train 2000, loss 1.124e+00, top1 73.09, top5 89.83
2021-11-08 13:32:31 train 2000, loss 1.126e+00, top1 73.15, top5 89.75
2021-11-08 13:41:52 train 3000, loss 1.127e+00, top1 72.97, top5 89.78
2021-11-08 13:41:52 train 3000, loss 1.129e+00, top1 73.04, top5 89.73
2021-11-08 13:41:52 train 3000, loss 1.134e+00, top1 72.88, top5 89.70
2021-11-08 13:51:17 train 4000, loss 1.131e+00, top1 72.88, top5 89.74
2021-11-08 13:51:17 train 4000, loss 1.137e+00, top1 72.77, top5 89.67
2021-11-08 13:51:17 train 4000, loss 1.131e+00, top1 72.98, top5 89.71
2021-11-08 14:00:39 train 5000, loss 1.136e+00, top1 72.80, top5 89.70
2021-11-08 14:00:39 train 5000, loss 1.136e+00, top1 72.81, top5 89.66
2021-11-08 14:00:39 train 5000, loss 1.132e+00, top1 72.93, top5 89.70
2021-11-08 14:01:03 valid 0000, loss 5.045e-01, top1 85.88, top5 97.65
2021-11-08 14:01:03 valid 0000, loss 5.045e-01, top1 85.88, top5 97.65
2021-11-08 14:01:03 valid 0000, loss 5.045e-01, top1 85.88, top5 97.65
2021-11-08 14:05:38 (JOBID 31684) epoch 84: train time 2837.85, inference time 285.35s, valid_top1 73.75 (best_top1 73.93), valid_top5 91.73
2021-11-08 14:05:38 (JOBID 31684) epoch 84: train time 2833.24, inference time 285.05s, valid_top1 73.75 (best_top1 73.93), valid_top5 91.73
2021-11-08 14:05:39 (JOBID 31684) epoch 84: train time 2860.10, inference time 286.15s, valid_top1 73.75 (best_top1 73.93), valid_top5 91.73
2021-11-08 14:05:52 train 0000, loss 9.555e-01, top1 77.65, top5 90.59
2021-11-08 14:05:52 train 0000, loss 7.358e-01, top1 81.18, top5 95.29
2021-11-08 14:05:52 train 0000, loss 9.822e-01, top1 71.76, top5 91.76
2021-11-08 14:14:51 train 1000, loss 1.117e+00, top1 73.18, top5 89.88
2021-11-08 14:14:51 train 1000, loss 1.126e+00, top1 73.12, top5 89.74
2021-11-08 14:14:51 train 1000, loss 1.126e+00, top1 73.14, top5 89.83
2021-11-08 14:23:47 train 2000, loss 1.129e+00, top1 73.04, top5 89.76
2021-11-08 14:23:47 train 2000, loss 1.126e+00, top1 73.06, top5 89.80
2021-11-08 14:23:47 train 2000, loss 1.122e+00, top1 73.00, top5 89.80
2021-11-08 14:32:49 train 3000, loss 1.132e+00, top1 72.98, top5 89.68
2021-11-08 14:32:49 train 3000, loss 1.130e+00, top1 72.90, top5 89.75
2021-11-08 14:32:49 train 3000, loss 1.130e+00, top1 72.88, top5 89.74
2021-11-08 14:41:57 train 4000, loss 1.132e+00, top1 72.83, top5 89.72
2021-11-08 14:41:57 train 4000, loss 1.130e+00, top1 72.91, top5 89.74
2021-11-08 14:41:57 train 4000, loss 1.132e+00, top1 72.95, top5 89.69
2021-11-08 14:51:07 train 5000, loss 1.133e+00, top1 72.84, top5 89.69
2021-11-08 14:51:07 train 5000, loss 1.132e+00, top1 72.96, top5 89.69
2021-11-08 14:51:07 train 5000, loss 1.133e+00, top1 72.84, top5 89.71
2021-11-08 14:51:30 valid 0000, loss 5.546e-01, top1 89.41, top5 96.47
2021-11-08 14:51:30 valid 0000, loss 5.546e-01, top1 89.41, top5 96.47
2021-11-08 14:51:30 valid 0000, loss 5.546e-01, top1 89.41, top5 96.47
2021-11-08 14:55:54 (JOBID 31684) epoch 85: train time 2741.79, inference time 273.35s, valid_top1 73.52 (best_top1 73.93), valid_top5 91.71
2021-11-08 14:55:55 (JOBID 31684) epoch 85: train time 2741.34, inference time 275.34s, valid_top1 73.52 (best_top1 73.93), valid_top5 91.71
2021-11-08 14:55:56 (JOBID 31684) epoch 85: train time 2742.16, inference time 275.68s, valid_top1 73.52 (best_top1 73.93), valid_top5 91.71
2021-11-08 14:56:08 train 0000, loss 1.208e+00, top1 74.12, top5 89.41
2021-11-08 14:56:09 train 0000, loss 1.202e+00, top1 72.94, top5 87.06
2021-11-08 14:56:09 train 0000, loss 8.245e-01, top1 78.82, top5 94.12
2021-11-08 15:04:47 train 1000, loss 1.130e+00, top1 73.07, top5 89.77
2021-11-08 15:04:47 train 1000, loss 1.125e+00, top1 73.23, top5 89.81
2021-11-08 15:04:47 train 1000, loss 1.123e+00, top1 73.07, top5 89.83
2021-11-08 15:13:28 train 2000, loss 1.130e+00, top1 73.06, top5 89.75
2021-11-08 15:13:28 train 2000, loss 1.130e+00, top1 72.92, top5 89.69
2021-11-08 15:13:28 train 2000, loss 1.127e+00, top1 73.06, top5 89.81
2021-11-08 15:22:18 train 3000, loss 1.133e+00, top1 72.85, top5 89.66
2021-11-08 15:22:18 train 3000, loss 1.130e+00, top1 73.02, top5 89.73
2021-11-08 15:22:18 train 3000, loss 1.127e+00, top1 73.14, top5 89.81
2021-11-08 15:30:56 train 4000, loss 1.127e+00, top1 73.08, top5 89.81
2021-11-08 15:30:56 train 4000, loss 1.129e+00, top1 73.01, top5 89.79
2021-11-08 15:30:56 train 4000, loss 1.135e+00, top1 72.81, top5 89.64
2021-11-08 15:39:36 train 5000, loss 1.130e+00, top1 72.97, top5 89.75
2021-11-08 15:39:36 train 5000, loss 1.134e+00, top1 72.82, top5 89.65
2021-11-08 15:39:36 train 5000, loss 1.128e+00, top1 73.05, top5 89.79
2021-11-08 15:39:59 valid 0000, loss 5.698e-01, top1 88.24, top5 95.29
2021-11-08 15:39:59 valid 0000, loss 5.698e-01, top1 88.24, top5 95.29
2021-11-08 15:39:59 valid 0000, loss 5.698e-01, top1 88.24, top5 95.29
2021-11-08 15:44:27 (JOBID 31684) epoch 86: train time 2635.31, inference time 277.91s, valid_top1 73.82 (best_top1 73.93), valid_top5 91.73
2021-11-08 15:44:27 (JOBID 31684) epoch 86: train time 2633.17, inference time 278.63s, valid_top1 73.82 (best_top1 73.93), valid_top5 91.73
2021-11-08 15:44:31 (JOBID 31684) epoch 86: train time 2633.54, inference time 282.10s, valid_top1 73.82 (best_top1 73.93), valid_top5 91.73
2021-11-08 15:44:41 train 0000, loss 1.115e+00, top1 72.94, top5 88.24
2021-11-08 15:44:41 train 0000, loss 1.121e+00, top1 70.59, top5 88.24
2021-11-08 15:44:45 train 0000, loss 1.352e+00, top1 64.71, top5 88.24
2021-11-08 15:53:32 train 1000, loss 1.119e+00, top1 73.08, top5 89.79
2021-11-08 15:53:32 train 1000, loss 1.134e+00, top1 72.90, top5 89.65
2021-11-08 15:53:32 train 1000, loss 1.127e+00, top1 73.09, top5 89.80
2021-11-08 16:02:31 train 2000, loss 1.131e+00, top1 72.96, top5 89.75
2021-11-08 16:02:31 train 2000, loss 1.122e+00, top1 73.11, top5 89.76
2021-11-08 16:02:31 train 2000, loss 1.125e+00, top1 73.04, top5 89.78
2021-11-08 16:11:26 train 3000, loss 1.129e+00, top1 72.96, top5 89.71
2021-11-08 16:11:26 train 3000, loss 1.125e+00, top1 73.07, top5 89.75
2021-11-08 16:11:26 train 3000, loss 1.128e+00, top1 73.01, top5 89.77
2021-11-08 16:20:24 train 4000, loss 1.130e+00, top1 72.95, top5 89.75
2021-11-08 16:20:24 train 4000, loss 1.128e+00, top1 72.98, top5 89.75
2021-11-08 16:20:24 train 4000, loss 1.128e+00, top1 72.95, top5 89.72
2021-11-08 16:29:28 train 5000, loss 1.127e+00, top1 73.02, top5 89.75
2021-11-08 16:29:28 train 5000, loss 1.131e+00, top1 72.92, top5 89.72
2021-11-08 16:29:28 train 5000, loss 1.129e+00, top1 72.93, top5 89.72
2021-11-08 16:29:51 valid 0000, loss 5.642e-01, top1 85.88, top5 95.29
2021-11-08 16:29:51 valid 0000, loss 5.642e-01, top1 85.88, top5 95.29
2021-11-08 16:29:51 valid 0000, loss 5.642e-01, top1 85.88, top5 95.29
2021-11-08 16:34:29 (JOBID 31684) epoch 87: train time 2710.45, inference time 287.56s, valid_top1 73.92 (best_top1 73.93), valid_top5 91.83
2021-11-08 16:34:29 (JOBID 31684) epoch 87: train time 2713.73, inference time 287.79s, valid_top1 73.92 (best_top1 73.93), valid_top5 91.83
2021-11-08 16:34:29 (JOBID 31684) epoch 87: train time 2714.43, inference time 287.55s, valid_top1 73.92 (best_top1 73.93), valid_top5 91.83
2021-11-08 16:34:43 train 0000, loss 1.269e+00, top1 69.41, top5 89.41
2021-11-08 16:34:43 train 0000, loss 1.352e+00, top1 68.24, top5 84.71
2021-11-08 16:34:43 train 0000, loss 1.260e+00, top1 68.24, top5 89.41
2021-11-08 16:43:08 train 1000, loss 1.137e+00, top1 72.73, top5 89.53
2021-11-08 16:43:08 train 1000, loss 1.126e+00, top1 73.14, top5 89.79
2021-11-08 16:43:08 train 1000, loss 1.112e+00, top1 73.23, top5 89.98
2021-11-08 16:51:31 train 2000, loss 1.128e+00, top1 73.04, top5 89.78
2021-11-08 16:51:32 train 2000, loss 1.128e+00, top1 72.98, top5 89.65
2021-11-08 16:51:32 train 2000, loss 1.116e+00, top1 73.15, top5 89.94
2021-11-08 16:59:57 train 3000, loss 1.129e+00, top1 73.00, top5 89.78
2021-11-08 16:59:57 train 3000, loss 1.118e+00, top1 73.12, top5 89.87
2021-11-08 16:59:57 train 3000, loss 1.123e+00, top1 73.10, top5 89.75
2021-11-08 17:08:33 train 4000, loss 1.123e+00, top1 73.10, top5 89.77
2021-11-08 17:08:33 train 4000, loss 1.128e+00, top1 72.99, top5 89.79
2021-11-08 17:08:33 train 4000, loss 1.120e+00, top1 73.08, top5 89.84
2021-11-08 17:16:58 train 5000, loss 1.122e+00, top1 73.07, top5 89.82
2021-11-08 17:16:58 train 5000, loss 1.127e+00, top1 73.00, top5 89.79
2021-11-08 17:16:58 train 5000, loss 1.122e+00, top1 73.12, top5 89.81
2021-11-08 17:17:21 valid 0000, loss 4.783e-01, top1 90.59, top5 96.47
2021-11-08 17:17:21 valid 0000, loss 4.783e-01, top1 90.59, top5 96.47
2021-11-08 17:17:21 valid 0000, loss 4.783e-01, top1 90.59, top5 96.47
2021-11-08 17:21:34 (JOBID 31684) epoch 88: train time 2562.02, inference time 262.93s, valid_top1 73.85 (best_top1 73.93), valid_top5 91.70
2021-11-08 17:21:50 (JOBID 31684) epoch 88: train time 2562.07, inference time 279.24s, valid_top1 73.85 (best_top1 73.93), valid_top5 91.70
2021-11-08 17:21:52 (JOBID 31684) epoch 88: train time 2561.69, inference time 280.67s, valid_top1 73.85 (best_top1 73.93), valid_top5 91.70
2021-11-08 17:22:04 train 0000, loss 1.424e+00, top1 65.88, top5 83.53
2021-11-08 17:21:47 train 0000, loss 9.892e-01, top1 80.00, top5 89.41
2021-11-08 17:22:05 train 0000, loss 1.044e+00, top1 75.29, top5 89.41
2021-11-08 17:30:36 train 1000, loss 1.127e+00, top1 73.11, top5 89.75
2021-11-08 17:30:37 train 1000, loss 1.124e+00, top1 73.13, top5 89.89
2021-11-08 17:30:37 train 1000, loss 1.131e+00, top1 72.97, top5 89.61
2021-11-08 17:39:10 train 2000, loss 1.123e+00, top1 73.11, top5 89.89
2021-11-08 17:39:10 train 2000, loss 1.125e+00, top1 73.10, top5 89.78
2021-11-08 17:39:10 train 2000, loss 1.130e+00, top1 73.05, top5 89.67
2021-11-08 17:47:39 train 3000, loss 1.124e+00, top1 73.11, top5 89.83
2021-11-08 17:47:39 train 3000, loss 1.124e+00, top1 73.06, top5 89.80
2021-11-08 17:47:39 train 3000, loss 1.125e+00, top1 73.09, top5 89.74
2021-11-08 17:56:10 train 4000, loss 1.124e+00, top1 73.11, top5 89.81
2021-11-08 17:56:10 train 4000, loss 1.126e+00, top1 73.04, top5 89.76
2021-11-08 17:56:10 train 4000, loss 1.124e+00, top1 73.09, top5 89.81
2021-11-08 18:04:39 train 5000, loss 1.126e+00, top1 73.04, top5 89.78
2021-11-08 18:04:39 train 5000, loss 1.122e+00, top1 73.14, top5 89.83
2021-11-08 18:04:39 train 5000, loss 1.125e+00, top1 73.09, top5 89.83
2021-11-08 18:05:02 valid 0000, loss 4.727e-01, top1 88.24, top5 97.65
2021-11-08 18:05:02 valid 0000, loss 4.727e-01, top1 88.24, top5 97.65
2021-11-08 18:05:02 valid 0000, loss 4.727e-01, top1 88.24, top5 97.65
2021-11-08 18:09:29 (JOBID 31684) epoch 89: train time 2597.77, inference time 277.35s, valid_top1 73.62 (best_top1 73.93), valid_top5 91.71
2021-11-08 18:09:29 (JOBID 31684) epoch 89: train time 2580.00, inference time 277.54s, valid_top1 73.62 (best_top1 73.93), valid_top5 91.71
2021-11-08 18:09:31 (JOBID 31684) epoch 89: train time 2581.48, inference time 278.92s, valid_top1 73.62 (best_top1 73.93), valid_top5 91.71
