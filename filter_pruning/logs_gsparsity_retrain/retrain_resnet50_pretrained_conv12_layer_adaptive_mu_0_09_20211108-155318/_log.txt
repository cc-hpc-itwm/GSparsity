2021-11-08 15:53:23 CARME Slurm ID: 31717
2021-11-08 15:53:23 CARME Slurm ID: 31717
2021-11-08 15:53:23 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_09', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.44:23456', distributed=True, epochs=90, evaluate=False, gpu=1, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-08 15:53:23 CARME Slurm ID: 31717
2021-11-08 15:53:23 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_09', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.44:23456', distributed=True, epochs=90, evaluate=False, gpu=0, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-08 15:53:23 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_09', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.44:23456', distributed=True, epochs=90, evaluate=False, gpu=2, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-08 15:53:25 => loading baseline model 'conv12_lr_0.001_momentum_0.9_wd_0.09_normalization_div_pretrained_True_20211102-092641/small_model_conv12_1e-06.pth.tar'
2021-11-08 15:53:25 => loading baseline model 'conv12_lr_0.001_momentum_0.9_wd_0.09_normalization_div_pretrained_True_20211102-092641/small_model_conv12_1e-06.pth.tar'
2021-11-08 15:53:25 => loading baseline model 'conv12_lr_0.001_momentum_0.9_wd_0.09_normalization_div_pretrained_True_20211102-092641/small_model_conv12_1e-06.pth.tar'
2021-11-08 15:53:25 => loaded baseline model 'conv12_lr_0.001_momentum_0.9_wd_0.09_normalization_div_pretrained_True_20211102-092641/small_model_conv12_1e-06.pth.tar'
2021-11-08 15:53:25 => loaded baseline model 'conv12_lr_0.001_momentum_0.9_wd_0.09_normalization_div_pretrained_True_20211102-092641/small_model_conv12_1e-06.pth.tar'
2021-11-08 15:53:25 => loaded baseline model 'conv12_lr_0.001_momentum_0.9_wd_0.09_normalization_div_pretrained_True_20211102-092641/small_model_conv12_1e-06.pth.tar'
2021-11-08 15:53:37 Computational complexity:       1.77 GMac
2021-11-08 15:53:37 Computational complexity:       1.77 GMac
2021-11-08 15:53:37 Computational complexity:       1.77 GMac
2021-11-08 15:53:37 Number of parameters:           12.51 M 
2021-11-08 15:53:37 Number of parameters:           12.51 M 
2021-11-08 15:53:37 Number of parameters:           12.51 M 
2021-11-08 15:53:54 valid 0000, loss 6.378e-01, top1 87.06, top5 95.29
2021-11-08 15:53:54 valid 0000, loss 6.378e-01, top1 87.06, top5 95.29
2021-11-08 15:53:54 valid 0000, loss 6.378e-01, top1 87.06, top5 95.29
2021-11-08 15:57:59 (JOBID 31717) epoch -1: valid_top1 72.47, valid_top5 90.50, inference time 257.47
2021-11-08 15:58:29 (JOBID 31717) epoch -1: valid_top1 72.47, valid_top5 90.50, inference time 287.06
2021-11-08 15:58:31 (JOBID 31717) epoch -1: valid_top1 72.47, valid_top5 90.50, inference time 289.80
2021-11-08 15:58:49 train 0000, loss 1.020e+00, top1 77.65, top5 89.41
2021-11-08 15:58:49 train 0000, loss 6.530e-01, top1 85.88, top5 95.29
2021-11-08 15:58:49 train 0000, loss 4.830e-01, top1 82.35, top5 100.00
2021-11-08 16:07:59 train 1000, loss 1.550e+00, top1 63.82, top5 83.76
2021-11-08 16:07:59 train 1000, loss 1.566e+00, top1 63.61, top5 83.63
2021-11-08 16:07:59 train 1000, loss 1.558e+00, top1 63.54, top5 83.60
2021-11-08 16:17:21 train 2000, loss 1.482e+00, top1 65.24, top5 84.77
2021-11-08 16:17:21 train 2000, loss 1.492e+00, top1 65.20, top5 84.65
2021-11-08 16:17:21 train 2000, loss 1.484e+00, top1 65.26, top5 84.71
2021-11-08 16:26:44 train 3000, loss 1.461e+00, top1 65.74, top5 85.11
2021-11-08 16:26:44 train 3000, loss 1.457e+00, top1 65.77, top5 85.18
2021-11-08 16:26:44 train 3000, loss 1.457e+00, top1 65.80, top5 85.14
2021-11-08 16:36:08 train 4000, loss 1.443e+00, top1 66.06, top5 85.38
2021-11-08 16:36:08 train 4000, loss 1.442e+00, top1 66.12, top5 85.38
2021-11-08 16:36:08 train 4000, loss 1.446e+00, top1 66.08, top5 85.36
2021-11-08 16:45:33 train 5000, loss 1.436e+00, top1 66.20, top5 85.48
2021-11-08 16:45:33 train 5000, loss 1.440e+00, top1 66.21, top5 85.46
2021-11-08 16:45:33 train 5000, loss 1.438e+00, top1 66.23, top5 85.48
2021-11-08 16:45:59 valid 0000, loss 6.931e-01, top1 89.41, top5 95.29
2021-11-08 16:45:59 valid 0000, loss 6.931e-01, top1 89.41, top5 95.29
2021-11-08 16:45:59 valid 0000, loss 6.931e-01, top1 89.41, top5 95.29
2021-11-08 16:50:21 (JOBID 31717) epoch 0: train time 2870.30, inference time 271.55s, valid_top1 63.95 (best_top1 63.95), valid_top5 85.08
2021-11-08 16:50:39 (JOBID 31717) epoch 0: train time 2840.70, inference time 290.05s, valid_top1 63.95 (best_top1 63.95), valid_top5 85.08
2021-11-08 16:50:42 (JOBID 31717) epoch 0: train time 2838.00, inference time 292.16s, valid_top1 63.95 (best_top1 63.95), valid_top5 85.08
2021-11-08 16:50:55 train 0000, loss 1.439e+00, top1 64.71, top5 80.00
2021-11-08 16:50:36 train 0000, loss 1.222e+00, top1 75.29, top5 87.06
2021-11-08 16:50:56 train 0000, loss 1.274e+00, top1 68.24, top5 87.06
2021-11-08 17:00:13 train 1000, loss 1.414e+00, top1 66.89, top5 85.93
2021-11-08 17:00:13 train 1000, loss 1.412e+00, top1 66.95, top5 86.13
2021-11-08 17:00:13 train 1000, loss 1.418e+00, top1 66.75, top5 85.88
2021-11-08 17:09:34 train 2000, loss 1.428e+00, top1 66.61, top5 85.96
2021-11-08 17:09:34 train 2000, loss 1.433e+00, top1 66.46, top5 85.74
2021-11-08 17:09:34 train 2000, loss 1.427e+00, top1 66.61, top5 85.89
2021-11-08 17:18:54 train 3000, loss 1.449e+00, top1 66.25, top5 85.67
2021-11-08 17:18:54 train 3000, loss 1.452e+00, top1 66.07, top5 85.57
2021-11-08 17:18:54 train 3000, loss 1.446e+00, top1 66.16, top5 85.62
2021-11-08 17:28:18 train 4000, loss 1.469e+00, top1 65.85, top5 85.40
2021-11-08 17:28:19 train 4000, loss 1.465e+00, top1 65.82, top5 85.41
2021-11-08 17:28:19 train 4000, loss 1.462e+00, top1 65.83, top5 85.41
2021-11-08 17:37:45 train 5000, loss 1.482e+00, top1 65.51, top5 85.22
2021-11-08 17:37:45 train 5000, loss 1.487e+00, top1 65.47, top5 85.18
2021-11-08 17:37:45 train 5000, loss 1.480e+00, top1 65.47, top5 85.22
2021-11-08 17:38:09 valid 0000, loss 8.610e-01, top1 84.71, top5 92.94
2021-11-08 17:38:09 valid 0000, loss 8.610e-01, top1 84.71, top5 92.94
2021-11-08 17:38:09 valid 0000, loss 8.610e-01, top1 84.71, top5 92.94
2021-11-08 17:42:24 (JOBID 31717) epoch 1: train time 2857.91, inference time 264.93s, valid_top1 61.94 (best_top1 63.95), valid_top5 84.16
2021-11-08 17:42:41 (JOBID 31717) epoch 1: train time 2837.56, inference time 281.66s, valid_top1 61.94 (best_top1 63.95), valid_top5 84.16
2021-11-08 17:42:41 (JOBID 31717) epoch 1: train time 2839.72, inference time 282.25s, valid_top1 61.94 (best_top1 63.95), valid_top5 84.16
2021-11-08 17:42:54 train 0000, loss 1.511e+00, top1 68.24, top5 83.53
2021-11-08 17:42:38 train 0000, loss 1.366e+00, top1 61.18, top5 89.41
2021-11-08 17:42:54 train 0000, loss 1.627e+00, top1 58.82, top5 82.35
2021-11-08 17:51:28 train 1000, loss 1.548e+00, top1 63.95, top5 84.48
2021-11-08 17:51:28 train 1000, loss 1.562e+00, top1 64.03, top5 84.22
2021-11-08 17:51:29 train 1000, loss 1.551e+00, top1 63.98, top5 84.47
2021-11-08 18:00:15 train 2000, loss 1.579e+00, top1 63.53, top5 84.09
2021-11-08 18:00:15 train 2000, loss 1.581e+00, top1 63.56, top5 83.96
2021-11-08 18:00:15 train 2000, loss 1.571e+00, top1 63.47, top5 84.24
2021-11-08 18:08:59 train 3000, loss 1.603e+00, top1 63.05, top5 83.69
2021-11-08 18:08:59 train 3000, loss 1.601e+00, top1 63.07, top5 83.83
2021-11-08 18:08:59 train 3000, loss 1.595e+00, top1 63.01, top5 83.92
2021-11-08 18:17:47 train 4000, loss 1.625e+00, top1 62.60, top5 83.44
2021-11-08 18:17:47 train 4000, loss 1.624e+00, top1 62.62, top5 83.50
2021-11-08 18:17:47 train 4000, loss 1.619e+00, top1 62.63, top5 83.58
2021-11-08 18:26:38 train 5000, loss 1.644e+00, top1 62.18, top5 83.18
2021-11-08 18:26:38 train 5000, loss 1.644e+00, top1 62.20, top5 83.22
2021-11-08 18:26:38 train 5000, loss 1.637e+00, top1 62.27, top5 83.31
2021-11-08 18:27:02 valid 0000, loss 1.103e+00, top1 82.35, top5 90.59
2021-11-08 18:27:02 valid 0000, loss 1.103e+00, top1 82.35, top5 90.59
2021-11-08 18:27:02 valid 0000, loss 1.103e+00, top1 82.35, top5 90.59
2021-11-08 18:31:15 (JOBID 31717) epoch 2: train time 2650.22, inference time 263.13s, valid_top1 57.99 (best_top1 63.95), valid_top5 81.44
2021-11-08 18:31:34 (JOBID 31717) epoch 2: train time 2650.93, inference time 282.00s, valid_top1 57.99 (best_top1 63.95), valid_top5 81.44
2021-11-08 18:31:34 (JOBID 31717) epoch 2: train time 2667.15, inference time 282.21s, valid_top1 57.99 (best_top1 63.95), valid_top5 81.44
2021-11-08 18:31:28 train 0000, loss 1.799e+00, top1 52.94, top5 82.35
2021-11-08 18:31:47 train 0000, loss 1.769e+00, top1 63.53, top5 80.00
2021-11-08 18:31:47 train 0000, loss 1.829e+00, top1 57.65, top5 84.71
2021-11-08 18:40:36 train 1000, loss 1.714e+00, top1 60.75, top5 82.45
2021-11-08 18:40:36 train 1000, loss 1.724e+00, top1 60.51, top5 82.29
2021-11-08 18:40:36 train 1000, loss 1.727e+00, top1 60.40, top5 82.09
2021-11-08 18:49:33 train 2000, loss 1.744e+00, top1 60.14, top5 81.97
2021-11-08 18:49:33 train 2000, loss 1.746e+00, top1 60.14, top5 81.96
2021-11-08 18:49:33 train 2000, loss 1.747e+00, top1 59.95, top5 81.81
2021-11-08 18:58:26 train 3000, loss 1.768e+00, top1 59.60, top5 81.56
2021-11-08 18:58:25 train 3000, loss 1.767e+00, top1 59.63, top5 81.67
2021-11-08 18:58:26 train 3000, loss 1.770e+00, top1 59.51, top5 81.50
2021-11-08 19:07:17 train 4000, loss 1.790e+00, top1 59.13, top5 81.20
2021-11-08 19:07:17 train 4000, loss 1.786e+00, top1 59.24, top5 81.37
2021-11-08 19:07:17 train 4000, loss 1.789e+00, top1 59.17, top5 81.27
2021-11-08 19:16:15 train 5000, loss 1.808e+00, top1 58.80, top5 81.00
2021-11-08 19:16:15 train 5000, loss 1.806e+00, top1 58.80, top5 81.06
2021-11-08 19:16:15 train 5000, loss 1.809e+00, top1 58.68, top5 80.93
2021-11-08 19:16:38 valid 0000, loss 9.868e-01, top1 78.82, top5 90.59
2021-11-08 19:16:38 valid 0000, loss 9.868e-01, top1 78.82, top5 90.59
2021-11-08 19:16:38 valid 0000, loss 9.868e-01, top1 78.82, top5 90.59
2021-11-08 19:21:13 (JOBID 31717) epoch 3: train time 2694.45, inference time 285.25s, valid_top1 57.85 (best_top1 63.95), valid_top5 81.67
2021-11-08 19:21:14 (JOBID 31717) epoch 3: train time 2713.21, inference time 285.74s, valid_top1 57.85 (best_top1 63.95), valid_top5 81.67
2021-11-08 19:21:14 (JOBID 31717) epoch 3: train time 2694.08, inference time 285.27s, valid_top1 57.85 (best_top1 63.95), valid_top5 81.67
2021-11-08 19:21:27 train 0000, loss 2.175e+00, top1 50.59, top5 74.12
2021-11-08 19:21:27 train 0000, loss 1.609e+00, top1 57.65, top5 82.35
2021-11-08 19:21:27 train 0000, loss 2.034e+00, top1 55.29, top5 74.12
2021-11-08 19:30:19 train 1000, loss 1.883e+00, top1 56.88, top5 79.87
2021-11-08 19:30:19 train 1000, loss 1.879e+00, top1 57.24, top5 80.03
2021-11-08 19:30:19 train 1000, loss 1.869e+00, top1 57.40, top5 80.12
2021-11-08 19:39:16 train 2000, loss 1.908e+00, top1 56.62, top5 79.57
2021-11-08 19:39:16 train 2000, loss 1.898e+00, top1 56.61, top5 79.64
2021-11-08 19:39:16 train 2000, loss 1.896e+00, top1 56.75, top5 79.68
2021-11-08 19:48:17 train 3000, loss 1.927e+00, top1 56.23, top5 79.28
2021-11-08 19:48:17 train 3000, loss 1.923e+00, top1 56.18, top5 79.25
2021-11-08 19:48:17 train 3000, loss 1.915e+00, top1 56.43, top5 79.37
2021-11-08 19:57:19 train 4000, loss 1.944e+00, top1 55.89, top5 78.97
2021-11-08 19:57:19 train 4000, loss 1.942e+00, top1 55.82, top5 78.96
2021-11-08 19:57:19 train 4000, loss 1.939e+00, top1 55.99, top5 79.02
2021-11-08 20:06:22 train 5000, loss 1.958e+00, top1 55.50, top5 78.76
2021-11-08 20:06:22 train 5000, loss 1.961e+00, top1 55.55, top5 78.70
2021-11-08 20:06:22 train 5000, loss 1.956e+00, top1 55.62, top5 78.77
2021-11-08 20:06:46 valid 0000, loss 6.443e-01, top1 85.88, top5 94.12
2021-11-08 20:06:46 valid 0000, loss 6.443e-01, top1 85.88, top5 94.12
2021-11-08 20:06:46 valid 0000, loss 6.443e-01, top1 85.88, top5 94.12
2021-11-08 20:11:10 (JOBID 31717) epoch 4: train time 2721.95, inference time 274.71s, valid_top1 57.42 (best_top1 63.95), valid_top5 81.43
2021-11-08 20:11:11 (JOBID 31717) epoch 4: train time 2721.97, inference time 275.16s, valid_top1 57.42 (best_top1 63.95), valid_top5 81.43
2021-11-08 20:11:11 (JOBID 31717) epoch 4: train time 2722.38, inference time 275.70s, valid_top1 57.42 (best_top1 63.95), valid_top5 81.43
2021-11-08 20:11:25 train 0000, loss 2.167e+00, top1 50.59, top5 75.29
2021-11-08 20:11:25 train 0000, loss 2.563e+00, top1 44.71, top5 71.76
2021-11-08 20:11:25 train 0000, loss 2.199e+00, top1 48.24, top5 77.65
2021-11-08 20:20:41 train 1000, loss 2.010e+00, top1 54.59, top5 77.84
2021-11-08 20:20:41 train 1000, loss 1.997e+00, top1 54.71, top5 78.17
2021-11-08 20:20:41 train 1000, loss 2.008e+00, top1 54.63, top5 77.89
2021-11-08 20:30:03 train 2000, loss 2.021e+00, top1 54.32, top5 77.76
2021-11-08 20:30:03 train 2000, loss 2.034e+00, top1 54.01, top5 77.50
2021-11-08 20:30:03 train 2000, loss 2.028e+00, top1 54.16, top5 77.69
2021-11-08 20:39:29 train 3000, loss 2.042e+00, top1 53.90, top5 77.42
2021-11-08 20:39:29 train 3000, loss 2.046e+00, top1 53.72, top5 77.33
2021-11-08 20:39:29 train 3000, loss 2.045e+00, top1 53.87, top5 77.38
2021-11-08 20:48:57 train 4000, loss 2.061e+00, top1 53.49, top5 77.13
2021-11-08 20:48:57 train 4000, loss 2.059e+00, top1 53.49, top5 77.13
2021-11-08 20:48:57 train 4000, loss 2.057e+00, top1 53.61, top5 77.20
2021-11-08 20:58:29 train 5000, loss 2.071e+00, top1 53.25, top5 76.96
2021-11-08 20:58:29 train 5000, loss 2.072e+00, top1 53.27, top5 76.95
2021-11-08 20:58:29 train 5000, loss 2.072e+00, top1 53.30, top5 76.97
2021-11-08 20:58:53 valid 0000, loss 1.167e+00, top1 76.47, top5 85.88
2021-11-08 20:58:53 valid 0000, loss 1.167e+00, top1 76.47, top5 85.88
2021-11-08 20:58:53 valid 0000, loss 1.167e+00, top1 76.47, top5 85.88
2021-11-08 21:03:22 (JOBID 31717) epoch 5: train time 2852.95, inference time 278.78s, valid_top1 53.68 (best_top1 63.95), valid_top5 79.06
2021-11-08 21:03:23 (JOBID 31717) epoch 5: train time 2851.97, inference time 279.37s, valid_top1 53.68 (best_top1 63.95), valid_top5 79.06
2021-11-08 21:03:24 (JOBID 31717) epoch 5: train time 2852.00, inference time 280.61s, valid_top1 53.68 (best_top1 63.95), valid_top5 79.06
2021-11-08 21:03:37 train 0000, loss 2.450e+00, top1 47.06, top5 71.76
2021-11-08 21:03:37 train 0000, loss 2.133e+00, top1 48.24, top5 75.29
2021-11-08 21:03:38 train 0000, loss 2.171e+00, top1 50.59, top5 76.47
2021-11-08 21:12:25 train 1000, loss 2.092e+00, top1 52.87, top5 76.54
2021-11-08 21:12:25 train 1000, loss 2.093e+00, top1 52.85, top5 76.63
2021-11-08 21:12:26 train 1000, loss 2.104e+00, top1 52.68, top5 76.33
2021-11-08 21:21:11 train 2000, loss 2.117e+00, top1 52.30, top5 76.24
2021-11-08 21:21:11 train 2000, loss 2.119e+00, top1 52.31, top5 76.14
2021-11-08 21:21:11 train 2000, loss 2.104e+00, top1 52.54, top5 76.40
2021-11-08 21:30:02 train 3000, loss 2.128e+00, top1 52.03, top5 76.13
2021-11-08 21:30:02 train 3000, loss 2.125e+00, top1 52.24, top5 76.09
2021-11-08 21:30:02 train 3000, loss 2.117e+00, top1 52.34, top5 76.19
2021-11-08 21:39:01 train 4000, loss 2.138e+00, top1 51.90, top5 75.95
2021-11-08 21:39:01 train 4000, loss 2.135e+00, top1 52.08, top5 75.91
2021-11-08 21:39:01 train 4000, loss 2.125e+00, top1 52.21, top5 76.06
2021-11-08 21:47:57 train 5000, loss 2.144e+00, top1 51.88, top5 75.78
2021-11-08 21:47:57 train 5000, loss 2.148e+00, top1 51.72, top5 75.77
2021-11-08 21:47:57 train 5000, loss 2.139e+00, top1 51.97, top5 75.88
2021-11-08 21:48:20 valid 0000, loss 1.117e+00, top1 78.82, top5 87.06
2021-11-08 21:48:20 valid 0000, loss 1.117e+00, top1 78.82, top5 87.06
2021-11-08 21:48:20 valid 0000, loss 1.117e+00, top1 78.82, top5 87.06
2021-11-08 21:52:40 (JOBID 31717) epoch 6: train time 2688.02, inference time 269.95s, valid_top1 53.83 (best_top1 63.95), valid_top5 79.19
2021-11-08 21:52:46 (JOBID 31717) epoch 6: train time 2687.24, inference time 275.56s, valid_top1 53.83 (best_top1 63.95), valid_top5 79.19
2021-11-08 21:52:49 (JOBID 31717) epoch 6: train time 2685.78, inference time 278.85s, valid_top1 53.83 (best_top1 63.95), valid_top5 79.19
2021-11-08 21:53:00 train 0000, loss 2.288e+00, top1 41.18, top5 74.12
2021-11-08 21:52:54 train 0000, loss 2.739e+00, top1 44.71, top5 71.76
2021-11-08 21:53:04 train 0000, loss 2.026e+00, top1 50.59, top5 76.47
2021-11-08 22:01:54 train 1000, loss 2.152e+00, top1 51.78, top5 75.71
2021-11-08 22:01:54 train 1000, loss 2.132e+00, top1 52.11, top5 75.85
2021-11-08 22:01:54 train 1000, loss 2.137e+00, top1 51.87, top5 75.98
2021-11-08 22:10:43 train 2000, loss 2.157e+00, top1 51.77, top5 75.60
2021-11-08 22:10:43 train 2000, loss 2.150e+00, top1 51.73, top5 75.70
2021-11-08 22:10:43 train 2000, loss 2.160e+00, top1 51.51, top5 75.59
2021-11-08 22:19:25 train 3000, loss 2.160e+00, top1 51.57, top5 75.58
2021-11-08 22:19:25 train 3000, loss 2.164e+00, top1 51.57, top5 75.52
2021-11-08 22:19:25 train 3000, loss 2.167e+00, top1 51.36, top5 75.51
2021-11-08 22:28:12 train 4000, loss 2.169e+00, top1 51.42, top5 75.41
2021-11-08 22:28:12 train 4000, loss 2.169e+00, top1 51.40, top5 75.42
2021-11-08 22:28:12 train 4000, loss 2.173e+00, top1 51.25, top5 75.38
2021-11-08 22:36:53 train 5000, loss 2.177e+00, top1 51.25, top5 75.32
2021-11-08 22:36:53 train 5000, loss 2.177e+00, top1 51.25, top5 75.29
2021-11-08 22:36:54 train 5000, loss 2.180e+00, top1 51.18, top5 75.30
2021-11-08 22:37:17 valid 0000, loss 1.076e+00, top1 81.18, top5 88.24
2021-11-08 22:37:17 valid 0000, loss 1.076e+00, top1 81.18, top5 88.24
2021-11-08 22:37:17 valid 0000, loss 1.076e+00, top1 81.18, top5 88.24
2021-11-08 22:41:44 (JOBID 31717) epoch 7: train time 2657.51, inference time 276.51s, valid_top1 51.74 (best_top1 63.95), valid_top5 77.35
2021-11-08 22:41:44 (JOBID 31717) epoch 7: train time 2666.68, inference time 276.92s, valid_top1 51.74 (best_top1 63.95), valid_top5 77.35
2021-11-08 22:41:45 (JOBID 31717) epoch 7: train time 2661.20, inference time 278.43s, valid_top1 51.74 (best_top1 63.95), valid_top5 77.35
2021-11-08 22:41:58 train 0000, loss 2.435e+00, top1 48.24, top5 68.24
2021-11-08 22:41:58 train 0000, loss 2.389e+00, top1 44.71, top5 69.41
2021-11-08 22:41:59 train 0000, loss 1.839e+00, top1 58.82, top5 77.65
2021-11-08 22:50:46 train 1000, loss 2.176e+00, top1 51.03, top5 75.36
2021-11-08 22:50:46 train 1000, loss 2.171e+00, top1 51.22, top5 75.50
2021-11-08 22:50:46 train 1000, loss 2.161e+00, top1 51.48, top5 75.76
2021-11-08 22:59:33 train 2000, loss 2.182e+00, top1 51.06, top5 75.26
2021-11-08 22:59:33 train 2000, loss 2.188e+00, top1 50.88, top5 75.18
2021-11-08 22:59:34 train 2000, loss 2.171e+00, top1 51.33, top5 75.47
2021-11-08 23:08:26 train 3000, loss 2.182e+00, top1 51.04, top5 75.32
2021-11-08 23:08:25 train 3000, loss 2.196e+00, top1 50.73, top5 74.99
2021-11-08 23:08:26 train 3000, loss 2.187e+00, top1 50.93, top5 75.19
2021-11-08 23:17:17 train 4000, loss 2.192e+00, top1 50.83, top5 75.12
2021-11-08 23:17:17 train 4000, loss 2.198e+00, top1 50.73, top5 74.99
2021-11-08 23:17:17 train 4000, loss 2.188e+00, top1 50.93, top5 75.19
2021-11-08 23:26:14 train 5000, loss 2.195e+00, top1 50.77, top5 75.05
2021-11-08 23:26:14 train 5000, loss 2.199e+00, top1 50.74, top5 75.02
2021-11-08 23:26:14 train 5000, loss 2.202e+00, top1 50.66, top5 74.94
2021-11-08 23:26:37 valid 0000, loss 1.064e+00, top1 74.12, top5 90.59
2021-11-08 23:26:37 valid 0000, loss 1.064e+00, top1 74.12, top5 90.59
2021-11-08 23:26:37 valid 0000, loss 1.064e+00, top1 74.12, top5 90.59
2021-11-08 23:31:01 (JOBID 31717) epoch 8: train time 2683.31, inference time 273.85s, valid_top1 51.51 (best_top1 63.95), valid_top5 77.15
2021-11-08 23:31:02 (JOBID 31717) epoch 8: train time 2681.56, inference time 275.46s, valid_top1 51.51 (best_top1 63.95), valid_top5 77.15
2021-11-08 23:31:04 (JOBID 31717) epoch 8: train time 2683.10, inference time 277.29s, valid_top1 51.51 (best_top1 63.95), valid_top5 77.15
2021-11-08 23:31:16 train 0000, loss 1.900e+00, top1 58.82, top5 76.47
2021-11-08 23:31:16 train 0000, loss 2.058e+00, top1 55.29, top5 77.65
2021-11-08 23:31:18 train 0000, loss 2.585e+00, top1 38.82, top5 71.76
2021-11-08 23:40:01 train 1000, loss 2.186e+00, top1 50.92, top5 75.20
2021-11-08 23:40:01 train 1000, loss 2.176e+00, top1 51.19, top5 75.38
2021-11-08 23:40:02 train 1000, loss 2.183e+00, top1 51.13, top5 75.18
2021-11-08 23:48:45 train 2000, loss 2.189e+00, top1 50.88, top5 75.23
2021-11-08 23:48:45 train 2000, loss 2.196e+00, top1 50.74, top5 75.08
2021-11-08 23:48:45 train 2000, loss 2.191e+00, top1 50.97, top5 75.10
2021-11-08 23:57:28 train 3000, loss 2.201e+00, top1 50.73, top5 75.01
2021-11-08 23:57:28 train 3000, loss 2.202e+00, top1 50.69, top5 74.95
2021-11-08 23:57:28 train 3000, loss 2.196e+00, top1 50.84, top5 74.98
2021-11-09 00:06:16 train 4000, loss 2.204e+00, top1 50.69, top5 74.90
2021-11-09 00:06:16 train 4000, loss 2.205e+00, top1 50.63, top5 74.93
2021-11-09 00:06:16 train 4000, loss 2.202e+00, top1 50.76, top5 74.92
2021-11-09 00:15:12 train 5000, loss 2.208e+00, top1 50.58, top5 74.85
2021-11-09 00:15:12 train 5000, loss 2.209e+00, top1 50.59, top5 74.82
2021-11-09 00:15:12 train 5000, loss 2.205e+00, top1 50.72, top5 74.85
2021-11-09 00:15:35 valid 0000, loss 1.024e+00, top1 76.47, top5 89.41
2021-11-09 00:15:35 valid 0000, loss 1.024e+00, top1 76.47, top5 89.41
2021-11-09 00:15:35 valid 0000, loss 1.024e+00, top1 76.47, top5 89.41
2021-11-09 00:19:52 (JOBID 31717) epoch 9: train time 2661.02, inference time 266.82s, valid_top1 51.49 (best_top1 63.95), valid_top5 76.97
2021-11-09 00:20:03 (JOBID 31717) epoch 9: train time 2663.00, inference time 277.28s, valid_top1 51.49 (best_top1 63.95), valid_top5 76.97
2021-11-09 00:20:04 (JOBID 31717) epoch 9: train time 2664.17, inference time 278.78s, valid_top1 51.49 (best_top1 63.95), valid_top5 76.97
2021-11-09 00:20:18 train 0000, loss 1.994e+00, top1 57.65, top5 76.47
2021-11-09 00:20:06 train 0000, loss 2.253e+00, top1 43.53, top5 76.47
2021-11-09 00:20:19 train 0000, loss 2.118e+00, top1 56.47, top5 76.47
2021-11-09 00:29:32 train 1000, loss 2.207e+00, top1 50.70, top5 74.80
2021-11-09 00:29:32 train 1000, loss 2.196e+00, top1 50.95, top5 75.19
2021-11-09 00:29:33 train 1000, loss 2.201e+00, top1 50.76, top5 75.06
2021-11-09 00:38:52 train 2000, loss 2.203e+00, top1 50.67, top5 74.92
2021-11-09 00:38:52 train 2000, loss 2.204e+00, top1 50.70, top5 74.85
2021-11-09 00:38:52 train 2000, loss 2.204e+00, top1 50.71, top5 74.96
2021-11-09 00:48:16 train 3000, loss 2.209e+00, top1 50.64, top5 74.86
2021-11-09 00:48:16 train 3000, loss 2.212e+00, top1 50.58, top5 74.83
2021-11-09 00:48:16 train 3000, loss 2.211e+00, top1 50.57, top5 74.74
2021-11-09 00:57:40 train 4000, loss 2.213e+00, top1 50.48, top5 74.80
2021-11-09 00:57:41 train 4000, loss 2.214e+00, top1 50.51, top5 74.74
2021-11-09 00:57:41 train 4000, loss 2.213e+00, top1 50.56, top5 74.74
2021-11-09 01:07:10 train 5000, loss 2.215e+00, top1 50.49, top5 74.73
2021-11-09 01:07:10 train 5000, loss 2.217e+00, top1 50.50, top5 74.66
2021-11-09 01:07:10 train 5000, loss 2.215e+00, top1 50.45, top5 74.74
2021-11-09 01:07:34 valid 0000, loss 1.234e+00, top1 78.82, top5 85.88
2021-11-09 01:07:34 valid 0000, loss 1.234e+00, top1 78.82, top5 85.88
2021-11-09 01:07:34 valid 0000, loss 1.234e+00, top1 78.82, top5 85.88
2021-11-09 01:12:07 (JOBID 31717) epoch 10: train time 2852.24, inference time 282.50s, valid_top1 51.68 (best_top1 63.95), valid_top5 77.15
2021-11-09 01:12:10 (JOBID 31717) epoch 10: train time 2839.83, inference time 285.88s, valid_top1 51.68 (best_top1 63.95), valid_top5 77.15
2021-11-09 01:12:10 (JOBID 31717) epoch 10: train time 2841.43, inference time 286.42s, valid_top1 51.68 (best_top1 63.95), valid_top5 77.15
2021-11-09 01:12:24 train 0000, loss 2.201e+00, top1 49.41, top5 70.59
2021-11-09 01:12:22 train 0000, loss 2.347e+00, top1 52.94, top5 67.06
2021-11-09 01:12:24 train 0000, loss 2.348e+00, top1 48.24, top5 75.29
2021-11-09 01:21:39 train 1000, loss 2.181e+00, top1 50.87, top5 75.15
2021-11-09 01:21:39 train 1000, loss 2.207e+00, top1 50.48, top5 74.77
2021-11-09 01:21:39 train 1000, loss 2.206e+00, top1 50.49, top5 75.00
2021-11-09 01:30:59 train 2000, loss 2.206e+00, top1 50.60, top5 74.95
2021-11-09 01:30:59 train 2000, loss 2.214e+00, top1 50.40, top5 74.65
2021-11-09 01:30:59 train 2000, loss 2.195e+00, top1 50.72, top5 74.96
2021-11-09 01:40:20 train 3000, loss 2.214e+00, top1 50.46, top5 74.79
2021-11-09 01:40:20 train 3000, loss 2.216e+00, top1 50.42, top5 74.64
2021-11-09 01:40:20 train 3000, loss 2.200e+00, top1 50.67, top5 74.93
2021-11-09 01:49:43 train 4000, loss 2.220e+00, top1 50.34, top5 74.60
2021-11-09 01:49:43 train 4000, loss 2.209e+00, top1 50.56, top5 74.79
2021-11-09 01:49:44 train 4000, loss 2.216e+00, top1 50.44, top5 74.71
2021-11-09 01:59:12 train 5000, loss 2.220e+00, top1 50.35, top5 74.65
2021-11-09 01:59:12 train 5000, loss 2.221e+00, top1 50.33, top5 74.61
2021-11-09 01:59:12 train 5000, loss 2.213e+00, top1 50.46, top5 74.72
2021-11-09 01:59:35 valid 0000, loss 8.944e-01, top1 83.53, top5 91.76
2021-11-09 01:59:36 valid 0000, loss 8.944e-01, top1 83.53, top5 91.76
2021-11-09 01:59:36 valid 0000, loss 8.944e-01, top1 83.53, top5 91.76
2021-11-09 02:04:05 (JOBID 31717) epoch 11: train time 2839.15, inference time 279.52s, valid_top1 50.46 (best_top1 63.95), valid_top5 76.46
2021-11-09 02:04:05 (JOBID 31717) epoch 11: train time 2835.18, inference time 279.71s, valid_top1 50.46 (best_top1 63.95), valid_top5 76.46
2021-11-09 02:04:06 (JOBID 31717) epoch 11: train time 2835.50, inference time 279.90s, valid_top1 50.46 (best_top1 63.95), valid_top5 76.46
2021-11-09 02:04:19 train 0000, loss 2.476e+00, top1 47.06, top5 72.94
2021-11-09 02:04:19 train 0000, loss 2.493e+00, top1 47.06, top5 68.24
2021-11-09 02:04:19 train 0000, loss 1.916e+00, top1 55.29, top5 80.00
2021-11-09 02:13:37 train 1000, loss 2.196e+00, top1 50.73, top5 74.88
2021-11-09 02:13:37 train 1000, loss 2.191e+00, top1 50.80, top5 75.25
2021-11-09 02:13:37 train 1000, loss 2.205e+00, top1 50.56, top5 74.81
2021-11-09 02:22:56 train 2000, loss 2.202e+00, top1 50.66, top5 74.84
2021-11-09 02:22:56 train 2000, loss 2.205e+00, top1 50.51, top5 74.98
2021-11-09 02:22:56 train 2000, loss 2.210e+00, top1 50.51, top5 74.79
2021-11-09 02:32:16 train 3000, loss 2.210e+00, top1 50.46, top5 74.88
2021-11-09 02:32:16 train 3000, loss 2.211e+00, top1 50.50, top5 74.68
2021-11-09 02:32:16 train 3000, loss 2.212e+00, top1 50.45, top5 74.75
2021-11-09 02:41:42 train 4000, loss 2.218e+00, top1 50.38, top5 74.67
2021-11-09 02:41:42 train 4000, loss 2.214e+00, top1 50.38, top5 74.84
2021-11-09 02:41:43 train 4000, loss 2.217e+00, top1 50.41, top5 74.60
2021-11-09 02:51:11 train 5000, loss 2.218e+00, top1 50.33, top5 74.76
2021-11-09 02:51:11 train 5000, loss 2.220e+00, top1 50.36, top5 74.61
2021-11-09 02:51:12 train 5000, loss 2.221e+00, top1 50.32, top5 74.65
2021-11-09 02:51:35 valid 0000, loss 1.053e+00, top1 77.65, top5 88.24
2021-11-09 02:51:35 valid 0000, loss 1.053e+00, top1 77.65, top5 88.24
2021-11-09 02:51:35 valid 0000, loss 1.053e+00, top1 77.65, top5 88.24
2021-11-09 02:55:48 (JOBID 31717) epoch 12: train time 2840.03, inference time 262.61s, valid_top1 53.30 (best_top1 63.95), valid_top5 78.75
2021-11-09 02:56:04 (JOBID 31717) epoch 12: train time 2839.51, inference time 278.77s, valid_top1 53.30 (best_top1 63.95), valid_top5 78.75
2021-11-09 02:56:05 (JOBID 31717) epoch 12: train time 2839.92, inference time 279.34s, valid_top1 53.30 (best_top1 63.95), valid_top5 78.75
2021-11-09 02:56:01 train 0000, loss 2.141e+00, top1 57.65, top5 75.29
2021-11-09 02:56:18 train 0000, loss 1.964e+00, top1 55.29, top5 77.65
2021-11-09 02:56:18 train 0000, loss 2.122e+00, top1 52.94, top5 77.65
2021-11-09 03:05:10 train 1000, loss 2.210e+00, top1 50.46, top5 74.84
2021-11-09 03:05:10 train 1000, loss 2.194e+00, top1 50.99, top5 74.99
2021-11-09 03:05:10 train 1000, loss 2.203e+00, top1 50.83, top5 74.88
2021-11-09 03:14:02 train 2000, loss 2.211e+00, top1 50.43, top5 74.91
2021-11-09 03:14:02 train 2000, loss 2.210e+00, top1 50.64, top5 74.79
2021-11-09 03:14:02 train 2000, loss 2.210e+00, top1 50.58, top5 74.80
2021-11-09 03:23:02 train 3000, loss 2.216e+00, top1 50.46, top5 74.71
2021-11-09 03:23:02 train 3000, loss 2.217e+00, top1 50.37, top5 74.79
2021-11-09 03:23:02 train 3000, loss 2.216e+00, top1 50.44, top5 74.67
2021-11-09 03:31:55 train 4000, loss 2.221e+00, top1 50.37, top5 74.61
2021-11-09 03:31:55 train 4000, loss 2.224e+00, top1 50.26, top5 74.69
2021-11-09 03:31:55 train 4000, loss 2.221e+00, top1 50.37, top5 74.59
2021-11-09 03:40:46 train 5000, loss 2.222e+00, top1 50.32, top5 74.59
2021-11-09 03:40:46 train 5000, loss 2.225e+00, top1 50.22, top5 74.63
2021-11-09 03:40:46 train 5000, loss 2.222e+00, top1 50.35, top5 74.58
2021-11-09 03:41:09 valid 0000, loss 9.211e-01, top1 81.18, top5 94.12
2021-11-09 03:41:09 valid 0000, loss 9.211e-01, top1 81.18, top5 94.12
2021-11-09 03:41:09 valid 0000, loss 9.211e-01, top1 81.18, top5 94.12
2021-11-09 03:45:27 (JOBID 31717) epoch 13: train time 2711.59, inference time 267.60s, valid_top1 51.65 (best_top1 63.95), valid_top5 77.29
2021-11-09 03:45:34 (JOBID 31717) epoch 13: train time 2694.75, inference time 274.38s, valid_top1 51.65 (best_top1 63.95), valid_top5 77.29
2021-11-09 03:45:41 (JOBID 31717) epoch 13: train time 2695.13, inference time 280.94s, valid_top1 51.65 (best_top1 63.95), valid_top5 77.29
2021-11-09 03:45:48 train 0000, loss 2.371e+00, top1 40.00, top5 71.76
2021-11-09 03:45:41 train 0000, loss 1.904e+00, top1 56.47, top5 80.00
2021-11-09 03:45:54 train 0000, loss 2.316e+00, top1 52.94, top5 71.76
2021-11-09 03:54:42 train 1000, loss 2.199e+00, top1 50.74, top5 74.79
2021-11-09 03:54:42 train 1000, loss 2.200e+00, top1 50.66, top5 74.92
2021-11-09 03:54:43 train 1000, loss 2.201e+00, top1 50.59, top5 74.94
2021-11-09 04:03:35 train 2000, loss 2.209e+00, top1 50.59, top5 74.85
2021-11-09 04:03:35 train 2000, loss 2.207e+00, top1 50.57, top5 74.80
2021-11-09 04:03:35 train 2000, loss 2.211e+00, top1 50.45, top5 74.72
2021-11-09 04:12:32 train 3000, loss 2.215e+00, top1 50.43, top5 74.68
2021-11-09 04:12:32 train 3000, loss 2.212e+00, top1 50.51, top5 74.80
2021-11-09 04:12:32 train 3000, loss 2.210e+00, top1 50.45, top5 74.74
2021-11-09 04:21:24 train 4000, loss 2.214e+00, top1 50.46, top5 74.76
2021-11-09 04:21:24 train 4000, loss 2.219e+00, top1 50.33, top5 74.63
2021-11-09 04:21:25 train 4000, loss 2.215e+00, top1 50.37, top5 74.68
2021-11-09 04:30:18 train 5000, loss 2.219e+00, top1 50.37, top5 74.65
2021-11-09 04:30:18 train 5000, loss 2.222e+00, top1 50.29, top5 74.57
2021-11-09 04:30:18 train 5000, loss 2.219e+00, top1 50.30, top5 74.64
2021-11-09 04:30:41 valid 0000, loss 9.057e-01, top1 81.18, top5 91.76
2021-11-09 04:30:41 valid 0000, loss 9.057e-01, top1 81.18, top5 91.76
2021-11-09 04:30:41 valid 0000, loss 9.057e-01, top1 81.18, top5 91.76
2021-11-09 04:34:55 (JOBID 31717) epoch 14: train time 2690.79, inference time 263.82s, valid_top1 51.77 (best_top1 63.95), valid_top5 77.28
2021-11-09 04:35:10 (JOBID 31717) epoch 14: train time 2704.23, inference time 278.54s, valid_top1 51.77 (best_top1 63.95), valid_top5 77.28
2021-11-09 04:35:10 (JOBID 31717) epoch 14: train time 2697.56, inference time 278.90s, valid_top1 51.77 (best_top1 63.95), valid_top5 77.28
2021-11-09 04:35:09 train 0000, loss 2.036e+00, top1 56.47, top5 75.29
2021-11-09 04:35:23 train 0000, loss 2.246e+00, top1 56.47, top5 74.12
2021-11-09 04:35:23 train 0000, loss 1.881e+00, top1 60.00, top5 78.82
2021-11-09 04:44:38 train 1000, loss 2.180e+00, top1 50.88, top5 75.28
2021-11-09 04:44:38 train 1000, loss 2.206e+00, top1 50.46, top5 74.93
2021-11-09 04:44:38 train 1000, loss 2.197e+00, top1 50.68, top5 74.95
2021-11-09 04:53:59 train 2000, loss 2.209e+00, top1 50.52, top5 74.77
2021-11-09 04:53:59 train 2000, loss 2.202e+00, top1 50.45, top5 74.90
2021-11-09 04:53:59 train 2000, loss 2.216e+00, top1 50.41, top5 74.73
2021-11-09 05:03:25 train 3000, loss 2.220e+00, top1 50.27, top5 74.65
2021-11-09 05:03:25 train 3000, loss 2.209e+00, top1 50.47, top5 74.75
2021-11-09 05:03:25 train 3000, loss 2.216e+00, top1 50.36, top5 74.68
2021-11-09 05:12:49 train 4000, loss 2.219e+00, top1 50.30, top5 74.64
2021-11-09 05:12:49 train 4000, loss 2.215e+00, top1 50.37, top5 74.68
2021-11-09 05:12:49 train 4000, loss 2.223e+00, top1 50.22, top5 74.53
2021-11-09 05:22:14 train 5000, loss 2.222e+00, top1 50.22, top5 74.58
2021-11-09 05:22:14 train 5000, loss 2.218e+00, top1 50.32, top5 74.63
2021-11-09 05:22:15 train 5000, loss 2.225e+00, top1 50.20, top5 74.51
2021-11-09 05:22:39 valid 0000, loss 1.010e+00, top1 80.00, top5 85.88
2021-11-09 05:22:39 valid 0000, loss 1.010e+00, top1 80.00, top5 85.88
2021-11-09 05:22:39 valid 0000, loss 1.010e+00, top1 80.00, top5 85.88
2021-11-09 05:27:08 (JOBID 31717) epoch 15: train time 2838.33, inference time 279.90s, valid_top1 52.19 (best_top1 63.95), valid_top5 77.95
2021-11-09 05:27:09 (JOBID 31717) epoch 15: train time 2838.53, inference time 280.09s, valid_top1 52.19 (best_top1 63.95), valid_top5 77.95
2021-11-09 05:27:09 (JOBID 31717) epoch 15: train time 2853.13, inference time 279.96s, valid_top1 52.19 (best_top1 63.95), valid_top5 77.95
2021-11-09 05:27:23 train 0000, loss 1.954e+00, top1 52.94, top5 74.12
2021-11-09 05:27:23 train 0000, loss 2.063e+00, top1 51.76, top5 77.65
2021-11-09 05:27:23 train 0000, loss 2.045e+00, top1 52.94, top5 80.00
2021-11-09 05:36:20 train 1000, loss 2.194e+00, top1 50.62, top5 74.96
2021-11-09 05:36:20 train 1000, loss 2.202e+00, top1 50.53, top5 74.82
2021-11-09 05:36:20 train 1000, loss 2.198e+00, top1 50.69, top5 74.96
2021-11-09 05:45:08 train 2000, loss 2.207e+00, top1 50.53, top5 74.74
2021-11-09 05:45:08 train 2000, loss 2.207e+00, top1 50.34, top5 74.81
2021-11-09 05:45:08 train 2000, loss 2.209e+00, top1 50.56, top5 74.73
2021-11-09 05:53:57 train 3000, loss 2.216e+00, top1 50.22, top5 74.66
2021-11-09 05:53:57 train 3000, loss 2.213e+00, top1 50.42, top5 74.68
2021-11-09 05:53:57 train 3000, loss 2.214e+00, top1 50.42, top5 74.65
2021-11-09 06:02:57 train 4000, loss 2.217e+00, top1 50.37, top5 74.64
2021-11-09 06:02:57 train 4000, loss 2.219e+00, top1 50.36, top5 74.52
2021-11-09 06:02:57 train 4000, loss 2.222e+00, top1 50.18, top5 74.58
2021-11-09 06:11:56 train 5000, loss 2.220e+00, top1 50.35, top5 74.54
2021-11-09 06:11:56 train 5000, loss 2.218e+00, top1 50.40, top5 74.60
2021-11-09 06:11:56 train 5000, loss 2.224e+00, top1 50.14, top5 74.57
2021-11-09 06:12:19 valid 0000, loss 7.130e-01, top1 84.71, top5 94.12
2021-11-09 06:12:19 valid 0000, loss 7.130e-01, top1 84.71, top5 94.12
2021-11-09 06:12:19 valid 0000, loss 7.130e-01, top1 84.71, top5 94.12
2021-11-09 06:16:43 (JOBID 31717) epoch 16: train time 2700.60, inference time 274.24s, valid_top1 52.20 (best_top1 63.95), valid_top5 77.93
2021-11-09 06:16:44 (JOBID 31717) epoch 16: train time 2700.46, inference time 275.48s, valid_top1 52.20 (best_top1 63.95), valid_top5 77.93
2021-11-09 06:16:45 (JOBID 31717) epoch 16: train time 2700.27, inference time 276.25s, valid_top1 52.20 (best_top1 63.95), valid_top5 77.93
2021-11-09 06:16:58 train 0000, loss 1.912e+00, top1 60.00, top5 78.82
2021-11-09 06:16:59 train 0000, loss 2.405e+00, top1 49.41, top5 71.76
2021-11-09 06:16:59 train 0000, loss 2.134e+00, top1 45.88, top5 74.12
2021-11-09 06:25:56 train 1000, loss 2.203e+00, top1 50.60, top5 74.90
2021-11-09 06:25:56 train 1000, loss 2.199e+00, top1 50.50, top5 75.08
2021-11-09 06:25:56 train 1000, loss 2.204e+00, top1 50.44, top5 74.91
2021-11-09 06:34:50 train 2000, loss 2.213e+00, top1 50.36, top5 74.78
2021-11-09 06:34:50 train 2000, loss 2.215e+00, top1 50.51, top5 74.65
2021-11-09 06:34:50 train 2000, loss 2.210e+00, top1 50.45, top5 74.68
2021-11-09 06:43:44 train 3000, loss 2.214e+00, top1 50.43, top5 74.65
2021-11-09 06:43:44 train 3000, loss 2.220e+00, top1 50.22, top5 74.63
2021-11-09 06:43:44 train 3000, loss 2.216e+00, top1 50.49, top5 74.59
2021-11-09 06:52:45 train 4000, loss 2.223e+00, top1 50.20, top5 74.60
2021-11-09 06:52:45 train 4000, loss 2.217e+00, top1 50.36, top5 74.63
2021-11-09 06:52:45 train 4000, loss 2.219e+00, top1 50.46, top5 74.55
2021-11-09 07:01:46 train 5000, loss 2.217e+00, top1 50.35, top5 74.65
2021-11-09 07:01:46 train 5000, loss 2.226e+00, top1 50.14, top5 74.55
2021-11-09 07:01:46 train 5000, loss 2.222e+00, top1 50.37, top5 74.53
2021-11-09 07:02:10 valid 0000, loss 8.550e-01, top1 84.71, top5 92.94
2021-11-09 07:02:10 valid 0000, loss 8.550e-01, top1 84.71, top5 92.94
2021-11-09 07:02:10 valid 0000, loss 8.550e-01, top1 84.71, top5 92.94
2021-11-09 07:06:28 (JOBID 31717) epoch 17: train time 2716.22, inference time 268.34s, valid_top1 50.88 (best_top1 63.95), valid_top5 76.46
2021-11-09 07:06:38 (JOBID 31717) epoch 17: train time 2715.10, inference time 278.34s, valid_top1 50.88 (best_top1 63.95), valid_top5 76.46
2021-11-09 07:06:40 (JOBID 31717) epoch 17: train time 2714.12, inference time 280.29s, valid_top1 50.88 (best_top1 63.95), valid_top5 76.46
2021-11-09 07:06:42 train 0000, loss 2.584e+00, top1 48.24, top5 67.06
2021-11-09 07:06:52 train 0000, loss 2.486e+00, top1 45.88, top5 74.12
2021-11-09 07:06:54 train 0000, loss 1.863e+00, top1 51.76, top5 83.53
2021-11-09 07:15:44 train 1000, loss 2.203e+00, top1 50.73, top5 74.77
2021-11-09 07:15:44 train 1000, loss 2.204e+00, top1 50.56, top5 74.69
2021-11-09 07:15:44 train 1000, loss 2.214e+00, top1 50.34, top5 74.57
2021-11-09 07:24:38 train 2000, loss 2.208e+00, top1 50.50, top5 74.72
2021-11-09 07:24:38 train 2000, loss 2.210e+00, top1 50.61, top5 74.78
2021-11-09 07:24:38 train 2000, loss 2.217e+00, top1 50.44, top5 74.57
2021-11-09 07:33:35 train 3000, loss 2.209e+00, top1 50.61, top5 74.82
2021-11-09 07:33:35 train 3000, loss 2.208e+00, top1 50.49, top5 74.72
2021-11-09 07:33:35 train 3000, loss 2.216e+00, top1 50.45, top5 74.68
2021-11-09 07:42:38 train 4000, loss 2.221e+00, top1 50.36, top5 74.55
2021-11-09 07:42:38 train 4000, loss 2.216e+00, top1 50.35, top5 74.59
2021-11-09 07:42:38 train 4000, loss 2.215e+00, top1 50.45, top5 74.72
2021-11-09 07:51:44 train 5000, loss 2.218e+00, top1 50.34, top5 74.59
2021-11-09 07:51:44 train 5000, loss 2.221e+00, top1 50.33, top5 74.56
2021-11-09 07:51:44 train 5000, loss 2.219e+00, top1 50.35, top5 74.67
2021-11-09 07:52:08 valid 0000, loss 1.394e+00, top1 77.65, top5 83.53
2021-11-09 07:52:08 valid 0000, loss 1.394e+00, top1 77.65, top5 83.53
2021-11-09 07:52:08 valid 0000, loss 1.394e+00, top1 77.65, top5 83.53
2021-11-09 07:56:24 (JOBID 31717) epoch 18: train time 2729.84, inference time 266.64s, valid_top1 50.17 (best_top1 63.95), valid_top5 76.08
2021-11-09 07:56:30 (JOBID 31717) epoch 18: train time 2719.80, inference time 271.96s, valid_top1 50.17 (best_top1 63.95), valid_top5 76.08
2021-11-09 07:56:38 (JOBID 31717) epoch 18: train time 2717.56, inference time 280.50s, valid_top1 50.17 (best_top1 63.95), valid_top5 76.08
2021-11-09 07:56:44 train 0000, loss 2.346e+00, top1 47.06, top5 69.41
2021-11-09 07:56:38 train 0000, loss 2.059e+00, top1 48.24, top5 77.65
2021-11-09 07:56:52 train 0000, loss 2.131e+00, top1 52.94, top5 76.47
2021-11-09 08:05:47 train 1000, loss 2.184e+00, top1 50.99, top5 75.17
2021-11-09 08:05:47 train 1000, loss 2.199e+00, top1 50.57, top5 74.94
2021-11-09 08:05:47 train 1000, loss 2.201e+00, top1 50.62, top5 74.79
2021-11-09 08:14:53 train 2000, loss 2.210e+00, top1 50.42, top5 74.74
2021-11-09 08:14:53 train 2000, loss 2.198e+00, top1 50.80, top5 74.91
2021-11-09 08:14:53 train 2000, loss 2.210e+00, top1 50.53, top5 74.75
2021-11-09 08:23:51 train 3000, loss 2.206e+00, top1 50.64, top5 74.81
2021-11-09 08:23:51 train 3000, loss 2.220e+00, top1 50.25, top5 74.58
2021-11-09 08:23:51 train 3000, loss 2.221e+00, top1 50.35, top5 74.58
2021-11-09 08:32:53 train 4000, loss 2.211e+00, top1 50.54, top5 74.74
2021-11-09 08:32:53 train 4000, loss 2.220e+00, top1 50.27, top5 74.59
2021-11-09 08:32:53 train 4000, loss 2.223e+00, top1 50.26, top5 74.55
2021-11-09 08:41:52 train 5000, loss 2.222e+00, top1 50.24, top5 74.56
2021-11-09 08:41:52 train 5000, loss 2.218e+00, top1 50.43, top5 74.62
2021-11-09 08:41:52 train 5000, loss 2.224e+00, top1 50.25, top5 74.56
2021-11-09 08:42:16 valid 0000, loss 2.050e+00, top1 57.65, top5 76.47
2021-11-09 08:42:16 valid 0000, loss 2.050e+00, top1 57.65, top5 76.47
2021-11-09 08:42:16 valid 0000, loss 2.050e+00, top1 57.65, top5 76.47
2021-11-09 08:46:44 (JOBID 31717) epoch 19: train time 2736.08, inference time 278.50s, valid_top1 48.81 (best_top1 63.95), valid_top5 74.79
2021-11-09 08:46:46 (JOBID 31717) epoch 19: train time 2741.37, inference time 279.86s, valid_top1 48.81 (best_top1 63.95), valid_top5 74.79
2021-11-09 08:46:46 (JOBID 31717) epoch 19: train time 2727.38, inference time 279.78s, valid_top1 48.81 (best_top1 63.95), valid_top5 74.79
2021-11-09 08:46:59 train 0000, loss 2.426e+00, top1 49.41, top5 71.76
2021-11-09 08:46:59 train 0000, loss 2.267e+00, top1 48.24, top5 70.59
2021-11-09 08:46:59 train 0000, loss 2.088e+00, top1 47.06, top5 81.18
2021-11-09 08:56:18 train 1000, loss 2.202e+00, top1 50.44, top5 74.92
2021-11-09 08:56:18 train 1000, loss 2.199e+00, top1 50.68, top5 75.00
2021-11-09 08:56:18 train 1000, loss 2.211e+00, top1 50.38, top5 74.89
2021-11-09 09:05:35 train 2000, loss 2.217e+00, top1 50.33, top5 74.75
2021-11-09 09:05:35 train 2000, loss 2.210e+00, top1 50.42, top5 74.76
2021-11-09 09:05:35 train 2000, loss 2.199e+00, top1 50.70, top5 75.00
2021-11-09 09:14:56 train 3000, loss 2.220e+00, top1 50.28, top5 74.61
2021-11-09 09:14:56 train 3000, loss 2.202e+00, top1 50.64, top5 74.91
2021-11-09 09:14:56 train 3000, loss 2.216e+00, top1 50.37, top5 74.68
2021-11-09 09:24:16 train 4000, loss 2.223e+00, top1 50.29, top5 74.59
2021-11-09 09:24:15 train 4000, loss 2.221e+00, top1 50.31, top5 74.57
2021-11-09 09:24:16 train 4000, loss 2.209e+00, top1 50.50, top5 74.81
2021-11-09 09:33:38 train 5000, loss 2.227e+00, top1 50.21, top5 74.53
2021-11-09 09:33:38 train 5000, loss 2.227e+00, top1 50.21, top5 74.45
2021-11-09 09:33:38 train 5000, loss 2.214e+00, top1 50.41, top5 74.75
2021-11-09 09:34:02 valid 0000, loss 1.232e+00, top1 75.29, top5 87.06
2021-11-09 09:34:02 valid 0000, loss 1.232e+00, top1 75.29, top5 87.06
2021-11-09 09:34:02 valid 0000, loss 1.232e+00, top1 75.29, top5 87.06
2021-11-09 09:38:29 (JOBID 31717) epoch 20: train time 2826.10, inference time 276.67s, valid_top1 50.19 (best_top1 63.95), valid_top5 76.24
2021-11-09 09:38:29 (JOBID 31717) epoch 20: train time 2826.07, inference time 277.33s, valid_top1 50.19 (best_top1 63.95), valid_top5 76.24
2021-11-09 09:38:32 (JOBID 31717) epoch 20: train time 2827.50, inference time 280.36s, valid_top1 50.19 (best_top1 63.95), valid_top5 76.24
2021-11-09 09:38:43 train 0000, loss 2.379e+00, top1 45.88, top5 71.76
2021-11-09 09:38:43 train 0000, loss 2.114e+00, top1 45.88, top5 77.65
2021-11-09 09:38:46 train 0000, loss 1.951e+00, top1 51.76, top5 83.53
2021-11-09 09:48:10 train 1000, loss 2.205e+00, top1 50.80, top5 74.93
2021-11-09 09:48:10 train 1000, loss 2.191e+00, top1 50.78, top5 75.03
2021-11-09 09:48:10 train 1000, loss 2.183e+00, top1 50.88, top5 75.30
2021-11-09 09:57:32 train 2000, loss 2.209e+00, top1 50.64, top5 74.81
2021-11-09 09:57:32 train 2000, loss 2.199e+00, top1 50.58, top5 75.03
2021-11-09 09:57:32 train 2000, loss 2.203e+00, top1 50.55, top5 74.85
2021-11-09 10:06:59 train 3000, loss 2.205e+00, top1 50.49, top5 74.88
2021-11-09 10:07:00 train 3000, loss 2.206e+00, top1 50.52, top5 74.87
2021-11-09 10:07:00 train 3000, loss 2.212e+00, top1 50.56, top5 74.71
2021-11-09 10:16:18 train 4000, loss 2.218e+00, top1 50.45, top5 74.64
2021-11-09 10:16:18 train 4000, loss 2.213e+00, top1 50.31, top5 74.76
2021-11-09 10:16:18 train 4000, loss 2.211e+00, top1 50.46, top5 74.80
2021-11-09 10:25:42 train 5000, loss 2.221e+00, top1 50.40, top5 74.59
2021-11-09 10:25:42 train 5000, loss 2.217e+00, top1 50.27, top5 74.72
2021-11-09 10:25:42 train 5000, loss 2.219e+00, top1 50.32, top5 74.70
2021-11-09 10:26:06 valid 0000, loss 8.696e-01, top1 82.35, top5 89.41
2021-11-09 10:26:06 valid 0000, loss 8.696e-01, top1 82.35, top5 89.41
2021-11-09 10:26:06 valid 0000, loss 8.696e-01, top1 82.35, top5 89.41
2021-11-09 10:30:27 (JOBID 31717) epoch 21: train time 2846.73, inference time 271.41s, valid_top1 54.18 (best_top1 63.95), valid_top5 79.14
2021-11-09 10:30:35 (JOBID 31717) epoch 21: train time 2846.98, inference time 278.78s, valid_top1 54.18 (best_top1 63.95), valid_top5 79.14
2021-11-09 10:30:35 (JOBID 31717) epoch 21: train time 2843.51, inference time 279.48s, valid_top1 54.18 (best_top1 63.95), valid_top5 79.14
2021-11-09 10:30:48 train 0000, loss 2.351e+00, top1 54.12, top5 75.29
2021-11-09 10:30:42 train 0000, loss 2.147e+00, top1 47.06, top5 76.47
2021-11-09 10:30:49 train 0000, loss 2.239e+00, top1 55.29, top5 72.94
2021-11-09 10:39:56 train 1000, loss 2.196e+00, top1 50.66, top5 75.15
2021-11-09 10:39:56 train 1000, loss 2.196e+00, top1 50.63, top5 75.17
2021-11-09 10:39:56 train 1000, loss 2.194e+00, top1 50.92, top5 75.12
2021-11-09 10:49:04 train 2000, loss 2.205e+00, top1 50.53, top5 74.92
2021-11-09 10:49:05 train 2000, loss 2.209e+00, top1 50.44, top5 74.86
2021-11-09 10:49:05 train 2000, loss 2.208e+00, top1 50.58, top5 74.95
2021-11-09 10:58:13 train 3000, loss 2.214e+00, top1 50.35, top5 74.81
2021-11-09 10:58:13 train 3000, loss 2.212e+00, top1 50.46, top5 74.79
2021-11-09 10:58:13 train 3000, loss 2.211e+00, top1 50.51, top5 74.81
2021-11-09 11:07:17 train 4000, loss 2.217e+00, top1 50.38, top5 74.73
2021-11-09 11:07:18 train 4000, loss 2.216e+00, top1 50.42, top5 74.71
2021-11-09 11:07:18 train 4000, loss 2.218e+00, top1 50.29, top5 74.76
2021-11-09 11:16:29 train 5000, loss 2.222e+00, top1 50.21, top5 74.67
2021-11-09 11:16:29 train 5000, loss 2.221e+00, top1 50.36, top5 74.64
2021-11-09 11:16:29 train 5000, loss 2.223e+00, top1 50.30, top5 74.63
2021-11-09 11:16:54 valid 0000, loss 1.041e+00, top1 76.47, top5 91.76
2021-11-09 11:16:54 valid 0000, loss 1.041e+00, top1 76.47, top5 91.76
2021-11-09 11:16:54 valid 0000, loss 1.041e+00, top1 76.47, top5 91.76
2021-11-09 11:21:10 (JOBID 31717) epoch 22: train time 2768.61, inference time 266.82s, valid_top1 52.87 (best_top1 63.95), valid_top5 78.16
2021-11-09 11:21:20 (JOBID 31717) epoch 22: train time 2776.06, inference time 276.89s, valid_top1 52.87 (best_top1 63.95), valid_top5 78.16
2021-11-09 11:21:22 (JOBID 31717) epoch 22: train time 2768.22, inference time 278.20s, valid_top1 52.87 (best_top1 63.95), valid_top5 78.16
2021-11-09 11:21:34 train 0000, loss 1.700e+00, top1 56.47, top5 82.35
2021-11-09 11:21:25 train 0000, loss 2.394e+00, top1 45.88, top5 72.94
2021-11-09 11:21:35 train 0000, loss 1.885e+00, top1 45.88, top5 80.00
2021-11-09 11:30:43 train 1000, loss 2.200e+00, top1 50.67, top5 74.95
2021-11-09 11:30:43 train 1000, loss 2.213e+00, top1 50.44, top5 74.72
2021-11-09 11:30:43 train 1000, loss 2.207e+00, top1 50.46, top5 74.93
2021-11-09 11:39:52 train 2000, loss 2.221e+00, top1 50.37, top5 74.57
2021-11-09 11:39:52 train 2000, loss 2.207e+00, top1 50.54, top5 74.82
2021-11-09 11:39:52 train 2000, loss 2.208e+00, top1 50.51, top5 74.88
2021-11-09 11:49:03 train 3000, loss 2.220e+00, top1 50.38, top5 74.59
2021-11-09 11:49:03 train 3000, loss 2.213e+00, top1 50.44, top5 74.81
2021-11-09 11:49:03 train 3000, loss 2.211e+00, top1 50.44, top5 74.74
2021-11-09 11:58:18 train 4000, loss 2.218e+00, top1 50.34, top5 74.65
2021-11-09 11:58:19 train 4000, loss 2.216e+00, top1 50.37, top5 74.75
2021-11-09 11:58:19 train 4000, loss 2.222e+00, top1 50.30, top5 74.57
2021-11-09 12:07:47 train 5000, loss 2.223e+00, top1 50.27, top5 74.56
2021-11-09 12:07:47 train 5000, loss 2.222e+00, top1 50.26, top5 74.55
2021-11-09 12:07:47 train 5000, loss 2.220e+00, top1 50.31, top5 74.70
2021-11-09 12:08:10 valid 0000, loss 1.430e+00, top1 67.06, top5 83.53
2021-11-09 12:08:10 valid 0000, loss 1.430e+00, top1 67.06, top5 83.53
2021-11-09 12:08:10 valid 0000, loss 1.430e+00, top1 67.06, top5 83.53
2021-11-09 12:12:42 (JOBID 31717) epoch 23: train time 2800.13, inference time 282.04s, valid_top1 53.14 (best_top1 63.95), valid_top5 78.13
2021-11-09 12:12:43 (JOBID 31717) epoch 23: train time 2798.62, inference time 282.47s, valid_top1 53.14 (best_top1 63.95), valid_top5 78.13
2021-11-09 12:12:43 (JOBID 31717) epoch 23: train time 2809.76, inference time 282.94s, valid_top1 53.14 (best_top1 63.95), valid_top5 78.13
2021-11-09 12:12:57 train 0000, loss 2.286e+00, top1 50.59, top5 74.12
2021-11-09 12:12:57 train 0000, loss 2.653e+00, top1 43.53, top5 63.53
2021-11-09 12:12:57 train 0000, loss 1.902e+00, top1 52.94, top5 81.18
2021-11-09 12:22:20 train 1000, loss 2.195e+00, top1 50.73, top5 74.91
2021-11-09 12:22:20 train 1000, loss 2.203e+00, top1 50.57, top5 74.83
2021-11-09 12:22:20 train 1000, loss 2.188e+00, top1 51.22, top5 75.00
2021-11-09 12:31:37 train 2000, loss 2.207e+00, top1 50.59, top5 74.87
2021-11-09 12:31:37 train 2000, loss 2.205e+00, top1 50.52, top5 74.78
2021-11-09 12:31:37 train 2000, loss 2.207e+00, top1 50.71, top5 74.78
2021-11-09 12:41:01 train 3000, loss 2.212e+00, top1 50.45, top5 74.68
2021-11-09 12:41:01 train 3000, loss 2.216e+00, top1 50.53, top5 74.62
2021-11-09 12:41:01 train 3000, loss 2.210e+00, top1 50.55, top5 74.84
2021-11-09 12:50:14 train 4000, loss 2.216e+00, top1 50.41, top5 74.72
2021-11-09 12:50:14 train 4000, loss 2.218e+00, top1 50.37, top5 74.62
2021-11-09 12:50:14 train 4000, loss 2.219e+00, top1 50.41, top5 74.60
2021-11-09 12:59:33 train 5000, loss 2.220e+00, top1 50.34, top5 74.68
2021-11-09 12:59:33 train 5000, loss 2.220e+00, top1 50.31, top5 74.59
2021-11-09 12:59:33 train 5000, loss 2.222e+00, top1 50.31, top5 74.58
2021-11-09 12:59:57 valid 0000, loss 1.237e+00, top1 74.12, top5 88.24
2021-11-09 12:59:57 valid 0000, loss 1.237e+00, top1 74.12, top5 88.24
2021-11-09 12:59:57 valid 0000, loss 1.237e+00, top1 74.12, top5 88.24
2021-11-09 13:04:23 (JOBID 31717) epoch 24: train time 2824.29, inference time 276.12s, valid_top1 50.76 (best_top1 63.95), valid_top5 76.41
2021-11-09 13:04:24 (JOBID 31717) epoch 24: train time 2823.51, inference time 276.50s, valid_top1 50.76 (best_top1 63.95), valid_top5 76.41
2021-11-09 13:04:25 (JOBID 31717) epoch 24: train time 2824.71, inference time 278.48s, valid_top1 50.76 (best_top1 63.95), valid_top5 76.41
2021-11-09 13:04:37 train 0000, loss 2.221e+00, top1 52.94, top5 75.29
2021-11-09 13:04:37 train 0000, loss 2.074e+00, top1 50.59, top5 76.47
2021-11-09 13:04:40 train 0000, loss 2.307e+00, top1 43.53, top5 74.12
2021-11-09 13:13:55 train 1000, loss 2.218e+00, top1 50.23, top5 74.77
2021-11-09 13:13:55 train 1000, loss 2.205e+00, top1 50.54, top5 74.88
2021-11-09 13:13:55 train 1000, loss 2.197e+00, top1 50.74, top5 75.07
2021-11-09 13:23:09 train 2000, loss 2.217e+00, top1 50.27, top5 74.68
2021-11-09 13:23:09 train 2000, loss 2.209e+00, top1 50.47, top5 74.90
2021-11-09 13:23:09 train 2000, loss 2.210e+00, top1 50.55, top5 74.77
2021-11-09 13:32:24 train 3000, loss 2.218e+00, top1 50.35, top5 74.64
2021-11-09 13:32:24 train 3000, loss 2.216e+00, top1 50.35, top5 74.77
2021-11-09 13:32:24 train 3000, loss 2.212e+00, top1 50.47, top5 74.71
2021-11-09 13:41:40 train 4000, loss 2.218e+00, top1 50.33, top5 74.72
2021-11-09 13:41:40 train 4000, loss 2.217e+00, top1 50.42, top5 74.64
2021-11-09 13:41:40 train 4000, loss 2.224e+00, top1 50.30, top5 74.56
2021-11-09 13:51:05 train 5000, loss 2.220e+00, top1 50.32, top5 74.60
2021-11-09 13:51:05 train 5000, loss 2.222e+00, top1 50.23, top5 74.62
2021-11-09 13:51:05 train 5000, loss 2.224e+00, top1 50.31, top5 74.56
2021-11-09 13:51:29 valid 0000, loss 1.319e+00, top1 76.47, top5 85.88
2021-11-09 13:51:29 valid 0000, loss 1.319e+00, top1 76.47, top5 85.88
2021-11-09 13:51:29 valid 0000, loss 1.319e+00, top1 76.47, top5 85.88
2021-11-09 13:55:52 (JOBID 31717) epoch 25: train time 2813.49, inference time 273.27s, valid_top1 53.05 (best_top1 63.95), valid_top5 78.41
2021-11-09 13:55:53 (JOBID 31717) epoch 25: train time 2815.18, inference time 274.18s, valid_top1 53.05 (best_top1 63.95), valid_top5 78.41
2021-11-09 13:55:55 (JOBID 31717) epoch 25: train time 2815.80, inference time 276.38s, valid_top1 53.05 (best_top1 63.95), valid_top5 78.41
2021-11-09 13:56:07 train 0000, loss 1.774e+00, top1 52.94, top5 83.53
2021-11-09 13:56:07 train 0000, loss 2.021e+00, top1 55.29, top5 75.29
2021-11-09 13:56:09 train 0000, loss 2.526e+00, top1 44.71, top5 69.41
2021-11-09 14:05:05 train 1000, loss 2.195e+00, top1 50.56, top5 74.93
2021-11-09 14:05:05 train 1000, loss 2.190e+00, top1 50.73, top5 75.14
2021-11-09 14:05:05 train 1000, loss 2.186e+00, top1 50.76, top5 75.02
2021-11-09 14:14:03 train 2000, loss 2.208e+00, top1 50.44, top5 74.73
2021-11-09 14:14:03 train 2000, loss 2.206e+00, top1 50.50, top5 74.83
2021-11-09 14:14:03 train 2000, loss 2.205e+00, top1 50.46, top5 74.75
2021-11-09 14:23:00 train 3000, loss 2.212e+00, top1 50.39, top5 74.72
2021-11-09 14:23:00 train 3000, loss 2.212e+00, top1 50.38, top5 74.67
2021-11-09 14:23:00 train 3000, loss 2.216e+00, top1 50.40, top5 74.67
2021-11-09 14:31:57 train 4000, loss 2.213e+00, top1 50.38, top5 74.67
2021-11-09 14:31:57 train 4000, loss 2.222e+00, top1 50.28, top5 74.52
2021-11-09 14:31:57 train 4000, loss 2.213e+00, top1 50.34, top5 74.68
2021-11-09 14:41:03 train 5000, loss 2.214e+00, top1 50.37, top5 74.66
2021-11-09 14:41:03 train 5000, loss 2.219e+00, top1 50.30, top5 74.62
2021-11-09 14:41:03 train 5000, loss 2.224e+00, top1 50.26, top5 74.54
2021-11-09 14:41:26 valid 0000, loss 1.006e+00, top1 80.00, top5 94.12
2021-11-09 14:41:26 valid 0000, loss 1.006e+00, top1 80.00, top5 94.12
2021-11-09 14:41:26 valid 0000, loss 1.006e+00, top1 80.00, top5 94.12
2021-11-09 14:45:59 (JOBID 31717) epoch 26: train time 2722.78, inference time 282.81s, valid_top1 52.44 (best_top1 63.95), valid_top5 77.84
2021-11-09 14:45:59 (JOBID 31717) epoch 26: train time 2723.98, inference time 283.16s, valid_top1 52.44 (best_top1 63.95), valid_top5 77.84
2021-11-09 14:45:59 (JOBID 31717) epoch 26: train time 2720.85, inference time 283.31s, valid_top1 52.44 (best_top1 63.95), valid_top5 77.84
2021-11-09 14:46:13 train 0000, loss 2.100e+00, top1 49.41, top5 83.53
2021-11-09 14:46:13 train 0000, loss 2.235e+00, top1 50.59, top5 72.94
2021-11-09 14:46:13 train 0000, loss 2.381e+00, top1 47.06, top5 72.94
2021-11-09 14:55:17 train 1000, loss 2.198e+00, top1 50.67, top5 74.72
2021-11-09 14:55:17 train 1000, loss 2.200e+00, top1 50.70, top5 74.92
2021-11-09 14:55:17 train 1000, loss 2.195e+00, top1 50.67, top5 75.04
2021-11-09 15:04:24 train 2000, loss 2.208e+00, top1 50.52, top5 74.67
2021-11-09 15:04:24 train 2000, loss 2.201e+00, top1 50.62, top5 74.91
2021-11-09 15:04:24 train 2000, loss 2.213e+00, top1 50.46, top5 74.77
2021-11-09 15:13:22 train 3000, loss 2.212e+00, top1 50.44, top5 74.70
2021-11-09 15:13:22 train 3000, loss 2.212e+00, top1 50.44, top5 74.81
2021-11-09 15:13:22 train 3000, loss 2.208e+00, top1 50.47, top5 74.84
2021-11-09 15:22:22 train 4000, loss 2.214e+00, top1 50.39, top5 74.65
2021-11-09 15:22:22 train 4000, loss 2.213e+00, top1 50.38, top5 74.74
2021-11-09 15:22:22 train 4000, loss 2.219e+00, top1 50.35, top5 74.70
2021-11-09 15:31:36 train 5000, loss 2.216e+00, top1 50.34, top5 74.70
2021-11-09 15:31:36 train 5000, loss 2.222e+00, top1 50.29, top5 74.63
2021-11-09 15:31:36 train 5000, loss 2.220e+00, top1 50.30, top5 74.59
2021-11-09 15:32:00 valid 0000, loss 1.165e+00, top1 78.82, top5 85.88
2021-11-09 15:32:00 valid 0000, loss 1.165e+00, top1 78.82, top5 85.88
2021-11-09 15:32:00 valid 0000, loss 1.165e+00, top1 78.82, top5 85.88
2021-11-09 15:36:23 (JOBID 31717) epoch 27: train time 2750.58, inference time 273.34s, valid_top1 50.82 (best_top1 63.95), valid_top5 76.85
2021-11-09 15:36:25 (JOBID 31717) epoch 27: train time 2750.55, inference time 275.08s, valid_top1 50.82 (best_top1 63.95), valid_top5 76.85
2021-11-09 15:36:27 (JOBID 31717) epoch 27: train time 2750.66, inference time 276.97s, valid_top1 50.82 (best_top1 63.95), valid_top5 76.85
2021-11-09 15:36:39 train 0000, loss 2.975e+00, top1 37.65, top5 56.47
2021-11-09 15:36:37 train 0000, loss 1.446e+00, top1 65.88, top5 89.41
2021-11-09 15:36:41 train 0000, loss 2.238e+00, top1 50.59, top5 70.59
2021-11-09 15:45:51 train 1000, loss 2.209e+00, top1 50.66, top5 74.72
2021-11-09 15:45:51 train 1000, loss 2.198e+00, top1 50.75, top5 74.84
2021-11-09 15:45:51 train 1000, loss 2.188e+00, top1 50.94, top5 75.04
2021-11-09 15:54:58 train 2000, loss 2.204e+00, top1 50.60, top5 74.87
2021-11-09 15:54:57 train 2000, loss 2.208e+00, top1 50.67, top5 74.76
2021-11-09 15:54:58 train 2000, loss 2.209e+00, top1 50.59, top5 74.75
2021-11-09 16:04:08 train 3000, loss 2.215e+00, top1 50.48, top5 74.68
2021-11-09 16:04:08 train 3000, loss 2.210e+00, top1 50.55, top5 74.76
2021-11-09 16:04:08 train 3000, loss 2.213e+00, top1 50.45, top5 74.71
2021-11-09 16:13:29 train 4000, loss 2.216e+00, top1 50.44, top5 74.66
2021-11-09 16:13:29 train 4000, loss 2.217e+00, top1 50.36, top5 74.61
2021-11-09 16:13:29 train 4000, loss 2.217e+00, top1 50.41, top5 74.63
2021-11-09 16:22:55 train 5000, loss 2.220e+00, top1 50.39, top5 74.60
2021-11-09 16:22:55 train 5000, loss 2.220e+00, top1 50.39, top5 74.59
2021-11-09 16:22:55 train 5000, loss 2.222e+00, top1 50.25, top5 74.54
2021-11-09 16:23:20 valid 0000, loss 1.466e+00, top1 74.12, top5 83.53
2021-11-09 16:23:20 valid 0000, loss 1.466e+00, top1 74.12, top5 83.53
2021-11-09 16:23:20 valid 0000, loss 1.466e+00, top1 74.12, top5 83.53
2021-11-09 16:27:55 (JOBID 31717) epoch 28: train time 2804.48, inference time 285.52s, valid_top1 52.36 (best_top1 63.95), valid_top5 78.11
2021-11-09 16:27:55 (JOBID 31717) epoch 28: train time 2806.33, inference time 285.45s, valid_top1 52.36 (best_top1 63.95), valid_top5 78.11
2021-11-09 16:27:55 (JOBID 31717) epoch 28: train time 2802.52, inference time 285.27s, valid_top1 52.36 (best_top1 63.95), valid_top5 78.11
2021-11-09 16:28:09 train 0000, loss 2.341e+00, top1 48.24, top5 78.82
2021-11-09 16:28:09 train 0000, loss 2.202e+00, top1 48.24, top5 71.76
2021-11-09 16:28:09 train 0000, loss 1.987e+00, top1 52.94, top5 78.82
2021-11-09 16:37:18 train 1000, loss 2.190e+00, top1 50.60, top5 75.08
2021-11-09 16:37:18 train 1000, loss 2.210e+00, top1 50.63, top5 74.77
2021-11-09 16:37:18 train 1000, loss 2.210e+00, top1 50.34, top5 74.74
2021-11-09 16:46:23 train 2000, loss 2.201e+00, top1 50.49, top5 74.94
2021-11-09 16:46:24 train 2000, loss 2.212e+00, top1 50.48, top5 74.78
2021-11-09 16:46:24 train 2000, loss 2.206e+00, top1 50.47, top5 74.82
2021-11-09 16:55:32 train 3000, loss 2.208e+00, top1 50.47, top5 74.84
2021-11-09 16:55:33 train 3000, loss 2.214e+00, top1 50.45, top5 74.70
2021-11-09 16:55:33 train 3000, loss 2.213e+00, top1 50.40, top5 74.74
2021-11-09 17:04:40 train 4000, loss 2.213e+00, top1 50.39, top5 74.74
2021-11-09 17:04:40 train 4000, loss 2.217e+00, top1 50.35, top5 74.64
2021-11-09 17:04:40 train 4000, loss 2.217e+00, top1 50.36, top5 74.69
2021-11-09 17:13:50 train 5000, loss 2.222e+00, top1 50.26, top5 74.59
2021-11-09 17:13:50 train 5000, loss 2.218e+00, top1 50.31, top5 74.69
2021-11-09 17:13:50 train 5000, loss 2.218e+00, top1 50.35, top5 74.64
2021-11-09 17:14:14 valid 0000, loss 1.413e+00, top1 75.29, top5 89.41
2021-11-09 17:14:14 valid 0000, loss 1.413e+00, top1 75.29, top5 89.41
2021-11-09 17:14:14 valid 0000, loss 1.413e+00, top1 75.29, top5 89.41
2021-11-09 17:18:39 (JOBID 31717) epoch 29: train time 2768.68, inference time 275.32s, valid_top1 52.90 (best_top1 63.95), valid_top5 78.06
2021-11-09 17:18:40 (JOBID 31717) epoch 29: train time 2768.79, inference time 276.18s, valid_top1 52.90 (best_top1 63.95), valid_top5 78.06
2021-11-09 17:18:40 (JOBID 31717) epoch 29: train time 2768.46, inference time 276.04s, valid_top1 52.90 (best_top1 63.95), valid_top5 78.06
2021-11-09 17:18:54 train 0000, loss 1.982e+00, top1 51.76, top5 75.29
2021-11-09 17:18:54 train 0000, loss 2.242e+00, top1 43.53, top5 76.47
2021-11-09 17:18:54 train 0000, loss 2.323e+00, top1 51.76, top5 72.94
2021-11-09 17:27:59 train 1000, loss 1.818e+00, top1 58.64, top5 80.47
2021-11-09 17:27:59 train 1000, loss 1.821e+00, top1 58.43, top5 80.57
2021-11-09 17:27:59 train 1000, loss 1.829e+00, top1 58.42, top5 80.37
2021-11-09 17:37:05 train 2000, loss 1.777e+00, top1 59.51, top5 81.18
2021-11-09 17:37:05 train 2000, loss 1.772e+00, top1 59.62, top5 81.17
2021-11-09 17:37:05 train 2000, loss 1.769e+00, top1 59.55, top5 81.24
2021-11-09 17:46:12 train 3000, loss 1.741e+00, top1 60.12, top5 81.64
2021-11-09 17:46:12 train 3000, loss 1.741e+00, top1 60.23, top5 81.57
2021-11-09 17:46:12 train 3000, loss 1.744e+00, top1 60.12, top5 81.64
2021-11-09 17:55:20 train 4000, loss 1.724e+00, top1 60.54, top5 81.84
2021-11-09 17:55:20 train 4000, loss 1.724e+00, top1 60.54, top5 81.90
2021-11-09 17:55:20 train 4000, loss 1.721e+00, top1 60.50, top5 81.91
2021-11-09 18:04:30 train 5000, loss 1.707e+00, top1 60.79, top5 82.13
2021-11-09 18:04:29 train 5000, loss 1.707e+00, top1 60.88, top5 82.08
2021-11-09 18:04:30 train 5000, loss 1.707e+00, top1 60.88, top5 82.14
2021-11-09 18:04:53 valid 0000, loss 6.109e-01, top1 87.06, top5 92.94
2021-11-09 18:04:53 valid 0000, loss 6.109e-01, top1 87.06, top5 92.94
2021-11-09 18:04:53 valid 0000, loss 6.109e-01, top1 87.06, top5 92.94
2021-11-09 18:09:10 (JOBID 31717) epoch 30: train time 2764.23, inference time 266.48s, valid_top1 67.23 (best_top1 67.23), valid_top5 87.99
2021-11-09 18:09:27 (JOBID 31717) epoch 30: train time 2763.23, inference time 282.74s, valid_top1 67.23 (best_top1 67.23), valid_top5 87.99
2021-11-09 18:09:27 (JOBID 31717) epoch 30: train time 2763.27, inference time 283.77s, valid_top1 67.23 (best_top1 67.23), valid_top5 87.99
2021-11-09 18:09:24 train 0000, loss 1.252e+00, top1 70.59, top5 87.06
2021-11-09 18:09:41 train 0000, loss 1.847e+00, top1 55.29, top5 80.00
2021-11-09 18:09:41 train 0000, loss 1.460e+00, top1 67.06, top5 88.24
2021-11-09 18:18:57 train 1000, loss 1.612e+00, top1 62.75, top5 83.46
2021-11-09 18:18:57 train 1000, loss 1.620e+00, top1 62.63, top5 83.47
2021-11-09 18:18:57 train 1000, loss 1.600e+00, top1 63.01, top5 83.60
2021-11-09 18:28:07 train 2000, loss 1.607e+00, top1 62.82, top5 83.50
2021-11-09 18:28:08 train 2000, loss 1.610e+00, top1 62.76, top5 83.45
2021-11-09 18:28:08 train 2000, loss 1.609e+00, top1 62.72, top5 83.58
2021-11-09 18:37:19 train 3000, loss 1.609e+00, top1 62.72, top5 83.40
2021-11-09 18:37:19 train 3000, loss 1.606e+00, top1 62.81, top5 83.59
2021-11-09 18:37:19 train 3000, loss 1.600e+00, top1 62.90, top5 83.59
2021-11-09 18:46:31 train 4000, loss 1.599e+00, top1 62.95, top5 83.61
2021-11-09 18:46:31 train 4000, loss 1.603e+00, top1 62.82, top5 83.50
2021-11-09 18:46:31 train 4000, loss 1.603e+00, top1 62.87, top5 83.61
2021-11-09 18:55:50 train 5000, loss 1.598e+00, top1 62.92, top5 83.59
2021-11-09 18:55:50 train 5000, loss 1.601e+00, top1 62.91, top5 83.64
2021-11-09 18:55:50 train 5000, loss 1.596e+00, top1 63.01, top5 83.62
2021-11-09 18:56:14 valid 0000, loss 6.787e-01, top1 85.88, top5 92.94
2021-11-09 18:56:14 valid 0000, loss 6.787e-01, top1 85.88, top5 92.94
2021-11-09 18:56:14 valid 0000, loss 6.787e-01, top1 85.88, top5 92.94
2021-11-09 19:00:30 (JOBID 31717) epoch 31: train time 2796.71, inference time 265.91s, valid_top1 68.05 (best_top1 68.05), valid_top5 88.50
2021-11-09 19:00:42 (JOBID 31717) epoch 31: train time 2796.97, inference time 278.01s, valid_top1 68.05 (best_top1 68.05), valid_top5 88.50
2021-11-09 19:00:44 (JOBID 31717) epoch 31: train time 2814.00, inference time 279.98s, valid_top1 68.05 (best_top1 68.05), valid_top5 88.50
2021-11-09 19:00:43 train 0000, loss 1.540e+00, top1 64.71, top5 83.53
2021-11-09 19:00:57 train 0000, loss 1.751e+00, top1 62.35, top5 82.35
2021-11-09 19:00:59 train 0000, loss 1.761e+00, top1 63.53, top5 82.35
2021-11-09 19:10:12 train 1000, loss 1.555e+00, top1 63.99, top5 84.13
2021-11-09 19:10:12 train 1000, loss 1.558e+00, top1 63.64, top5 84.26
2021-11-09 19:10:13 train 1000, loss 1.557e+00, top1 63.78, top5 84.19
2021-11-09 19:19:27 train 2000, loss 1.559e+00, top1 63.80, top5 84.15
2021-11-09 19:19:27 train 2000, loss 1.566e+00, top1 63.55, top5 84.07
2021-11-09 19:19:27 train 2000, loss 1.559e+00, top1 63.79, top5 84.15
2021-11-09 19:28:34 train 3000, loss 1.564e+00, top1 63.68, top5 84.06
2021-11-09 19:28:34 train 3000, loss 1.560e+00, top1 63.74, top5 84.16
2021-11-09 19:28:34 train 3000, loss 1.562e+00, top1 63.76, top5 84.11
2021-11-09 19:37:42 train 4000, loss 1.561e+00, top1 63.75, top5 84.11
2021-11-09 19:37:42 train 4000, loss 1.560e+00, top1 63.76, top5 84.17
2021-11-09 19:37:42 train 4000, loss 1.564e+00, top1 63.68, top5 84.07
2021-11-09 19:46:49 train 5000, loss 1.563e+00, top1 63.65, top5 84.08
2021-11-09 19:46:49 train 5000, loss 1.559e+00, top1 63.75, top5 84.13
2021-11-09 19:46:50 train 5000, loss 1.560e+00, top1 63.75, top5 84.19
2021-11-09 19:47:13 valid 0000, loss 5.237e-01, top1 87.06, top5 97.65
2021-11-09 19:47:13 valid 0000, loss 5.237e-01, top1 87.06, top5 97.65
2021-11-09 19:47:13 valid 0000, loss 5.237e-01, top1 87.06, top5 97.65
2021-11-09 19:51:47 (JOBID 31717) epoch 32: train time 2779.53, inference time 283.28s, valid_top1 68.48 (best_top1 68.48), valid_top5 88.89
2021-11-09 19:51:48 (JOBID 31717) epoch 32: train time 2781.13, inference time 283.82s, valid_top1 68.48 (best_top1 68.48), valid_top5 88.89
2021-11-09 19:51:53 (JOBID 31717) epoch 32: train time 2793.70, inference time 289.71s, valid_top1 68.48 (best_top1 68.48), valid_top5 88.89
2021-11-09 19:52:01 train 0000, loss 1.552e+00, top1 61.18, top5 84.71
2021-11-09 19:52:01 train 0000, loss 1.576e+00, top1 67.06, top5 88.24
2021-11-09 19:52:07 train 0000, loss 1.675e+00, top1 62.35, top5 80.00
2021-11-09 20:01:20 train 1000, loss 1.541e+00, top1 64.06, top5 84.46
2021-11-09 20:01:20 train 1000, loss 1.528e+00, top1 64.44, top5 84.61
2021-11-09 20:01:20 train 1000, loss 1.530e+00, top1 64.37, top5 84.53
2021-11-09 20:10:34 train 2000, loss 1.542e+00, top1 64.00, top5 84.40
2021-11-09 20:10:34 train 2000, loss 1.534e+00, top1 64.28, top5 84.47
2021-11-09 20:10:34 train 2000, loss 1.533e+00, top1 64.28, top5 84.54
2021-11-09 20:19:39 train 3000, loss 1.536e+00, top1 64.24, top5 84.50
2021-11-09 20:19:39 train 3000, loss 1.533e+00, top1 64.26, top5 84.51
2021-11-09 20:19:39 train 3000, loss 1.539e+00, top1 64.12, top5 84.44
2021-11-09 20:28:44 train 4000, loss 1.540e+00, top1 64.15, top5 84.44
2021-11-09 20:28:45 train 4000, loss 1.535e+00, top1 64.22, top5 84.50
2021-11-09 20:28:45 train 4000, loss 1.538e+00, top1 64.20, top5 84.47
2021-11-09 20:37:51 train 5000, loss 1.540e+00, top1 64.15, top5 84.42
2021-11-09 20:37:52 train 5000, loss 1.538e+00, top1 64.19, top5 84.46
2021-11-09 20:37:52 train 5000, loss 1.536e+00, top1 64.22, top5 84.48
2021-11-09 20:38:15 valid 0000, loss 6.198e-01, top1 87.06, top5 95.29
2021-11-09 20:38:15 valid 0000, loss 6.198e-01, top1 87.06, top5 95.29
2021-11-09 20:38:15 valid 0000, loss 6.198e-01, top1 87.06, top5 95.29
2021-11-09 20:42:34 (JOBID 31717) epoch 33: train time 2772.01, inference time 269.26s, valid_top1 68.33 (best_top1 68.48), valid_top5 88.71
2021-11-09 20:42:41 (JOBID 31717) epoch 33: train time 2777.41, inference time 275.36s, valid_top1 68.33 (best_top1 68.48), valid_top5 88.71
2021-11-09 20:42:41 (JOBID 31717) epoch 33: train time 2778.58, inference time 276.33s, valid_top1 68.33 (best_top1 68.48), valid_top5 88.71
2021-11-09 20:42:55 train 0000, loss 1.556e+00, top1 65.88, top5 84.71
2021-11-09 20:42:48 train 0000, loss 1.338e+00, top1 65.88, top5 83.53
2021-11-09 20:42:55 train 0000, loss 1.380e+00, top1 67.06, top5 85.88
2021-11-09 20:52:13 train 1000, loss 1.515e+00, top1 64.65, top5 84.76
2021-11-09 20:52:13 train 1000, loss 1.500e+00, top1 65.01, top5 85.00
2021-11-09 20:52:13 train 1000, loss 1.515e+00, top1 64.63, top5 84.86
2021-11-09 21:01:26 train 2000, loss 1.516e+00, top1 64.61, top5 84.77
2021-11-09 21:01:26 train 2000, loss 1.517e+00, top1 64.68, top5 84.72
2021-11-09 21:01:26 train 2000, loss 1.519e+00, top1 64.59, top5 84.78
2021-11-09 21:10:41 train 3000, loss 1.522e+00, top1 64.57, top5 84.63
2021-11-09 21:10:41 train 3000, loss 1.523e+00, top1 64.50, top5 84.69
2021-11-09 21:10:41 train 3000, loss 1.518e+00, top1 64.59, top5 84.75
2021-11-09 21:19:50 train 4000, loss 1.522e+00, top1 64.52, top5 84.62
2021-11-09 21:19:50 train 4000, loss 1.520e+00, top1 64.54, top5 84.69
2021-11-09 21:19:50 train 4000, loss 1.523e+00, top1 64.51, top5 84.67
2021-11-09 21:28:59 train 5000, loss 1.524e+00, top1 64.51, top5 84.61
2021-11-09 21:28:59 train 5000, loss 1.523e+00, top1 64.49, top5 84.68
2021-11-09 21:28:59 train 5000, loss 1.519e+00, top1 64.57, top5 84.72
2021-11-09 21:29:23 valid 0000, loss 6.389e-01, top1 84.71, top5 92.94
2021-11-09 21:29:23 valid 0000, loss 6.389e-01, top1 84.71, top5 92.94
2021-11-09 21:29:23 valid 0000, loss 6.389e-01, top1 84.71, top5 92.94
2021-11-09 21:33:47 (JOBID 31717) epoch 34: train time 2798.25, inference time 273.95s, valid_top1 68.85 (best_top1 68.85), valid_top5 89.12
2021-11-09 21:33:48 (JOBID 31717) epoch 34: train time 2792.30, inference time 274.15s, valid_top1 68.85 (best_top1 68.85), valid_top5 89.12
2021-11-09 21:33:50 (JOBID 31717) epoch 34: train time 2791.34, inference time 277.52s, valid_top1 68.85 (best_top1 68.85), valid_top5 89.12
2021-11-09 21:34:01 train 0000, loss 1.670e+00, top1 68.24, top5 82.35
2021-11-09 21:34:01 train 0000, loss 1.507e+00, top1 60.00, top5 85.88
2021-11-09 21:34:05 train 0000, loss 1.350e+00, top1 70.59, top5 82.35
2021-11-09 21:43:20 train 1000, loss 1.505e+00, top1 64.96, top5 84.97
2021-11-09 21:43:20 train 1000, loss 1.494e+00, top1 65.01, top5 85.28
2021-11-09 21:43:20 train 1000, loss 1.502e+00, top1 64.98, top5 84.85
2021-11-09 21:52:24 train 2000, loss 1.505e+00, top1 64.87, top5 84.85
2021-11-09 21:52:23 train 2000, loss 1.503e+00, top1 64.92, top5 85.02
2021-11-09 21:52:24 train 2000, loss 1.500e+00, top1 64.92, top5 85.03
2021-11-09 22:01:29 train 3000, loss 1.503e+00, top1 64.91, top5 85.03
2021-11-09 22:01:29 train 3000, loss 1.505e+00, top1 64.85, top5 84.91
2021-11-09 22:01:29 train 3000, loss 1.508e+00, top1 64.74, top5 84.84
2021-11-09 22:10:30 train 4000, loss 1.511e+00, top1 64.71, top5 84.85
2021-11-09 22:10:30 train 4000, loss 1.506e+00, top1 64.78, top5 84.99
2021-11-09 22:10:30 train 4000, loss 1.512e+00, top1 64.67, top5 84.80
2021-11-09 22:19:35 train 5000, loss 1.513e+00, top1 64.72, top5 84.81
2021-11-09 22:19:36 train 5000, loss 1.513e+00, top1 64.65, top5 84.80
2021-11-09 22:19:36 train 5000, loss 1.510e+00, top1 64.71, top5 84.91
2021-11-09 22:19:59 valid 0000, loss 7.379e-01, top1 81.18, top5 92.94
2021-11-09 22:19:59 valid 0000, loss 7.379e-01, top1 81.18, top5 92.94
2021-11-09 22:19:59 valid 0000, loss 7.379e-01, top1 81.18, top5 92.94
2021-11-09 22:24:21 (JOBID 31717) epoch 35: train time 2759.03, inference time 271.85s, valid_top1 68.38 (best_top1 68.85), valid_top5 88.71
2021-11-09 22:24:26 (JOBID 31717) epoch 35: train time 2762.76, inference time 276.75s, valid_top1 68.38 (best_top1 68.85), valid_top5 88.71
2021-11-09 22:24:27 (JOBID 31717) epoch 35: train time 2761.83, inference time 276.98s, valid_top1 68.38 (best_top1 68.85), valid_top5 88.71
2021-11-09 22:24:35 train 0000, loss 1.541e+00, top1 58.82, top5 87.06
2021-11-09 22:24:40 train 0000, loss 1.361e+00, top1 68.24, top5 81.18
2021-11-09 22:24:40 train 0000, loss 1.681e+00, top1 62.35, top5 83.53
2021-11-09 22:34:07 train 1000, loss 1.498e+00, top1 64.99, top5 84.98
2021-11-09 22:34:07 train 1000, loss 1.495e+00, top1 64.99, top5 85.04
2021-11-09 22:34:07 train 1000, loss 1.498e+00, top1 65.07, top5 85.06
2021-11-09 22:43:35 train 2000, loss 1.500e+00, top1 64.92, top5 84.98
2021-11-09 22:43:35 train 2000, loss 1.503e+00, top1 64.93, top5 84.89
2021-11-09 22:43:35 train 2000, loss 1.504e+00, top1 64.87, top5 84.95
2021-11-09 22:53:10 train 3000, loss 1.504e+00, top1 64.82, top5 84.91
2021-11-09 22:53:11 train 3000, loss 1.499e+00, top1 64.89, top5 85.04
2021-11-09 22:53:11 train 3000, loss 1.511e+00, top1 64.75, top5 84.83
2021-11-09 23:02:50 train 4000, loss 1.512e+00, top1 64.67, top5 84.83
2021-11-09 23:02:50 train 4000, loss 1.501e+00, top1 64.83, top5 84.99
2021-11-09 23:02:50 train 4000, loss 1.504e+00, top1 64.84, top5 84.90
2021-11-09 23:12:27 train 5000, loss 1.513e+00, top1 64.67, top5 84.81
2021-11-09 23:12:27 train 5000, loss 1.503e+00, top1 64.79, top5 84.93
2021-11-09 23:12:27 train 5000, loss 1.507e+00, top1 64.77, top5 84.89
2021-11-09 23:12:51 valid 0000, loss 6.789e-01, top1 83.53, top5 92.94
2021-11-09 23:12:51 valid 0000, loss 6.789e-01, top1 83.53, top5 92.94
2021-11-09 23:12:51 valid 0000, loss 6.789e-01, top1 83.53, top5 92.94
2021-11-09 23:17:21 (JOBID 31717) epoch 36: train time 2894.77, inference time 280.34s, valid_top1 68.87 (best_top1 68.87), valid_top5 89.16
2021-11-09 23:17:21 (JOBID 31717) epoch 36: train time 2894.32, inference time 279.63s, valid_top1 68.87 (best_top1 68.87), valid_top5 89.16
2021-11-09 23:17:22 (JOBID 31717) epoch 36: train time 2899.64, inference time 280.65s, valid_top1 68.87 (best_top1 68.87), valid_top5 89.16
2021-11-09 23:17:36 train 0000, loss 1.298e+00, top1 64.71, top5 90.59
2021-11-09 23:17:36 train 0000, loss 1.718e+00, top1 61.18, top5 81.18
2021-11-09 23:17:36 train 0000, loss 1.240e+00, top1 68.24, top5 85.88
2021-11-09 23:26:40 train 1000, loss 1.476e+00, top1 65.35, top5 85.21
2021-11-09 23:26:40 train 1000, loss 1.490e+00, top1 65.02, top5 85.20
2021-11-09 23:26:40 train 1000, loss 1.483e+00, top1 65.28, top5 85.42
2021-11-09 23:35:49 train 2000, loss 1.494e+00, top1 64.95, top5 85.10
2021-11-09 23:35:49 train 2000, loss 1.497e+00, top1 64.95, top5 85.04
2021-11-09 23:35:49 train 2000, loss 1.486e+00, top1 65.19, top5 85.14
2021-11-09 23:44:56 train 3000, loss 1.499e+00, top1 64.90, top5 85.04
2021-11-09 23:44:56 train 3000, loss 1.494e+00, top1 65.07, top5 85.03
2021-11-09 23:44:56 train 3000, loss 1.500e+00, top1 64.90, top5 85.02
2021-11-09 23:54:00 train 4000, loss 1.502e+00, top1 64.86, top5 85.01
2021-11-09 23:54:00 train 4000, loss 1.504e+00, top1 64.86, top5 84.94
2021-11-09 23:54:00 train 4000, loss 1.498e+00, top1 64.99, top5 84.99
2021-11-10 00:03:04 train 5000, loss 1.505e+00, top1 64.76, top5 84.94
2021-11-10 00:03:04 train 5000, loss 1.500e+00, top1 64.93, top5 84.97
2021-11-10 00:03:04 train 5000, loss 1.506e+00, top1 64.82, top5 84.92
2021-11-10 00:03:27 valid 0000, loss 7.294e-01, top1 84.71, top5 94.12
2021-11-10 00:03:27 valid 0000, loss 7.294e-01, top1 84.71, top5 94.12
2021-11-10 00:03:27 valid 0000, loss 7.294e-01, top1 84.71, top5 94.12
2021-11-10 00:07:47 (JOBID 31717) epoch 37: train time 2755.77, inference time 269.77s, valid_top1 68.78 (best_top1 68.87), valid_top5 89.02
2021-11-10 00:07:50 (JOBID 31717) epoch 37: train time 2755.59, inference time 273.32s, valid_top1 68.78 (best_top1 68.87), valid_top5 89.02
2021-11-10 00:07:52 (JOBID 31717) epoch 37: train time 2756.04, inference time 274.79s, valid_top1 68.78 (best_top1 68.87), valid_top5 89.02
2021-11-10 00:08:05 train 0000, loss 2.034e+00, top1 56.47, top5 75.29
2021-11-10 00:08:02 train 0000, loss 1.560e+00, top1 67.06, top5 81.18
2021-11-10 00:08:06 train 0000, loss 1.365e+00, top1 69.41, top5 90.59
2021-11-10 00:17:12 train 1000, loss 1.483e+00, top1 65.33, top5 85.22
2021-11-10 00:17:12 train 1000, loss 1.489e+00, top1 65.09, top5 85.17
2021-11-10 00:17:12 train 1000, loss 1.492e+00, top1 65.00, top5 85.26
2021-11-10 00:26:25 train 2000, loss 1.494e+00, top1 65.10, top5 85.09
2021-11-10 00:26:25 train 2000, loss 1.494e+00, top1 65.03, top5 85.12
2021-11-10 00:26:25 train 2000, loss 1.494e+00, top1 65.08, top5 85.23
2021-11-10 00:35:30 train 3000, loss 1.503e+00, top1 64.94, top5 85.01
2021-11-10 00:35:30 train 3000, loss 1.496e+00, top1 64.92, top5 85.08
2021-11-10 00:35:30 train 3000, loss 1.501e+00, top1 65.00, top5 85.01
2021-11-10 00:44:41 train 4000, loss 1.498e+00, top1 64.90, top5 85.04
2021-11-10 00:44:41 train 4000, loss 1.506e+00, top1 64.85, top5 84.95
2021-11-10 00:44:41 train 4000, loss 1.504e+00, top1 64.87, top5 84.99
2021-11-10 00:53:45 train 5000, loss 1.500e+00, top1 64.87, top5 85.02
2021-11-10 00:53:45 train 5000, loss 1.507e+00, top1 64.84, top5 84.91
2021-11-10 00:53:45 train 5000, loss 1.505e+00, top1 64.86, top5 84.96
2021-11-10 00:54:09 valid 0000, loss 6.336e-01, top1 85.88, top5 94.12
2021-11-10 00:54:09 valid 0000, loss 6.336e-01, top1 85.88, top5 94.12
2021-11-10 00:54:09 valid 0000, loss 6.336e-01, top1 85.88, top5 94.12
2021-11-10 00:58:16 (JOBID 31717) epoch 38: train time 2771.57, inference time 257.32s, valid_top1 67.74 (best_top1 68.87), valid_top5 88.29
2021-11-10 00:58:44 (JOBID 31717) epoch 38: train time 2766.79, inference time 285.52s, valid_top1 67.74 (best_top1 68.87), valid_top5 88.29
2021-11-10 00:58:50 (JOBID 31717) epoch 38: train time 2768.40, inference time 291.63s, valid_top1 67.74 (best_top1 68.87), valid_top5 88.29
2021-11-10 00:58:58 train 0000, loss 1.536e+00, top1 61.18, top5 84.71
2021-11-10 00:58:31 train 0000, loss 1.210e+00, top1 76.47, top5 89.41
2021-11-10 00:59:03 train 0000, loss 1.619e+00, top1 60.00, top5 83.53
2021-11-10 01:08:16 train 1000, loss 1.489e+00, top1 65.31, top5 85.22
2021-11-10 01:08:16 train 1000, loss 1.485e+00, top1 65.27, top5 85.27
2021-11-10 01:08:16 train 1000, loss 1.482e+00, top1 65.31, top5 85.20
2021-11-10 01:17:37 train 2000, loss 1.490e+00, top1 65.21, top5 85.11
2021-11-10 01:17:37 train 2000, loss 1.494e+00, top1 65.08, top5 85.09
2021-11-10 01:17:37 train 2000, loss 1.497e+00, top1 65.01, top5 85.09
2021-11-10 01:26:51 train 3000, loss 1.498e+00, top1 65.00, top5 85.09
2021-11-10 01:26:51 train 3000, loss 1.496e+00, top1 65.01, top5 85.00
2021-11-10 01:26:51 train 3000, loss 1.493e+00, top1 65.10, top5 85.13
2021-11-10 01:36:09 train 4000, loss 1.497e+00, top1 65.00, top5 85.12
2021-11-10 01:36:09 train 4000, loss 1.503e+00, top1 64.84, top5 85.00
2021-11-10 01:36:09 train 4000, loss 1.500e+00, top1 64.93, top5 84.95
2021-11-10 01:45:21 train 5000, loss 1.504e+00, top1 64.82, top5 84.94
2021-11-10 01:45:21 train 5000, loss 1.507e+00, top1 64.74, top5 84.95
2021-11-10 01:45:21 train 5000, loss 1.503e+00, top1 64.89, top5 85.01
2021-11-10 01:45:46 valid 0000, loss 6.151e-01, top1 87.06, top5 95.29
2021-11-10 01:45:46 valid 0000, loss 6.151e-01, top1 87.06, top5 95.29
2021-11-10 01:45:46 valid 0000, loss 6.151e-01, top1 87.06, top5 95.29
2021-11-10 01:50:13 (JOBID 31717) epoch 39: train time 2804.87, inference time 277.72s, valid_top1 68.48 (best_top1 68.87), valid_top5 88.99
2021-11-10 01:50:15 (JOBID 31717) epoch 39: train time 2838.99, inference time 279.08s, valid_top1 68.48 (best_top1 68.87), valid_top5 88.99
2021-11-10 01:50:15 (JOBID 31717) epoch 39: train time 2810.90, inference time 279.55s, valid_top1 68.48 (best_top1 68.87), valid_top5 88.99
2021-11-10 01:50:28 train 0000, loss 1.602e+00, top1 57.65, top5 81.18
2021-11-10 01:50:28 train 0000, loss 1.845e+00, top1 56.47, top5 76.47
2021-11-10 01:50:28 train 0000, loss 1.753e+00, top1 55.29, top5 81.18
2021-11-10 01:59:37 train 1000, loss 1.476e+00, top1 65.27, top5 85.33
2021-11-10 01:59:37 train 1000, loss 1.479e+00, top1 65.29, top5 85.37
2021-11-10 01:59:37 train 1000, loss 1.484e+00, top1 65.18, top5 85.34
2021-11-10 02:08:50 train 2000, loss 1.489e+00, top1 65.06, top5 85.28
2021-11-10 02:08:50 train 2000, loss 1.488e+00, top1 65.20, top5 85.19
2021-11-10 02:08:50 train 2000, loss 1.486e+00, top1 65.11, top5 85.19
2021-11-10 02:18:00 train 3000, loss 1.493e+00, top1 65.07, top5 85.17
2021-11-10 02:18:00 train 3000, loss 1.496e+00, top1 64.96, top5 85.16
2021-11-10 02:18:00 train 3000, loss 1.492e+00, top1 65.01, top5 85.12
2021-11-10 02:27:07 train 4000, loss 1.501e+00, top1 64.86, top5 85.04
2021-11-10 02:27:07 train 4000, loss 1.497e+00, top1 64.97, top5 85.07
2021-11-10 02:27:07 train 4000, loss 1.497e+00, top1 64.96, top5 85.06
2021-11-10 02:36:25 train 5000, loss 1.505e+00, top1 64.79, top5 84.93
2021-11-10 02:36:25 train 5000, loss 1.500e+00, top1 64.93, top5 85.03
2021-11-10 02:36:25 train 5000, loss 1.507e+00, top1 64.73, top5 84.94
2021-11-10 02:36:49 valid 0000, loss 8.237e-01, top1 83.53, top5 90.59
2021-11-10 02:36:49 valid 0000, loss 8.237e-01, top1 83.53, top5 90.59
2021-11-10 02:36:49 valid 0000, loss 8.237e-01, top1 83.53, top5 90.59
2021-11-10 02:41:15 (JOBID 31717) epoch 40: train time 2785.36, inference time 276.18s, valid_top1 67.83 (best_top1 68.87), valid_top5 88.41
2021-11-10 02:41:15 (JOBID 31717) epoch 40: train time 2783.62, inference time 276.19s, valid_top1 67.83 (best_top1 68.87), valid_top5 88.41
2021-11-10 02:41:15 (JOBID 31717) epoch 40: train time 2783.81, inference time 276.13s, valid_top1 67.83 (best_top1 68.87), valid_top5 88.41
2021-11-10 02:41:29 train 0000, loss 1.195e+00, top1 68.24, top5 89.41
2021-11-10 02:41:29 train 0000, loss 1.564e+00, top1 67.06, top5 84.71
2021-11-10 02:41:29 train 0000, loss 1.602e+00, top1 69.41, top5 84.71
2021-11-10 02:50:42 train 1000, loss 1.494e+00, top1 65.03, top5 85.15
2021-11-10 02:50:42 train 1000, loss 1.487e+00, top1 65.31, top5 85.10
2021-11-10 02:50:42 train 1000, loss 1.493e+00, top1 65.04, top5 85.04
2021-11-10 02:59:57 train 2000, loss 1.493e+00, top1 64.99, top5 85.05
2021-11-10 02:59:57 train 2000, loss 1.497e+00, top1 65.01, top5 85.09
2021-11-10 02:59:57 train 2000, loss 1.493e+00, top1 65.22, top5 85.13
2021-11-10 03:09:19 train 3000, loss 1.503e+00, top1 64.84, top5 84.99
2021-11-10 03:09:19 train 3000, loss 1.502e+00, top1 64.99, top5 85.04
2021-11-10 03:09:19 train 3000, loss 1.495e+00, top1 64.98, top5 85.06
2021-11-10 03:18:40 train 4000, loss 1.510e+00, top1 64.67, top5 84.91
2021-11-10 03:18:40 train 4000, loss 1.498e+00, top1 64.91, top5 85.02
2021-11-10 03:18:40 train 4000, loss 1.502e+00, top1 64.98, top5 85.01
2021-11-10 03:28:15 train 5000, loss 1.506e+00, top1 64.83, top5 84.94
2021-11-10 03:28:15 train 5000, loss 1.503e+00, top1 64.79, top5 84.93
2021-11-10 03:28:15 train 5000, loss 1.512e+00, top1 64.60, top5 84.87
2021-11-10 03:28:39 valid 0000, loss 8.564e-01, top1 81.18, top5 90.59
2021-11-10 03:28:39 valid 0000, loss 8.564e-01, top1 81.18, top5 90.59
2021-11-10 03:28:39 valid 0000, loss 8.564e-01, top1 81.18, top5 90.59
2021-11-10 03:32:48 (JOBID 31717) epoch 41: train time 2834.27, inference time 258.93s, valid_top1 67.75 (best_top1 68.87), valid_top5 88.25
2021-11-10 03:33:15 (JOBID 31717) epoch 41: train time 2834.43, inference time 286.30s, valid_top1 67.75 (best_top1 68.87), valid_top5 88.25
2021-11-10 03:33:16 (JOBID 31717) epoch 41: train time 2834.42, inference time 286.63s, valid_top1 67.75 (best_top1 68.87), valid_top5 88.25
2021-11-10 03:33:29 train 0000, loss 1.286e+00, top1 70.59, top5 89.41
2021-11-10 03:33:02 train 0000, loss 1.686e+00, top1 63.53, top5 83.53
2021-11-10 03:33:29 train 0000, loss 1.353e+00, top1 58.82, top5 88.24
2021-11-10 03:42:51 train 1000, loss 1.482e+00, top1 65.06, top5 85.30
2021-11-10 03:42:51 train 1000, loss 1.500e+00, top1 65.10, top5 85.00
2021-11-10 03:42:51 train 1000, loss 1.489e+00, top1 65.06, top5 85.15
2021-11-10 03:52:11 train 2000, loss 1.495e+00, top1 64.91, top5 85.08
2021-11-10 03:52:11 train 2000, loss 1.498e+00, top1 65.03, top5 85.13
2021-11-10 03:52:11 train 2000, loss 1.501e+00, top1 64.92, top5 84.97
2021-11-10 04:01:31 train 3000, loss 1.506e+00, top1 64.82, top5 84.99
2021-11-10 04:01:31 train 3000, loss 1.497e+00, top1 64.82, top5 85.05
2021-11-10 04:01:31 train 3000, loss 1.503e+00, top1 64.86, top5 84.95
2021-11-10 04:10:50 train 4000, loss 1.508e+00, top1 64.74, top5 84.89
2021-11-10 04:10:50 train 4000, loss 1.511e+00, top1 64.75, top5 84.91
2021-11-10 04:10:50 train 4000, loss 1.504e+00, top1 64.73, top5 84.98
2021-11-10 04:20:11 train 5000, loss 1.514e+00, top1 64.62, top5 84.85
2021-11-10 04:20:11 train 5000, loss 1.509e+00, top1 64.69, top5 84.93
2021-11-10 04:20:11 train 5000, loss 1.511e+00, top1 64.62, top5 84.84
2021-11-10 04:20:36 valid 0000, loss 5.930e-01, top1 83.53, top5 95.29
2021-11-10 04:20:36 valid 0000, loss 5.930e-01, top1 83.53, top5 95.29
2021-11-10 04:20:36 valid 0000, loss 5.930e-01, top1 83.53, top5 95.29
2021-11-10 04:25:09 (JOBID 31717) epoch 42: train time 2830.00, inference time 283.40s, valid_top1 67.92 (best_top1 68.87), valid_top5 88.63
2021-11-10 04:25:10 (JOBID 31717) epoch 42: train time 2829.57, inference time 284.41s, valid_top1 67.92 (best_top1 68.87), valid_top5 88.63
2021-11-10 04:25:11 (JOBID 31717) epoch 42: train time 2857.16, inference time 285.15s, valid_top1 67.92 (best_top1 68.87), valid_top5 88.63
2021-11-10 04:25:24 train 0000, loss 1.543e+00, top1 61.18, top5 84.71
2021-11-10 04:25:25 train 0000, loss 1.413e+00, top1 70.59, top5 82.35
2021-11-10 04:25:25 train 0000, loss 1.411e+00, top1 65.88, top5 84.71
2021-11-10 04:35:43 train 1000, loss 1.497e+00, top1 65.01, top5 85.00
2021-11-10 04:35:43 train 1000, loss 1.487e+00, top1 64.98, top5 85.24
2021-11-10 04:35:43 train 1000, loss 1.496e+00, top1 64.96, top5 84.96
2021-11-10 04:46:00 train 2000, loss 1.504e+00, top1 64.75, top5 84.89
2021-11-10 04:46:00 train 2000, loss 1.498e+00, top1 64.94, top5 85.03
2021-11-10 04:46:00 train 2000, loss 1.501e+00, top1 64.79, top5 84.99
2021-11-10 04:56:17 train 3000, loss 1.506e+00, top1 64.68, top5 84.91
2021-11-10 04:56:17 train 3000, loss 1.505e+00, top1 64.67, top5 84.99
2021-11-10 04:56:17 train 3000, loss 1.504e+00, top1 64.86, top5 84.96
2021-11-10 05:06:31 train 4000, loss 1.510e+00, top1 64.61, top5 84.87
2021-11-10 05:06:32 train 4000, loss 1.504e+00, top1 64.84, top5 84.96
2021-11-10 05:06:32 train 4000, loss 1.510e+00, top1 64.61, top5 84.91
2021-11-10 05:16:49 train 5000, loss 1.509e+00, top1 64.74, top5 84.88
2021-11-10 05:16:49 train 5000, loss 1.514e+00, top1 64.56, top5 84.82
2021-11-10 05:16:49 train 5000, loss 1.509e+00, top1 64.59, top5 84.88
2021-11-10 05:17:15 valid 0000, loss 6.038e-01, top1 87.06, top5 92.94
2021-11-10 05:17:15 valid 0000, loss 6.038e-01, top1 87.06, top5 92.94
2021-11-10 05:17:15 valid 0000, loss 6.038e-01, top1 87.06, top5 92.94
2021-11-10 05:21:51 (JOBID 31717) epoch 43: train time 3115.09, inference time 286.45s, valid_top1 68.16 (best_top1 68.87), valid_top5 88.61
2021-11-10 05:21:51 (JOBID 31717) epoch 43: train time 3113.88, inference time 286.62s, valid_top1 68.16 (best_top1 68.87), valid_top5 88.61
2021-11-10 05:21:51 (JOBID 31717) epoch 43: train time 3115.98, inference time 286.72s, valid_top1 68.16 (best_top1 68.87), valid_top5 88.61
2021-11-10 05:22:06 train 0000, loss 1.048e+00, top1 69.41, top5 92.94
2021-11-10 05:22:06 train 0000, loss 1.306e+00, top1 65.88, top5 90.59
2021-11-10 05:22:06 train 0000, loss 1.579e+00, top1 61.18, top5 84.71
2021-11-10 05:32:08 train 1000, loss 1.491e+00, top1 65.15, top5 85.13
2021-11-10 05:32:08 train 1000, loss 1.507e+00, top1 64.84, top5 84.92
2021-11-10 05:32:08 train 1000, loss 1.489e+00, top1 64.98, top5 85.20
2021-11-10 05:42:09 train 2000, loss 1.500e+00, top1 64.76, top5 85.08
2021-11-10 05:42:09 train 2000, loss 1.500e+00, top1 64.91, top5 85.05
2021-11-10 05:42:09 train 2000, loss 1.506e+00, top1 64.79, top5 85.02
2021-11-10 05:52:07 train 3000, loss 1.509e+00, top1 64.64, top5 84.91
2021-11-10 05:52:07 train 3000, loss 1.505e+00, top1 64.70, top5 84.99
2021-11-10 05:52:07 train 3000, loss 1.505e+00, top1 64.81, top5 84.95
2021-11-10 06:02:05 train 4000, loss 1.508e+00, top1 64.76, top5 84.94
2021-11-10 06:02:05 train 4000, loss 1.509e+00, top1 64.62, top5 84.94
2021-11-10 06:02:05 train 4000, loss 1.513e+00, top1 64.56, top5 84.87
2021-11-10 06:12:00 train 5000, loss 1.511e+00, top1 64.70, top5 84.89
2021-11-10 06:12:00 train 5000, loss 1.512e+00, top1 64.53, top5 84.88
2021-11-10 06:12:00 train 5000, loss 1.517e+00, top1 64.51, top5 84.81
2021-11-10 06:12:25 valid 0000, loss 6.024e-01, top1 85.88, top5 95.29
2021-11-10 06:12:25 valid 0000, loss 6.024e-01, top1 85.88, top5 95.29
2021-11-10 06:12:25 valid 0000, loss 6.024e-01, top1 85.88, top5 95.29
2021-11-10 06:16:36 (JOBID 31717) epoch 44: train time 3023.35, inference time 260.68s, valid_top1 68.48 (best_top1 68.87), valid_top5 88.84
2021-11-10 06:17:03 (JOBID 31717) epoch 44: train time 3023.53, inference time 288.61s, valid_top1 68.48 (best_top1 68.87), valid_top5 88.84
2021-11-10 06:17:06 (JOBID 31717) epoch 44: train time 3023.34, inference time 291.00s, valid_top1 68.48 (best_top1 68.87), valid_top5 88.84
2021-11-10 06:16:50 train 0000, loss 1.750e+00, top1 60.00, top5 82.35
2021-11-10 06:17:18 train 0000, loss 1.494e+00, top1 63.53, top5 88.24
2021-11-10 06:17:20 train 0000, loss 1.327e+00, top1 67.06, top5 84.71
2021-11-10 06:27:08 train 1000, loss 1.494e+00, top1 64.98, top5 85.18
2021-11-10 06:27:08 train 1000, loss 1.496e+00, top1 65.10, top5 85.01
2021-11-10 06:27:08 train 1000, loss 1.498e+00, top1 64.91, top5 84.95
2021-11-10 06:36:56 train 2000, loss 1.502e+00, top1 64.76, top5 84.99
2021-11-10 06:36:56 train 2000, loss 1.499e+00, top1 64.86, top5 85.04
2021-11-10 06:36:56 train 2000, loss 1.506e+00, top1 64.70, top5 84.91
2021-11-10 06:46:44 train 3000, loss 1.511e+00, top1 64.66, top5 84.90
2021-11-10 06:46:44 train 3000, loss 1.508e+00, top1 64.63, top5 84.90
2021-11-10 06:46:44 train 3000, loss 1.508e+00, top1 64.73, top5 84.89
2021-11-10 06:56:32 train 4000, loss 1.513e+00, top1 64.56, top5 84.82
2021-11-10 06:56:32 train 4000, loss 1.514e+00, top1 64.54, top5 84.86
2021-11-10 06:56:32 train 4000, loss 1.511e+00, top1 64.65, top5 84.85
2021-11-10 07:06:20 train 5000, loss 1.516e+00, top1 64.53, top5 84.83
2021-11-10 07:06:20 train 5000, loss 1.517e+00, top1 64.48, top5 84.76
2021-11-10 07:06:20 train 5000, loss 1.514e+00, top1 64.58, top5 84.80
2021-11-10 07:06:45 valid 0000, loss 5.516e-01, top1 87.06, top5 95.29
2021-11-10 07:06:45 valid 0000, loss 5.516e-01, top1 87.06, top5 95.29
2021-11-10 07:06:45 valid 0000, loss 5.516e-01, top1 87.06, top5 95.29
2021-11-10 07:11:16 (JOBID 31717) epoch 45: train time 2968.49, inference time 281.92s, valid_top1 67.44 (best_top1 68.87), valid_top5 88.28
2021-11-10 07:11:16 (JOBID 31717) epoch 45: train time 2998.56, inference time 281.90s, valid_top1 67.44 (best_top1 68.87), valid_top5 88.28
2021-11-10 07:11:17 (JOBID 31717) epoch 45: train time 2970.93, inference time 282.75s, valid_top1 67.44 (best_top1 68.87), valid_top5 88.28
2021-11-10 07:11:31 train 0000, loss 1.348e+00, top1 60.00, top5 90.59
2021-11-10 07:11:31 train 0000, loss 1.407e+00, top1 71.76, top5 83.53
2021-11-10 07:11:31 train 0000, loss 1.255e+00, top1 71.76, top5 85.88
2021-11-10 07:21:21 train 1000, loss 1.481e+00, top1 65.36, top5 85.23
2021-11-10 07:21:21 train 1000, loss 1.486e+00, top1 65.31, top5 85.16
2021-11-10 07:21:21 train 1000, loss 1.505e+00, top1 64.78, top5 84.94
2021-11-10 07:31:10 train 2000, loss 1.495e+00, top1 65.10, top5 84.99
2021-11-10 07:31:10 train 2000, loss 1.498e+00, top1 64.99, top5 84.98
2021-11-10 07:31:10 train 2000, loss 1.512e+00, top1 64.65, top5 84.94
2021-11-10 07:40:58 train 3000, loss 1.501e+00, top1 64.90, top5 84.93
2021-11-10 07:40:58 train 3000, loss 1.501e+00, top1 64.94, top5 84.92
2021-11-10 07:40:58 train 3000, loss 1.511e+00, top1 64.63, top5 84.92
2021-11-10 07:50:45 train 4000, loss 1.506e+00, top1 64.81, top5 84.89
2021-11-10 07:50:45 train 4000, loss 1.508e+00, top1 64.74, top5 84.87
2021-11-10 07:50:46 train 4000, loss 1.515e+00, top1 64.57, top5 84.82
2021-11-10 08:00:31 train 5000, loss 1.513e+00, top1 64.63, top5 84.84
2021-11-10 08:00:31 train 5000, loss 1.510e+00, top1 64.68, top5 84.83
2021-11-10 08:00:31 train 5000, loss 1.517e+00, top1 64.53, top5 84.83
2021-11-10 08:00:55 valid 0000, loss 7.986e-01, top1 83.53, top5 91.76
2021-11-10 08:00:55 valid 0000, loss 7.986e-01, top1 83.53, top5 91.76
2021-11-10 08:00:55 valid 0000, loss 7.986e-01, top1 83.53, top5 91.76
2021-11-10 08:06:19 (JOBID 31717) epoch 46: train time 2967.81, inference time 333.66s, valid_top1 68.26 (best_top1 68.87), valid_top5 88.62
2021-11-10 08:06:32 (JOBID 31717) epoch 46: train time 2968.47, inference time 347.35s, valid_top1 68.26 (best_top1 68.87), valid_top5 88.62
2021-11-10 08:06:35 (JOBID 31717) epoch 46: train time 2968.60, inference time 350.65s, valid_top1 68.26 (best_top1 68.87), valid_top5 88.62
2021-11-10 08:06:47 train 0000, loss 1.519e+00, top1 63.53, top5 84.71
2021-11-10 08:06:33 train 0000, loss 1.872e+00, top1 57.65, top5 81.18
2021-11-10 08:06:50 train 0000, loss 1.401e+00, top1 70.59, top5 84.71
2021-11-10 08:16:49 train 1000, loss 1.489e+00, top1 64.95, top5 85.27
2021-11-10 08:16:49 train 1000, loss 1.491e+00, top1 65.04, top5 85.24
2021-11-10 08:16:49 train 1000, loss 1.500e+00, top1 65.07, top5 84.96
2021-11-10 08:26:48 train 2000, loss 1.495e+00, top1 64.85, top5 85.18
2021-11-10 08:26:48 train 2000, loss 1.505e+00, top1 64.67, top5 85.04
2021-11-10 08:26:48 train 2000, loss 1.508e+00, top1 64.83, top5 84.91
2021-11-10 08:36:45 train 3000, loss 1.512e+00, top1 64.69, top5 84.92
2021-11-10 08:36:45 train 3000, loss 1.505e+00, top1 64.72, top5 84.96
2021-11-10 08:36:45 train 3000, loss 1.511e+00, top1 64.56, top5 84.94
2021-11-10 08:46:40 train 4000, loss 1.507e+00, top1 64.67, top5 84.94
2021-11-10 08:46:40 train 4000, loss 1.515e+00, top1 64.58, top5 84.86
2021-11-10 08:46:40 train 4000, loss 1.512e+00, top1 64.53, top5 84.92
2021-11-10 08:56:35 train 5000, loss 1.516e+00, top1 64.55, top5 84.82
2021-11-10 08:56:35 train 5000, loss 1.511e+00, top1 64.59, top5 84.90
2021-11-10 08:56:35 train 5000, loss 1.519e+00, top1 64.42, top5 84.81
2021-11-10 08:57:00 valid 0000, loss 5.545e-01, top1 87.06, top5 96.47
2021-11-10 08:57:00 valid 0000, loss 5.545e-01, top1 87.06, top5 96.47
2021-11-10 08:57:00 valid 0000, loss 5.545e-01, top1 87.06, top5 96.47
2021-11-10 09:01:52 (JOBID 31717) epoch 47: train time 3014.38, inference time 302.33s, valid_top1 68.16 (best_top1 68.87), valid_top5 88.64
2021-11-10 09:01:52 (JOBID 31717) epoch 47: train time 3017.47, inference time 302.35s, valid_top1 68.16 (best_top1 68.87), valid_top5 88.64
2021-11-10 09:01:54 (JOBID 31717) epoch 47: train time 3031.38, inference time 303.71s, valid_top1 68.16 (best_top1 68.87), valid_top5 88.64
2021-11-10 09:02:07 train 0000, loss 1.695e+00, top1 68.24, top5 82.35
2021-11-10 09:02:07 train 0000, loss 1.433e+00, top1 67.06, top5 88.24
2021-11-10 09:02:07 train 0000, loss 1.093e+00, top1 75.29, top5 90.59
2021-11-10 09:11:52 train 1000, loss 1.487e+00, top1 64.99, top5 85.17
2021-11-10 09:11:52 train 1000, loss 1.500e+00, top1 64.94, top5 85.09
2021-11-10 09:11:53 train 1000, loss 1.480e+00, top1 65.16, top5 85.36
2021-11-10 09:21:48 train 2000, loss 1.499e+00, top1 64.87, top5 85.01
2021-11-10 09:21:48 train 2000, loss 1.509e+00, top1 64.62, top5 84.94
2021-11-10 09:21:48 train 2000, loss 1.493e+00, top1 64.93, top5 85.10
2021-11-10 09:31:19 train 3000, loss 1.506e+00, top1 64.67, top5 84.90
2021-11-10 09:31:19 train 3000, loss 1.515e+00, top1 64.52, top5 84.82
2021-11-10 09:31:19 train 3000, loss 1.502e+00, top1 64.74, top5 85.01
2021-11-10 09:40:51 train 4000, loss 1.509e+00, top1 64.65, top5 84.90
2021-11-10 09:40:51 train 4000, loss 1.516e+00, top1 64.51, top5 84.80
2021-11-10 09:40:51 train 4000, loss 1.507e+00, top1 64.65, top5 84.95
2021-11-10 09:50:18 train 5000, loss 1.519e+00, top1 64.43, top5 84.76
2021-11-10 09:50:18 train 5000, loss 1.515e+00, top1 64.57, top5 84.83
2021-11-10 09:50:19 train 5000, loss 1.510e+00, top1 64.59, top5 84.90
2021-11-10 09:50:43 valid 0000, loss 5.957e-01, top1 88.24, top5 95.29
2021-11-10 09:50:43 valid 0000, loss 5.957e-01, top1 88.24, top5 95.29
2021-11-10 09:50:43 valid 0000, loss 5.957e-01, top1 88.24, top5 95.29
2021-11-10 09:55:14 (JOBID 31717) epoch 48: train time 2920.63, inference time 281.65s, valid_top1 67.15 (best_top1 68.87), valid_top5 88.05
2021-11-10 09:55:15 (JOBID 31717) epoch 48: train time 2920.44, inference time 281.76s, valid_top1 67.15 (best_top1 68.87), valid_top5 88.05
2021-11-10 09:55:15 (JOBID 31717) epoch 48: train time 2919.15, inference time 282.67s, valid_top1 67.15 (best_top1 68.87), valid_top5 88.05
2021-11-10 09:55:29 train 0000, loss 1.349e+00, top1 68.24, top5 87.06
2021-11-10 09:55:29 train 0000, loss 1.516e+00, top1 67.06, top5 84.71
2021-11-10 09:55:29 train 0000, loss 1.289e+00, top1 67.06, top5 87.06
2021-11-10 10:04:57 train 1000, loss 1.474e+00, top1 65.49, top5 85.40
2021-11-10 10:04:57 train 1000, loss 1.507e+00, top1 64.85, top5 84.96
2021-11-10 10:04:57 train 1000, loss 1.491e+00, top1 65.03, top5 85.11
2021-11-10 10:14:17 train 2000, loss 1.495e+00, top1 65.03, top5 85.09
2021-11-10 10:14:17 train 2000, loss 1.496e+00, top1 64.85, top5 85.12
2021-11-10 10:14:17 train 2000, loss 1.507e+00, top1 64.74, top5 84.97
2021-11-10 10:23:43 train 3000, loss 1.509e+00, top1 64.71, top5 84.95
2021-11-10 10:23:43 train 3000, loss 1.503e+00, top1 64.88, top5 84.96
2021-11-10 10:23:43 train 3000, loss 1.503e+00, top1 64.73, top5 85.00
2021-11-10 10:32:59 train 4000, loss 1.510e+00, top1 64.70, top5 84.92
2021-11-10 10:32:59 train 4000, loss 1.512e+00, top1 64.68, top5 84.86
2021-11-10 10:32:59 train 4000, loss 1.508e+00, top1 64.66, top5 84.91
2021-11-10 10:42:15 train 5000, loss 1.513e+00, top1 64.61, top5 84.87
2021-11-10 10:42:15 train 5000, loss 1.516e+00, top1 64.64, top5 84.80
2021-11-10 10:42:15 train 5000, loss 1.508e+00, top1 64.63, top5 84.92
2021-11-10 10:42:40 valid 0000, loss 7.120e-01, top1 83.53, top5 94.12
2021-11-10 10:42:40 valid 0000, loss 7.120e-01, top1 83.53, top5 94.12
2021-11-10 10:42:40 valid 0000, loss 7.120e-01, top1 83.53, top5 94.12
2021-11-10 10:46:54 (JOBID 31717) epoch 49: train time 2833.72, inference time 265.35s, valid_top1 67.18 (best_top1 68.87), valid_top5 88.06
2021-11-10 10:47:15 (JOBID 31717) epoch 49: train time 2834.34, inference time 285.68s, valid_top1 67.18 (best_top1 68.87), valid_top5 88.06
2021-11-10 10:47:15 (JOBID 31717) epoch 49: train time 2834.67, inference time 286.27s, valid_top1 67.18 (best_top1 68.87), valid_top5 88.06
2021-11-10 10:47:29 train 0000, loss 1.375e+00, top1 67.06, top5 84.71
2021-11-10 10:47:09 train 0000, loss 1.550e+00, top1 62.35, top5 82.35
2021-11-10 10:47:29 train 0000, loss 1.577e+00, top1 62.35, top5 81.18
2021-11-10 10:56:55 train 1000, loss 1.492e+00, top1 64.85, top5 85.13
2021-11-10 10:56:55 train 1000, loss 1.495e+00, top1 64.98, top5 85.19
2021-11-10 10:56:55 train 1000, loss 1.498e+00, top1 64.92, top5 85.06
2021-11-10 11:06:23 train 2000, loss 1.504e+00, top1 64.85, top5 85.01
2021-11-10 11:06:23 train 2000, loss 1.501e+00, top1 64.82, top5 85.00
2021-11-10 11:06:23 train 2000, loss 1.501e+00, top1 64.72, top5 85.04
2021-11-10 11:15:55 train 3000, loss 1.508e+00, top1 64.71, top5 84.94
2021-11-10 11:15:55 train 3000, loss 1.509e+00, top1 64.63, top5 84.91
2021-11-10 11:15:55 train 3000, loss 1.506e+00, top1 64.77, top5 84.99
2021-11-10 11:25:23 train 4000, loss 1.511e+00, top1 64.57, top5 84.88
2021-11-10 11:25:23 train 4000, loss 1.509e+00, top1 64.62, top5 84.92
2021-11-10 11:25:23 train 4000, loss 1.508e+00, top1 64.68, top5 84.95
2021-11-10 11:34:55 train 5000, loss 1.513e+00, top1 64.57, top5 84.88
2021-11-10 11:34:56 train 5000, loss 1.515e+00, top1 64.50, top5 84.83
2021-11-10 11:34:56 train 5000, loss 1.515e+00, top1 64.55, top5 84.88
2021-11-10 11:35:20 valid 0000, loss 6.792e-01, top1 85.88, top5 94.12
2021-11-10 11:35:20 valid 0000, loss 6.792e-01, top1 85.88, top5 94.12
2021-11-10 11:35:20 valid 0000, loss 6.792e-01, top1 85.88, top5 94.12
2021-11-10 11:39:46 (JOBID 31717) epoch 50: train time 2874.47, inference time 276.44s, valid_top1 67.41 (best_top1 68.87), valid_top5 88.24
2021-11-10 11:39:47 (JOBID 31717) epoch 50: train time 2895.26, inference time 277.14s, valid_top1 67.41 (best_top1 68.87), valid_top5 88.24
2021-11-10 11:39:50 (JOBID 31717) epoch 50: train time 2874.67, inference time 279.90s, valid_top1 67.41 (best_top1 68.87), valid_top5 88.24
2021-11-10 11:40:01 train 0000, loss 1.541e+00, top1 64.71, top5 85.88
2021-11-10 11:40:01 train 0000, loss 1.194e+00, top1 68.24, top5 92.94
2021-11-10 11:40:04 train 0000, loss 1.679e+00, top1 62.35, top5 80.00
2021-11-10 11:49:51 train 1000, loss 1.507e+00, top1 64.75, top5 84.95
2021-11-10 11:49:51 train 1000, loss 1.495e+00, top1 65.08, top5 85.12
2021-11-10 11:49:51 train 1000, loss 1.478e+00, top1 65.26, top5 85.40
2021-11-10 11:59:39 train 2000, loss 1.502e+00, top1 64.92, top5 85.07
2021-11-10 11:59:38 train 2000, loss 1.506e+00, top1 64.84, top5 84.95
2021-11-10 11:59:39 train 2000, loss 1.492e+00, top1 64.96, top5 85.20
2021-11-10 12:09:19 train 3000, loss 1.510e+00, top1 64.68, top5 84.90
2021-11-10 12:09:19 train 3000, loss 1.498e+00, top1 64.85, top5 85.12
2021-11-10 12:09:19 train 3000, loss 1.504e+00, top1 64.82, top5 85.06
2021-11-10 12:18:56 train 4000, loss 1.514e+00, top1 64.60, top5 84.84
2021-11-10 12:18:56 train 4000, loss 1.504e+00, top1 64.70, top5 85.05
2021-11-10 12:18:56 train 4000, loss 1.508e+00, top1 64.72, top5 84.97
2021-11-10 12:28:29 train 5000, loss 1.510e+00, top1 64.61, top5 84.96
2021-11-10 12:28:29 train 5000, loss 1.515e+00, top1 64.55, top5 84.82
2021-11-10 12:28:29 train 5000, loss 1.510e+00, top1 64.65, top5 84.94
2021-11-10 12:28:54 valid 0000, loss 6.670e-01, top1 84.71, top5 92.94
2021-11-10 12:28:54 valid 0000, loss 6.670e-01, top1 84.71, top5 92.94
2021-11-10 12:28:54 valid 0000, loss 6.670e-01, top1 84.71, top5 92.94
2021-11-10 12:33:24 (JOBID 31717) epoch 51: train time 2937.45, inference time 280.18s, valid_top1 67.84 (best_top1 68.87), valid_top5 88.38
2021-11-10 12:33:25 (JOBID 31717) epoch 51: train time 2933.89, inference time 280.70s, valid_top1 67.84 (best_top1 68.87), valid_top5 88.38
2021-11-10 12:33:30 (JOBID 31717) epoch 51: train time 2936.84, inference time 286.03s, valid_top1 67.84 (best_top1 68.87), valid_top5 88.38
2021-11-10 12:33:38 train 0000, loss 1.222e+00, top1 67.06, top5 88.24
2021-11-10 12:33:38 train 0000, loss 1.454e+00, top1 68.24, top5 83.53
2021-11-10 12:33:44 train 0000, loss 1.681e+00, top1 64.71, top5 83.53
2021-11-10 12:43:22 train 1000, loss 1.478e+00, top1 65.26, top5 85.35
2021-11-10 12:43:22 train 1000, loss 1.488e+00, top1 65.09, top5 85.32
2021-11-10 12:43:23 train 1000, loss 1.494e+00, top1 64.95, top5 85.06
2021-11-10 12:53:06 train 2000, loss 1.493e+00, top1 64.99, top5 85.15
2021-11-10 12:53:06 train 2000, loss 1.492e+00, top1 64.96, top5 85.16
2021-11-10 12:53:06 train 2000, loss 1.495e+00, top1 64.92, top5 85.09
2021-11-10 13:02:45 train 3000, loss 1.503e+00, top1 64.75, top5 85.02
2021-11-10 13:02:45 train 3000, loss 1.503e+00, top1 64.77, top5 84.96
2021-11-10 13:02:45 train 3000, loss 1.499e+00, top1 64.81, top5 85.09
2021-11-10 13:12:00 train 4000, loss 1.507e+00, top1 64.70, top5 84.93
2021-11-10 13:12:00 train 4000, loss 1.506e+00, top1 64.70, top5 84.98
2021-11-10 13:12:00 train 4000, loss 1.511e+00, top1 64.60, top5 84.91
2021-11-10 13:21:18 train 5000, loss 1.513e+00, top1 64.59, top5 84.86
2021-11-10 13:21:18 train 5000, loss 1.508e+00, top1 64.65, top5 84.97
2021-11-10 13:21:18 train 5000, loss 1.512e+00, top1 64.57, top5 84.90
2021-11-10 13:21:43 valid 0000, loss 5.015e-01, top1 88.24, top5 94.12
2021-11-10 13:21:43 valid 0000, loss 5.015e-01, top1 88.24, top5 94.12
2021-11-10 13:21:43 valid 0000, loss 5.015e-01, top1 88.24, top5 94.12
2021-11-10 13:26:07 (JOBID 31717) epoch 52: train time 2882.83, inference time 274.29s, valid_top1 67.99 (best_top1 68.87), valid_top5 88.46
2021-11-10 13:26:07 (JOBID 31717) epoch 52: train time 2888.67, inference time 274.29s, valid_top1 67.99 (best_top1 68.87), valid_top5 88.46
2021-11-10 13:26:07 (JOBID 31717) epoch 52: train time 2887.82, inference time 274.33s, valid_top1 67.99 (best_top1 68.87), valid_top5 88.46
2021-11-10 13:26:21 train 0000, loss 1.603e+00, top1 65.88, top5 83.53
2021-11-10 13:26:21 train 0000, loss 1.599e+00, top1 64.71, top5 81.18
2021-11-10 13:26:21 train 0000, loss 1.256e+00, top1 69.41, top5 90.59
2021-11-10 13:35:45 train 1000, loss 1.492e+00, top1 65.08, top5 85.06
2021-11-10 13:35:45 train 1000, loss 1.498e+00, top1 64.99, top5 85.15
2021-11-10 13:35:45 train 1000, loss 1.502e+00, top1 64.91, top5 85.01
2021-11-10 13:45:11 train 2000, loss 1.499e+00, top1 64.94, top5 85.12
2021-11-10 13:45:11 train 2000, loss 1.498e+00, top1 64.87, top5 85.06
2021-11-10 13:45:11 train 2000, loss 1.504e+00, top1 64.82, top5 85.04
2021-11-10 13:54:39 train 3000, loss 1.510e+00, top1 64.70, top5 84.92
2021-11-10 13:54:39 train 3000, loss 1.503e+00, top1 64.84, top5 85.01
2021-11-10 13:54:39 train 3000, loss 1.502e+00, top1 64.79, top5 85.03
2021-11-10 14:04:14 train 4000, loss 1.506e+00, top1 64.74, top5 84.97
2021-11-10 14:04:14 train 4000, loss 1.504e+00, top1 64.75, top5 85.00
2021-11-10 14:04:14 train 4000, loss 1.513e+00, top1 64.60, top5 84.89
2021-11-10 14:13:53 train 5000, loss 1.508e+00, top1 64.65, top5 84.94
2021-11-10 14:13:53 train 5000, loss 1.517e+00, top1 64.50, top5 84.80
2021-11-10 14:13:53 train 5000, loss 1.508e+00, top1 64.66, top5 84.94
2021-11-10 14:14:17 valid 0000, loss 7.091e-01, top1 83.53, top5 92.94
2021-11-10 14:14:17 valid 0000, loss 7.091e-01, top1 83.53, top5 92.94
2021-11-10 14:14:17 valid 0000, loss 7.091e-01, top1 83.53, top5 92.94
2021-11-10 14:18:55 (JOBID 31717) epoch 53: train time 2880.24, inference time 287.42s, valid_top1 67.96 (best_top1 68.87), valid_top5 88.58
2021-11-10 14:18:55 (JOBID 31717) epoch 53: train time 2880.40, inference time 287.32s, valid_top1 67.96 (best_top1 68.87), valid_top5 88.58
2021-11-10 14:18:57 (JOBID 31717) epoch 53: train time 2880.09, inference time 289.11s, valid_top1 67.96 (best_top1 68.87), valid_top5 88.58
2021-11-10 14:19:09 train 0000, loss 1.443e+00, top1 68.24, top5 83.53
2021-11-10 14:19:09 train 0000, loss 1.792e+00, top1 56.47, top5 81.18
2021-11-10 14:19:11 train 0000, loss 1.136e+00, top1 72.94, top5 94.12
2021-11-10 14:28:49 train 1000, loss 1.486e+00, top1 65.04, top5 85.11
2021-11-10 14:28:49 train 1000, loss 1.492e+00, top1 65.00, top5 85.08
2021-11-10 14:28:49 train 1000, loss 1.492e+00, top1 64.92, top5 85.05
2021-11-10 14:38:31 train 2000, loss 1.498e+00, top1 64.90, top5 84.97
2021-11-10 14:38:31 train 2000, loss 1.502e+00, top1 64.84, top5 84.93
2021-11-10 14:38:31 train 2000, loss 1.505e+00, top1 64.66, top5 84.89
2021-11-10 14:48:18 train 3000, loss 1.507e+00, top1 64.74, top5 84.90
2021-11-10 14:48:18 train 3000, loss 1.505e+00, top1 64.72, top5 84.88
2021-11-10 14:48:18 train 3000, loss 1.508e+00, top1 64.59, top5 84.88
2021-11-10 14:57:57 train 4000, loss 1.507e+00, top1 64.68, top5 84.86
2021-11-10 14:57:57 train 4000, loss 1.508e+00, top1 64.57, top5 84.88
2021-11-10 14:57:57 train 4000, loss 1.510e+00, top1 64.66, top5 84.89
2021-11-10 15:07:37 train 5000, loss 1.510e+00, top1 64.61, top5 84.83
2021-11-10 15:07:37 train 5000, loss 1.510e+00, top1 64.54, top5 84.87
2021-11-10 15:07:37 train 5000, loss 1.511e+00, top1 64.61, top5 84.89
2021-11-10 15:08:01 valid 0000, loss 6.063e-01, top1 87.06, top5 96.47
2021-11-10 15:08:01 valid 0000, loss 6.063e-01, top1 87.06, top5 96.47
2021-11-10 15:08:01 valid 0000, loss 6.063e-01, top1 87.06, top5 96.47
2021-11-10 15:12:34 (JOBID 31717) epoch 54: train time 2935.01, inference time 282.25s, valid_top1 67.69 (best_top1 68.87), valid_top5 88.50
2021-11-10 15:12:35 (JOBID 31717) epoch 54: train time 2936.90, inference time 283.48s, valid_top1 67.69 (best_top1 68.87), valid_top5 88.50
2021-11-10 15:12:36 (JOBID 31717) epoch 54: train time 2936.92, inference time 284.50s, valid_top1 67.69 (best_top1 68.87), valid_top5 88.50
2021-11-10 15:12:49 train 0000, loss 1.577e+00, top1 58.82, top5 84.71
2021-11-10 15:12:49 train 0000, loss 1.502e+00, top1 69.41, top5 84.71
2021-11-10 15:12:49 train 0000, loss 1.334e+00, top1 65.88, top5 85.88
2021-11-10 15:22:27 train 1000, loss 1.486e+00, top1 65.13, top5 85.31
2021-11-10 15:22:27 train 1000, loss 1.491e+00, top1 65.06, top5 85.19
2021-11-10 15:22:27 train 1000, loss 1.486e+00, top1 64.98, top5 85.23
2021-11-10 15:32:03 train 2000, loss 1.494e+00, top1 64.96, top5 85.24
2021-11-10 15:32:03 train 2000, loss 1.495e+00, top1 64.79, top5 85.12
2021-11-10 15:32:03 train 2000, loss 1.500e+00, top1 64.94, top5 85.00
2021-11-10 15:41:40 train 3000, loss 1.498e+00, top1 64.84, top5 85.12
2021-11-10 15:41:40 train 3000, loss 1.498e+00, top1 64.66, top5 85.10
2021-11-10 15:41:40 train 3000, loss 1.506e+00, top1 64.77, top5 84.94
2021-11-10 15:51:20 train 4000, loss 1.501e+00, top1 64.80, top5 85.03
2021-11-10 15:51:20 train 4000, loss 1.501e+00, top1 64.67, top5 85.04
2021-11-10 15:51:20 train 4000, loss 1.509e+00, top1 64.70, top5 84.90
2021-11-10 16:01:00 train 5000, loss 1.513e+00, top1 64.59, top5 84.85
2021-11-10 16:01:00 train 5000, loss 1.504e+00, top1 64.64, top5 84.98
2021-11-10 16:01:00 train 5000, loss 1.507e+00, top1 64.70, top5 84.93
2021-11-10 16:01:24 valid 0000, loss 7.043e-01, top1 84.71, top5 94.12
2021-11-10 16:01:24 valid 0000, loss 7.043e-01, top1 84.71, top5 94.12
2021-11-10 16:01:24 valid 0000, loss 7.043e-01, top1 84.71, top5 94.12
2021-11-10 16:15:47 CARME Slurm ID: 31798
2021-11-10 16:15:47 CARME Slurm ID: 31798
2021-11-10 16:15:47 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_09', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.44:23456', distributed=True, epochs=90, evaluate=False, gpu=1, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-10 16:15:47 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_09', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.44:23456', distributed=True, epochs=90, evaluate=False, gpu=2, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-10 16:15:47 CARME Slurm ID: 31798
2021-11-10 16:15:47 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_09', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.44:23456', distributed=True, epochs=90, evaluate=False, gpu=0, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-10 16:15:57 Computational complexity:       1.77 GMac
2021-11-10 16:15:57 Number of parameters:           12.51 M 
2021-11-10 16:15:57 Computational complexity:       1.77 GMac
2021-11-10 16:15:57 Computational complexity:       1.77 GMac
2021-11-10 16:15:57 Number of parameters:           12.51 M 
2021-11-10 16:15:57 Number of parameters:           12.51 M 
2021-11-10 16:15:57 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318'
2021-11-10 16:15:57 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318'
2021-11-10 16:15:57 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318'
2021-11-10 16:15:58 => loaded checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318' (epoch 55)
2021-11-10 16:15:58 => loaded checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318' (epoch 55)
2021-11-10 16:15:58 => loaded checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318' (epoch 55)
2021-11-10 17:20:01 CARME Slurm ID: 31798
2021-11-10 17:20:01 CARME Slurm ID: 31798
2021-11-10 17:20:01 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_09', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.44:23456', distributed=True, epochs=90, evaluate=False, gpu=0, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-10 17:20:01 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_09', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.44:23456', distributed=True, epochs=90, evaluate=False, gpu=1, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-10 17:20:01 CARME Slurm ID: 31798
2021-11-10 17:20:01 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_09', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.44:23456', distributed=True, epochs=90, evaluate=False, gpu=2, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-10 17:20:11 Computational complexity:       1.77 GMac
2021-11-10 17:20:11 Number of parameters:           12.51 M 
2021-11-10 17:20:11 Computational complexity:       1.77 GMac
2021-11-10 17:20:11 Number of parameters:           12.51 M 
2021-11-10 17:20:11 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318'
2021-11-10 17:20:11 Computational complexity:       1.77 GMac
2021-11-10 17:20:11 Number of parameters:           12.51 M 
2021-11-10 17:20:11 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318'
2021-11-10 17:20:11 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318'
2021-11-10 17:20:11 => loaded checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318' (epoch 55)
2021-11-10 17:20:11 => loaded checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318' (epoch 55)
2021-11-10 17:20:11 => loaded checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318' (epoch 55)
2021-11-10 17:20:30 valid 0000, loss 6.063e-01, top1 87.06, top5 96.47
2021-11-10 17:20:30 valid 0000, loss 6.063e-01, top1 87.06, top5 96.47
2021-11-10 17:20:30 valid 0000, loss 6.063e-01, top1 87.06, top5 96.47
2021-11-10 17:24:39 (JOBID 31798) epoch -1: valid_top1 67.69, valid_top5 88.50, inference time 261.91
2021-11-10 17:25:02 (JOBID 31798) epoch -1: valid_top1 67.69, valid_top5 88.50, inference time 285.35
2021-11-10 17:25:02 (JOBID 31798) epoch -1: valid_top1 67.69, valid_top5 88.50, inference time 285.20
2021-11-10 17:25:20 train 0000, loss 1.530e+00, top1 64.71, top5 84.71
2021-11-10 17:25:20 train 0000, loss 1.511e+00, top1 68.24, top5 85.88
2021-11-10 17:25:20 train 0000, loss 1.864e+00, top1 57.65, top5 75.29
2021-11-10 17:34:52 train 1000, loss 1.493e+00, top1 64.93, top5 84.94
2021-11-10 17:34:52 train 1000, loss 1.478e+00, top1 65.21, top5 85.27
2021-11-10 17:34:52 train 1000, loss 1.487e+00, top1 65.21, top5 85.18
2021-11-10 17:44:22 train 2000, loss 1.495e+00, top1 65.02, top5 84.98
2021-11-10 17:44:22 train 2000, loss 1.491e+00, top1 65.03, top5 85.16
2021-11-10 17:44:22 train 2000, loss 1.497e+00, top1 64.96, top5 85.04
2021-11-10 17:53:49 train 3000, loss 1.503e+00, top1 64.82, top5 84.97
2021-11-10 17:53:49 train 3000, loss 1.504e+00, top1 64.81, top5 84.91
2021-11-10 17:53:49 train 3000, loss 1.495e+00, top1 64.84, top5 85.10
2021-11-10 18:03:20 train 4000, loss 1.506e+00, top1 64.76, top5 84.93
2021-11-10 18:03:20 train 4000, loss 1.505e+00, top1 64.83, top5 84.92
2021-11-10 18:03:20 train 4000, loss 1.498e+00, top1 64.78, top5 85.08
2021-11-10 18:12:56 train 5000, loss 1.507e+00, top1 64.74, top5 84.93
2021-11-10 18:12:56 train 5000, loss 1.501e+00, top1 64.75, top5 85.03
2021-11-10 18:12:57 train 5000, loss 1.510e+00, top1 64.64, top5 84.89
2021-11-10 18:13:23 valid 0000, loss 5.476e-01, top1 87.06, top5 94.12
2021-11-10 18:13:23 valid 0000, loss 5.476e-01, top1 87.06, top5 94.12
2021-11-10 18:13:23 valid 0000, loss 5.476e-01, top1 87.06, top5 94.12
2021-11-10 18:17:50 (JOBID 31798) epoch 55: train time 2914.91, inference time 276.82s, valid_top1 66.95 (best_top1 68.87), valid_top5 87.95
2021-11-10 18:17:52 (JOBID 31798) epoch 55: train time 2891.67, inference time 278.49s, valid_top1 66.95 (best_top1 68.87), valid_top5 87.95
2021-11-10 18:17:56 (JOBID 31798) epoch 55: train time 2891.77, inference time 281.82s, valid_top1 66.95 (best_top1 68.87), valid_top5 87.95
2021-11-10 18:18:04 train 0000, loss 1.578e+00, top1 68.24, top5 83.53
2021-11-10 18:18:06 train 0000, loss 1.457e+00, top1 64.71, top5 89.41
2021-11-10 18:18:09 train 0000, loss 1.706e+00, top1 65.88, top5 82.35
2021-11-10 18:27:37 train 1000, loss 1.484e+00, top1 65.08, top5 85.37
2021-11-10 18:27:37 train 1000, loss 1.487e+00, top1 65.20, top5 85.06
2021-11-10 18:27:37 train 1000, loss 1.490e+00, top1 65.10, top5 85.17
2021-11-10 18:36:57 train 2000, loss 1.492e+00, top1 64.91, top5 85.09
2021-11-10 18:36:57 train 2000, loss 1.491e+00, top1 64.98, top5 85.25
2021-11-10 18:36:57 train 2000, loss 1.495e+00, top1 64.91, top5 85.11
2021-11-10 18:46:18 train 3000, loss 1.496e+00, top1 64.88, top5 85.12
2021-11-10 18:46:18 train 3000, loss 1.500e+00, top1 64.77, top5 85.04
2021-11-10 18:46:18 train 3000, loss 1.494e+00, top1 64.87, top5 85.13
2021-11-10 18:55:31 train 4000, loss 1.502e+00, top1 64.79, top5 85.03
2021-11-10 18:55:31 train 4000, loss 1.502e+00, top1 64.72, top5 85.04
2021-11-10 18:55:31 train 4000, loss 1.503e+00, top1 64.70, top5 85.01
2021-11-10 19:04:50 train 5000, loss 1.507e+00, top1 64.67, top5 84.98
2021-11-10 19:04:50 train 5000, loss 1.505e+00, top1 64.69, top5 84.99
2021-11-10 19:04:50 train 5000, loss 1.508e+00, top1 64.63, top5 84.92
2021-11-10 19:05:14 valid 0000, loss 7.837e-01, top1 85.88, top5 92.94
2021-11-10 19:05:14 valid 0000, loss 7.837e-01, top1 85.88, top5 92.94
2021-11-10 19:05:14 valid 0000, loss 7.837e-01, top1 85.88, top5 92.94
2021-11-10 19:09:46 (JOBID 31798) epoch 56: train time 2827.90, inference time 282.17s, valid_top1 68.06 (best_top1 68.87), valid_top5 88.60
2021-11-10 19:09:47 (JOBID 31798) epoch 56: train time 2831.74, inference time 282.82s, valid_top1 68.06 (best_top1 68.87), valid_top5 88.60
2021-11-10 19:09:48 (JOBID 31798) epoch 56: train time 2833.23, inference time 283.87s, valid_top1 68.06 (best_top1 68.87), valid_top5 88.60
2021-11-10 19:10:01 train 0000, loss 1.635e+00, top1 61.18, top5 82.35
2021-11-10 19:10:01 train 0000, loss 1.592e+00, top1 63.53, top5 82.35
2021-11-10 19:10:02 train 0000, loss 1.642e+00, top1 64.71, top5 81.18
2021-11-10 19:19:53 train 1000, loss 1.481e+00, top1 65.23, top5 85.34
2021-11-10 19:19:53 train 1000, loss 1.486e+00, top1 65.17, top5 85.24
2021-11-10 19:19:53 train 1000, loss 1.490e+00, top1 65.00, top5 85.13
2021-11-10 19:29:51 train 2000, loss 1.489e+00, top1 65.07, top5 85.22
2021-11-10 19:29:51 train 2000, loss 1.497e+00, top1 64.96, top5 85.04
2021-11-10 19:29:51 train 2000, loss 1.498e+00, top1 64.88, top5 85.03
2021-11-10 19:39:50 train 3000, loss 1.495e+00, top1 64.93, top5 85.11
2021-11-10 19:39:50 train 3000, loss 1.496e+00, top1 64.97, top5 85.08
2021-11-10 19:39:50 train 3000, loss 1.499e+00, top1 64.83, top5 84.99
2021-11-10 19:49:54 train 4000, loss 1.503e+00, top1 64.79, top5 85.00
2021-11-10 19:49:54 train 4000, loss 1.500e+00, top1 64.88, top5 85.00
2021-11-10 19:49:54 train 4000, loss 1.503e+00, top1 64.71, top5 84.92
2021-11-10 20:00:00 train 5000, loss 1.505e+00, top1 64.75, top5 84.96
2021-11-10 20:00:00 train 5000, loss 1.508e+00, top1 64.62, top5 84.89
2021-11-10 20:00:00 train 5000, loss 1.503e+00, top1 64.79, top5 85.00
2021-11-10 20:00:25 valid 0000, loss 6.168e-01, top1 83.53, top5 94.12
2021-11-10 20:00:25 valid 0000, loss 6.168e-01, top1 83.53, top5 94.12
2021-11-10 20:00:25 valid 0000, loss 6.168e-01, top1 83.53, top5 94.12
2021-11-10 20:04:55 (JOBID 31798) epoch 57: train time 3028.47, inference time 280.31s, valid_top1 66.80 (best_top1 68.87), valid_top5 87.74
2021-11-10 20:04:56 (JOBID 31798) epoch 57: train time 3029.08, inference time 280.29s, valid_top1 66.80 (best_top1 68.87), valid_top5 87.74
2021-11-10 20:04:58 (JOBID 31798) epoch 57: train time 3027.75, inference time 282.57s, valid_top1 66.80 (best_top1 68.87), valid_top5 87.74
2021-11-10 20:05:09 train 0000, loss 1.255e+00, top1 75.29, top5 87.06
2021-11-10 20:05:09 train 0000, loss 1.538e+00, top1 64.71, top5 84.71
2021-11-10 20:05:12 train 0000, loss 1.559e+00, top1 64.71, top5 80.00
2021-11-10 20:14:34 train 1000, loss 1.481e+00, top1 65.51, top5 85.28
2021-11-10 20:14:34 train 1000, loss 1.485e+00, top1 65.03, top5 85.41
2021-11-10 20:14:34 train 1000, loss 1.486e+00, top1 65.15, top5 85.22
2021-11-10 20:23:58 train 2000, loss 1.493e+00, top1 64.98, top5 85.14
2021-11-10 20:23:58 train 2000, loss 1.495e+00, top1 64.88, top5 85.17
2021-11-10 20:23:58 train 2000, loss 1.486e+00, top1 65.30, top5 85.20
2021-11-10 20:33:23 train 3000, loss 1.497e+00, top1 64.88, top5 85.13
2021-11-10 20:33:23 train 3000, loss 1.490e+00, top1 65.13, top5 85.12
2021-11-10 20:33:23 train 3000, loss 1.500e+00, top1 64.84, top5 85.03
2021-11-10 20:42:52 train 4000, loss 1.504e+00, top1 64.76, top5 84.97
2021-11-10 20:42:52 train 4000, loss 1.497e+00, top1 64.99, top5 85.03
2021-11-10 20:42:52 train 4000, loss 1.498e+00, top1 64.83, top5 85.12
2021-11-10 20:52:22 train 5000, loss 1.507e+00, top1 64.69, top5 84.93
2021-11-10 20:52:22 train 5000, loss 1.503e+00, top1 64.80, top5 84.96
2021-11-10 20:52:22 train 5000, loss 1.501e+00, top1 64.76, top5 85.07
2021-11-10 20:52:46 valid 0000, loss 8.398e-01, top1 81.18, top5 89.41
2021-11-10 20:52:46 valid 0000, loss 8.398e-01, top1 81.18, top5 89.41
2021-11-10 20:52:46 valid 0000, loss 8.398e-01, top1 81.18, top5 89.41
2021-11-10 20:57:00 (JOBID 31798) epoch 58: train time 2860.62, inference time 264.32s, valid_top1 67.57 (best_top1 68.87), valid_top5 88.41
2021-11-10 20:57:10 (JOBID 31798) epoch 58: train time 2858.20, inference time 273.62s, valid_top1 67.57 (best_top1 68.87), valid_top5 88.41
2021-11-10 20:57:11 (JOBID 31798) epoch 58: train time 2860.49, inference time 275.12s, valid_top1 67.57 (best_top1 68.87), valid_top5 88.41
2021-11-10 20:57:24 train 0000, loss 1.734e+00, top1 55.29, top5 87.06
2021-11-10 20:57:15 train 0000, loss 1.221e+00, top1 70.59, top5 89.41
2021-11-10 20:57:24 train 0000, loss 1.828e+00, top1 54.12, top5 82.35
2021-11-10 21:07:10 train 1000, loss 1.486e+00, top1 65.03, top5 85.24
2021-11-10 21:07:10 train 1000, loss 1.485e+00, top1 64.95, top5 85.31
2021-11-10 21:07:10 train 1000, loss 1.487e+00, top1 65.04, top5 85.27
2021-11-10 21:16:53 train 2000, loss 1.498e+00, top1 64.89, top5 85.03
2021-11-10 21:16:53 train 2000, loss 1.492e+00, top1 64.96, top5 85.19
2021-11-10 21:16:53 train 2000, loss 1.497e+00, top1 64.80, top5 85.17
2021-11-10 21:26:43 train 3000, loss 1.497e+00, top1 64.85, top5 85.11
2021-11-10 21:26:43 train 3000, loss 1.499e+00, top1 64.92, top5 84.99
2021-11-10 21:26:43 train 3000, loss 1.496e+00, top1 64.89, top5 85.09
2021-11-10 21:36:17 train 4000, loss 1.501e+00, top1 64.80, top5 84.98
2021-11-10 21:36:18 train 4000, loss 1.503e+00, top1 64.85, top5 84.94
2021-11-10 21:36:18 train 4000, loss 1.502e+00, top1 64.74, top5 85.05
2021-11-10 21:46:08 train 5000, loss 1.501e+00, top1 64.81, top5 84.96
2021-11-10 21:46:08 train 5000, loss 1.504e+00, top1 64.79, top5 84.93
2021-11-10 21:46:08 train 5000, loss 1.505e+00, top1 64.71, top5 84.98
2021-11-10 21:46:32 valid 0000, loss 8.911e-01, top1 82.35, top5 90.59
2021-11-10 21:46:32 valid 0000, loss 8.911e-01, top1 82.35, top5 90.59
2021-11-10 21:46:32 valid 0000, loss 8.911e-01, top1 82.35, top5 90.59
2021-11-10 21:50:58 (JOBID 31798) epoch 59: train time 2952.47, inference time 275.97s, valid_top1 67.94 (best_top1 68.87), valid_top5 88.53
2021-11-10 21:50:58 (JOBID 31798) epoch 59: train time 2950.70, inference time 275.98s, valid_top1 67.94 (best_top1 68.87), valid_top5 88.53
2021-11-10 21:50:59 (JOBID 31798) epoch 59: train time 2961.82, inference time 276.85s, valid_top1 67.94 (best_top1 68.87), valid_top5 88.53
2021-11-10 21:51:13 train 0000, loss 1.804e+00, top1 57.65, top5 80.00
2021-11-10 21:51:13 train 0000, loss 1.320e+00, top1 61.18, top5 88.24
2021-11-10 21:51:14 train 0000, loss 1.453e+00, top1 70.59, top5 88.24
2021-11-10 22:01:04 train 1000, loss 1.351e+00, top1 68.22, top5 87.06
2021-11-10 22:01:04 train 1000, loss 1.368e+00, top1 67.84, top5 86.80
2021-11-10 22:01:04 train 1000, loss 1.369e+00, top1 67.98, top5 86.63
2021-11-10 22:10:51 train 2000, loss 1.346e+00, top1 68.36, top5 87.01
2021-11-10 22:10:50 train 2000, loss 1.330e+00, top1 68.60, top5 87.35
2021-11-10 22:10:51 train 2000, loss 1.350e+00, top1 68.34, top5 86.91
2021-11-10 22:20:36 train 3000, loss 1.334e+00, top1 68.70, top5 87.16
2021-11-10 22:20:36 train 3000, loss 1.322e+00, top1 68.77, top5 87.41
2021-11-10 22:20:36 train 3000, loss 1.332e+00, top1 68.67, top5 87.19
2021-11-10 22:30:18 train 4000, loss 1.326e+00, top1 68.83, top5 87.24
2021-11-10 22:30:18 train 4000, loss 1.312e+00, top1 68.98, top5 87.53
2021-11-10 22:30:18 train 4000, loss 1.318e+00, top1 68.93, top5 87.38
2021-11-10 22:40:04 train 5000, loss 1.306e+00, top1 69.10, top5 87.61
2021-11-10 22:40:04 train 5000, loss 1.314e+00, top1 69.06, top5 87.45
2021-11-10 22:40:04 train 5000, loss 1.319e+00, top1 68.98, top5 87.35
2021-11-10 22:40:29 valid 0000, loss 6.536e-01, top1 82.35, top5 94.12
2021-11-10 22:40:29 valid 0000, loss 6.536e-01, top1 82.35, top5 94.12
2021-11-10 22:40:29 valid 0000, loss 6.536e-01, top1 82.35, top5 94.12
2021-11-10 22:44:59 (JOBID 31798) epoch 60: train time 2960.21, inference time 280.84s, valid_top1 72.35 (best_top1 72.35), valid_top5 90.91
2021-11-10 22:45:01 (JOBID 31798) epoch 60: train time 2960.00, inference time 281.66s, valid_top1 72.35 (best_top1 72.35), valid_top5 90.91
2021-11-10 22:45:04 (JOBID 31798) epoch 60: train time 2959.34, inference time 285.07s, valid_top1 72.35 (best_top1 72.35), valid_top5 90.91
2021-11-10 22:45:14 train 0000, loss 1.358e+00, top1 63.53, top5 89.41
2021-11-10 22:45:15 train 0000, loss 1.665e+00, top1 58.82, top5 82.35
2021-11-10 22:45:18 train 0000, loss 1.194e+00, top1 71.76, top5 88.24
2021-11-10 22:55:04 train 1000, loss 1.272e+00, top1 69.91, top5 87.99
2021-11-10 22:55:04 train 1000, loss 1.272e+00, top1 69.87, top5 88.05
2021-11-10 22:55:04 train 1000, loss 1.273e+00, top1 69.93, top5 87.95
2021-11-10 23:04:53 train 2000, loss 1.271e+00, top1 69.88, top5 88.11
2021-11-10 23:04:53 train 2000, loss 1.270e+00, top1 69.95, top5 88.01
2021-11-10 23:04:53 train 2000, loss 1.272e+00, top1 69.90, top5 87.97
2021-11-10 23:14:39 train 3000, loss 1.270e+00, top1 69.98, top5 88.03
2021-11-10 23:14:39 train 3000, loss 1.269e+00, top1 69.93, top5 88.01
2021-11-10 23:14:39 train 3000, loss 1.262e+00, top1 70.04, top5 88.16
2021-11-10 23:24:25 train 4000, loss 1.269e+00, top1 69.97, top5 88.00
2021-11-10 23:24:25 train 4000, loss 1.262e+00, top1 70.06, top5 88.17
2021-11-10 23:24:25 train 4000, loss 1.269e+00, top1 69.98, top5 88.05
2021-11-10 23:34:12 train 5000, loss 1.262e+00, top1 70.09, top5 88.17
2021-11-10 23:34:12 train 5000, loss 1.267e+00, top1 69.98, top5 88.04
2021-11-10 23:34:12 train 5000, loss 1.268e+00, top1 70.02, top5 88.04
2021-11-10 23:34:37 valid 0000, loss 6.151e-01, top1 87.06, top5 94.12
2021-11-10 23:34:37 valid 0000, loss 6.151e-01, top1 87.06, top5 94.12
2021-11-10 23:34:37 valid 0000, loss 6.151e-01, top1 87.06, top5 94.12
2021-11-10 23:39:07 (JOBID 31798) epoch 61: train time 2967.05, inference time 281.16s, valid_top1 72.68 (best_top1 72.68), valid_top5 91.03
2021-11-10 23:39:08 (JOBID 31798) epoch 61: train time 2962.76, inference time 281.91s, valid_top1 72.68 (best_top1 72.68), valid_top5 91.03
2021-11-10 23:39:14 (JOBID 31798) epoch 61: train time 2965.71, inference time 287.23s, valid_top1 72.68 (best_top1 72.68), valid_top5 91.03
2021-11-10 23:39:22 train 0000, loss 1.207e+00, top1 71.76, top5 90.59
2021-11-10 23:39:22 train 0000, loss 1.294e+00, top1 69.41, top5 88.24
2021-11-10 23:39:28 train 0000, loss 1.047e+00, top1 75.29, top5 91.76
2021-11-10 23:49:05 train 1000, loss 1.252e+00, top1 70.37, top5 88.32
2021-11-10 23:49:05 train 1000, loss 1.244e+00, top1 70.50, top5 88.36
2021-11-10 23:49:05 train 1000, loss 1.232e+00, top1 70.82, top5 88.45
2021-11-10 23:58:45 train 2000, loss 1.248e+00, top1 70.38, top5 88.35
2021-11-10 23:58:45 train 2000, loss 1.246e+00, top1 70.50, top5 88.34
2021-11-10 23:58:45 train 2000, loss 1.244e+00, top1 70.49, top5 88.32
2021-11-11 00:08:27 train 3000, loss 1.249e+00, top1 70.46, top5 88.25
2021-11-11 00:08:27 train 3000, loss 1.251e+00, top1 70.31, top5 88.30
2021-11-11 00:08:27 train 3000, loss 1.242e+00, top1 70.55, top5 88.35
2021-11-11 00:18:06 train 4000, loss 1.249e+00, top1 70.46, top5 88.23
2021-11-11 00:18:06 train 4000, loss 1.250e+00, top1 70.35, top5 88.34
2021-11-11 00:18:06 train 4000, loss 1.241e+00, top1 70.57, top5 88.38
2021-11-11 00:27:46 train 5000, loss 1.250e+00, top1 70.35, top5 88.33
2021-11-11 00:27:46 train 5000, loss 1.249e+00, top1 70.42, top5 88.24
2021-11-11 00:27:46 train 5000, loss 1.242e+00, top1 70.57, top5 88.37
2021-11-11 00:28:12 valid 0000, loss 6.315e-01, top1 84.71, top5 94.12
2021-11-11 00:28:12 valid 0000, loss 6.315e-01, top1 84.71, top5 94.12
2021-11-11 00:28:12 valid 0000, loss 6.315e-01, top1 84.71, top5 94.12
2021-11-11 00:32:35 (JOBID 31798) epoch 62: train time 2932.99, inference time 273.38s, valid_top1 72.77 (best_top1 72.77), valid_top5 91.16
2021-11-11 00:32:36 (JOBID 31798) epoch 62: train time 2933.75, inference time 274.35s, valid_top1 72.77 (best_top1 72.77), valid_top5 91.16
2021-11-11 00:32:36 (JOBID 31798) epoch 62: train time 2927.09, inference time 273.74s, valid_top1 72.77 (best_top1 72.77), valid_top5 91.16
2021-11-11 00:32:49 train 0000, loss 1.406e+00, top1 67.06, top5 83.53
2021-11-11 00:32:49 train 0000, loss 1.344e+00, top1 69.41, top5 88.24
2021-11-11 00:32:49 train 0000, loss 1.132e+00, top1 70.59, top5 88.24
2021-11-11 00:42:49 train 1000, loss 1.240e+00, top1 70.60, top5 88.39
2021-11-11 00:42:49 train 1000, loss 1.237e+00, top1 70.65, top5 88.41
2021-11-11 00:42:49 train 1000, loss 1.234e+00, top1 70.83, top5 88.54
2021-11-11 00:52:44 train 2000, loss 1.242e+00, top1 70.61, top5 88.37
2021-11-11 00:52:44 train 2000, loss 1.237e+00, top1 70.63, top5 88.45
2021-11-11 00:52:44 train 2000, loss 1.232e+00, top1 70.81, top5 88.50
2021-11-11 01:02:41 train 3000, loss 1.238e+00, top1 70.72, top5 88.45
2021-11-11 01:02:41 train 3000, loss 1.236e+00, top1 70.63, top5 88.48
2021-11-11 01:02:41 train 3000, loss 1.232e+00, top1 70.78, top5 88.48
2021-11-11 01:12:33 train 4000, loss 1.237e+00, top1 70.66, top5 88.45
2021-11-11 01:12:33 train 4000, loss 1.235e+00, top1 70.68, top5 88.46
2021-11-11 01:12:33 train 4000, loss 1.235e+00, top1 70.74, top5 88.43
2021-11-11 01:22:25 train 5000, loss 1.235e+00, top1 70.72, top5 88.44
2021-11-11 01:22:25 train 5000, loss 1.237e+00, top1 70.64, top5 88.44
2021-11-11 01:22:25 train 5000, loss 1.236e+00, top1 70.66, top5 88.44
2021-11-11 01:22:50 valid 0000, loss 5.909e-01, top1 87.06, top5 96.47
2021-11-11 01:22:50 valid 0000, loss 5.909e-01, top1 87.06, top5 96.47
2021-11-11 01:22:50 valid 0000, loss 5.909e-01, top1 87.06, top5 96.47
2021-11-11 01:27:12 (JOBID 31798) epoch 63: train time 3004.30, inference time 271.93s, valid_top1 72.71 (best_top1 72.77), valid_top5 91.17
2021-11-11 01:27:16 (JOBID 31798) epoch 63: train time 3004.42, inference time 275.97s, valid_top1 72.71 (best_top1 72.77), valid_top5 91.17
2021-11-11 01:27:20 (JOBID 31798) epoch 63: train time 3005.38, inference time 279.85s, valid_top1 72.71 (best_top1 72.77), valid_top5 91.17
2021-11-11 01:27:27 train 0000, loss 1.446e+00, top1 64.71, top5 87.06
2021-11-11 01:27:32 train 0000, loss 1.508e+00, top1 62.35, top5 83.53
2021-11-11 01:27:34 train 0000, loss 1.339e+00, top1 69.41, top5 85.88
2021-11-11 01:37:11 train 1000, loss 1.220e+00, top1 71.07, top5 88.59
2021-11-11 01:37:11 train 1000, loss 1.222e+00, top1 71.07, top5 88.69
2021-11-11 01:37:11 train 1000, loss 1.218e+00, top1 71.24, top5 88.68
2021-11-11 01:46:49 train 2000, loss 1.225e+00, top1 71.03, top5 88.61
2021-11-11 01:46:49 train 2000, loss 1.223e+00, top1 70.96, top5 88.60
2021-11-11 01:46:49 train 2000, loss 1.226e+00, top1 71.00, top5 88.51
2021-11-11 01:56:24 train 3000, loss 1.227e+00, top1 70.94, top5 88.54
2021-11-11 01:56:24 train 3000, loss 1.222e+00, top1 70.97, top5 88.64
2021-11-11 01:56:24 train 3000, loss 1.229e+00, top1 70.93, top5 88.47
2021-11-11 02:05:59 train 4000, loss 1.227e+00, top1 70.90, top5 88.55
2021-11-11 02:05:59 train 4000, loss 1.219e+00, top1 71.00, top5 88.71
2021-11-11 02:05:59 train 4000, loss 1.230e+00, top1 70.91, top5 88.49
2021-11-11 02:15:32 train 5000, loss 1.220e+00, top1 70.97, top5 88.69
2021-11-11 02:15:32 train 5000, loss 1.224e+00, top1 70.93, top5 88.60
2021-11-11 02:15:32 train 5000, loss 1.230e+00, top1 70.89, top5 88.49
2021-11-11 02:15:56 valid 0000, loss 5.754e-01, top1 85.88, top5 97.65
2021-11-11 02:15:56 valid 0000, loss 5.754e-01, top1 85.88, top5 97.65
2021-11-11 02:15:56 valid 0000, loss 5.754e-01, top1 85.88, top5 97.65
2021-11-11 02:20:31 (JOBID 31798) epoch 64: train time 2910.33, inference time 284.49s, valid_top1 72.97 (best_top1 72.97), valid_top5 91.27
2021-11-11 02:20:34 (JOBID 31798) epoch 64: train time 2906.45, inference time 287.52s, valid_top1 72.97 (best_top1 72.97), valid_top5 91.27
2021-11-11 02:20:39 (JOBID 31798) epoch 64: train time 2914.25, inference time 292.10s, valid_top1 72.97 (best_top1 72.97), valid_top5 91.27
2021-11-11 02:20:48 train 0000, loss 1.609e+00, top1 64.71, top5 81.18
2021-11-11 02:20:46 train 0000, loss 9.562e-01, top1 71.76, top5 90.59
2021-11-11 02:20:53 train 0000, loss 1.121e+00, top1 81.18, top5 90.59
2021-11-11 02:30:33 train 1000, loss 1.215e+00, top1 71.21, top5 88.67
2021-11-11 02:30:33 train 1000, loss 1.218e+00, top1 71.16, top5 88.70
2021-11-11 02:30:33 train 1000, loss 1.226e+00, top1 70.87, top5 88.44
2021-11-11 02:40:10 train 2000, loss 1.213e+00, top1 71.20, top5 88.70
2021-11-11 02:40:10 train 2000, loss 1.225e+00, top1 70.86, top5 88.56
2021-11-11 02:40:10 train 2000, loss 1.218e+00, top1 71.09, top5 88.65
2021-11-11 02:49:45 train 3000, loss 1.215e+00, top1 71.15, top5 88.67
2021-11-11 02:49:45 train 3000, loss 1.221e+00, top1 70.99, top5 88.59
2021-11-11 02:49:45 train 3000, loss 1.226e+00, top1 70.85, top5 88.52
2021-11-11 02:59:23 train 4000, loss 1.222e+00, top1 70.98, top5 88.57
2021-11-11 02:59:23 train 4000, loss 1.218e+00, top1 71.09, top5 88.66
2021-11-11 02:59:23 train 4000, loss 1.221e+00, top1 71.00, top5 88.59
2021-11-11 03:09:03 train 5000, loss 1.218e+00, top1 71.06, top5 88.65
2021-11-11 03:09:03 train 5000, loss 1.221e+00, top1 70.99, top5 88.58
2021-11-11 03:09:04 train 5000, loss 1.223e+00, top1 71.00, top5 88.57
2021-11-11 03:09:28 valid 0000, loss 6.126e-01, top1 87.06, top5 94.12
2021-11-11 03:09:28 valid 0000, loss 6.126e-01, top1 87.06, top5 94.12
2021-11-11 03:09:28 valid 0000, loss 6.126e-01, top1 87.06, top5 94.12
2021-11-11 03:13:52 (JOBID 31798) epoch 65: train time 2927.27, inference time 273.97s, valid_top1 73.04 (best_top1 73.04), valid_top5 91.37
2021-11-11 03:13:52 (JOBID 31798) epoch 65: train time 2924.23, inference time 274.05s, valid_top1 73.04 (best_top1 73.04), valid_top5 91.37
2021-11-11 03:13:56 (JOBID 31798) epoch 65: train time 2919.01, inference time 277.19s, valid_top1 73.04 (best_top1 73.04), valid_top5 91.37
2021-11-11 03:14:06 train 0000, loss 1.349e+00, top1 71.76, top5 85.88
2021-11-11 03:14:06 train 0000, loss 1.116e+00, top1 75.29, top5 89.41
2021-11-11 03:14:09 train 0000, loss 1.251e+00, top1 76.47, top5 88.24
2021-11-11 03:23:47 train 1000, loss 1.204e+00, top1 71.40, top5 88.85
2021-11-11 03:23:47 train 1000, loss 1.215e+00, top1 71.18, top5 88.74
2021-11-11 03:23:47 train 1000, loss 1.209e+00, top1 71.03, top5 88.78
2021-11-11 03:33:26 train 2000, loss 1.216e+00, top1 71.12, top5 88.65
2021-11-11 03:33:26 train 2000, loss 1.206e+00, top1 71.35, top5 88.85
2021-11-11 03:33:26 train 2000, loss 1.215e+00, top1 70.99, top5 88.71
2021-11-11 03:43:04 train 3000, loss 1.219e+00, top1 71.02, top5 88.63
2021-11-11 03:43:04 train 3000, loss 1.214e+00, top1 71.08, top5 88.69
2021-11-11 03:43:04 train 3000, loss 1.206e+00, top1 71.34, top5 88.85
2021-11-11 03:52:42 train 4000, loss 1.209e+00, top1 71.30, top5 88.80
2021-11-11 03:52:42 train 4000, loss 1.220e+00, top1 71.01, top5 88.63
2021-11-11 03:52:42 train 4000, loss 1.211e+00, top1 71.18, top5 88.74
2021-11-11 04:02:22 train 5000, loss 1.210e+00, top1 71.29, top5 88.77
2021-11-11 04:02:22 train 5000, loss 1.217e+00, top1 71.06, top5 88.67
2021-11-11 04:02:22 train 5000, loss 1.210e+00, top1 71.23, top5 88.76
2021-11-11 04:02:47 valid 0000, loss 5.816e-01, top1 85.88, top5 96.47
2021-11-11 04:02:47 valid 0000, loss 5.816e-01, top1 85.88, top5 96.47
2021-11-11 04:02:47 valid 0000, loss 5.816e-01, top1 85.88, top5 96.47
2021-11-11 04:07:23 (JOBID 31798) epoch 66: train time 2924.26, inference time 286.24s, valid_top1 73.10 (best_top1 73.10), valid_top5 91.41
2021-11-11 04:07:23 (JOBID 31798) epoch 66: train time 2924.32, inference time 286.11s, valid_top1 73.10 (best_top1 73.10), valid_top5 91.41
2021-11-11 04:07:23 (JOBID 31798) epoch 66: train time 2920.42, inference time 286.35s, valid_top1 73.10 (best_top1 73.10), valid_top5 91.41
2021-11-11 04:07:37 train 0000, loss 1.089e+00, top1 70.59, top5 94.12
2021-11-11 04:07:37 train 0000, loss 1.399e+00, top1 67.06, top5 84.71
2021-11-11 04:07:37 train 0000, loss 1.069e+00, top1 72.94, top5 90.59
2021-11-11 04:17:38 train 1000, loss 1.197e+00, top1 71.56, top5 88.77
2021-11-11 04:17:38 train 1000, loss 1.200e+00, top1 71.56, top5 88.91
2021-11-11 04:17:38 train 1000, loss 1.206e+00, top1 71.33, top5 88.88
2021-11-11 04:27:34 train 2000, loss 1.202e+00, top1 71.47, top5 88.86
2021-11-11 04:27:34 train 2000, loss 1.202e+00, top1 71.45, top5 88.71
2021-11-11 04:27:34 train 2000, loss 1.200e+00, top1 71.42, top5 88.87
2021-11-11 04:37:33 train 3000, loss 1.203e+00, top1 71.44, top5 88.70
2021-11-11 04:37:33 train 3000, loss 1.207e+00, top1 71.34, top5 88.83
2021-11-11 04:37:33 train 3000, loss 1.199e+00, top1 71.37, top5 88.92
2021-11-11 04:47:29 train 4000, loss 1.207e+00, top1 71.37, top5 88.67
2021-11-11 04:47:30 train 4000, loss 1.202e+00, top1 71.37, top5 88.89
2021-11-11 04:47:30 train 4000, loss 1.211e+00, top1 71.29, top5 88.74
2021-11-11 04:57:23 train 5000, loss 1.202e+00, top1 71.35, top5 88.88
2021-11-11 04:57:23 train 5000, loss 1.207e+00, top1 71.37, top5 88.69
2021-11-11 04:57:23 train 5000, loss 1.212e+00, top1 71.27, top5 88.73
2021-11-11 04:57:48 valid 0000, loss 5.889e-01, top1 85.88, top5 96.47
2021-11-11 04:57:48 valid 0000, loss 5.889e-01, top1 85.88, top5 96.47
2021-11-11 04:57:48 valid 0000, loss 5.889e-01, top1 85.88, top5 96.47
2021-11-11 05:02:21 (JOBID 31798) epoch 67: train time 3015.25, inference time 283.68s, valid_top1 73.26 (best_top1 73.26), valid_top5 91.51
2021-11-11 05:02:23 (JOBID 31798) epoch 67: train time 3014.60, inference time 284.87s, valid_top1 73.26 (best_top1 73.26), valid_top5 91.51
2021-11-11 05:02:23 (JOBID 31798) epoch 67: train time 3015.06, inference time 285.65s, valid_top1 73.26 (best_top1 73.26), valid_top5 91.51
2021-11-11 05:02:36 train 0000, loss 1.078e+00, top1 70.59, top5 91.76
2021-11-11 05:02:36 train 0000, loss 1.264e+00, top1 67.06, top5 87.06
2021-11-11 05:02:37 train 0000, loss 1.027e+00, top1 75.29, top5 87.06
2021-11-11 05:12:14 train 1000, loss 1.202e+00, top1 71.47, top5 88.91
2021-11-11 05:12:14 train 1000, loss 1.189e+00, top1 71.68, top5 89.00
2021-11-11 05:12:14 train 1000, loss 1.204e+00, top1 71.35, top5 88.76
2021-11-11 05:21:50 train 2000, loss 1.203e+00, top1 71.40, top5 88.82
2021-11-11 05:21:50 train 2000, loss 1.205e+00, top1 71.35, top5 88.85
2021-11-11 05:21:50 train 2000, loss 1.192e+00, top1 71.61, top5 88.93
2021-11-11 05:31:26 train 3000, loss 1.202e+00, top1 71.39, top5 88.89
2021-11-11 05:31:26 train 3000, loss 1.205e+00, top1 71.40, top5 88.79
2021-11-11 05:31:26 train 3000, loss 1.196e+00, top1 71.51, top5 88.89
2021-11-11 05:41:06 train 4000, loss 1.201e+00, top1 71.42, top5 88.82
2021-11-11 05:41:06 train 4000, loss 1.204e+00, top1 71.40, top5 88.82
2021-11-11 05:41:06 train 4000, loss 1.203e+00, top1 71.33, top5 88.87
2021-11-11 05:50:45 train 5000, loss 1.203e+00, top1 71.43, top5 88.84
2021-11-11 05:50:45 train 5000, loss 1.202e+00, top1 71.38, top5 88.83
2021-11-11 05:50:45 train 5000, loss 1.205e+00, top1 71.30, top5 88.85
2021-11-11 05:51:09 valid 0000, loss 6.019e-01, top1 84.71, top5 95.29
2021-11-11 05:51:09 valid 0000, loss 6.019e-01, top1 84.71, top5 95.29
2021-11-11 05:51:09 valid 0000, loss 6.019e-01, top1 84.71, top5 95.29
2021-11-11 05:55:30 (JOBID 31798) epoch 68: train time 2917.73, inference time 270.86s, valid_top1 73.11 (best_top1 73.26), valid_top5 91.47
2021-11-11 05:55:35 (JOBID 31798) epoch 68: train time 2915.87, inference time 275.46s, valid_top1 73.11 (best_top1 73.26), valid_top5 91.47
2021-11-11 05:55:35 (JOBID 31798) epoch 68: train time 2916.09, inference time 276.16s, valid_top1 73.11 (best_top1 73.26), valid_top5 91.47
2021-11-11 05:55:44 train 0000, loss 1.247e+00, top1 77.65, top5 87.06
2021-11-11 05:55:49 train 0000, loss 1.270e+00, top1 64.71, top5 88.24
2021-11-11 05:55:49 train 0000, loss 1.140e+00, top1 75.29, top5 91.76
2021-11-11 06:05:50 train 1000, loss 1.186e+00, top1 71.76, top5 89.04
2021-11-11 06:05:49 train 1000, loss 1.199e+00, top1 71.61, top5 88.82
2021-11-11 06:05:50 train 1000, loss 1.198e+00, top1 71.39, top5 88.91
2021-11-11 06:15:49 train 2000, loss 1.196e+00, top1 71.65, top5 88.91
2021-11-11 06:15:49 train 2000, loss 1.196e+00, top1 71.44, top5 88.97
2021-11-11 06:15:49 train 2000, loss 1.192e+00, top1 71.66, top5 88.98
2021-11-11 06:25:48 train 3000, loss 1.195e+00, top1 71.49, top5 88.93
2021-11-11 06:25:48 train 3000, loss 1.195e+00, top1 71.59, top5 88.95
2021-11-11 06:25:48 train 3000, loss 1.189e+00, top1 71.70, top5 88.99
2021-11-11 06:35:44 train 4000, loss 1.194e+00, top1 71.57, top5 88.95
2021-11-11 06:35:44 train 4000, loss 1.195e+00, top1 71.56, top5 88.90
2021-11-11 06:35:44 train 4000, loss 1.194e+00, top1 71.56, top5 88.94
2021-11-11 06:45:38 train 5000, loss 1.195e+00, top1 71.52, top5 88.91
2021-11-11 06:45:38 train 5000, loss 1.197e+00, top1 71.52, top5 88.91
2021-11-11 06:45:38 train 5000, loss 1.195e+00, top1 71.53, top5 88.94
2021-11-11 06:46:03 valid 0000, loss 6.223e-01, top1 83.53, top5 96.47
2021-11-11 06:46:03 valid 0000, loss 6.223e-01, top1 83.53, top5 96.47
2021-11-11 06:46:03 valid 0000, loss 6.223e-01, top1 83.53, top5 96.47
2021-11-11 06:50:10 (JOBID 31798) epoch 69: train time 3017.07, inference time 256.94s, valid_top1 73.36 (best_top1 73.36), valid_top5 91.47
2021-11-11 06:50:37 (JOBID 31798) epoch 69: train time 3022.46, inference time 284.59s, valid_top1 73.36 (best_top1 73.36), valid_top5 91.47
2021-11-11 06:50:38 (JOBID 31798) epoch 69: train time 3018.10, inference time 285.39s, valid_top1 73.36 (best_top1 73.36), valid_top5 91.47
2021-11-11 06:50:25 train 0000, loss 1.181e+00, top1 71.76, top5 89.41
2021-11-11 06:50:51 train 0000, loss 1.088e+00, top1 72.94, top5 90.59
2021-11-11 06:50:51 train 0000, loss 1.148e+00, top1 74.12, top5 88.24
2021-11-11 07:00:26 train 1000, loss 1.199e+00, top1 71.46, top5 88.89
2021-11-11 07:00:26 train 1000, loss 1.187e+00, top1 71.79, top5 89.07
2021-11-11 07:00:26 train 1000, loss 1.188e+00, top1 71.83, top5 89.09
2021-11-11 07:10:02 train 2000, loss 1.192e+00, top1 71.61, top5 88.97
2021-11-11 07:10:02 train 2000, loss 1.191e+00, top1 71.62, top5 89.04
2021-11-11 07:10:02 train 2000, loss 1.189e+00, top1 71.64, top5 89.08
2021-11-11 07:19:37 train 3000, loss 1.191e+00, top1 71.69, top5 88.96
2021-11-11 07:19:37 train 3000, loss 1.189e+00, top1 71.67, top5 89.06
2021-11-11 07:19:37 train 3000, loss 1.191e+00, top1 71.63, top5 89.00
2021-11-11 07:29:13 train 4000, loss 1.192e+00, top1 71.66, top5 88.97
2021-11-11 07:29:13 train 4000, loss 1.193e+00, top1 71.65, top5 88.93
2021-11-11 07:29:13 train 4000, loss 1.190e+00, top1 71.63, top5 89.04
2021-11-11 07:38:50 train 5000, loss 1.191e+00, top1 71.64, top5 89.04
2021-11-11 07:38:50 train 5000, loss 1.194e+00, top1 71.63, top5 88.93
2021-11-11 07:38:50 train 5000, loss 1.192e+00, top1 71.65, top5 88.97
2021-11-11 07:39:14 valid 0000, loss 5.873e-01, top1 88.24, top5 95.29
2021-11-11 07:39:15 valid 0000, loss 5.873e-01, top1 88.24, top5 95.29
2021-11-11 07:39:15 valid 0000, loss 5.873e-01, top1 88.24, top5 95.29
2021-11-11 07:43:47 (JOBID 31798) epoch 70: train time 2934.40, inference time 282.24s, valid_top1 73.23 (best_top1 73.36), valid_top5 91.54
2021-11-11 07:43:47 (JOBID 31798) epoch 70: train time 2906.70, inference time 282.47s, valid_top1 73.23 (best_top1 73.36), valid_top5 91.54
2021-11-11 07:43:48 (JOBID 31798) epoch 70: train time 2907.66, inference time 283.69s, valid_top1 73.23 (best_top1 73.36), valid_top5 91.54
2021-11-11 07:44:02 train 0000, loss 1.040e+00, top1 75.29, top5 91.76
2021-11-11 07:44:02 train 0000, loss 1.153e+00, top1 74.12, top5 87.06
2021-11-11 07:44:02 train 0000, loss 1.021e+00, top1 77.65, top5 90.59
2021-11-11 07:53:40 train 1000, loss 1.180e+00, top1 71.83, top5 89.12
2021-11-11 07:53:40 train 1000, loss 1.179e+00, top1 71.81, top5 89.18
2021-11-11 07:53:40 train 1000, loss 1.196e+00, top1 71.66, top5 88.90
2021-11-11 08:03:12 train 2000, loss 1.185e+00, top1 71.69, top5 89.04
2021-11-11 08:03:12 train 2000, loss 1.181e+00, top1 71.95, top5 89.12
2021-11-11 08:03:12 train 2000, loss 1.188e+00, top1 71.84, top5 88.99
2021-11-11 08:12:52 train 3000, loss 1.186e+00, top1 71.63, top5 89.06
2021-11-11 08:12:52 train 3000, loss 1.184e+00, top1 71.90, top5 89.03
2021-11-11 08:12:52 train 3000, loss 1.193e+00, top1 71.70, top5 88.97
2021-11-11 08:22:25 train 4000, loss 1.186e+00, top1 71.81, top5 89.04
2021-11-11 08:22:25 train 4000, loss 1.187e+00, top1 71.62, top5 89.01
2021-11-11 08:22:25 train 4000, loss 1.193e+00, top1 71.64, top5 88.97
2021-11-11 08:32:00 train 5000, loss 1.188e+00, top1 71.74, top5 89.02
2021-11-11 08:32:00 train 5000, loss 1.189e+00, top1 71.61, top5 88.97
2021-11-11 08:32:00 train 5000, loss 1.193e+00, top1 71.62, top5 88.98
2021-11-11 08:32:24 valid 0000, loss 5.709e-01, top1 85.88, top5 96.47
2021-11-11 08:32:24 valid 0000, loss 5.709e-01, top1 85.88, top5 96.47
2021-11-11 08:32:24 valid 0000, loss 5.709e-01, top1 85.88, top5 96.47
2021-11-11 08:36:32 (JOBID 31798) epoch 71: train time 2906.80, inference time 257.52s, valid_top1 73.29 (best_top1 73.36), valid_top5 91.46
2021-11-11 08:37:01 (JOBID 31798) epoch 71: train time 2907.06, inference time 286.31s, valid_top1 73.29 (best_top1 73.36), valid_top5 91.46
2021-11-11 08:37:01 (JOBID 31798) epoch 71: train time 2905.69, inference time 286.66s, valid_top1 73.29 (best_top1 73.36), valid_top5 91.46
2021-11-11 08:36:45 train 0000, loss 1.308e+00, top1 65.88, top5 85.88
2021-11-11 08:37:14 train 0000, loss 1.105e+00, top1 76.47, top5 91.76
2021-11-11 08:37:14 train 0000, loss 1.485e+00, top1 62.35, top5 85.88
2021-11-11 08:46:52 train 1000, loss 1.177e+00, top1 71.93, top5 89.18
2021-11-11 08:46:52 train 1000, loss 1.189e+00, top1 71.72, top5 89.05
2021-11-11 08:46:52 train 1000, loss 1.183e+00, top1 71.88, top5 89.10
2021-11-11 08:56:22 train 2000, loss 1.178e+00, top1 71.97, top5 89.17
2021-11-11 08:56:22 train 2000, loss 1.182e+00, top1 71.85, top5 89.16
2021-11-11 08:56:22 train 2000, loss 1.183e+00, top1 71.87, top5 89.12
2021-11-11 09:05:53 train 3000, loss 1.184e+00, top1 71.82, top5 89.13
2021-11-11 09:05:53 train 3000, loss 1.178e+00, top1 71.95, top5 89.13
2021-11-11 09:05:53 train 3000, loss 1.187e+00, top1 71.79, top5 89.05
2021-11-11 09:15:25 train 4000, loss 1.185e+00, top1 71.80, top5 89.11
2021-11-11 09:15:25 train 4000, loss 1.187e+00, top1 71.75, top5 89.06
2021-11-11 09:15:26 train 4000, loss 1.182e+00, top1 71.82, top5 89.10
2021-11-11 09:25:00 train 5000, loss 1.184e+00, top1 71.79, top5 89.12
2021-11-11 09:25:00 train 5000, loss 1.184e+00, top1 71.79, top5 89.05
2021-11-11 09:25:00 train 5000, loss 1.187e+00, top1 71.70, top5 89.04
2021-11-11 09:25:24 valid 0000, loss 5.769e-01, top1 85.88, top5 96.47
2021-11-11 09:25:24 valid 0000, loss 5.769e-01, top1 85.88, top5 96.47
2021-11-11 09:25:24 valid 0000, loss 5.769e-01, top1 85.88, top5 96.47
2021-11-11 09:29:53 (JOBID 31798) epoch 72: train time 2922.89, inference time 278.66s, valid_top1 73.29 (best_top1 73.36), valid_top5 91.45
2021-11-11 09:29:53 (JOBID 31798) epoch 72: train time 2893.71, inference time 278.60s, valid_top1 73.29 (best_top1 73.36), valid_top5 91.45
2021-11-11 09:29:54 (JOBID 31798) epoch 72: train time 2893.85, inference time 279.70s, valid_top1 73.29 (best_top1 73.36), valid_top5 91.45
2021-11-11 09:30:07 train 0000, loss 1.053e+00, top1 70.59, top5 94.12
2021-11-11 09:30:07 train 0000, loss 1.002e+00, top1 72.94, top5 90.59
2021-11-11 09:30:09 train 0000, loss 1.174e+00, top1 71.76, top5 89.41
2021-11-11 09:39:49 train 1000, loss 1.176e+00, top1 72.00, top5 89.14
2021-11-11 09:39:49 train 1000, loss 1.171e+00, top1 72.17, top5 89.22
2021-11-11 09:39:49 train 1000, loss 1.169e+00, top1 72.16, top5 89.36
2021-11-11 09:49:27 train 2000, loss 1.178e+00, top1 71.98, top5 89.10
2021-11-11 09:49:27 train 2000, loss 1.172e+00, top1 72.05, top5 89.25
2021-11-11 09:49:27 train 2000, loss 1.172e+00, top1 72.04, top5 89.20
2021-11-11 09:58:55 train 3000, loss 1.177e+00, top1 71.96, top5 89.11
2021-11-11 09:58:55 train 3000, loss 1.177e+00, top1 71.93, top5 89.16
2021-11-11 09:58:55 train 3000, loss 1.174e+00, top1 72.01, top5 89.23
2021-11-11 10:08:28 train 4000, loss 1.178e+00, top1 71.94, top5 89.13
2021-11-11 10:08:28 train 4000, loss 1.176e+00, top1 71.97, top5 89.19
2021-11-11 10:08:28 train 4000, loss 1.179e+00, top1 71.87, top5 89.16
2021-11-11 10:18:01 train 5000, loss 1.180e+00, top1 71.89, top5 89.10
2021-11-11 10:18:01 train 5000, loss 1.177e+00, top1 71.94, top5 89.17
2021-11-11 10:18:01 train 5000, loss 1.183e+00, top1 71.78, top5 89.11
2021-11-11 10:18:25 valid 0000, loss 5.676e-01, top1 87.06, top5 95.29
2021-11-11 10:18:25 valid 0000, loss 5.676e-01, top1 87.06, top5 95.29
2021-11-11 10:18:25 valid 0000, loss 5.676e-01, top1 87.06, top5 95.29
2021-11-11 10:23:05 (JOBID 31798) epoch 73: train time 2902.10, inference time 290.01s, valid_top1 73.34 (best_top1 73.36), valid_top5 91.50
2021-11-11 10:23:05 (JOBID 31798) epoch 73: train time 2902.13, inference time 290.00s, valid_top1 73.34 (best_top1 73.36), valid_top5 91.50
2021-11-11 10:23:05 (JOBID 31798) epoch 73: train time 2900.92, inference time 290.00s, valid_top1 73.34 (best_top1 73.36), valid_top5 91.50
2021-11-11 10:23:19 train 0000, loss 8.544e-01, top1 78.82, top5 95.29
2021-11-11 10:23:19 train 0000, loss 1.744e+00, top1 64.71, top5 81.18
2021-11-11 10:23:19 train 0000, loss 1.151e+00, top1 68.24, top5 89.41
2021-11-11 10:33:59 train 1000, loss 1.171e+00, top1 72.18, top5 89.16
2021-11-11 10:33:59 train 1000, loss 1.177e+00, top1 71.94, top5 89.28
2021-11-11 10:33:59 train 1000, loss 1.176e+00, top1 71.98, top5 89.24
2021-11-11 10:43:11 train 2000, loss 1.174e+00, top1 72.09, top5 89.16
2021-11-11 10:43:11 train 2000, loss 1.182e+00, top1 71.88, top5 89.14
2021-11-11 10:43:11 train 2000, loss 1.177e+00, top1 72.03, top5 89.17
2021-11-11 10:52:20 train 3000, loss 1.175e+00, top1 72.03, top5 89.18
2021-11-11 10:52:20 train 3000, loss 1.180e+00, top1 71.97, top5 89.14
2021-11-11 10:52:20 train 3000, loss 1.183e+00, top1 71.87, top5 89.09
2021-11-11 11:01:27 train 4000, loss 1.179e+00, top1 71.97, top5 89.13
2021-11-11 11:01:27 train 4000, loss 1.175e+00, top1 72.01, top5 89.16
2021-11-11 11:01:28 train 4000, loss 1.182e+00, top1 71.89, top5 89.12
2021-11-11 11:10:33 train 5000, loss 1.174e+00, top1 72.02, top5 89.20
2021-11-11 11:10:33 train 5000, loss 1.180e+00, top1 71.93, top5 89.10
2021-11-11 11:10:33 train 5000, loss 1.182e+00, top1 71.83, top5 89.10
2021-11-11 11:10:56 valid 0000, loss 5.783e-01, top1 85.88, top5 96.47
2021-11-11 11:10:56 valid 0000, loss 5.783e-01, top1 85.88, top5 96.47
2021-11-11 11:10:56 valid 0000, loss 5.783e-01, top1 85.88, top5 96.47
2021-11-11 11:15:08 (JOBID 31798) epoch 74: train time 2861.40, inference time 261.74s, valid_top1 73.25 (best_top1 73.36), valid_top5 91.57
2021-11-11 11:15:29 (JOBID 31798) epoch 74: train time 2861.49, inference time 282.27s, valid_top1 73.25 (best_top1 73.36), valid_top5 91.57
2021-11-11 11:15:29 (JOBID 31798) epoch 74: train time 2861.06, inference time 282.41s, valid_top1 73.25 (best_top1 73.36), valid_top5 91.57
2021-11-11 11:15:42 train 0000, loss 1.135e+00, top1 74.12, top5 87.06
2021-11-11 11:15:23 train 0000, loss 1.348e+00, top1 70.59, top5 88.24
2021-11-11 11:15:42 train 0000, loss 1.240e+00, top1 71.76, top5 85.88
2021-11-11 11:25:05 train 1000, loss 1.168e+00, top1 72.23, top5 89.29
2021-11-11 11:25:05 train 1000, loss 1.170e+00, top1 71.98, top5 89.38
2021-11-11 11:25:05 train 1000, loss 1.175e+00, top1 71.97, top5 89.16
2021-11-11 11:34:27 train 2000, loss 1.167e+00, top1 72.19, top5 89.29
2021-11-11 11:34:27 train 2000, loss 1.174e+00, top1 71.96, top5 89.27
2021-11-11 11:34:27 train 2000, loss 1.173e+00, top1 72.09, top5 89.18
2021-11-11 11:44:16 train 3000, loss 1.175e+00, top1 71.94, top5 89.24
2021-11-11 11:44:16 train 3000, loss 1.167e+00, top1 72.15, top5 89.28
2021-11-11 11:44:16 train 3000, loss 1.173e+00, top1 72.07, top5 89.21
2021-11-11 11:53:56 train 4000, loss 1.176e+00, top1 71.92, top5 89.24
2021-11-11 11:53:56 train 4000, loss 1.171e+00, top1 72.08, top5 89.22
2021-11-11 11:53:56 train 4000, loss 1.170e+00, top1 72.14, top5 89.26
2021-11-11 12:03:10 train 5000, loss 1.172e+00, top1 72.07, top5 89.24
2021-11-11 12:03:10 train 5000, loss 1.176e+00, top1 71.92, top5 89.23
2021-11-11 12:03:10 train 5000, loss 1.172e+00, top1 72.10, top5 89.26
2021-11-11 12:03:34 valid 0000, loss 5.475e-01, top1 88.24, top5 95.29
2021-11-11 12:03:34 valid 0000, loss 5.475e-01, top1 88.24, top5 95.29
2021-11-11 12:03:35 valid 0000, loss 5.475e-01, top1 88.24, top5 95.29
2021-11-11 12:07:59 (JOBID 31798) epoch 75: train time 2875.40, inference time 275.00s, valid_top1 73.59 (best_top1 73.59), valid_top5 91.60
2021-11-11 12:08:06 (JOBID 31798) epoch 75: train time 2895.95, inference time 281.41s, valid_top1 73.59 (best_top1 73.59), valid_top5 91.60
2021-11-11 12:08:06 (JOBID 31798) epoch 75: train time 2875.25, inference time 281.36s, valid_top1 73.59 (best_top1 73.59), valid_top5 91.60
2021-11-11 12:08:14 train 0000, loss 1.004e+00, top1 76.47, top5 87.06
2021-11-11 12:08:20 train 0000, loss 1.287e+00, top1 71.76, top5 89.41
2021-11-11 12:08:20 train 0000, loss 1.093e+00, top1 71.76, top5 92.94
2021-11-11 12:17:50 train 1000, loss 1.160e+00, top1 72.39, top5 89.28
2021-11-11 12:17:51 train 1000, loss 1.160e+00, top1 72.37, top5 89.41
2021-11-11 12:17:51 train 1000, loss 1.172e+00, top1 72.17, top5 89.29
2021-11-11 12:27:34 train 2000, loss 1.168e+00, top1 72.11, top5 89.23
2021-11-11 12:27:34 train 2000, loss 1.164e+00, top1 72.26, top5 89.34
2021-11-11 12:27:34 train 2000, loss 1.170e+00, top1 72.18, top5 89.28
2021-11-11 12:37:14 train 3000, loss 1.170e+00, top1 72.08, top5 89.21
2021-11-11 12:37:14 train 3000, loss 1.168e+00, top1 72.17, top5 89.32
2021-11-11 12:37:14 train 3000, loss 1.168e+00, top1 72.22, top5 89.27
2021-11-11 12:46:54 train 4000, loss 1.172e+00, top1 72.02, top5 89.20
2021-11-11 12:46:54 train 4000, loss 1.169e+00, top1 72.10, top5 89.30
2021-11-11 12:46:54 train 4000, loss 1.169e+00, top1 72.19, top5 89.25
2021-11-11 12:56:34 train 5000, loss 1.171e+00, top1 72.03, top5 89.21
2021-11-11 12:56:34 train 5000, loss 1.171e+00, top1 72.08, top5 89.26
2021-11-11 12:56:34 train 5000, loss 1.170e+00, top1 72.18, top5 89.26
2021-11-11 12:56:59 valid 0000, loss 5.399e-01, top1 87.06, top5 96.47
2021-11-11 12:56:59 valid 0000, loss 5.399e-01, top1 87.06, top5 96.47
2021-11-11 12:56:59 valid 0000, loss 5.399e-01, top1 87.06, top5 96.47
2021-11-11 13:01:21 (JOBID 31798) epoch 76: train time 2922.39, inference time 272.09s, valid_top1 73.38 (best_top1 73.59), valid_top5 91.63
2021-11-11 13:01:22 (JOBID 31798) epoch 76: train time 2929.26, inference time 273.21s, valid_top1 73.38 (best_top1 73.59), valid_top5 91.63
2021-11-11 13:01:22 (JOBID 31798) epoch 76: train time 2922.92, inference time 273.21s, valid_top1 73.38 (best_top1 73.59), valid_top5 91.63
2021-11-11 13:01:36 train 0000, loss 1.033e+00, top1 76.47, top5 90.59
2021-11-11 13:01:36 train 0000, loss 9.037e-01, top1 78.82, top5 94.12
2021-11-11 13:01:36 train 0000, loss 1.012e+00, top1 71.76, top5 92.94
2021-11-11 13:11:20 train 1000, loss 1.168e+00, top1 72.19, top5 89.25
2021-11-11 13:11:20 train 1000, loss 1.156e+00, top1 72.33, top5 89.39
2021-11-11 13:11:20 train 1000, loss 1.158e+00, top1 72.20, top5 89.38
2021-11-11 13:20:57 train 2000, loss 1.168e+00, top1 72.18, top5 89.28
2021-11-11 13:20:57 train 2000, loss 1.157e+00, top1 72.32, top5 89.46
2021-11-11 13:20:57 train 2000, loss 1.157e+00, top1 72.36, top5 89.36
2021-11-11 13:30:09 train 3000, loss 1.168e+00, top1 72.21, top5 89.28
2021-11-11 13:30:09 train 3000, loss 1.159e+00, top1 72.28, top5 89.33
2021-11-11 13:30:09 train 3000, loss 1.161e+00, top1 72.33, top5 89.40
2021-11-11 13:39:14 train 4000, loss 1.162e+00, top1 72.22, top5 89.33
2021-11-11 13:39:14 train 4000, loss 1.168e+00, top1 72.19, top5 89.27
2021-11-11 13:39:14 train 4000, loss 1.164e+00, top1 72.31, top5 89.36
2021-11-11 13:48:21 train 5000, loss 1.164e+00, top1 72.19, top5 89.30
2021-11-11 13:48:21 train 5000, loss 1.171e+00, top1 72.12, top5 89.23
2021-11-11 13:48:22 train 5000, loss 1.167e+00, top1 72.22, top5 89.30
2021-11-11 13:48:50 valid 0000, loss 5.149e-01, top1 87.06, top5 96.47
2021-11-11 13:48:50 valid 0000, loss 5.149e-01, top1 87.06, top5 96.47
2021-11-11 13:48:50 valid 0000, loss 5.149e-01, top1 87.06, top5 96.47
2021-11-11 13:53:05 (JOBID 31798) epoch 77: train time 2833.01, inference time 270.02s, valid_top1 73.36 (best_top1 73.59), valid_top5 91.62
2021-11-11 13:53:24 (JOBID 31798) epoch 77: train time 2833.90, inference time 287.78s, valid_top1 73.36 (best_top1 73.59), valid_top5 91.62
2021-11-11 13:53:26 (JOBID 31798) epoch 77: train time 2832.87, inference time 291.26s, valid_top1 73.36 (best_top1 73.59), valid_top5 91.62
2021-11-11 13:53:30 train 0000, loss 1.426e+00, top1 64.71, top5 88.24
2021-11-11 13:53:38 train 0000, loss 1.026e+00, top1 75.29, top5 90.59
2021-11-11 13:53:40 train 0000, loss 1.182e+00, top1 70.59, top5 88.24
2021-11-11 14:03:10 train 1000, loss 1.161e+00, top1 72.35, top5 89.26
2021-11-11 14:03:10 train 1000, loss 1.174e+00, top1 71.93, top5 89.14
2021-11-11 14:03:10 train 1000, loss 1.154e+00, top1 72.26, top5 89.56
2021-11-11 14:12:41 train 2000, loss 1.163e+00, top1 72.29, top5 89.32
2021-11-11 14:12:41 train 2000, loss 1.160e+00, top1 72.21, top5 89.42
2021-11-11 14:12:41 train 2000, loss 1.172e+00, top1 72.03, top5 89.25
2021-11-11 14:52:28 CARME Slurm ID: 31737
2021-11-11 14:52:28 CARME Slurm ID: 31737
2021-11-11 14:52:28 CARME Slurm ID: 31737
2021-11-11 14:52:28 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_09', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.34:23456', distributed=True, epochs=90, evaluate=False, gpu=1, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-11 14:52:28 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_09', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.34:23456', distributed=True, epochs=90, evaluate=False, gpu=0, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-11 14:52:28 args = Namespace(arch='resnet50', baseline_model='pretrained_conv12_layer_adaptive_mu_0_09', batch_size=256, data='/home/SSD/Dataset_ImageNet', dist_backend='nccl', dist_url='tcp://192.168.152.34:23456', distributed=True, epochs=90, evaluate=False, gpu=2, lr=0.1, momentum=0.9, multiprocessing_distributed=True, path_to_resume='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', path_to_save='retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', print_freq=1000, pruning_threshold=1e-06, rank=0, run_id='resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318', seed=None, start_epoch=0, weight_decay=0.0001, workers=4, world_size=3)
2021-11-11 14:52:42 Computational complexity:       1.77 GMac
2021-11-11 14:52:42 Computational complexity:       1.77 GMac
2021-11-11 14:52:42 Number of parameters:           12.51 M 
2021-11-11 14:52:42 Number of parameters:           12.51 M 
2021-11-11 14:52:42 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318'
2021-11-11 14:52:42 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318'
2021-11-11 14:52:42 Computational complexity:       1.77 GMac
2021-11-11 14:52:42 Number of parameters:           12.51 M 
2021-11-11 14:52:42 => loading checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318'
2021-11-11 14:52:47 => loaded checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318' (epoch 78)
2021-11-11 14:52:47 => loaded checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318' (epoch 78)
2021-11-11 14:52:47 => loaded checkpoint 'retrain_resnet50_pretrained_conv12_layer_adaptive_mu_0_09_20211108-155318' (epoch 78)
2021-11-11 14:53:10 valid 0000, loss 5.149e-01, top1 87.06, top5 96.47
2021-11-11 14:53:10 valid 0000, loss 5.149e-01, top1 87.06, top5 96.47
2021-11-11 14:53:10 valid 0000, loss 5.149e-01, top1 87.06, top5 96.47
2021-11-11 14:57:28 (JOBID 31737) epoch -1: valid_top1 73.36, valid_top5 91.62, inference time 276.09
2021-11-11 14:57:30 (JOBID 31737) epoch -1: valid_top1 73.36, valid_top5 91.62, inference time 278.29
2021-11-11 14:57:35 (JOBID 31737) epoch -1: valid_top1 73.36, valid_top5 91.62, inference time 283.64
2021-11-11 14:57:54 train 0000, loss 1.257e+00, top1 68.24, top5 90.59
2021-11-11 14:57:54 train 0000, loss 1.464e+00, top1 64.71, top5 87.06
2021-11-11 14:57:54 train 0000, loss 1.353e+00, top1 71.76, top5 85.88
2021-11-11 15:07:45 train 1000, loss 1.171e+00, top1 71.97, top5 89.36
2021-11-11 15:07:45 train 1000, loss 1.151e+00, top1 72.57, top5 89.52
2021-11-11 15:07:45 train 1000, loss 1.155e+00, top1 72.33, top5 89.53
2021-11-11 15:17:11 train 2000, loss 1.157e+00, top1 72.39, top5 89.41
2021-11-11 15:17:11 train 2000, loss 1.165e+00, top1 72.10, top5 89.40
2021-11-11 15:17:11 train 2000, loss 1.157e+00, top1 72.25, top5 89.46
2021-11-11 15:26:33 train 3000, loss 1.162e+00, top1 72.31, top5 89.32
2021-11-11 15:26:33 train 3000, loss 1.166e+00, top1 72.13, top5 89.34
2021-11-11 15:26:33 train 3000, loss 1.160e+00, top1 72.18, top5 89.41
2021-11-11 15:35:53 train 4000, loss 1.163e+00, top1 72.26, top5 89.33
2021-11-11 15:35:53 train 4000, loss 1.166e+00, top1 72.14, top5 89.31
2021-11-11 15:35:53 train 4000, loss 1.160e+00, top1 72.22, top5 89.39
2021-11-11 15:45:11 train 5000, loss 1.165e+00, top1 72.13, top5 89.29
2021-11-11 15:45:11 train 5000, loss 1.164e+00, top1 72.22, top5 89.30
2021-11-11 15:45:11 train 5000, loss 1.162e+00, top1 72.20, top5 89.35
2021-11-11 15:45:52 valid 0000, loss 4.989e-01, top1 87.06, top5 96.47
2021-11-11 15:45:52 valid 0000, loss 4.989e-01, top1 87.06, top5 96.47
2021-11-11 15:45:52 valid 0000, loss 4.989e-01, top1 87.06, top5 96.47
2021-11-11 15:50:09 (JOBID 31737) epoch 78: train time 2879.82, inference time 280.32s, valid_top1 73.55 (best_top1 73.59), valid_top5 91.55
2021-11-11 15:50:24 (JOBID 31737) epoch 78: train time 2872.27, inference time 296.15s, valid_top1 73.55 (best_top1 73.59), valid_top5 91.55
2021-11-11 15:50:24 (JOBID 31737) epoch 78: train time 2877.62, inference time 296.15s, valid_top1 73.55 (best_top1 73.59), valid_top5 91.55
2021-11-11 15:50:23 train 0000, loss 1.031e+00, top1 74.12, top5 95.29
2021-11-11 15:50:37 train 0000, loss 1.056e+00, top1 72.94, top5 92.94
2021-11-11 15:50:37 train 0000, loss 1.181e+00, top1 71.76, top5 88.24
2021-11-11 16:00:23 train 1000, loss 1.164e+00, top1 72.16, top5 89.38
2021-11-11 16:00:23 train 1000, loss 1.150e+00, top1 72.39, top5 89.48
2021-11-11 16:00:23 train 1000, loss 1.155e+00, top1 72.52, top5 89.41
2021-11-11 16:09:54 train 2000, loss 1.159e+00, top1 72.24, top5 89.38
2021-11-11 16:09:54 train 2000, loss 1.155e+00, top1 72.49, top5 89.45
2021-11-11 16:09:54 train 2000, loss 1.161e+00, top1 72.20, top5 89.34
2021-11-11 16:19:21 train 3000, loss 1.159e+00, top1 72.37, top5 89.39
2021-11-11 16:19:21 train 3000, loss 1.162e+00, top1 72.21, top5 89.35
2021-11-11 16:19:21 train 3000, loss 1.158e+00, top1 72.25, top5 89.40
2021-11-11 16:28:56 train 4000, loss 1.160e+00, top1 72.27, top5 89.36
2021-11-11 16:28:56 train 4000, loss 1.165e+00, top1 72.17, top5 89.30
2021-11-11 16:28:56 train 4000, loss 1.157e+00, top1 72.38, top5 89.41
2021-11-11 16:40:38 train 5000, loss 1.162e+00, top1 72.27, top5 89.34
2021-11-11 16:40:38 train 5000, loss 1.166e+00, top1 72.17, top5 89.28
2021-11-11 16:40:39 train 5000, loss 1.159e+00, top1 72.35, top5 89.41
2021-11-11 16:41:04 valid 0000, loss 4.709e-01, top1 88.24, top5 96.47
2021-11-11 16:41:04 valid 0000, loss 4.709e-01, top1 88.24, top5 96.47
2021-11-11 16:41:05 valid 0000, loss 4.709e-01, top1 88.24, top5 96.47
2021-11-11 16:45:31 (JOBID 31737) epoch 79: train time 3028.88, inference time 277.99s, valid_top1 73.50 (best_top1 73.59), valid_top5 91.50
2021-11-11 16:45:31 (JOBID 31737) epoch 79: train time 3028.96, inference time 278.53s, valid_top1 73.50 (best_top1 73.59), valid_top5 91.50
2021-11-11 16:45:37 (JOBID 31737) epoch 79: train time 3044.14, inference time 283.50s, valid_top1 73.50 (best_top1 73.59), valid_top5 91.50
2021-11-11 16:45:46 train 0000, loss 1.187e+00, top1 67.06, top5 88.24
2021-11-11 16:45:46 train 0000, loss 1.151e+00, top1 71.76, top5 85.88
2021-11-11 16:45:52 train 0000, loss 1.246e+00, top1 70.59, top5 87.06
2021-11-11 16:55:59 train 1000, loss 1.154e+00, top1 72.42, top5 89.46
2021-11-11 16:55:58 train 1000, loss 1.162e+00, top1 72.38, top5 89.42
2021-11-11 16:55:59 train 1000, loss 1.155e+00, top1 72.41, top5 89.45
2021-11-11 17:05:16 train 2000, loss 1.157e+00, top1 72.39, top5 89.43
2021-11-11 17:05:16 train 2000, loss 1.156e+00, top1 72.35, top5 89.42
2021-11-11 17:05:16 train 2000, loss 1.155e+00, top1 72.38, top5 89.50
2021-11-11 17:14:32 train 3000, loss 1.155e+00, top1 72.45, top5 89.44
2021-11-11 17:14:32 train 3000, loss 1.156e+00, top1 72.40, top5 89.43
2021-11-11 17:14:32 train 3000, loss 1.158e+00, top1 72.37, top5 89.44
2021-11-11 17:23:47 train 4000, loss 1.156e+00, top1 72.42, top5 89.47
2021-11-11 17:23:47 train 4000, loss 1.160e+00, top1 72.31, top5 89.36
2021-11-11 17:23:47 train 4000, loss 1.157e+00, top1 72.36, top5 89.41
2021-11-11 17:33:08 train 5000, loss 1.158e+00, top1 72.33, top5 89.42
2021-11-11 17:33:08 train 5000, loss 1.161e+00, top1 72.24, top5 89.36
2021-11-11 17:33:08 train 5000, loss 1.156e+00, top1 72.40, top5 89.47
2021-11-11 17:33:47 valid 0000, loss 5.179e-01, top1 85.88, top5 96.47
2021-11-11 17:33:47 valid 0000, loss 5.179e-01, top1 85.88, top5 96.47
2021-11-11 17:33:47 valid 0000, loss 5.179e-01, top1 85.88, top5 96.47
2021-11-11 17:38:05 (JOBID 31737) epoch 80: train time 2864.80, inference time 281.69s, valid_top1 73.37 (best_top1 73.59), valid_top5 91.56
2021-11-11 17:38:19 (JOBID 31737) epoch 80: train time 2871.07, inference time 297.36s, valid_top1 73.37 (best_top1 73.59), valid_top5 91.56
2021-11-11 17:38:20 (JOBID 31737) epoch 80: train time 2870.36, inference time 298.20s, valid_top1 73.37 (best_top1 73.59), valid_top5 91.56
2021-11-11 17:38:36 train 0000, loss 7.968e-01, top1 77.65, top5 97.65
2021-11-11 17:38:36 train 0000, loss 1.138e+00, top1 74.12, top5 87.06
2021-11-11 17:38:36 train 0000, loss 9.077e-01, top1 78.82, top5 94.12
2021-11-11 17:48:03 train 1000, loss 1.147e+00, top1 72.49, top5 89.65
2021-11-11 17:48:03 train 1000, loss 1.153e+00, top1 72.33, top5 89.42
2021-11-11 17:48:03 train 1000, loss 1.153e+00, top1 72.48, top5 89.49
2021-11-11 17:57:25 train 2000, loss 1.144e+00, top1 72.58, top5 89.61
2021-11-11 17:57:25 train 2000, loss 1.152e+00, top1 72.46, top5 89.44
2021-11-11 17:57:25 train 2000, loss 1.154e+00, top1 72.44, top5 89.41
2021-11-11 18:06:48 train 3000, loss 1.149e+00, top1 72.47, top5 89.56
2021-11-11 18:06:48 train 3000, loss 1.152e+00, top1 72.46, top5 89.42
2021-11-11 18:06:48 train 3000, loss 1.157e+00, top1 72.39, top5 89.40
2021-11-11 18:16:13 train 4000, loss 1.154e+00, top1 72.41, top5 89.42
2021-11-11 18:16:13 train 4000, loss 1.159e+00, top1 72.36, top5 89.39
2021-11-11 18:16:13 train 4000, loss 1.151e+00, top1 72.46, top5 89.50
2021-11-11 18:26:04 train 5000, loss 1.159e+00, top1 72.33, top5 89.40
2021-11-11 18:26:04 train 5000, loss 1.157e+00, top1 72.39, top5 89.40
2021-11-11 18:26:04 train 5000, loss 1.155e+00, top1 72.35, top5 89.46
2021-11-11 18:26:44 valid 0000, loss 4.230e-01, top1 91.76, top5 96.47
2021-11-11 18:26:44 valid 0000, loss 4.230e-01, top1 91.76, top5 96.47
2021-11-11 18:26:44 valid 0000, loss 4.230e-01, top1 91.76, top5 96.47
2021-11-11 18:31:11 (JOBID 31737) epoch 81: train time 2879.96, inference time 291.37s, valid_top1 73.60 (best_top1 73.60), valid_top5 91.56
2021-11-11 18:31:11 (JOBID 31737) epoch 81: train time 2895.19, inference time 290.80s, valid_top1 73.60 (best_top1 73.60), valid_top5 91.56
2021-11-11 18:31:12 (JOBID 31737) epoch 81: train time 2880.66, inference time 292.62s, valid_top1 73.60 (best_top1 73.60), valid_top5 91.56
2021-11-11 18:31:33 train 0000, loss 1.067e+00, top1 71.76, top5 89.41
2021-11-11 18:31:33 train 0000, loss 1.114e+00, top1 75.29, top5 90.59
2021-11-11 18:31:33 train 0000, loss 1.001e+00, top1 80.00, top5 90.59
2021-11-11 18:41:03 train 1000, loss 1.136e+00, top1 72.67, top5 89.73
2021-11-11 18:41:03 train 1000, loss 1.149e+00, top1 72.70, top5 89.57
2021-11-11 18:41:03 train 1000, loss 1.144e+00, top1 72.65, top5 89.52
2021-11-11 18:50:21 train 2000, loss 1.145e+00, top1 72.64, top5 89.51
2021-11-11 18:50:21 train 2000, loss 1.144e+00, top1 72.74, top5 89.64
2021-11-11 18:50:21 train 2000, loss 1.144e+00, top1 72.49, top5 89.62
2021-11-11 18:59:37 train 3000, loss 1.148e+00, top1 72.41, top5 89.54
2021-11-11 18:59:37 train 3000, loss 1.151e+00, top1 72.63, top5 89.51
2021-11-11 18:59:37 train 3000, loss 1.146e+00, top1 72.62, top5 89.51
2021-11-11 19:08:49 train 4000, loss 1.151e+00, top1 72.56, top5 89.52
2021-11-11 19:08:49 train 4000, loss 1.152e+00, top1 72.34, top5 89.49
2021-11-11 19:08:49 train 4000, loss 1.149e+00, top1 72.54, top5 89.48
2021-11-11 19:18:03 train 5000, loss 1.153e+00, top1 72.49, top5 89.50
2021-11-11 19:18:03 train 5000, loss 1.154e+00, top1 72.35, top5 89.46
2021-11-11 19:18:03 train 5000, loss 1.154e+00, top1 72.43, top5 89.43
2021-11-11 19:18:33 valid 0000, loss 4.652e-01, top1 88.24, top5 97.65
2021-11-11 19:18:33 valid 0000, loss 4.652e-01, top1 88.24, top5 97.65
2021-11-11 19:18:33 valid 0000, loss 4.652e-01, top1 88.24, top5 97.65
2021-11-11 19:22:52 (JOBID 31737) epoch 82: train time 2823.59, inference time 275.85s, valid_top1 73.45 (best_top1 73.60), valid_top5 91.65
2021-11-11 19:23:04 (JOBID 31737) epoch 82: train time 2824.66, inference time 287.07s, valid_top1 73.45 (best_top1 73.60), valid_top5 91.65
2021-11-11 19:23:05 (JOBID 31737) epoch 82: train time 2824.77, inference time 289.33s, valid_top1 73.45 (best_top1 73.60), valid_top5 91.65
2021-11-11 19:23:18 train 0000, loss 1.173e+00, top1 69.41, top5 91.76
2021-11-11 19:23:06 train 0000, loss 1.133e+00, top1 71.76, top5 94.12
2021-11-11 19:23:19 train 0000, loss 1.058e+00, top1 78.82, top5 89.41
2021-11-11 19:32:43 train 1000, loss 1.145e+00, top1 72.51, top5 89.59
2021-11-11 19:32:43 train 1000, loss 1.144e+00, top1 72.57, top5 89.70
2021-11-11 19:32:43 train 1000, loss 1.147e+00, top1 72.64, top5 89.60
2021-11-11 19:42:07 train 2000, loss 1.146e+00, top1 72.62, top5 89.47
2021-11-11 19:42:07 train 2000, loss 1.149e+00, top1 72.44, top5 89.60
2021-11-11 19:42:07 train 2000, loss 1.149e+00, top1 72.54, top5 89.51
2021-11-11 19:51:32 train 3000, loss 1.149e+00, top1 72.50, top5 89.55
2021-11-11 19:51:32 train 3000, loss 1.149e+00, top1 72.51, top5 89.49
2021-11-11 19:51:32 train 3000, loss 1.152e+00, top1 72.43, top5 89.46
2021-11-11 20:00:54 train 4000, loss 1.150e+00, top1 72.46, top5 89.52
2021-11-11 20:00:54 train 4000, loss 1.150e+00, top1 72.51, top5 89.46
2021-11-11 20:00:54 train 4000, loss 1.153e+00, top1 72.43, top5 89.43
2021-11-11 20:10:16 train 5000, loss 1.156e+00, top1 72.36, top5 89.39
2021-11-11 20:10:16 train 5000, loss 1.152e+00, top1 72.45, top5 89.46
2021-11-11 20:10:16 train 5000, loss 1.151e+00, top1 72.44, top5 89.52
2021-11-11 20:10:42 valid 0000, loss 4.828e-01, top1 85.88, top5 97.65
2021-11-11 20:10:42 valid 0000, loss 4.828e-01, top1 85.88, top5 97.65
2021-11-11 20:10:42 valid 0000, loss 4.828e-01, top1 85.88, top5 97.65
2021-11-11 20:15:08 (JOBID 31737) epoch 83: train time 2844.11, inference time 278.60s, valid_top1 73.52 (best_top1 73.60), valid_top5 91.62
2021-11-11 20:15:08 (JOBID 31737) epoch 83: train time 2857.56, inference time 278.66s, valid_top1 73.52 (best_top1 73.60), valid_top5 91.62
2021-11-11 20:15:10 (JOBID 31737) epoch 83: train time 2845.79, inference time 279.77s, valid_top1 73.52 (best_top1 73.60), valid_top5 91.62
2021-11-11 20:15:29 train 0000, loss 9.771e-01, top1 77.65, top5 91.76
2021-11-11 20:15:29 train 0000, loss 1.281e+00, top1 72.94, top5 83.53
2021-11-11 20:15:29 train 0000, loss 9.939e-01, top1 71.76, top5 89.41
2021-11-11 20:24:26 train 1000, loss 1.133e+00, top1 72.90, top5 89.67
2021-11-11 20:24:26 train 1000, loss 1.146e+00, top1 72.60, top5 89.52
2021-11-11 20:24:26 train 1000, loss 1.154e+00, top1 72.58, top5 89.35
2021-11-11 20:33:28 train 2000, loss 1.149e+00, top1 72.59, top5 89.48
2021-11-11 20:33:27 train 2000, loss 1.146e+00, top1 72.57, top5 89.54
2021-11-11 20:33:28 train 2000, loss 1.133e+00, top1 72.89, top5 89.72
2021-11-11 20:42:23 train 3000, loss 1.149e+00, top1 72.57, top5 89.51
2021-11-11 20:42:23 train 3000, loss 1.137e+00, top1 72.79, top5 89.66
2021-11-11 20:42:23 train 3000, loss 1.149e+00, top1 72.56, top5 89.49
2021-11-11 20:51:24 train 4000, loss 1.151e+00, top1 72.52, top5 89.47
2021-11-11 20:51:24 train 4000, loss 1.140e+00, top1 72.73, top5 89.64
2021-11-11 20:51:24 train 4000, loss 1.151e+00, top1 72.45, top5 89.48
2021-11-11 21:00:23 train 5000, loss 1.143e+00, top1 72.68, top5 89.58
2021-11-11 21:00:23 train 5000, loss 1.153e+00, top1 72.42, top5 89.43
2021-11-11 21:00:23 train 5000, loss 1.151e+00, top1 72.52, top5 89.44
2021-11-11 21:00:46 valid 0000, loss 5.341e-01, top1 87.06, top5 96.47
2021-11-11 21:00:46 valid 0000, loss 5.341e-01, top1 87.06, top5 96.47
2021-11-11 21:00:46 valid 0000, loss 5.341e-01, top1 87.06, top5 96.47
2021-11-11 21:05:10 (JOBID 31737) epoch 84: train time 2728.15, inference time 273.39s, valid_top1 73.55 (best_top1 73.60), valid_top5 91.69
2021-11-11 21:05:13 (JOBID 31737) epoch 84: train time 2728.05, inference time 276.83s, valid_top1 73.55 (best_top1 73.60), valid_top5 91.69
2021-11-11 21:05:14 (JOBID 31737) epoch 84: train time 2726.65, inference time 277.04s, valid_top1 73.55 (best_top1 73.60), valid_top5 91.69
2021-11-11 21:05:30 train 0000, loss 1.201e+00, top1 67.06, top5 88.24
2021-11-11 21:05:30 train 0000, loss 9.598e-01, top1 75.29, top5 94.12
2021-11-11 21:05:30 train 0000, loss 7.699e-01, top1 83.53, top5 95.29
2021-11-11 21:14:42 train 1000, loss 1.139e+00, top1 72.75, top5 89.55
2021-11-11 21:14:42 train 1000, loss 1.150e+00, top1 72.62, top5 89.47
2021-11-11 21:14:42 train 1000, loss 1.129e+00, top1 72.93, top5 89.76
2021-11-11 21:23:52 train 2000, loss 1.149e+00, top1 72.55, top5 89.51
2021-11-11 21:23:51 train 2000, loss 1.143e+00, top1 72.62, top5 89.58
2021-11-11 21:23:52 train 2000, loss 1.137e+00, top1 72.79, top5 89.68
2021-11-11 21:32:52 train 3000, loss 1.148e+00, top1 72.51, top5 89.50
2021-11-11 21:32:52 train 3000, loss 1.150e+00, top1 72.55, top5 89.49
2021-11-11 21:32:52 train 3000, loss 1.142e+00, top1 72.63, top5 89.64
2021-11-11 21:41:56 train 4000, loss 1.149e+00, top1 72.56, top5 89.51
2021-11-11 21:41:56 train 4000, loss 1.144e+00, top1 72.62, top5 89.57
2021-11-11 21:41:56 train 4000, loss 1.148e+00, top1 72.53, top5 89.51
2021-11-11 21:51:03 train 5000, loss 1.146e+00, top1 72.62, top5 89.55
2021-11-11 21:51:03 train 5000, loss 1.150e+00, top1 72.53, top5 89.48
2021-11-11 21:51:04 train 5000, loss 1.149e+00, top1 72.49, top5 89.50
2021-11-11 21:51:27 valid 0000, loss 4.989e-01, top1 88.24, top5 96.47
2021-11-11 21:51:27 valid 0000, loss 4.989e-01, top1 88.24, top5 96.47
2021-11-11 21:51:27 valid 0000, loss 4.989e-01, top1 88.24, top5 96.47
2021-11-11 21:55:58 (JOBID 31737) epoch 85: train time 2767.27, inference time 280.71s, valid_top1 73.55 (best_top1 73.60), valid_top5 91.62
2021-11-11 21:55:58 (JOBID 31737) epoch 85: train time 2763.33, inference time 280.71s, valid_top1 73.55 (best_top1 73.60), valid_top5 91.62
2021-11-11 21:55:58 (JOBID 31737) epoch 85: train time 2764.10, inference time 281.29s, valid_top1 73.55 (best_top1 73.60), valid_top5 91.62
2021-11-11 21:56:20 train 0000, loss 9.553e-01, top1 77.65, top5 88.24
2021-11-11 21:56:20 train 0000, loss 1.073e+00, top1 72.94, top5 87.06
2021-11-11 21:56:20 train 0000, loss 1.143e+00, top1 71.76, top5 90.59
2021-11-11 22:05:29 train 1000, loss 1.138e+00, top1 72.88, top5 89.57
2021-11-11 22:05:29 train 1000, loss 1.138e+00, top1 72.79, top5 89.70
2021-11-11 22:05:29 train 1000, loss 1.139e+00, top1 72.57, top5 89.78
2021-11-11 22:14:36 train 2000, loss 1.143e+00, top1 72.63, top5 89.64
2021-11-11 22:14:36 train 2000, loss 1.145e+00, top1 72.69, top5 89.54
2021-11-11 22:14:36 train 2000, loss 1.136e+00, top1 72.70, top5 89.73
2021-11-11 22:23:40 train 3000, loss 1.145e+00, top1 72.66, top5 89.54
2021-11-11 22:23:40 train 3000, loss 1.146e+00, top1 72.60, top5 89.58
2021-11-11 22:23:40 train 3000, loss 1.141e+00, top1 72.68, top5 89.63
2021-11-11 22:32:45 train 4000, loss 1.145e+00, top1 72.67, top5 89.53
2021-11-11 22:32:45 train 4000, loss 1.148e+00, top1 72.56, top5 89.55
2021-11-11 22:32:45 train 4000, loss 1.143e+00, top1 72.64, top5 89.63
2021-11-11 22:41:50 train 5000, loss 1.146e+00, top1 72.61, top5 89.52
2021-11-11 22:41:50 train 5000, loss 1.150e+00, top1 72.53, top5 89.52
2021-11-11 22:41:50 train 5000, loss 1.143e+00, top1 72.67, top5 89.61
2021-11-11 22:42:14 valid 0000, loss 4.782e-01, top1 88.24, top5 96.47
2021-11-11 22:42:14 valid 0000, loss 4.782e-01, top1 88.24, top5 96.47
2021-11-11 22:42:14 valid 0000, loss 4.782e-01, top1 88.24, top5 96.47
2021-11-11 22:46:35 (JOBID 31737) epoch 86: train time 2765.87, inference time 270.16s, valid_top1 73.51 (best_top1 73.60), valid_top5 91.65
2021-11-11 22:46:46 (JOBID 31737) epoch 86: train time 2765.56, inference time 282.39s, valid_top1 73.51 (best_top1 73.60), valid_top5 91.65
2021-11-11 22:46:47 (JOBID 31737) epoch 86: train time 2766.16, inference time 283.33s, valid_top1 73.51 (best_top1 73.60), valid_top5 91.65
2021-11-11 22:46:50 train 0000, loss 1.041e+00, top1 72.94, top5 90.59
2021-11-11 22:47:01 train 0000, loss 9.544e-01, top1 81.18, top5 92.94
2021-11-11 22:47:01 train 0000, loss 1.221e+00, top1 74.12, top5 89.41
2021-11-11 22:56:16 train 1000, loss 1.132e+00, top1 72.91, top5 89.64
2021-11-11 22:56:16 train 1000, loss 1.133e+00, top1 72.89, top5 89.66
2021-11-11 22:56:17 train 1000, loss 1.141e+00, top1 72.80, top5 89.63
2021-11-11 23:05:39 train 2000, loss 1.136e+00, top1 72.86, top5 89.59
2021-11-11 23:05:39 train 2000, loss 1.135e+00, top1 72.79, top5 89.72
2021-11-11 23:05:39 train 2000, loss 1.142e+00, top1 72.76, top5 89.58
2021-11-11 23:15:01 train 3000, loss 1.141e+00, top1 72.74, top5 89.59
2021-11-11 23:15:01 train 3000, loss 1.140e+00, top1 72.67, top5 89.66
2021-11-11 23:15:01 train 3000, loss 1.140e+00, top1 72.83, top5 89.59
2021-11-11 23:24:21 train 4000, loss 1.140e+00, top1 72.63, top5 89.65
2021-11-11 23:24:21 train 4000, loss 1.144e+00, top1 72.68, top5 89.56
2021-11-11 23:24:21 train 4000, loss 1.141e+00, top1 72.77, top5 89.59
2021-11-11 23:33:41 train 5000, loss 1.141e+00, top1 72.61, top5 89.64
2021-11-11 23:33:41 train 5000, loss 1.144e+00, top1 72.68, top5 89.56
2021-11-11 23:33:41 train 5000, loss 1.144e+00, top1 72.69, top5 89.57
2021-11-11 23:34:05 valid 0000, loss 5.498e-01, top1 88.24, top5 95.29
2021-11-11 23:34:05 valid 0000, loss 5.498e-01, top1 88.24, top5 95.29
2021-11-11 23:34:05 valid 0000, loss 5.498e-01, top1 88.24, top5 95.29
2021-11-11 23:38:45 (JOBID 31737) epoch 87: train time 2827.42, inference time 289.79s, valid_top1 73.65 (best_top1 73.65), valid_top5 91.74
2021-11-11 23:38:45 (JOBID 31737) epoch 87: train time 2828.61, inference time 290.38s, valid_top1 73.65 (best_top1 73.65), valid_top5 91.74
2021-11-11 23:38:47 (JOBID 31737) epoch 87: train time 2839.93, inference time 291.74s, valid_top1 73.65 (best_top1 73.65), valid_top5 91.74
2021-11-11 23:38:59 train 0000, loss 1.176e+00, top1 69.41, top5 88.24
2021-11-11 23:38:59 train 0000, loss 1.189e+00, top1 78.82, top5 88.24
2021-11-11 23:39:02 train 0000, loss 1.188e+00, top1 72.94, top5 90.59
2021-11-11 23:48:32 train 1000, loss 1.132e+00, top1 72.98, top5 89.68
2021-11-11 23:48:32 train 1000, loss 1.142e+00, top1 72.59, top5 89.68
2021-11-11 23:48:32 train 1000, loss 1.156e+00, top1 72.40, top5 89.46
2021-11-11 23:58:07 train 2000, loss 1.134e+00, top1 72.95, top5 89.68
2021-11-11 23:58:07 train 2000, loss 1.151e+00, top1 72.51, top5 89.51
2021-11-11 23:58:08 train 2000, loss 1.147e+00, top1 72.48, top5 89.52
2021-11-12 00:07:48 train 3000, loss 1.151e+00, top1 72.50, top5 89.51
2021-11-12 00:07:48 train 3000, loss 1.139e+00, top1 72.85, top5 89.61
2021-11-12 00:07:48 train 3000, loss 1.145e+00, top1 72.55, top5 89.57
2021-11-12 00:17:06 train 4000, loss 1.139e+00, top1 72.82, top5 89.61
2021-11-12 00:17:06 train 4000, loss 1.149e+00, top1 72.59, top5 89.54
2021-11-12 00:17:06 train 4000, loss 1.143e+00, top1 72.58, top5 89.57
2021-11-12 00:26:26 train 5000, loss 1.142e+00, top1 72.72, top5 89.55
2021-11-12 00:26:26 train 5000, loss 1.148e+00, top1 72.60, top5 89.54
2021-11-12 00:26:26 train 5000, loss 1.144e+00, top1 72.58, top5 89.54
2021-11-12 00:26:49 valid 0000, loss 4.369e-01, top1 94.12, top5 98.82
2021-11-12 00:26:49 valid 0000, loss 4.369e-01, top1 94.12, top5 98.82
2021-11-12 00:26:49 valid 0000, loss 4.369e-01, top1 94.12, top5 98.82
2021-11-12 00:31:13 (JOBID 31737) epoch 88: train time 2874.84, inference time 273.92s, valid_top1 73.67 (best_top1 73.67), valid_top5 91.71
2021-11-12 00:31:15 (JOBID 31737) epoch 88: train time 2872.06, inference time 274.81s, valid_top1 73.67 (best_top1 73.67), valid_top5 91.71
2021-11-12 00:31:15 (JOBID 31737) epoch 88: train time 2874.02, inference time 275.92s, valid_top1 73.67 (best_top1 73.67), valid_top5 91.71
2021-11-12 00:31:29 train 0000, loss 1.126e+00, top1 68.24, top5 91.76
2021-11-12 00:31:28 train 0000, loss 9.908e-01, top1 77.65, top5 94.12
2021-11-12 00:31:30 train 0000, loss 1.305e+00, top1 69.41, top5 87.06
2021-11-12 00:40:48 train 1000, loss 1.145e+00, top1 72.70, top5 89.65
2021-11-12 00:40:48 train 1000, loss 1.137e+00, top1 72.91, top5 89.68
2021-11-12 00:40:48 train 1000, loss 1.141e+00, top1 72.73, top5 89.66
2021-11-12 00:50:10 train 2000, loss 1.142e+00, top1 72.74, top5 89.59
2021-11-12 00:50:10 train 2000, loss 1.141e+00, top1 72.86, top5 89.60
2021-11-12 00:50:10 train 2000, loss 1.138e+00, top1 72.77, top5 89.65
2021-11-12 00:59:30 train 3000, loss 1.138e+00, top1 72.74, top5 89.64
2021-11-12 00:59:30 train 3000, loss 1.138e+00, top1 72.86, top5 89.64
2021-11-12 00:59:30 train 3000, loss 1.142e+00, top1 72.71, top5 89.60
2021-11-12 01:08:53 train 4000, loss 1.139e+00, top1 72.83, top5 89.63
2021-11-12 01:08:53 train 4000, loss 1.142e+00, top1 72.73, top5 89.61
2021-11-12 01:08:54 train 4000, loss 1.140e+00, top1 72.68, top5 89.61
2021-11-12 01:18:29 train 5000, loss 1.141e+00, top1 72.76, top5 89.62
2021-11-12 01:18:29 train 5000, loss 1.144e+00, top1 72.70, top5 89.60
2021-11-12 01:18:29 train 5000, loss 1.140e+00, top1 72.69, top5 89.60
2021-11-12 01:18:54 valid 0000, loss 3.988e-01, top1 91.76, top5 97.65
2021-11-12 01:18:54 valid 0000, loss 3.988e-01, top1 91.76, top5 97.65
2021-11-12 01:18:54 valid 0000, loss 3.988e-01, top1 91.76, top5 97.65
2021-11-12 01:23:21 (JOBID 31737) epoch 89: train time 2848.03, inference time 278.02s, valid_top1 73.41 (best_top1 73.67), valid_top5 91.65
2021-11-12 01:23:21 (JOBID 31737) epoch 89: train time 2850.05, inference time 278.03s, valid_top1 73.41 (best_top1 73.67), valid_top5 91.65
2021-11-12 01:23:22 (JOBID 31737) epoch 89: train time 2848.63, inference time 278.61s, valid_top1 73.41 (best_top1 73.67), valid_top5 91.65
